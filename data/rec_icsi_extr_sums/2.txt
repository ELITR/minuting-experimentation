C:  It 's basically uh talks about uh  <inbreath> It just refers to the fact that uh  one of main things we had to do was to  decide what the intermediate sort of nodes were , 

B:  So then the features we decided  or we decided we were  talked about , 

B:  Uh the  the prosody , the discourse ,  verb choice . 
B:  You know . We had a list of things like " to go " and " to visit " and what not . 
B:  The " landmark - iness " of uh  

B:  " Nice walls " <breath> which we can look up 

B:  The context , which in this case we 've limited to  " business person " , " tourist " , or  " unknown " , 
B:  the time of day , 

D:  There 's landmark for um , touristic reasons and landmark for 

D:  navigational reasons or something . 

D:  but you can imagine maybe wanting the oth both kinds of things there for different um , goals . 

B:  OK , So our initial idea was not very satisfying ,  because  uh our initial idea was basically all the features pointing to the output node . 

B:  Reasons being , you know , it 'd be a pain to set up all the probabilities for that . 
B:  If we moved onto the next step and did learning of some sort , uh according Bhaskara we 'd be handicapped . 

C:  If you have N features , then it 's two to the N   or exponential in N . 

B:  So then our next idea was to add a middle layer , 

B:  but the middle thing , we were thinking along the lines of maybe trying to figure out , like , the concept of whether they 're a tourist  or  whether they 're running an errand or something like that 

B:  Yes , we could things we couldn't extract the  from the data , the hidden variables . 

B:  So then the hidden variables  hair variables we came up with were whether someone was on a tour , running an errand , or whether they were in a hurry , 

B:  Um right now it 's still kind of  in a toy  version of it , 
B:  because we didn't know the probabilities of   or  

B:  So . The mode  basically has three different  outputs . 
B:  The probability  whether the probability of a Vista , Tango , or Enter . 
B:  Um  The " context " , we simplified . 
B:  Basically it 's just the businessman , the tourist , unknown . 

B:  mainly because it 's  it 's just whether the verb is a Tango verb , an Enter verb , or a  Vista verb . 

C:  That 's  that  that needs a lot of work . 

C:  but the other ones , the final destination , the whether they 're doing business , whether they 're in a hurry , and whether they 're tourists , 
C:  that kind of thing is all uh <mouth> sort of  you know probabilistically depends on the other things . 

C:  Like we don't have nodes for " discourse " and " parse " , 
C:  although like in some sense they are parts of this belief - net . 
C:  But uh  <breath> The idea is that we just extract those features from them , so we don't actually have a node for the entire parse , 

C:  So we looked at the data 
C:  and in a lot of data people were saying things like <breath> " Can I get to this place ? " 
C:  " What is the admission fee ? " . 
C:  So that 's like a huge uh clue that they 're trying to Enter the place rather than uh to Tango or Vista , 

D:  So there are certain cues that are very strong  either lexical or topic - based um , concept cues 

D:  And then in that second row  or whatever that row of Time of Day through that  So all of those  Some of them come from the utterance 
D:  and some of them are sort of <breath> either world knowledge or situational  things . 

B:  but you could see perhaps discus the " admission fee " going directly to the mode pointing at " Enter " , 

B:  Uh  we kept um  things from directly affecting the mode  beyond the concept , 

B:  But we just decided to keep all the things we extracted  to point at the middle and then  down . 

C:  Normally context will include a huge amount of information , 
C:  but um , we are just using the particular <cough> part of the context which consists of the switch that they flick to indicate whether they 're a tourist or not , I guess . 

C:  Similarly prosody is not all of prosody 
C:  but simply <breath> for our purposes whether or not they appear tense or relaxed . 

A:  So , the  the middle layer is also binary ? 

C:  Yeah , 

D:  So um , of course this will happen when we think more about the kinds of verbs that are used in each cases 
D:  but you can imagine that it 's verb plus various other things that are also not in the bottom layer that would  that would help you  

A:  and um  Uh maybe at this stage we will  we do want to  uh sort of get  uh modifiers in there 
A:  because they may also tell us whether the person is in a hurry or not 

C:  I mean  We can do a demo in the sense that we can um , <breath> just ob observe the fact that this will , in fact do inference . 
C:  So we can , you know , set some of the uh nodes 
C:  and then try to find the probability of other nodes . 

B:  The reason I say the  demo doesn't work very well is yesterday we uh   observed everything in favor of  taking a tour , 
B:  and it came up as " Tango " , 

C:  Well , that 's obviously just to do with our probabilities . 
C:  Like ,  we totally hand - tuned the probabilities , 

A:  However you know , it  The purpose was not really , at this stage , to come up with meaningful probabilities 
A:  but to get thinking about that hidden middle layer . 

B:  I guess once we look at the data more we 'll get more hidden  nodes , 

D:  So . Are " doing business " versus " tourist "  
D:  They refer to your current task . 

C:  I think it 's more like " Are you are tourist ? 

D:  so , I thought that was directly given by the context  switch . 

C:  That 's a different thing . 

D:  So the " tourists " node  should be  um , very consistent with the context node . 

C:  If the context were to set one way or another , that like strongly uh um , says something about whether  whether or not they 're tourists . 

C:  So the issue is that um in belief - nets , it 's not common to do what we did of like having , you know , a d bunch of values and then " unknown " as an actual value . 
C:  What 's common is you just like don't observe the variable , 

C:  and then just marginalizes  
C:  But uh  <breath> We didn't do this because we felt that there 'd  
C:  I guess we were thinking in terms of a switch that actually  

A:  um  How long would it take to  to add another  node on the observatory and , um , play around with it ? 

C:  So you want to have a  a node for like whether or not it can be entered ? 

A:  And then um , there 's also the question whether it may be entered . 

B:  Whether it 's a  Whether it 's a public building , and whether it 's  actually has a door . 

B:  explain to me why it 's necessary  to distinguish between whether something has a door and is  not public . 

A:  So I guess your question is  so far I have no really arg no real argument why to differentiate between statues as  statues and houses of celebrities , 
A:  from that point of view . 

A:  Can we add , just so I can see how it 's done , uh , a " has door "  property 

B:  You could affect   Theoretically you could affect " doing business " with " has door " . 

C:  I don't know if JavaBayes is nice about that . 
C:  It might be that if you add a new thing pointing to a variable , you just like  it just overwrites everything . 

C:  What would be nice if it  is if it just like kept the old function for either value 

C:  I mean in a way this is a lot of good features in Java 
C:  it 's cra has a GUI and it 's uh  

B:  I didn't think it did learning . 
B:  Maybe it did a little bit of learning , 

C:  But uh  it 's free . 

C:  But I mean its interface is not the greatest . 

B:  But actually it had an interface . 
B:  A lot of them were like , you know . 

A:  Command line . 

C:  There is actually a text file that you can edit . 

C:  So theoretically you could edit that . 
C:  But  they 're not very friendly . 

B:  Yeah the ordering isn't very clear on  

C:  we can maybe write an interface th for uh entering probability distributions easily , 
C:  something like  like a little script . 

C:  I don't know if it actually manipulate the source , though . 
C:  That might be a bit complicated . 
C:  I think it might  it might be simpler to just  have a script that , you know  

A:  But if th if there is an XML  file that  or format that it can also read  

B:  Yeah I know there is an  I was looking on the we web page 
B:  and he 's updated it for an XML version of I guess Bayes - nets . 

B:  Well th you can either  you ca or you can read both . 

A:  is that maybe we ob we could observe a couple of um discourse phenomena such as the admission fee , 
A:  and something else and something else , that happened in the discourse before . 

A:  So maybe this could be sort of a separate region of the net ,  which has two   has it 's own middle layer . 

A:  which is maybe something that is uh , a more general version of the actual  phenomenon that you can observe . 

B:  That would all f funnel into one node that would  constitute entrance requirements or something like that . 

D:  I mean it sort of get into plan recognition kinds of things in the discourse . 

D:  That 's a whole set of discourse related cues to your middle layer . 

A:  They ra may have there own hidden layer  that points to some of  the  the real hidden layer , um or the general hidden layer . 
A:  And the same we will be able to do for syntactic information , 

C:  So essentially a lot of those nodes can be expanded into little Bayes - nets of their own . 

B:  I guess , the fact that the  there 's a complete separation between the  observed features and in the output . 

B:  well for instance , the " discourse admission fee "  node seems like it should point directly to the  
B:  or increase the probability of " enter  directly " versus " going there via tourist " . 

A:  Something  Somebody can have discussed the admission fee and u the answer  is s if we  
A:  um , you know , um  still , based on that result is never going to enter that building . 

B:  So the discourse refers to " admission fee " but it just turns out that they change their mind in the middle of the discourse . 

B:  What sort of discourse  processing is uh  are the  
B:  How much is built into SmartKom and  

A:  And this um  m won't differentiate between all modes , 

A:  but at least it 'll tell us " OK here we have something that  
A:  somebody that wants to go someplace , 

A:  what happens is you know the parser parses it 
A:  and then it 's handed on to the discourse history which is , um o one of the most elaborate  elaborate modules . 

A:  It helps an an anaphora resolution and it  and it fills in all the structures that are omitted , 

A:  the discourse model actually stores what was presented at what location on the s on the screen 

A:  We can query it whether admission fees were discussed in the last turn 

D:  So one thing that might be helpful which is implicit in the  use of " admission fee discussion " as a cue for entry , <breath>  is thinking about the plans that various people might have . 

D:  They 're  in  in non in sort of more traditional AI kinds of plan recognition things you sort of have <breath>  you know , some idea at each turn of agent doing something , 

A:  I mean there are some  some of them are extremely elaborate , 

D:  So by the way tha that structure  that Robert drew on the board was like more um , <mouth>  cue - type - based , 

D:  and then  some of the things we 're talking about here are more  

D:  entering or som you know like they might be more task - based . 

A:  so <breath> maybe what  what  what happened  what might happen is that we do get this sort of task - based middle layer , 

A:  So , um I suggest w to  for  to proceed with this in  in the sense that  maybe throughout this week the three of us will  will talk some more about maybe segmenting off different regions , 

A:  Identify  four regions , 
A:  maybe make up some features for each region 

A:  middle layer for those . 
A:  And then these should then connect somehow to the more plan - based deep space 

C:  The probabilities and all are completely ad - hoc . 

C:  Yeah , another thing to do , um , is also to , um  I guess to ask around people about other Bayes - net packages . 

A:  also we can uh , start looking at the SmartKom tables 

A:  OK , I have to report <breath> um , data collection . 
A:  We interviewed Fey , 
A:  She 's willing to do it , 
A:  meaning be the wizard for the data collection , 
A:  also <breath> maybe transcribe a little bit , if she has to , 
A:  but also recruiting subjects , organizing them , and so forth . 

A:  Jerry however suggested that we should uh have a trial run with her , 

A:  and it looks as if Friday afternoon will be the time when we have a first trial run for the data . 

C:  Well I just figured it has to be someone who 's , um , familiar enough with the data to cause problems for the wizard , so we can , uh , see if they 're you know good . 

A:  but <breath> you know , if we take a subject that is completely unfamiliar with the task , or any of the set up , we get a more realistic 

A:  yes w we  we would like to test the wizard , 

D:  So , is it a experimental setup for the um , data collection  totally  ready  determined ? 

A:  But um  in terms of specifying the scenario , <breath> um  uh  uh  we 've gotten a little further 
A:  but um  we wanted to wait until we know who is the wizard , 
A:  and have the wizard partake in the  ultimate  sort of definition probe . 
A:  So  so if  if on Friday it turns out that she really likes it and  and we really like her , then nothing should stop us from sitting down next week and <lateral tongue click>  getting all the details completely figured out . 

D:  Like we wanna  we wanna be able to collect <breath> as much of the variables that are needed for that , 

A:  Bu - e e e I 'm even  This  this Tango , Enter , Vista is sort of , itself , an ad - hoc scenario . 
A:  The  the basic u um idea behind the uh  data collection was the following . 
A:  The data we get from Munich is  very command line , 

A:  Not a rich language . 
A:  So we wanted just to collect data , to get  that  that  that  elicits more , uh , that elicits richer language . 
A:  And we actually did not want to constrain it too much , 

A:  Um . So this  this  this is a parallel track , 

A:  So it may get us some more information on the human - machine pragmatics , um , that no one knows anything about , as of yesterday . 

A:  So now I think we should maybe have at least one navigational task with  with sort of explicit  uh 
A:  not ex it 's implicit that the person wants to enter , 
A:  and maybe some task where it 's more or less explicit 

A:  So that we can label it . 

