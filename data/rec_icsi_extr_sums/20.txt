C:  but um uh Jose and I were just talking about <inbreath> the uh <page turn> uh , speech e energy thing , 

C:  Right now , that he 's not really showing any kind of uh distinction , but uh  

C:  Um . And uh one is that uh this is all in log energy 
C:  and log energy is basically compressing the distances <inbreath> uh  between things . 
C:  Um  Another is that he needs to play with the  the different uh  uh temporal sizes . 
C:  He was  he  he was taking everything over two hundred milliseconds 

C:  Um And uh  and the other thing is that the  yeah doing the  <inbreath> subtracting off the mean and the variance in the   uh and dividing it by the  standard deviation in the log domain , <inbreath> may not be  the right thing to do . 

C:  uh , and uh he 's going to vary that number and also look at moving windows , as we discussed before . 

C:  It 's uh between the pauses  uh for some segment . 

D:  Are these the long term means ? 

C:  And so i i his  his  He 's making the constraint it has to be at least two hundred milliseconds . 

C:  And then he 's  he 's uh measuring at the frame level  

C:  and then  and then just uh normalizing with that larger amount . 
C:  um and  But one thing he was pointing out is when he  he looked at a bunch of examples in log domain , it is actually pretty hard to see <inbreath> the change . 

C:  So  So what I was suggesting to him is that  
C:  Actually , a PDF . 

C:  And when he 's looking in the log domain he 's not really seeing it . 

C:  And when he 's looking in straight energy he is , 

C:  Yeah , but I think  also u I think a good first indicator is when the  the  the researcher looks at <inbreath> examples of the data and can not see a change  in how big the  the signal is , <inbreath> when the two speaker  

C:  So yeah there  there  there  There 's a good chance then given that different people do talk different amounts  that there is  there  there is still a lot more to be gained from gain norm normalization with some sort 

C:  Uh . But we were agreed that in addition to that  uh there should be  s stuff related to pitch and harmonics and so forth . 

C:  so that 's a good place to start . 

C:  Well , actually , you do have some distributions here , uh for these cases . 

C:  um  and  uh , they don't look very separate . 
C:  uh <laugh>  separated . 

C:  Before we get complicated , let 's start with the most basic wh thing , which is  we 're arguing that if you take energy  uh if you look at the energy , that , when two people are speaking at the same time , usually <inbreath>  there 'll be more energy than when one is 

C:  That 's  that sort of hypothesis . 

C:  is that you would just take a look at the distribution of those two things , 

C:  But I had maybe made it too complicated by suggesting early on , that you look at scatter plots 

C:  Let 's start off just in one , uh , with this feature . 

C:  Um And then we w I think we 're agreed that pitch - related things are  are  are going to be a  a really likely candidate to help . 
C:  Um  But  since  <inbreath> uh your intuition from looking at some of the data , is that when you looked at the regular energy , that it did in fact usually go up , <laugh> when two people were talking , <inbreath> that 's  eh you know , you should be able to come up with a measure which will  match your intuition . 

A:  What you would imagine eventually , is that you 'll feed all of these features into some  discriminative system . 

A:  And  I was just going to say that  that  right now we 're just exploring . 

A:  And so even if  if one of the features does a good job at one type of overlap , another feature might do a good job at another type of overlap . 

E:  This is the thing I  I comment with you before , that uh we have a great variation of th situation of overlapping . 

C:  So uh , if you generated something like that just for the energy and see , and then , a a a as  as Liz says , when they g have uh uh smaller um , more coherent groups to look at , that would be another interesting thing later . 
C:  And then that should give us some indication  between those , should give us some indication of whether there 's anything to be achieved f from energy at all . 
C:  And then you can move on to the uh  uh more <mike loud pop> pitch related stuff . 

E:  I  I  I think this is a good idea . 
E:  Not consider the log energy . 

C:  I think I would just sort of look at the energy  and then get into the harmonicity as  as a suggestion . 

B:  so I was planning to do a taxonomy of types overlaps with reference to that . 

B:  So , when I presented my results about the uh distribution of overlaps and the speakers and the profiles of the speakers , at the bottom of that I did have a proposal , 
B:  and I had plan to go through with it , of  of co coding the types of overlaps that people were involved in s just with reference to speaker style so , you know , with reference  

B:  that  you know so it 's like people may have different amounts of being overlapped with or overlapping 
B:  but that in itself is not informative without knowing what types of overlaps they 're involved in 

E:  I  I think a a another parameter we c we  we can consider is eh the  duration . 

E:  Because is possible <inbreath> eh some s s um eh some classes eh has eh  a type of a duration , 

D:  Well , we  we wouldn't be able to do any work without a forced alignment anyway , 
D:  so somehow if  once he gets going we 're gonna hafta come up with one 

D:  But it is definitely true that we need to have the time marks , 
D:  and I was assuming that will be inherited because , if you have the words and they 're roughly aligned in time via forced alignment or whatever we end up using , then you know , this  student and I would be looking at the time marks 

E:  I mean that you have eh you have a backchannel , eh , eh  you have a overlapping zone very short 

E:  eh  that I  I mean the  the e effect of the normalization eh with the mean and the  and the variance eh is different that if you consider  only a  window compared eh with the n the duration of overlapping . 

A:  Yeah this was the problem with these categories , 
A:  I  I picked those categories from TIMIT . 

A:  But I don't know how to  I don't know how to  I don't know how to categorize them . 

A:  So I 'm not sure what to do about the Region field for English variety . 

A:  Um , did you guys get my email on the multitrans ? 

A:  Yeah . So . So . I  I have a version also which actually displays all the channels . 

A:  The  what  the ones I applied , that you can actually do are Dan 's , because it doesn't slow it down . 

A:  No , the  the one that 's installed is fine . 
A:  It 's not slow at all . 
A:  I wrote another version . Which , instead of having the one pane with the one view , It has multiple panes  with the views . 
A:  But the problem with it is the drawing of those waveforms is so slow that every time you do anything it just crawls . 

A:  Just about anything , and it  it was so slow it was not usable . 

B:  And this 'll be a  hav having the multiwave will be a big help 

A:  So . I think that the one Dan has is usable enough . 
A:  It doesn't display the others . 
A:  It displays just the mixed signal . 
A:  But you can listen to any of them . 

D:  So is there any hope for actually displaying the wave form ? 

A:  Um , not if we 're going to use Tcl - TK At least not if we 're going to use Snack . 

A:  And so it 's really  It 's not too bad to find places in the  in the stream where things are happening . 

A:  I think if  if  if one of us sat down and coded it , so that it could be displayed fast enough I 'm sure they would be quite willing to incorporate it . 
A:  But it 's not a trivial task . 

C:  but we discussed a couple of the possible things that uh he can look at . 

