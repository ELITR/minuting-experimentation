A:  So y you guys had a  a meeting with uh  with Hynek which I unfortunately had to miss . 

A:  So everybody knows what happened except me . 

C:  Well . Uh first we discussed about some of the points that I was addressing in the mail I sent last week . 

C:  About the um , well  the downsampling problem . 
C:  Uh and about the f the length of the filters 

A:  Was there any conclusion about that ? 

C:  Uh " try it " . 

C:  We should have a look first at , perhaps , <inbreath> the modulation spectrum . 

C:  Um . <mouth> <inbreath> So the i this idea of trying to find filters with shorter delays . 
C:  Um . We started to work with this . 

C:  And the third point um <mouth> <inbreath> was the um , 
C:  yeah , <inbreath> the on - line normalization where , 
C:  well , the recursion f recursion for the mean estimation <inbreath> is a filter with some kind of delay 

C:  For this , the conclusion of Hynek was , well , " we can try it but  " 

C:  So basically that was  that 's <inbreath> all we discussed about . 

A:  I mean I g I guess the key thing for me is  is figuring out how to better coordinate between the two sides 

A:  uh I was talking with Hynek about it later 
A:  and the  the  sort of had the sense sort of that  that neither group of people wanted to  to bother the other group too much . 

C:  But there was also problem  perhaps a problem of communication . 

C:  Now we will try to  

A:  Just talk more . 

A:  but I think that <inbreath> you were sort of waiting for them to <inbreath> tell you that they had something for you 

A:  and <inbreath> they were sort of waiting for you 
A:  and  and  and uh we ended up with this thing where they  they were filling up all of the possible latency themselves , 

A:  Let 's  let 's , I mean , I think that as  as we said before that one of the things that we 're imagining is that uh there  there will be <inbreath> uh in the system we end up with there 'll be something to explicitly uh uh do something about noise 

A:  in terms of uh I think they were using Ericsson 's <inbreath> approach or something 

C:  Uh so Carmen is just looking at the Ericsson  Ericsson code . 

D:  Yeah , I modified it  

D:  to take @ @ the first step the spectral subtraction . 

D:  But we haven't result until this moment . 
D:  But well , we are working in this also 

A:  So um I suggest actually now we  we  we sorta move on and  and hear what 's  what 's  what 's happening in  in other areas 
A:  like <inbreath> what 's  what 's happening with your <inbreath> investigations <inbreath> about echos and so on . 

F:  Well um I haven't started writing the test yet , I 'm meeting with Adam today 
F:  um and he 's going t show me the scripts he has for um <mouth> <inbreath> running recognition on mee Meeting Recorder digits . 

F:  I haven't asked Hynek for  for the  for his code yet . 
F:  Cuz I looked at uh Avendano 's thesis and <mouth> I don't really understand what he 's doing yet 
F:  but it  <inbreath> it  it sounded like um <inbreath> the channel normalization part <inbreath> um of his thesis um <inbreath> was done in a  a bit of I don't know what the word is , a  a bit of a rough way 

F:  he  he  it  it wasn't really fleshed out 

F:  but I  I 'm not sure if it 's <inbreath> what I 'd wanna use 

F:  and maybe he did something that was <inbreath> interesting for the test situation 

F:  I don't really understand what he 's doing yet . 

E:  Um .  So continuing to um extend 

A:  Um . <inbreath> And uh I don't know if we 've talked lately about the  the plans you 're developing that we talked about this morning 

B:  So they 're training up nets to try to recognize these acoustic features ? 

A:  But that 's uh uh all  that 's  is a  a certainly relevant  <inbreath> uh study 

A:  So I mean , there 's these issues of what are the  what are the variables that you use 
A:  and do you combine them using the soft " AND - OR " or you do something , you know , more complicated 

A:  and eh w why don't you tell us again about this  this database ? 

B:  that  people have done studies like that w way way back 

B:  I mean <inbreath> I can't remember where  uh Wisconsin or someplace that used to have a big database of  

B:  Um , <mouth> <inbreath> researcher at A T - andT a while back that was studying , trying to do speech recognition from these kinds of features . 

A:  you mean when was  was Mark Randolph there , or  ? 
A:  Yeah he 's  he 's  he 's at Motorola now . 

C:  Is it the guy that was using the pattern of pressure on the tongue 

B:  But I know  I just remember it had to do with you know <inbreath> uh positional parameters 
B:  and trying to m you know do speech recognition based on them . 

A:  So the only  the only uh hesitation I had about it since , I mean I haven't see the data is it sounds like it 's  it 's <inbreath> continuous variables and a bunch of them . 

A:  I don't know how complicated it is to go from there  
A:  What you really want are these binary  labels , and just a few of them . 
A:  And maybe there 's a trivial mapping if you wanna do it 
A:  and it 's e but it  
A:  I  I  I worry a little bit that this is a research project in itself , 
A:  whereas um <inbreath> if you did something instead that  like um having some manual annotation by <inbreath> uh you know , linguistics students , 
A:  this would  there 'd be a limited s set of things that you could do a as per our discussions with  with John before 

A:  Course then , that 's the other question is do you want binary variables . 

A:  Uh what 's next ? 

B:  I could say a little bit about w stuff I 've been playing with . 

B:  Um <inbreath> so I wanted to do this experiment to see um <mouth> uh what happens if we try to uh improve the performance of the back - end recognizer for the Aurora task 
B:  and see how that affects things . 

B:  and then com and then uh optimize the b HTK system and run that again . 
B:  So look at the difference there 
B:  and then uh do the same thing for <inbreath> the ICSI - OGI front - end . 

B:  Uh I 'm looking at the Italian right now . 

B:  One of the first things I thought of was the fact that they use <inbreath> the same number of states for all of the models 

B:  and just looked at , you know , the number of phones in each one of the digits . 

B:  And so when I did that for the Italian digits , I got a number of states , ranging on the low end from nine to the high end , eighteen . 

B:  And so um <mouth> <inbreath> their guess of eighteen states seems to be pretty well matched to the two longest words of the Italian digits , 

B:  Um <mouth> <inbreath> but for the  most of the words are sh much shorter . 
B:  So the majority of them wanna have nine states . 
B:  And so theirs are s sort of twice as long . 

B:  and it turns out that the longest words are actually the ones that do the best . 

B:  So um I 'm going to try to um create more word - specific <inbreath> um uh prototype H M Ms to start training from . 

B:  Yeah so I 'll  I 'll , the next experiment I 'm gonna try is to just um you know create <inbreath> uh models that seem to be more w matched to my guess about how long they should be . 

A:  I guess your plan for  You  you  you guys ' plan for the next  next week is <inbreath> just continue on these  these same things we 've been talking about for Aurora and 

C:  I guess we can try to <inbreath> have some kind of new baseline for next week perhaps . 
C:  with all these minor things <inbreath> <mouth> modified . 

A:  You have a big list of  <laugh> of things to do . 

A:  Well that 's good . 

