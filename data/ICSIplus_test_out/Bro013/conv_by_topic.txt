D:  <noise> 
A:  We 're going ? OK . <breath> 
B:  OK . 
A:  Sh - Close your door on  door on the way out ? Thanks . 
B:  Thanks . 
B:  <breath> 
B:  Oh . 
B:  <laugh> 
A:  Yeah . Probably wanna get this other door , too . <breath> 




A:  OK . So . <breath> 
A:  Um . <mouth> <breath> 
A:  What are we talking about today ? <laugh> 
E:  <breath> 
E:  Uh , well , first there are perhaps these uh Meeting Recorder 
E:  digits 
A:  <breath> 
A:  Oh , yeah . That was kind of uh interesting . The  both the uh  <breath> 
E:  that we tested . So . 
E:  Um . 
A:  the SRI System and the oth And 
A:  for one thing that  that sure shows the <breath> 
B:  <breath> <breath> 
A:  difference between having a lot of uh 
E:  Of data ?  
A:  training data <laugh> 
E:  <laugh> Yeah . 
A:  or not , uh , the uh  <breath> 
A:  The best kind of number we have on the English uh  
A:  on 
A:  near microphone only is  is uh three or four percent . <breath> 
E:  Mm - hmm . 
A:  And uh it 's significantly better than that , using 
A:  fairly simple front - ends <breath> on  <laugh> on the uh  <breath> 
E:  Mm - hmm . 
A:  uh , with the SRI system . So I th I think that the <breath> uh  
A:  But that 's  that 's using uh a  a pretty huge amount of data , 
B:  <breath> 
A:  mostly not digits , of course , but  but then again  
A:  <breath> Well , yeah . In fact , mostly not digits for the actual training the H M Ms whereas uh in this case we 're just using digits for training the H M Ms . <breath> 
B:  <noise> 
D:  <breath> 
D:  <breath> 
E:  Yeah . Right . 
A:  Did anybody mention about whether the  the SRI system is a  <breath> 
A:  is  is doing the digits um 
A:  the wor as a word model or as 
E:  <inbreath> 
A:  uh a sub s sub - phone states ? 
E:  I guess it 's  it 's uh allophone models , so , well  
A:  Yeah . Probably . Huh ?  
E:  Yeah . I think so , because it 's their very d huge , their huge system . <breath> 
A:  Yeah . 
E:  And . <breath> 
E:  But . So . There is one difference  Well , the SRI system  the result for the SRI system that are represented here are with adaptation . So there is  
E:  It 's their complete system and  including on - line 
D:  <breath> 
E:  uh unsupervised adaptation . <breath> 
A:  That 's true . 
E:  And if you don't use adaptation , the error rate is 
E:  around 
E:  fifty percent worse , I think , if I remember . Yeah . 
A:  OK . 
A:  It 's tha it 's that much , huh ? 
E:  Nnn . 
E:  It 's  Yeah . It 's quite significant . Yeah . 
A:  Oh . OK . 
A:  Still . <laugh> <breath> 
D:  <breath> 
E:  Mm - hmm . 
A:  But  but uh what  what I think I 'd be interested to do given that , is that we  we should uh <breath> 
A:  take  I guess that somebody 's gonna do this , right ?  is to take some of these tandem things and feed it into the SRI system , right ? 
E:  Yeah . 
A:  Yeah . 
E:  We can do something like that . Yeah . 
A:  Yeah . Because  
E:  But  
E:  But I guess the main point is the data because uh <breath> 
E:  I am not sure . Our back - end is  is fairly simple but until now , well , the attempts 
D:  <breath> 
E:  to improve it or  have fail Ah , well , I mean 
E:  uh what Chuck 
E:  tried 
E:  to  to  to do 
A:  Yeah , but he 's doing it with the same data , right ? I mean so to  
E:  Yeah . So it 's  Yeah . 
A:  <breath> 
A:  So there 's  there 's  there 's two things being affected . I mean . One is that  that , you know , there 's something simple that 's wrong with the back - end . We 've been playing a number of states <breath> uh I  I don't know if he got to the point of playing with the uh number of Gaussians yet but  but uh , <breath> 
E:  Mm - hmm . 
E:  Mm - hmm . 
E:  <inbreath> 
A:  uh , you know . But , yeah , so far he hadn't gotten any big improvement , but that 's all with the same amount of data which is pretty small . <breath> 
E:  <clears throat> 
D:  <breath> 
E:  Mm - hmm . 
D:  <breath> 
E:  Yeah . 
E:  Mmm . 
A:  And um . 
E:  So , yeah , we could retrain 
E:  some of these tandem 
A:  <breath> Well , you could do that , but I 'm saying even with it not  with that part not retrained , 
E:  on  on huge  
E:  Ah , yeah . Just  
A:  just  just using  having the H M Ms  
E:  f for the HMM models . Yeah . Mm - hmm . 
A:  much better H M Ms . Yeah . 
E:  Mm - hmm . 
A:  Um . <breath> 
A:  But just train those H M Ms using different features , the features coming from our Aurora stuff . So . 
E:  Yeah . 
E:  Yeah . 
D:  <breath> 
E:  But <breath> what would be interesting to see also is what  what  
E:  perhaps it 's not related , the amount of data but the um 
E:  recording conditions . I don't know . Because <breath> 
E:  it 's probably not a problem of noise , because 
D:  <breath> 
E:  our features are supposed to be robust to noise . 
E:  It 's not a problem of channel , because there is 
A:  Well , yeah . 
E:  um 
E:  <mouth> <breath> 
E:  normalization with respect to the channel . So  
A:  <breath> 
A:  I  I  I 'm sorry . What  what is the problem that you 're trying to explain ? 
E:  <uncodeable> 
E:  <mouth-click> 
E:  The  the fact that  the result with the tandem and Aurora system are <breath> 
A:  That the  Oh . 
A:  So much worse ? 
E:  uh so much worse . Yeah . 
A:  <breath> 
A:  Oh . I uh but I 'm  I 'm almost certain that it  it  <breath> 
E:  It  
A:  I mean , that it has to do with the um amount of training data . It  it 's  it 's orders of magnitude off . 
E:  <inbreath> 
E:  Yeah but  Yeah . 
E:  Yeah but we train only on digits and it 's  it 's a digit task , so . Well . 
A:  But  but 
A:  having a huge  If  <breath> 
E:  It  
A:  if you look at what commercial places do , they use a huge amount of data . This is a modest amount of data . 
E:  Mm - hmm . 
E:  Alright . 
E:  Yeah . Mm - hmm . 
A:  So . <breath> 
A:  I mean , ordinarily you would say " well , given that you have enough occurrences of the digits , you can just train with digits rather than with , you know "  <breath> 
E:  Mm - hmm . 
A:  But the thing is , if you have a huge  in other words , do word models  But if you have a huge amount of data 
E:  Right . 
E:  Mmm . 
A:  then you 're going to have many occurrences of similar uh allophones . 
E:  Yeah . 
A:  And that 's just a huge amount of training for it . So it 's <breath> um  <breath> 
E:  Mm - hmm . 
A:  I  I think it has to be that , because , as you say , this is , you know , this is near - microphone , it 's really pretty clean data . 
D:  <breath> 
E:  Mm - hmm . 
A:  Um . <breath> 
A:  Now , some of it could be the fact that uh  let 's see , in the  in these multi - train things did we include noisy data in the 
E:  Yeah . 
A:  training ? I mean , that could be hurting us actually , for the clean case . 
D:  <breath> 
E:  Yeah . Well , actually we see that the clean train for the Aurora proposals are  
A:  It is if  
E:  are better than the multi - train , yeah . 
D:  <breath> 
A:  Yeah . Yeah . Cuz this is clean data , and so that 's not too surprising . <breath> 
D:  <breath> 
E:  Mm - hmm . 
A:  But um . 
A:  Uh . 
A:  So . 
E:  Well , o I guess what I meant is that <breath> 
E:  well , let 's say if we  if we add enough data to train on the um 
A:  Uh - huh . 
E:  on the Meeting Recorder digits , 
D:  <breath> 
A:  Mm - hmm . 
E:  I guess we could have better results than this . 
E:  And . 
E:  What I meant is that perhaps we can learn something 
E:  uh from this , 
E:  what 's  what 's wrong 
E:  uh 
E:  what  what is different between TI - digits and these digits and  
A:  <breath> 
A:  What kind of numbers are we getting on TI - digits ? 
D:  <breath> 
E:  It 's point eight percent , so . 
A:  Oh . I see . 
E:  Four - Fourier . 
A:  <breath> 
E:  @ @ 
A:  So in the actual TI - digits database we 're getting point eight percent , <breath> 
E:  Yeah . Yeah . 
A:  and here we 're getting three or four  three , let 's see , three for this ? <breath> 
E:  Mm - hmm . 
A:  Yeah . 
A:  Sure , but I mean , 
D:  <breath> 
A:  um point eight percent is something like double uh or triple what people have gotten who 've worked very hard at doing that . And  and also , as you point out , there 's adaptation in these numbers also . <breath> 
E:  Mm - hmm . 
E:  <clears throat> 
E:  Mmm . 
A:  So if you , you know , put the ad adap take the adaptation off , then it  for the English - Near you get something like two percent . <breath> 
A:  And here you had , you know , something like three point four . <breath> 
E:  Mm - hmm . 
A:  And I could easily see that difference coming from this huge amount of data that it was trained on . So it 's  <breath> 
D:  <breath> 
E:  Mm - hmm . 
A:  You know , I don't think there 's anything magical here . It 's , you know , we used a simple HTK system with a modest amount of data . And this is a  a , you know , modern <breath> uh system uh has  has a lot of nice points to it . <breath> 
E:  Yeah . 
E:  Yeah . Mm - hmm . 
A:  Um . 
A:  So . I mean , the HTK is an older HTK , even . So . <breath> 
E:  Mm - hmm . 
A:  Yeah it  it 's not that surprising . But to me it just  it just meant a practical <breath> point that um if we want to <breath> publish results on digits that  that people pay <breath> attention to we probably should uh  
A:  Cuz we 've had the problem before that you get  show some <breath> nice improvement on something that 's  that 's uh , uh  it seems like too large a number , and uh <breath> uh people don't necessarily take it so seriously . <breath> 
E:  Mm - hmm . 
A:  Um . 
A:  Yeah . 
A:  Yeah . So the three point four percent for this uh is  is uh  <breath> 


A:  So why is it  It 's an interesting question though , still . Why is  why is it three point four percent for the d the digits recorded in this environment as opposed to <breath> 
B:  <breath> 
A:  the uh point eight percent for  for  for the original TI - digits database ? 
A:  Um . 
E:  Yeah . th that 's  
A:  Given  given the same  Yeah . So ignore  ignoring the  the  the SRI system for a moment , just looking at <breath> 
E:  th that 's my point I  I  I don't 
D:  <breath> 
E:  I  
E:  Mm - hmm . 
D:  <breath> 
A:  the TI - di the uh tandem system , <breath> 
A:  if we 're getting point eight percent , which , yes , it 's high . It 's , you know , it  it 's not awfully high , but it 's , you know  it 's  it 's high . <breath> 
E:  Mm - hmm . 
A:  Um . <breath> Why is it <breath> uh four times as high , 
A:  or more ? 
E:  <laugh> Yeah , I guess . <laugh> 
B:  <breath-laugh> 
A:  <breath> <breath> <laugh> 
A:  Right ? I mean , there 's  <breath> even though it 's close - miked there 's still  there really is background noise . 
E:  <laugh> 
E:  <clears throat> 
E:  Mm - hmm . 
A:  Um . And <breath> uh I suspect when the TI - digits were recorded if somebody fumbled or said something wrong or something that they probably made them take it over . 
B:  <laugh> 
E:  Mm - hmm . 
A:  It was not  I mean there was no attempt to have it be realistic in any  in any sense at all . 
E:  Well . 
E:  Yeah . 
D:  <breath> 
E:  And acoustically , it 's q it 's  I listened . It 's quite different . TI - digit is  
D:  <breath> 
E:  it 's very , very clean and it 's like studio recording <breath> 
A:  Mm - hmm . 
E:  whereas these Meeting Recorder digits 
D:  <breath> 
E:  sometimes you have breath noise and 
E:  Mmm . 
A:  Right . <breath> 
A:  Yeah . So I think they were  <breath> 
E:  It 's <door noise> not controlled at all , I mean . 
B:  <sneeze> 
D:  <breath> 
A:  Bless you . <breath> <breath> 
B:  Thanks . <laugh> 
D:  <breath> 
A:  I  Yeah . I think it 's  it 's  <breath> 
E:  Mm - hmm . <inbreath> But - 
A:  So . Yes . It 's  I think it 's  
A:  it 's the indication it 's harder . <laugh> 
B:  <noise> 
A:  <breath> <laugh> <breath> 
E:  Yeah . <laugh> 
B:  <laugh> 
A:  Uh . <breath> 
B:  <sniffing and blowing nose> 
A:  Yeah and again , you know , i that 's true either way . I mean so take a look at the uh  <breath> 
A:  um , 
A:  the SRI results . I mean , they 're much much better , but still you 're getting something like one point three percent 
B:  <breath> <sniff> <breath> 
E:  Mm - hmm . 
A:  for uh things that are same data as in T  TI - digits the same  same text . <breath> 
A:  Uh . And uh , I 'm sure the same  
C:  <pages turning> 
A:  same system would  would get , you know , point  point three or point four or something <breath> 
D:  <noise> 
A:  on the actual TI - digits . So this  I think , on both systems the <breath> these digits are showing up as harder . 
E:  Mmm . 
D:  <breath> 
A:  Um . 
E:  Mm - hmm . 
A:  Which I find sort of interesting cause I think this is closer to  <breath> 
A:  uh I mean it 's still read . 
A:  But I still think it 's much closer to  to what  what people actually face , <breath> 
D:  <breath> 
A:  um when they 're  they 're dealing with people saying digits over the telephone . I mean . <breath> 
A:  I don't think uh  
A:  I mean , I 'm sure they wouldn't release the numbers , but I don't think that uh 
A:  <breath> 
A:  the uh  the  the companies that  that do telephone <breath> speech get anything like point four percent on their 
A:  <breath> 
A:  digits . I 'm  I 'm  I 'm sure they get  
A:  Uh , I mean , for one thing people do phone up who don't have uh 
A:  uh Middle America accents and 
D:  <breath> 
A:  <breath> 
E:  Mm - hmm . 
B:  <breath-laugh> 
A:  it 's a we we it 's  it 's  
E:  <breath-laugh> 
A:  it 's US . it has  has many people <breath> <laugh> who sound in many different ways . So . <breath> 
B:  <laugh> 
A:  Um . 
A:  I mean . 


A:  OK . That was that topic . What else we got ? 
E:  Um . 
E:  <mouth> <inbreath> 
E:  But  
A:  Did we end up giving up on  on , any Eurospeech submissions , or  ?  <breath> 
A:  I know Thilo and Dan Ellis are  are submitting something , but uh . 
E:  Yeah . I  <breath> I guess e the only thing with 
E:  these  
E:  the Meeting Recorder and , well ,  
E:  So , I think , yeah  I think we basically gave up . <laugh> 
B:  <mike noise> 
B:  <blowing nose> 
A:  Um . <breath> 
E:  But  
A:  Now , actually for the  for the Aur - uh we do have stuff for Aurora , right ? Because  because we have ano an extra month or something . 
E:  Yeah . Yeah . 
B:  <blowing nose> 
E:  Yeah . So . Yeah , for sure we will 
A:  Yeah . 
E:  do something for 
A:  Well , that 's fine . So th so  so we have a couple  a couple little things on Meeting Recorder and we have  <breath> 
E:  the special session . Yeah . 
E:  Mm - hmm . 
A:  We don't  we don't have to flood it with papers . We 're not trying to prove anything to anybody . so . <breath> 
A:  That 's fine . 


A:  Um . 
A:  Anything else ? 
E:  Yeah . Well . So . <breath> 
D:  <breath> 
E:  Perhaps the point is that we 've been working on <breath> 
E:  is , yeah , we have put the um the good VAD in the system and <breath> 
E:  it really makes a huge difference . Um . <breath> 
C:  <breath> 
D:  <breath> 
B:  <laugh> 
E:  So , yeah . 
E:  I think , yeah , this is perhaps one of the reason why our system was not  <breath> 
E:  not the best , because with the new VAD , it 's very  
E:  the results are 
E:  similar to the 
E:  France Telecom results and 
C:  <mike noise> 
A:  Hmm . 
E:  perhaps even better sometimes . <breath> 
B:  <breath> Huh . 
E:  Um . 
E:  So there is this point . 


E:  Uh . The problem is that it 's very big and <breath> 
E:  <mouth> we still have to think how to  
E:  where to put it and  <breath> 
E:  um , 
A:  Mm - hmm . 
E:  <inbreath> 
E:  because it  it  
E:  well , this VAD 
E:  uh either some delay <breath> 
E:  and we  if we put it on the server side , 
E:  it doesn't work , because on the server side features you already have LDA applied <breath> 
E:  from the f from the terminal side and <breath> 
E:  so you accumulate the delay so 
E:  the VAD should be before the LDA <breath> 
E:  which means perhaps on the terminal side and then smaller <breath> 
E:  and 
A:  <breath> 
A:  So wha where did this good VAD come from ? 
E:  So . 
E:  It 's 
E:  um from OGI . So 
E:  it 's the network trained  
E:  it 's the network with the huge amounts on hidden  of hidden units , and 
E:  um 
E:  nine input frames compared to 
E:  the VAD that was 
E:  in the proposal which has 
E:  a very small amount of hidden units and fewer inputs . 
A:  This is the one they had originally ? Oh . <breath> 
E:  Yeah . 
A:  Yeah , but they had to  get rid of it because of the space , didn't they ? 
E:  Yeah . So . 
E:  Yeah . But the abso assumption is that 
D:  <breath> 
E:  we will be able to make a VAD that 's small and that works fine . <breath> 
E:  And . 
A:  Well . So that 's a problem . Yeah . <breath> <breath> 
D:  <breath> 
E:  So we can  
E:  Yeah but  nnn . 
A:  But the other thing is uh to use a different VAD entirely . I mean , uh i if  if there 's a <breath> 
A:  if  if  I  I don't know what the thinking was amongst the  the  the <breath> the ETSI folk but um 
E:  Mm - hmm . 
A:  if everybody agreed sure let 's use this VAD and take that out of there  
E:  Mm - hmm . <inbreath> 
C:  <mike noise> 
E:  They just want , apparently  they don't want to fix the VAD because 
E:  they think there is some interaction between 
E:  feature extraction and  
E:  and 
E:  VAD or frame dropping <breath> 
D:  <breath> 
E:  But 
E:  they still <mouth> want to  just to give some 
E:  um <breath> 
D:  <breath> 
E:  requirement for this VAD because it 's  it will not be part of  they don't want it to be part of the standard . 
A:  OK . 
E:  So . 
E:  So it must be at least 
B:  <breath> 
E:  uh somewhat fixed but not completely . So there just will be some requirements that are still not  
E:  uh not yet 
D:  <breath> 
E:  uh ready I think . <breath> 
A:  Determined .  
A:  I see . <breath> 
E:  Nnn . 
A:  But I was thinking that  that uh <breath> 
A:  s 
A:  " Sure , there may be some interaction , but I don't think we need to be stuck on using our or OGI 's  VAD . We could use somebody else 's if it 's smaller or  
E:  Yeah . 
A:  You know , as long as it did the job . 
E:  Mm - hmm . 
A:  So that 's good . 


E:  Uh . So there is this thing . There is um  <mouth> 
E:  Yeah . 
E:  Uh I designed a new  a new filter 
E:  because 
E:  when I designed other filters 
E:  with shorter delay from the LDA filters , <breath> 
E:  there was one filter with fif sixty millisecond delay and the other with ten milliseconds and <breath> 
B:  <breath> 
A:  Right . 
E:  uh Hynek suggested that both could have sixty - five sixty - s 
E:  I think it 's sixty - five . Yeah . <breath> 
A:  Yeah . 
E:  Both should have sixty - five because  Yeah . <breath> 
A:  You didn't gain anything , right ? 
E:  And . So I did that and 
E:  uh it 's running . 
E:  So , <laugh> let 's see 
C:  <breath> 
D:  <breath> 
B:  <breath> 
B:  <breath> 
E:  what will happen . 
E:  Uh but the filter is of course closer 
E:  to the reference filter . <breath> 
A:  Mm - hmm . 
E:  Mmm . 
E:  <mouth-click> <inbreath> 
E:  Um . Yeah . 
A:  <breath> 
E:  I think  
A:  So that means logically , in principle , it should be better . So probably it 'll be worse . 
E:  <laugh> 
B:  <laugh> 
A:  <laugh> 
C:  <breath> 
D:  <breath> 
E:  Yeah <laugh> 
A:  Or in the basic 
A:  perverse nature uh of reality . Yeah . <breath> 
A:  OK . <breath> <breath> <breath> <breath> 
E:  Yeah . Sure . 
B:  <laugh> 
E:  <laugh> 
C:  <breath> Yeah . 
D:  <breath> 
A:  OK . 
E:  Yeah , and then we 've started to work with this of um 
C:  <mike noise> 
E:  voiced - unvoiced 
A:  Mm - hmm . 
E:  stuff . 
E:  And 
B:  <blowing nose> 
C:  <breath> 
E:  next week I think we will <breath> 
E:  perhaps try to have um 
B:  <sniff> 
E:  a new system with uh uh MSG stream also 
E:  see what  what happens . 
E:  So , something that 's similar to the proposal too , but with MSG stream . 
A:  Mm - hmm . 
A:  Mm - hmm . 
E:  Mmm . 
A:  OK . 


D:  <breath-laugh> 
E:  <breath-laugh> 
D:  <inbreath> 
D:  No , I w <breath> 
D:  I begin to play 
D:  <laugh> 
D:  with Matlab and to found some parameter robust for voiced - unvoiced decision . <laugh> 
D:  But only to play . And we  <breath> 
D:  they  we found that maybe w is a classical parameter , the <breath> 
D:  sq the variance <breath> 
B:  <breath> 
D:  between the um FFT of the signal and the small 
D:  spectrum of time <breath> 
D:  we  after the um mel filter bank . 
A:  Uh - huh . 
D:  And , well , is more or less robust . 
D:  Is good for clean speech . Is 
D:  quite good <laugh> 
A:  Huh ? 
D:  for noisy speech . 
A:  Mm - hmm . 
D:  but um we must to have bigger statistic with TIMIT , 
A:  Mm - hmm . 
D:  and is not ready yet 
A:  Yeah . 
D:  to use on , well , I don't know . 
D:  <laugh> 
A:  Yeah . 
E:  Yeah . So , basically we wa want to look at something like the ex the ex excitation signal and  <mouth> 
A:  Right . 
D:  Mm - hmm . 
E:  which are the variance of it and  
D:  <breath> 
D:  I have here . 
D:  I have here 
E:  Mmm . 
D:  for one signal , for one frame . 
A:  Yeah . 
D:  <inbreath> 
D:  The  the mix of the two , noise and unnoise , and the signal is this . 
A:  Uh - huh . 
D:  Clean , and this noise . <breath> 
A:  Uh . 
D:  These are the two  the mixed , the big signal is for clean . 
A:  Well , I 'm s uh  
A:  There 's  None of these axes are labeled , so I don't know what this  What 's this axis ? 
D:  Uh this is uh  this axis is <breath> 
D:  nnn , " frame " . 
A:  Frame . <breath> 
D:  Mm - hmm . 
A:  And what 's th what this ? 
D:  Uh , this is uh energy , log - energy of the spectrum . 
D:  Of the - No , this is the variance , the difference 
D:  <noise> 
D:  between 
D:  the spectrum of the signal 
D:  and 
D:  FFT of each frame of the signal and 
D:  this mouth spectrum of time after the f 
A:  For this one . 
D:  may fit 
A:  For the noi 
D:  for the two , 
D:  this big , to here , they are to signal . 
D:  This is for clean and this is for noise . 
A:  Oh . There 's two things on the same graph . 
D:  Yeah . I don't know . I  I think that I have d another graph , but I 'm not sure . 
E:  Yeah . 
A:  So w which is clean and which is noise ? 
E:  I think the lower one is noise . 
D:  The lower is noise and the height is clean . 
A:  OK . So it 's harder to distinguish 
D:  It 's height . 
A:  but it  but it g with noise of course but  but  <breath> 
E:  Yeah . 
D:  Oh . I must to have . 
A:  Uh . <breath> <breath> 
D:  Pity , but I don't have 
D:  two different 
A:  And presumably when there 's a  a  
D:  <pages turning> 
E:  So this should the  the  the t 
E:  voiced 
D:  <breath> 
A:  Uh - huh . 
D:  Yeah , it is the height 
E:  portions . 
D:  is voiced portion . 
E:  The p the peaks should be voiced portion . <breath> 
D:  And this is the noise portion . 
A:  Uh - huh . 
D:  And this is more or less like this . 
D:  But I meant to have see @ @ two  two the picture . 
A:  Yeah . 
D:  <breath> 
A:  Yeah . 
D:  This is , for example , for one frame . 
A:  Yeah 
D:  the  the spectrum of the signal . 
D:  And this is the small 
D:  version of the spectrum after ML 
D:  mel filter bank . 
A:  Yeah . And this is the difference ? 
D:  And this is 
D:  I don't know . 
D:  This is not the different . This is trying to obtain <breath> 
D:  with LPC model 
D:  the spectrum but 
D:  using Matlab without going factor and s 
A:  No pre - emphasis ? Yeah . <breath> 
D:  Not pre - emphasis . Nothing . 
A:  Yeah so it 's  doesn't do too well there . <breath> 
D:  And the  I think that this is good . 


D:  This is quite similar . <breath> 
D:  <pages turning> 
D:  this is  <breath> 
D:  this is another frame . 
D:  ho how I obtained the <mouth> 
D:  envelope , 
D:  <mike noise> 
D:  this envelope , 
D:  with the mel filter bank . 
A:  Right . <breath> 
A:  So now I wonder  I mean , do you want to  
D:  <breath> 
A:  I know you want to get at something orthogonal from what you get with the smooth spectrum <breath> 
A:  Um . 
A:  But if you were to really try and get a voiced - unvoiced , do you  do you want to totally ignore that ? I mean , do you  do you  I mean , 
A:  clearly a  a very big  very big cues <breath> for voiced - unvoiced come from uh spectral slope and so on , right ? 
E:  Mm - hmm . 
A:  Um . 
E:  Yeah . Well , this would be  
D:  <breath> 
E:  this would be perhaps an additional parameter , simply isn't  
A:  Yeah . I see . 
E:  Yeah . 
D:  Yeah because when did noise 
E:  Uh . 
D:  clear <pages turning> 
D:  in these section is clear <breath> 
D:  <breath> 
A:  Mm - hmm . 
D:  if s @ @ 
D:  <noise> 
D:  val value is 
D:  indicative that is a voice frame and it 's 
D:  low values @ @  
A:  Yeah . 
A:  Yeah . 
A:  Well , you probably want  I mean , <breath> 
A:  certainly if <breath> you want to do good voiced - unvoiced detection , you need a few features . Each  each feature is <breath> by itself not enough . But , you know , people look at  at slope and <breath> uh 
E:  Mmm . 
A:  first auto - correlation coefficient , divided by power . Or  or uh <breath> um <mouth> 
A:  there 's uh  <breath> 
A:  I guess we prob probably don't have enough computation to do a simple pitch detector or something ? I mean with a pitch detector you could have a  <breath> 
E:  Mmm . 
A:  have a  an estimate of  of what the  
A:  Uh . Or maybe you could you just do it going through the P FFT 's figuring out some um probable <breath> um harmonic structure . 
A:  Right . And  and uh . 
E:  Mmm . 
D:  <breath> you have read up and  you have a paper , <breath> 
D:  the paper that you s give me yesterday . 
E:  Oh , yeah . But  
D:  they say that yesterday <breath> 
D:  they are some 
D:  <noise> 
D:  problem 
E:  Yeah , but it 's not  it 's , yeah , it 's  it 's another problem . Yeah 
D:  and the  
D:  Is another problem . 
E:  Um . <breath> 


E:  Yeah , there is 
E:  th this fact actually . If you 
E:  look at this um spectrum , <breath> 
A:  Yeah . 
E:  What 's this again ? Is it <breath> the mel - filters ? 
D:  Yeah like this . Of kind like this . 
E:  Yeah . 
E:  OK . 
E:  So the envelope here is the output of the mel - filters 
A:  Mm - hmm . 
E:  and what we clearly see is that in some cases , 
E:  and it clearly appears here , <breath> 
E:  and 
E:  the  the harmonics are resolved by the f Well , 
E:  there are still appear after mel - filtering , 
A:  Mm - hmm . 
E:  and it happens <breath> 
E:  for high pitched voice because 
B:  <breath> <breath> 
E:  the width of the lower frequency mel - filters <breath> 
E:  is sometimes even smaller than the pitch . 
A:  Yeah . 
E:  It 's around one hundred , one hundred and fifty hertz <breath> 
B:  <breath> 
A:  Right . 
E:  Nnn . 
E:  And so what happens is that this 
E:  uh , add additional variability to this envelope and <mouth> <breath> 
A:  Yeah . 
E:  um 
E:  so we were thinking to modify the mel - spectrum to have something that  that 's smoother on low frequencies . 
A:  That 's as  as a separate thing . Yeah . <breath> 
E:  i 
D:  <breath> 
E:  Yeah . This is a separate thing . 
A:  <breath> 
D:  Yeah . 
A:  Separate thing ? Yeah . 
E:  And . 
A:  Yeah . Maybe so . <breath> 
A:  Um . <breath> 


A:  Yeah . So , what  Yeah . What I was talking about was just , starting with the FFT you could  you could uh do a very rough thing to estimate  estimate uh pitch . <breath> 
E:  Yeah . 
E:  Mm - hmm . 
A:  And uh uh , given  you know , given that , uh <breath> you could uh uh come up with some kind of estimate of how much of the low frequency energy was  was explained by  <breath> 
E:  Mm - hmm . 
A:  by uh 
A:  uh those harmonics . Uh . <breath> 
D:  <breath> <noise> 
A:  It 's uh a variant on what you 're s what you 're doing . The  I mean , the  the <breath> the mel 
D:  <breath> 
E:  <clears throat> 
A:  does give a smooth thing . But as you say it 's not that smooth here . And  and so if you  <breath> 
A:  if you just you know subtracted off uh your guess of the harmonics then something like this would end up with <breath> 
A:  quite a bit lower energy in the first fifteen hundred hertz or so and  
E:  Mm - hmm . 
A:  and our first kilohertz , even . <breath> 
B:  <breath> 
A:  And um <breath> 
A:  if was uh noisy , the proportion that it would go down would be 
E:  Mm - hmm . 
A:  if it was  if it was unvoiced or something . 
A:  So you oughta be able to <breath> pick out voiced segments . 
A:  At least it should be another  another cue . 
A:  So . <breath> 
E:  Mm - hmm . 
D:  <breath> 


A:  Anyway . <breath> <breath> 
A:  OK ? <breath> <breath> 
A:  That 's what 's going on . <breath> 
D:  <breath> <noise> <breath> 
A:  Uh . <breath> 
B:  <breath> <breath> 
A:  What 's up with you ? <breath> 
B:  and um 
B:  yeah , I 've just been <breath> continue reading 
B:  um about certain things . 
A:  Mm - hmm . 
B:  <breath> um 
B:  <mouth> 
B:  thinking of maybe using um <breath> 
B:  um 
B:  m modulation spectrum stuff to <breath> um  
D:  <breath> 
B:  as features um also in the  in the sub - bands because <breath> 
A:  Mm - hmm . 
B:  it seems like <breath> the modulation um spectrum tells you a lot about 
B:  the intelligibility of  of certain um words and stuff <breath> 
B:  So , um . Yeah . 
B:  Just 
B:  that 's about it . 


B:  Um <breath> our t I went to <breath> talk with uh Mike Jordan this  this week <breath> 
D:  <breath> 
A:  Mm - hmm . 
B:  um <noise> 
B:  and uh <breath> shared with him the ideas about um <breath> 
D:  <breath> 
B:  extending the Larry Saul work <breath> 
B:  and um I asked him some questions about factorial H M Ms so like later down the line when <breath> 
B:  we 've come up with these  these feature detectors , how do we  <breath> 
B:  how do we uh <breath> 
B:  you know , 
B:  uh model the time series that  that happens <breath> 
B:  um <breath> 
B:  <mouth> 
B:  and <breath> 
B:  and we talked a little bit about <breath> factorial H M Ms and how <breath> 
B:  um 
B:  when you 're doing inference  or w when you 're doing recognition , there 's like simple Viterbi stuff that you can do for  <breath> 
B:  for these H M Ms and <breath> 
B:  the uh  <breath> the great advantages that 
D:  <breath> 
B:  um a lot of times the factorial H M Ms don't <breath> 
B:  um <breath> 
B:  don't over - alert the problem there they have a limited number of parameters and they focus directly on  <breath> 
D:  <breath> 
B:  on uh the sub - problems at hand so <breath> 
B:  you can imagine <breath> um 
B:  <mouth> five or so parallel <breath> 
B:  um features 
B:  um transitioning independently and then <breath> 
B:  at the end you  you uh couple these factorial H M Ms with uh  <breath> 
B:  with uh undirected links 
B:  um based on  <breath> 
A:  Hmm . 
B:  based on some more data . <breath> 
B:  So he  he seemed  he seemed like really interested in  <breath> 
B:  in um  in this and said  said this is  this is something very do - able and can learn a lot <breath> 


B:  <breath> <breath> <breath> 
A:  OK . 
B:  <breath> 
C:  OK . And um so I 've been looking at Avendano 's work and um 
B:  <sniff> <sniff> 
C:  uh I 'll try to write up in my next stat status report a nice description of <breath> 
B:  <sniff> <sniff> <sniff> 
C:  what he 's doing , but it 's  it 's an approach to deal with <breath> 
E:  <mike noise> 
C:  reverberation or that  the aspect of his work that I 'm interested in <breath> 
B:  <sniff> 
C:  the idea is that um <mouth> <breath> 
C:  <breath> normally an analysis frames are um <breath> 
C:  too short to encompass reverberation effects um in full . You miss most of the reverberation tail in a ten millisecond window <breath> 
C:  and so <breath> <mouth> 
C:  you  you 'd like it to be that <breath> 
E:  <mike noise> 
C:  um <breath> 
C:  the reverberation responses um simply convolved 
C:  um 
C:  in , but 
C:  it 's not really with these ten millisecond frames 
C:  cuz you j 
C:  But if you take , say , a two millisecond <breath> 
C:  um window  <breath> 
C:  I 'm sorry a two second window  <breath> 
C:  then in a room like this , most of the reverberation response <breath> 
C:  is included in the window <breath> 
C:  and the  then it um 
C:  <breath> 
C:  then things are l more linear . It is  it is more like the reverberation response is simply c convolved <breath> 
C:  and um  <breath> 
C:  and you can use channel normalization techniques <breath> 
C:  like uh in his thesis he 's assuming that the reverberation response is fixed . He just does um <breath> 
D:  <breath> 
C:  mean subtraction , which is like removing the DC component of the modulation spectrum <breath> 
C:  and <breath> 
C:  that 's supposed to d 
C:  um deal  uh deal pretty well with the um reverberation <breath> 
C:  and um <breath> the neat thing is you can't take these two second frames and feed them to a speech recognizer <breath> 
C:  um <breath> so he does this <breath> um <mouth> 
C:  method training trading the um <breath> the spectral resolution for time resolution <breath> and um 
C:  <breath> 
C:  come ca uh synthesizes a new representation which is with say ten second frames but a lower s um <breath> 
C:  frequency resolution . 
C:  So I don't really know the theory . I guess it 's  these are called " time frequency representations " and h he 's making the  the time sh um finer grained and the frequency resolution um less fine grained . <breath> 
D:  <breath> 
E:  Mm - hmm . 
C:  s so I 'm  I guess my first stab actually in continuing <breath> his work is to um <breath> re - implement this  this thing which um <breath> changes the time and frequency resolutions cuz he doesn't have code for me . So that that 'll take some reading about the theory . I don't really know the theory . <breath> 
D:  <breath> 
D:  <breath> 
E:  Mm - hmm . 
C:  Oh , and um , <breath> another f first step is um , so the  the way I want to extend his work is make it able to deal with a time varying reverberation response um <breath> and um 
D:  <breath> 
C:  we don't really know <breath> how fast 
D:  <breath> 
C:  the um  the reverberation response is varying the Meeting Recorder data <breath> 
D:  <breath> 
C:  um so um <breath> 
C:  we  we have this um block least squares um 
C:  imp echo canceller implementation and um <breath> 
D:  <breath> 
C:  I want to try <breath> finding <breath> 
C:  the  the response , say , between a near mike and the table mike for someone using the echo canceller and looking at the echo canceller taps and then <breath> 
C:  see how fast that varies <breath> from block to block . That should give an idea of how fast the reverberation response is changing . <breath> 
E:  Mm - hmm . 
E:  Mm - hmm . 
A:  <breath> <breath> 


A:  OK . 
A:  <mouth> 
A:  Um . I think we 're <breath> sort of done . <breath> 
E:  Yeah . 
A:  <laugh> So let 's read our digits and go home . <breath> <laugh> 
E:  <laugh> 
D:  <breath> 
B:  <laugh> 
E:  <mike noise> 
A:  <laugh> 
E:  <laugh> 
B:  <laugh> 
A:  OK . We 're done . 


E:  OK . I 'm reading transcript L dash forty  
E:  three four nine one one O five one eight three  
E:  six two O five seven O four one nine six  
E:  O one four four nine five seven three seven  
D:  <breath> 
E:  six one four two O five two seven  
E:  eight nine nine three six six three eight nine  
E:  seven one seven eight three one nine three O  
E:  one nine five seven five five one eight zero  
E:  eight two nine eight four six one nine four eight one two  
D:  <breath> 
C:  Um . <breath> S so um <breath> y you do  I think you read some of the  the zeros as O 's and some as zeros . <breath> 
A:  Yeah . 
C:  Is there a particular way we 're supposed to read them ? 
E:  There are only zeros here . Well . 
A:  No . " O "  " O "  " O " and " zero " are two ways that we say that digit . 
E:  Eee .  
E:  Yeah . 
A:  So it 's  
E:  But  
B:  <breath> Ha ! 
A:  so it 's  i 
E:  Perhaps in the sheets there should be another sign for the  if we want to  the  the guy to say " O " or 
B:  <laugh> 
D:  <breath> 
B:  <laugh> 
A:  No . I mean . I think people will do what they say . It 's OK . <breath> 
E:  It 's  
E:  Yeah . 
E:  OK . 
C:  Alright . 
A:  I mean in digit recognition we 've done before , you have  you have two pronunciations for that value , " O " and " zero " . <laugh> 
C:  OK . 
E:  But it 's perhaps more difficult for the people to prepare the database then , if  
E:  because here you only have zeros 
B:  <sniff> <sniff> <sniff> <sniff> 
E:  and  and people pronounce " O " or zero  
A:  No , they just write  
A:  they  they write down OH . or they write down ZERO a and they  and they each have their own pronunciation . 
C:  <mike noise> 
B:  <breath> 
E:  Yeah but if the sh the sheet was prepared with a different sign for the " O " . 
A:  But people wouldn't know what that wa 
A:  I mean <breath> there is no convention for it . 
E:  OK . 
E:  Yeah . 
B:  <laugh> 
E:  OK . <breath-laugh> 
A:  See . I mean , you 'd have to tell them <breath> 
A:  " OK when we write this , say it tha " , you know , and you just  They just want people to read the digits as you ordinarily would and  and people 
E:  Mm - hmm . 
E:  Yeah . 
E:  Yep . 
A:  say it different ways . 
C:  OK . Is this a change from the last batch of  of um forms ? Because in the last batch it was spelled out which one you should read . 
E:  Yeah , it was orthographic , so . 
C:  <breath> 
A:  Yes . That 's right . It was  it was spelled out , and they decided they wanted to get at more the way people would really say things . <breath> That 's also why they 're  they 're bunched together in these different groups . So  so it 's  Yeah . So it 's  it 's  Everything 's fine . <breath> <laugh> 
C:  Oh . OK . 
C:  OK . 
B:  <laugh> 
C:  OK . 
E:  <laugh> 
A:  OK . 
A:  <breath> 
A:  Uh . Transcript L dash three nine . <breath>  
A:  one three two six one zero one four two four seven five  
A:  nine three eight seven two six two six two seven  
D:  <breath> 
A:  six seven three four two two two four  
D:  <breath> 
A:  two nine six four O four O eight eight two  
E:  <mike noise> 
A:  eight seven nine nine four O O eight two  
E:  <mike noise> 
A:  seven eight zero three nine five one two three  
D:  <breath> 
A:  eight four three five five nine eight one four two  
A:  zero two zero nine two nine two six  
A:  Actually , let me just s since  since you brought it up , I was just  it was hard not to be self - conscious about that when it <laugh> after we  since we just discussed it . <breath> But I realized that  that um <breath> 
B:  <breath> 
A:  when I 'm talking on the phone , certainly , and  and saying these numbers , <breath> I almost always say zero . 
D:  <breath> 
A:  And uh  cuz  because uh i it 's two syllables . It 's  it 's more likely they 'll understand what I said . <breath> So that  that  that 's the habit I 'm in , but some people say " O " and  
D:  <breath> 
B:  <laugh> 
B:  Yeah I normally say " O " cuz it 's easier to say . <breath> 
E:  <laugh> 
A:  Yeah it 's shorter . Yeah . So it 's  So . <breath> So uh . Now , don't think about it . 
B:  " O " <laugh> 
B:  Oh , no ! <laugh> 
C:  <laugh> 
A:  <laugh> 
B:  <laugh> 
D:  <laugh> 
B:  OK . I 'm reading transcript L thirty eight <breath>  
B:  five four five O three two eight five eight  
B:  three three eight nine O four one O nine  
B:  eight five O seven one one one four O  
B:  two one six one eight two five six seven eight  
B:  five seven six eight two O O O four  
B:  seven O O five eight seven seven seven five six  
B:  five six one three seven one nine one three  
B:  four three six O O nine nine two two O  
D:  <breath> 
C:  I 'm reading transcript L dash thirty seven .  
C:  O five one nine O three two seven one six six nine  
D:  <breath> 
C:  six two seven O two six four five one O  
C:  five four two nine five O O one  
C:  seven one one two seven one eight one two three  
D:  <breath> 
C:  four O eight four five seven six two two nine  
D:  <breath> 
D:  <breath> 
C:  eight two three six seven two six seven six four  
C:  nine two seven three one two five three  
D:  <breath> 
C:  nine three six eight six one nine one seven seven  
D:  Transcript L dash thirty six <breath>  
D:  O four four one six two nine O  
D:  four seven three eight four five six five four six eight eight  
D:  three one two five two five four five nine  
D:  nine seven zero six nine eight five eight five one  
D:  zero eight three two nine seven three one four five  
D:  six four nine three eight four four two two three  
D:  four five three O two four five four two two  
D:  six eight two one eight nine eight one nine  


