B:  It 's already dead . 
B:  Right . It would have to be hand  
B:  Right . 
B:  It would have to be  
B:  Well , a h a person would  would check it over 
B:  and then give a final  
B:  I 'm  
B:  Well , it 's more 
B:  you didn't  
B:  Oh , sorry . 
B:  You were saying that we were waiting for Chuck , 
B:  so I just  
B:  OK . 
B:  OK . 
B:  Well , that 's good . 
B:  I overlap exactly with the times you 're gone . 
B:  I mean  
B:  Yeah . 
B:  Pie . 
B:  Mmm . 
B:  You mean  
B:  But  but that was read speech . 
B:  Maybe like twenty hours . We could try , 
B:  but  Maybe not counting the non - native speech , 
B:  cuz if  That  that just doesn't translate very well . 
B:  Right . And actually the  I was thinking about this 
B:  the original application doesn't really appl 
B:  I mean , if you 're using this over and over again , you 're gonna be testing on the same  the same speakers . 
B:  I just mean that it 's not a terrible thing to assume that you don't  that you don't have disjoint sets , 
B:  for this particular kind of  application . 
B:  I mean  
B:  Yeah . 
B:  Somewhat . Although what 's interesting is that the majority of the words in the language model are actually  
B:  Yeah . They 're actually these , like , function words 
B:  and " Yeah ! " and s stuff like that . 
B:  And there there 's a lot of speaker dependence there . 
B:  Even the transcribers will say they know who the speaker is after a while just from their backchannels 
B:  and  
B:  Right . 
B:  So y So , I don't think you 're talking the way you write , in  in other words . 
B:  What 's the plan if  were we still going to be like a  center for transcribing data ? 
B:  What happens if th they don't deliver things until  next year or something when we  have less  resources 
B:  or  ? 
B:  Mm - hmm . 

B:  Are they  they 're doing , like , twenty - two 
B:  or s ? 
B:  Could  
B:  Forty - eight ? 
B:  Forty  forty - four ? 
B:  Yeah . 
B:  CD - ROM . 
B:  Yeah . 
B:  Forty - four . 
B:  S 
B:  But  but it  but forty - four and sixteen are not easy ? 
B:  Yeah ? 
B:  It 's not lossy ? 
B:  As long as you 're  
B:  Yeah . 
B:  As long as you 're not doing the processing on the  downsampled  
B:  I mean  Just for transcribing it , you mean ? 
B:  For  
B:  Yeah . 
B:  They 're taking up more disk space . 
B:  Yeah . 
B:  They 'll have to start kicking people out of the meetings , 
B:  like  
B:  As long as they have only , like , three people per meeting . 
B:  I mean , they can just limit the number of people . 
B:  Yeah . They were g they said they were gonna record @ @  
B:  I don't know if there were fifty , 
B:  but there were definitely above , like , twenty . 
B:  It was  it was high . 
B:  Sixteen . 
B:  You just get , like , one backchannel at a time or something . 

B:  And there 's never any talk  ? 
B:  Was there ever any talk of taking the , um , close - talking mikes when people aren't talking and deleting those portions ? 
B:  Or is the breathing and things  ? 
B:  Yeah ? 
B:  OK . 
B:  And if they 're still that big  
B:  I see . Yeah , that 's true . 
B:  OK . So it 's still really big even if you 're  only one person or two people at most are actually talking all the time . 
B:  Wow . 
B:  Have shorter meetings ! 
B:  Sorry . <laugh> <mike noise> Thanks , Morgan . 
B:  Wow . 
B:  Yeah . So  so they 're really going to have a huge  
B:  Especially Hawaii . 

B:  Oh . Really ? 
B:  Are they like these , 
B:  right ? 
B:  OK . 
B:  They usually do Thursdays . 
B:  I don't get a lot of advance notice , 
B:  but it 's al always been either Mondays or Thursdays . 
B:  So . 
B:  Yeah . They  they often do it after  
B:  for a while they were doing it after this meeting . 
B:  Yeah . Wednesdays , Fridays  
B:  Definitely Wed - Definitely Wednesday I 'm not here , 
B:  so I don't record anything . 
B:  But feel free to overlap . 
B:  No , I mean  <laugh> I always get scared when you do these portions where you 're not gonna overlap 
B:  because <laugh> there 's less data points . 
B:  I mean , people could , like , backchannel 
B:  and ask questions and stuff . 
B:  OK . 
B:  Right . 
B:  Uh - huh . 
B:  But I don't think it 's " aha ! " . 
B:  It 's more like " uh - huh ! " 
B:  rather than " uh - huh " . 
B:  Great . Great . 
B:  Y y yeah . W we should talk to you off - line about something . 
B:  Yeah . 
B:  Mm - hmm . 
B:  But it has to be multi - stream . 
B:  Th - they  
B:  In other words , the beginning of something could be one  speaker 
B:  and the end of that unit , like question - answer pair , could be a different speaker . 
B:  That 's why we can't  just annotate the transcripts , uh , one  listening to one at a time . 
B:  So  so that 's why the Transcriber 's nice for sort of listening to it , 
B:  but you can't actually encode , um  encode someth 
B:  Yeah , exactly . 
B:  So . 
B:  It 's actually not a bad idea to say " beep " as a word 
B:  because you can search the transcripts , y you know , for  for that , to find these places . 
B:  No , I 'm s I 'm totally serious . To have one word , like " beep " , 
B:  especially with a really long " eee "  like that . 
B:  Works great . 
B:  Wisconsin fishing . 
B:  Twentieth . 
B:  Beep . 
B:  Mm - hmm . 
B:  Yeah . Actually we had this ide from the last time that they were here , that it 'd be nice to have UW do some work on  language modeling that would be trying to get at the same  detection as what we do acoustically 
B:  since they can ramp up much ques quicker in the language modeling 
B:  and we don <inbreath> you know , we 'll do the , uh , prosodic side . 
B:  And so this is supposed to be a project that we could actually  integrate the posteriors that they get from their language model for every word boundary or every frame boundary , 
B:  and then train up the classifiers . 
B:  And it 's  I guess it 's an undergrad , too , that  that 's going to be doing this work . 
B:  So . 
B:  So . Well , I 'll just really briefly , um  
B:  So , I 've been working with Don and also  <inbreath> and  and Andreas on the  this paper on prosody , 
B:  and what we 're trying to do is predict where people  at  
B:  given all information up to whatever point in time you 're considering , try to predict if that 's a good location for someone else to jump in . 
B:  So , that 's the idea of that paper . 
B:  And that 's  the same task that Mari , a um , <mouth> a student named Dustin , and also Sarah who was at this last meeting <inbreath> will be looking into doing from the language modeling side . 
B:  Maybe some kind of clu you know , clustered class N - gram or something . 
B:  Um . And also we 're  we 're using a couple of the labellers who are doing emotion to help us , um , finalize some transcripts for this . 
B:  So these undergra undergrad students are really helping us out a lot , 
B:  under Don 's supervision , actually . 
B:  So that 's good . 
B:  So these offices are being , uh , very busy  
B:  Don 's and the one across from him . 
B:  And then also , um , working with Jeremy on Communicator emotion labelling . 
B:  And <inbreath> most of that up to a few weeks ago was just getting the  people labelling these utterances to a computer for emotion 
B:  and that 's going pretty well now . 
B:  Um . 
B:  Well , we 're mostly looking for places where the person 's frustrated with the system . 
B:  There  there are actually  that 's how we started it . 
B:  And we had different levels . 
B:  Now we have things like " amuse " . 
B:  Like , " oh , you finally got it " . 
B:  And  <inbreath> um , and " disappointed - tired " . Like , " yeah , no , that 's wrong again " . 
B:  Which isn't really mad , 
B:  but , you know . 
B:  So th they gave me a lot of feedback . The labellers , after doing this , 
B:  told me what they wanted as categories . 
B:  So .  And then there 's jokes . 
B:  And  
B:  Yeah , right . 
B:  Um . 
B:  There 's not a lot of  enough frustration for us to really go through quickly , 
B:  cuz we have to label every meeting 
B:  and also things like repeats for the same information , and so forth . 
B:  And I 've been coordinating a little bit with <inbreath> Katrin at , uh , UW who was doing  user correction work that she presented at the  at the meeting . 
B:  So there 's some overlap there in what you m 
B:  there 's a correlation between corrections and annoyance or frustration . 
B:  Um , but Jeremy 's been starting to really work on that project now from the acoustic side . 
B:  So we have all these waveforms , 
B:  and he 's been <inbreath> with Morgan 's help and , uh , Dan Ellis 's , I think , looking into spectral tilt a bit , 
B:  so he can talk about that . 
B:  It 's a feature we haven't used before . 
B:  Um , and starting to , uh , r r take information from alignments 
B:  and create a database that we can use sort of as a  <inbreath> a large feature vector or table to feed to our decision trees , 
B:  which will try to give us back an answer from the speech only as  to whether the person 's frustrated or not . 
B:  So . 
B:  Yeah . <inbreath> Actually , I wanted  to talk with you about that 
B:  cuz there 's a similar project at SRI where we 're using  we want to do something like that to look at whether or not some of the p stylized pitch stuff <inbreath> is , um , sort of perceptually similar to the kinds of things that people would mark . 
B:  So , I  I actually wanted to talk to you about that . 
B:  So . 
B:  OK . Yeah . Cuz this will be , like , after  
B:  OK . Yeah . This will be after September anyway , 
B:  so I  
B:  Right . 
B:  Yeah . There was just no  way to use the energy in Festival , that was  
B:  OK - Anyway . <laugh> I  I should move on 
B:  cuz we 're running late , 
B:  but I wanted to say there 's one question in my mind , which maybe Morgan can talk to Jeremy about , is how to sort of normalize spectral tilt . 
B:  It 's just  I 'm sort of in this , uh , area I don't know much about 
B:  and so we should talk off - line . 
B:  But if you have a certain speaker <inbreath> and you wanna sort of get a bunch of data from that speaker but compare it , you know , directly on a feature to  to like a decision tree that won't normalize anything for you once you feed it the features , how do you sort of normalize over a particular speaker ? 
B:  What kinds of  what  what makes sense to do with that feature ? 
B:  So . 
B:  i Yeah . 
B:  But that 's something we  would  be  glad to  have help on . 
B:  So . Go ahead , Jeremy . 
B:  The thing i 
B:  Yeah . We  we  you wanna use spectral tilt to try to get at the s n the voice quality of these utterances . 
B:  So you could have something like " no " versus " no ! " 
B:  and these might differ in that way . 
B:  But the problem is we don't know  <laugh> th we don't  we don't know whether the " no " is frustrated or not . 
B:  So  
B:  Right . <laugh> Exactly . 
B:  And then you also have the different speakers . 
B:  And so , the sort of question is , <inbreath> do you wanna average all the data together or do you  do you  ? 
B:  You wanna capture the change in voice quality within a speaker , 
B:  without having to know ahead of time w which is which , 
B:  cuz that would be circular . 
B:  So , 
B:  u this is  
B:  But do you do this , say , just in the vowel regions , 
B:  and do you  ? 
B:  a There 's  there 's a whole bunch of , um , sort of unknowns . 
B:  And we can try all of them 
B:  and just put them into the tree as features , 
B:  and  
B:  Yeah . 
B:  Everything up to that point . 
B:  Oh , yeah . That 's OK . 
B:  That  that 's the sort of  w we keep  you keep , uh , iterat you keep updating those numbers for future utterances . 
B:  Th - That  that would work . 
B:  Yeah . 
B:  So you mean , you 're just  using a mean and the varian and a variance ? 
B:  You mean just a  a Z - square , 
B:  like ? 
B:  Right , right . Right . OK . 
B:  So it is distributed  in a way that you can do this . Yeah . OK . 
B:  OK . So , that 's  so  that was our sort of  
B:  maybe this will work , 
B:  I don't know . 
B:  OK . 
B:  Well , we probably won't get that far . Yeah . 
B:  OK . 
B:  OK . 
B:  Yeah . 
B:  m Median , yeah . 
B:  We could just plot  plot these for a speaker , 
B:  and 
B:  get a bunch of histograms . 
B:  OK . 
B:  Right . 
B:  Thanks . 
B:  Really s really hungry fish . 
B:  It 's already dead . 
