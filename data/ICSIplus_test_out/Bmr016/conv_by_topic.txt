B:  <mike noise> 
D:  And we already got the crash out of the way . It did crash , so I feel much better , earlier . 
F:  @ @ 
F:  Yeah . 
E:  Interesting . 
F:  Will you get the door , and  ?  
E:  Hmm . 
F:  <mike noise> 
F:  @ @ 
F:  OK . You collected an agenda , huh ? 
D:  OK , so um . 
D:  I did collect an agenda . So I 'm gonna go first . 
D:  <outbreath> Mwa - ha - ha !  It shouldn't take too long . 
F:  <laugh> 


E:  Yeah . <clears throat> 
D:  Um , so we 're pretty much out of digits . We 've gone once through the set . 
D:  Um , so the only thing I have to do 
F:  No there 's only ten . <mike noise> 
D:  Yeah , that 's right .  
B:  <laugh> 
A:  <laugh> 
E:  <laugh> 
D:  so I  I just have to go through them and uh 
F:  Well , OK . 
D:  pick out the ones that have problems , and either correct them or have them re - read . So we probably have like 
D:  four or five more forms to be read , to be once through the set . 
D:  I 've also extracted out about an hour 's worth . We have about two hours worth . 
D:  I extracted out about an hour 's worth which are the f digits with  for which 
D:  whose speaker have speaker forms , have filled out speaker forms . Not everyone 's filled out a speaker form . So I extracted one 
D:  for speakers who have speaker forms 
D:  and for meetings in which the " key " file and the transcript files are parsable . 
D:  Some of the early key files , it looks like , were done by hand , and so they 're not automatically parsable and I have to go back and fix those . 
D:  So what that means is we have about an hour of transcribed digits that we can play with . 
D:  Um , 
F:  So you think two  you think two hours is the  is the total that we have ? 
D:  Liz   
D:  Yep , 
D:  yeah . 
F:  And you think we th uh , 
F:  I  I didn't quite catch all these different things that are not quite right , but you think we 'll be able to retrieve the other hour , reasonably ? 
D:  Yes , absolutely . 
F:  OK . 
D:  So it 's just a question of a little hand - editing of some files and then waiting for more people to turn in their speaker forms . 
D:  I have this web - based speaker form , and I sent mail to everyone who hadn't filled out a speaker form , and they 're slowly s trickling in . 
E:  <clears throat> 
F:  So the relevance of the speaker form here , s 
D:  It 's for labeling the extracted audio files . 
F:  Oh , OK . 
D:  By speaker ID and microphone type . 
F:  Wasn't like whether they were giving us permission to use their digits or something . 
D:  No , I spoke with Jane about that and we sort of decided that 
D:  it 's probably not an issue that  We edit out any of the errors anyway . 
D:  Right ? So the there are no errors in the digits , you 'll always read the string correctly .  
F:  Yeah . 
D:  So I can't imagine why anyone would care . 
D:  So the other topic with digits is uh , 
D:  OK , are we done with digits ? 


D:  Liz would like to elicit different prosodics , and so we tried last week with them written out in English . 
B:  <mike noise> <cough> 
E:  <clears throat> 
D:  And it just didn't work at all because no one grouped them together . So it just sounded like 
D:  many many more lines instead of anything else . 
D:  So in conversations with Liz and uh Jane 
D:  we decided that if you wrote them out as numbers instead of words it would elicit more phone number , social security number - like readings . 
D:  The problem with that is it becomes numbers instead of digits . 
D:  When I look at this , that first line is " sixty one , sixty two , eighteen , eighty six , ten . " 
D:  Um , and so the question is does anyone care ? Um , I 've already spoken with Liz and she feels that , 
E:  <inbreath>  
E:  Mm - hmm . 
D:  correct me if I 'm wrong , that for her , connected numbers is fine , as opposed to connected digits . 
D:  Um , I think two hours is probably fine for a test set , 
D:  but it may be a little short if we actually wanna do training and adaptation and all that other stuff . 
F:  Yeah 
E:  <mouth> <inbreath>  
F:  Um , do um 
F:  you want different prosodics , so if you always had the same groupings you wouldn't like that ? Is that correct ? 
E:  <mike noise> 
G:  Well , we actually figured out a way to  the  the groupings are randomly generated . 
D:  Yeah , the  the  
F:  No but , 
F:  I was asking if that was something you really cared about because if it wasn't , 
F:  it seems to me if you made it really specifically 
F:  telephone groupings 
F:  that maybe people wouldn't , uh , go and do numbers so much . 
F:  You know if it if it 's  
A:  Uh  
G:  I think they may still do it , um , 
F:  Maybe some , but I probably not so much . 
B:  What about putting a hyphen between the numbers in the group ? 
G:  And  
F:  Right ? So if you  if  if you have uh 
D:  Six dash one , you mean ? 
F:  if you go six six six uh dash uh two nine three one . 
G:  I  well OK  I  it might help , I would like to g get away from having only one specific 
G:  grouping . Um , so if that 's your question , but I mean it seems to me that , at least for us , we can learn to read them as digits if that 's what people want . I  I 'm 
F:  That 's what I was asking , yeah . 
F:  Yeah . 
E:  Yeah . 
E:  Yeah . 
G:  don't think that 'd be that hard to read them as single digits . Um , 
E:  I agree . 
G:  and it seems like that might be better for you guys since then you 'll have just more digit data , and that 's always a good thing . 
D:  Right . 
G:  It 's a little bit better for me too because the digits are easier to recognize . They 're better trained than the numbers . 
D:  Yep . 
F:  Right . 
D:  So we could just , uh , put in the 
D:  instructions " read them as digits " . 
G:  Right . Right , read them as single digits , so sixty - one w is read as six one , and if people make a mistake we  
E:  Mm - hmm . 
D:  How about " O " versus " zero " ? 
F:  I mean , the other thing is we could just bag it because it 's  it 's  
F:  it 's - I 'm not worrying about it I mean , because we do have digits training data that we have from 
F:  uh from OGI . I 'm sorry , digits  numbers training that we have from OGI , we 've 
F:  done lots and lots of studies with that . And um . 
G:  But it 's nice to get it in this room with the acous I mean  for  it 's  
E:  <mouth> <inbreath> 
F:  Yeah . 
F:  No , no , I guess what I 'm saying is that 
D:  Just let them read it how they read it . 
F:  to some extent maybe we could just read them  have them read how  how they read it 
F:  and it just means that we have to expand our  our vocabulary out to stuff that we already have . Yeah . 
G:  Right . 
G:  Well that 's fine with me as long as  It 's just that I didn't want to cause the people who would have been collecting digits the other way 
G:  to not have the digits . So  
E:  <mouth> 
F:  We can go back to the other thing later . I mean we s we  we 've  
G:  OK . 
F:  We can do this for awhile and then go back to digits for awhile , or 
F:  um . Do yo I mean , do you want  do you want this  
G:  OK . 
F:  Do you need training data or adaptation data out of this ? How much of this do you need ? with uh the  
G:  <mike noise> 
G:  It 's actually unclear right now . I just thought well we 're  if we 're collec collecting digits , and Adam had said we were running out of the TI forms , 
G:  I thought it 'd be nice to have them in groups , and probably , all else being equal , it 'd be better for me to just have single digits since it 's , 
F:  OK . 
G:  you know , a recognizer 's gonna do better on those anyway , 
G:  um , and it 's more predictable . So we can know from the transcript what the person said and the transcriber , in general . But if they make mistakes , it 's no big deal if the people say a hundred instead of " one OO " . 
F:  OK , well if you pre 
E:  <long breath> 
G:  and also w maybe we can just let them choose " zero " versus " O " as they  as they like because even the same person c sometimes says " O " and sometimes 
G:  says " zero " in different context , and that 's sort of interesting . 
F:  Yeah . 
G:  So I don't have a 
G:  Specific need cuz if I did I 'd probably try to collect it , 
G:  you know , without bothering this group , but 
G:  If we can try it  
D:  OK so  so I can just add to the instructions to read it as digits not as connected numbers . 
G:  Right , and you can give an example like , 
E:  Mm - hmm . 
G:  you know , " six  sixty - one would be read as six one " . And I think people will get it . 
D:  Right . 
E:  Mm - hmm . And i actually it 's no more artificial than what we 've been doing with words . I 'm sure people can adapt to this , 
G:  Right , right . It 's just easier to read . 
E:  read it single . The spaces already bias it toward being separated . 
G:  Right . 
E:  And I know I 'm gonna find this easier than words . 
D:  Oh yeah , absolutely , cognitively it 's much easier . 
G:  OK - 
G:  I also had a hard  hard time with the words , but then we went back and forth on that .  OK , so let 's give that a try and  
E:  <clears throat> 
F:  Yeah . 
D:  OK . And is the spacing alright or do you think there should be more space between digits and groups ? 
E:  <inbreath>   
F:  OK . 
G:  I mean what do other people think cuz you guys are reading  them . 
D:  Or is that alright ? 
E:  <mouth> <inbreath> 
E:  I think that i it 's fine . I it  it  to me it looks like you 've got the func the idea of grouping and you have the grou the idea of separation and , you know , it 's just a matter of u i the instructions , that 's all . 
D:  OK . 
G:  OK . 
G:  Great . OK . Well let 's give it a try . 
D:  And I think there are about ten different gouping patterns isn't that right , Liz ? 
F:  Let 's try it . 
G:  Righ - right , and you just  they 're randomly <mike noise> generated and randomly assigned to digits . 
D:  That we did . 
E:  <inbreath> 
E:  I did  Mm - hmm . Go ahead . 


F:  So we have  Sorry , I  I was just gonna say , so we have in the vicinity of forty hours 
F:  of  of recordings now . 
F:  And you 're saying two hours , uh , is digits , so that 's roughly the ratio then , something like twenty  twenty to one . Which I guess makes  
D:  Yep . 
F:  makes sense . So if we did another forty hours of recordings then we could get another couple hours of this . 
D:  Right . 
F:  Um , yeah like you say , I think a couple hours for a  for a  for a test  test set 's OK . 
F:  It 'd be nice to get , you know , more later because we 'll  we might use  use this up , uh , in some sense , but  but uh  
E:  Mm - hmm . 
D:  Right . 
E:  <mouth> <inbreath> 
E:  Yeah , I also would like to argue for that cuz it  it seems to me that , um , 
E:  there 's a real strength in having the same test replicated in  a whole bunch of times and adding to that 
E:  basic test bank . Hmm ? Cuz then you have , you know , more and more , 
D:  Right . 
E:  u chances to get away from random errors . 
E:  And I think , 
E:  um , the other thing too is that right now we have sort of a stratified sample with reference to dialect groups , and it might be  there might be an argument to be made for having 
E:  uh f for replicating all of the digits that we 've done , which were done by non - native speakers so that we have a core that totally replicates the original data set , 
E:  which is totally American speakers , and then we have these stratified additional language groups overlapping certain aspects of the database . 
D:  Right . 
D:  I think that uh trying to duplicate , 
D:  spending too much effort trying to duplicate the existing TI - digits 
E:  <clears throat> 
D:  probably isn't too worthwhile because the recording situation is so different . It 's gonna be very hard to be comparable . 
F:  Yeah . 
E:  <mouth> <inbreath> 
E:  Except that if you have the stimuli  comparable , 
E:  then it says something about the  the contribution of setting and  
F:  No it 's  it 's not the same . 
F:  A little bit , but the other differences are so major . 
E:  OK . 
F:  They 're such major sources of variance that it 's  it 's  it 's uh  
D:  Yeah I mean read versus not . 
E:  What 's an example of a  of m some of the other differences ? Any 
E:  other a difference ? 
F:  Well i i individual human glottis <laugh> is going to be different for each one , you know , it 's just  There 's so many things . 
E:  OK . 
E:  OK . 
F:  it 's  it  and  and enunciation . 
D:  Well , and not just that , I mean the uh 
D:  the corpus itself . I mean , we 're collecting it in a read digit in a particular list , and I 'm sure that they 're doing 
D:  more specific stuff . I mean if I remember correctly it was like postman reading zipcodes and things like that . 
F:  TI - digits was ? I thought  I thought it was read . 
D:  I thought so . 
D:  Was it read ? 
F:  Yeah , I think the reading zipcode stuff you 're thinking of would be OGI . 
D:  Oh , I may well be . 
F:  Yeah , no TI - digits was read in th in read in the studio I believe . 
D:  I haven't ever listened to TI - digits . So I don't really know how it compares . 
F:  Yeah . 
E:  <mike noise> 
F:  Yeah . But it  but  
D:  But  but regardless it 's gonna  it 's hard to compare cross - corpus . 
F:  It - it 's different people  is the  is the core thing . And they 're different circumstances with different recording environment and so forth , so it 's  it 's  it 's really pretty different . But I think 
D:  So . 
E:  OK , fine .  
F:  the idea of using a set thing was just to give you some sort of framework , so that even though you couldn't do exact comparisons , it wouldn't be s valid scientifically at least it 'd give you 
E:  <mike noise> 
E:  <mike noise> 
E:  <mike noise> 
F:  some kind of 
F:  uh frame of reference . Uh , you know it 's not  
E:  <mike noise> 
E:  OK . 


B:  Hey Liz , 
E:  <mike noise> 
B:  What  what do the groupings represent ? You said there 's like ten different groupings ? 
G:  Right , just groupings in terms of 
G:  number of groups in a line , and number of digits in a group , and the pattern of groupings . <mike noise> 
B:  Mm - hmm . 
B:  Are the patterns  like are they based on anything or  
E:  <mike noise> 
G:  Um , 
G:  I  I just roughly looked at what kinds of digit strings are out there , and they 're usually grouped into either two , three , or four , 
B:  Oh . 
G:  four digits at a time . And they can have , 
G:  I mean , actually , things are getting longer and longer . <laugh> In the old days you probably only had three sequences , and telephone numbers were less , and so forth . 
G:  So , there 's between , um  
G:  Well if you look at it , there are between like three and five groups , and each one has between two and 
G:  four groupings and  
G:  I purposely didn't want them to look like they were in any kind of pattern . So  
B:  Mmm . 
D:  And which group appears is picked randomly , and what the numbers are are picked randomly . 
G:  <mike noise> Right . 
B:  Mm - hmm . 
D:  So unlike the previous one , which I d simply replicated TI - digits , this is generated randomly . 
B:  Mmm , oh , OK . 
A:  Oh OK . 
F:  <inbreath>  


G:  But I think it 'd be great i to be able to compare digits , whether it 's these digits or TI - digits , 
F:  <cough> 
G:  to speakers , um , and compare that to their spontaneous speech , and then we do need 
G:  you know a fair amount of  of digit data because you might be wearing a different microphone and , I mean  so it 's  it 's nice to have the digits 
D:  Mm - hmm . 
G:  you know , replicated many times . 
G:  Especially for speakers that don't talk a lot . So <laugh> um , for adaptation . No , I 'm serious , so 
D:  Yeah . 
C:  <laugh> 
E:  <mouth> 
F:  Yeah . 
G:  we have a problem with acoustic adaptation , and we 're not using the digit data now , but you know  
D:  Yeah all we have for some people is digits . 
A:  Yeah . 
E:  <breath-laugh> 
D:  Oh , you 're not . 
G:  Not for adaptation , nope . v 
G:  W we 're not  we were running adaptation only on the data that we ran recognition on 
G:  and I 'd  As soon as someone started to read transcript number , that 's read speech and I thought " well , we 're gonna do better on that , 
D:  Oh I see . 
G:  that 's not fair to use " . But , it might be fair to use the data for adaptation , so . 
D:  Oh yeah that 's true , absolutely . 
A:  OK . 
G:  So those speakers who are very quiet ,  shy  r Right  
D:  That would be interesting to see whether that helps . 
A:  <laugh> 
D:  Do you think that would help adapting on  Yeah . Yeah , I have a real problem with that . 
B:  Like Adam ? 
C:  <laugh> 
F:  Yeah . 
G:  Well , it sh I mean it 's the same micropho see the nice thing is we have that in the  in the same meeting , 
B:  <laugh> 
D:  Right . Same  same acoustics , same microphone , same channel . 
G:  and so you don't get  
F:  Yeah . 
A:  Yeah . 
G:  Right , and so I still like the idea of having some kind of  
D:  OK . 
D:  Good . 
G:  digit data .  
F:  Yeah I mean , for the  for the um 
F:  acoustic research , for the signal - processing , 
F:  farfield stuff , 
F:  I see it as  as  as the place that we start . 
F:  But , th I mean , it 'd be nice to have twenty hours of digits data , but  but uh the truth is I 'm hoping that 
F:  we  we through the  the stuff that  that you guys have been doing 
F:  as you continue that , we get , uh , the best we can do on the spontaneous stuff uh , 
F:  uh nearfield , and then um , 
F:  we do a lot of the testing of the algorithms on the digits for the farfield , 
F:  and at some point when we feel it 's mature and we understand what 's going on with it then we  we have to move on 
F:  to the spontaneous data with the farfield . So . 


G:  The only thing that we don't have , I know this 
E:  Great . 
G:  sounds weird , and maybe it 's completely stupid , but we don't have any overlapping digits . 
D:  Yeah , we talked about that a couple times . 
G:  An - yea I know it 's weird , but 
G:  um  
A:  Overlapping digits !  
D:  The  the problem I see with trying to do overlapping digits is the cognitive load . 
F:  <laugh> 
G:  Alright everybody 's laughing . OK . <laugh> 
C:  <laugh> Dueling digits . 
D:  No it 's  it 's not stupid , it 's just  I mean , try to do it . 
G:  I 'm just talkin for the stuff that like Dan Ellis is gonna try , you know , cross - talk cancellation . OK . <laugh>  
D:  I mean , here , let 's try it . You read the last line , I 'll read the first line . 
F:  Let 's try it . 
A:  Oh ! <laugh-breath> 
G:  Wait  oh it  these are all the same forms . OK  So but  
F:  Sixty - one . 
D:  So  so you read the last line , I 'll read the first line . 
G:  So you plu you plug your ears . <laugh> 
F:  No , I 'll p 
D:  Oh I guess if you plug you 're ears you could do it , but then you don't get the  
D:  the same effects . 
A:  Yeah . 
G:  Well , what I mean is actually no 
G:  not the overlaps that are well - governed linguistically , but the actual 
A:  <laugh> 
E:  <breath-laugh> 
G:  fact that there is speech coming from two people and the beam - forming stuf all the acoustic stuff that like Dan Ellis and  and company want to do . 
D:  Yeah . 
D:  Oh I see . 
G:  Digits are nice and well behaved , I mean  
G:  Anyway , it 's just a thought . It  it would go faster . <laugh> 
D:  I guess we could try . We could try doing some . 
B:  <laugh> Parallel . <laugh> It 's the P - make of digit reading . <laugh> 
C:  <laugh> 
D:  <laugh> 
G:  It would take one around  amount of ti  That 's right .  
E:  <breath-laugh> 
D:  Well  Well OK . Well let 's try it . 
C:  <laugh> 
G:  I  I mea I 'm  I was sort of serious , but I really , I mean , I 'm  I don't feel strongly enough that it 's a good idea , so .  
F:  See , y 
D:  You do the last line , I 'll do the first line . 
F:  OK . 
D:  Six one , six two , one eight , eight six , one O .  
F:  Zero zero nine , six six three , nine one nine .  
D:  That 's not bad . 
F:  No , I can do it . 
G:  A and that prosody was great , by the way .  
B:  I couldn't understand a single thing you guys were saying .  <laugh> 
C:  <laugh> 
A:  <laugh> 
D:  <laugh> 
E:  I think it was numbers , but I 'm not sure .  
B:  <laugh> 
D:  <laugh> 
E:  <laugh> 
G:  It  it sort of sounded like a duet , or something .  <laugh> 
D:  <laugh> 
B:  <laugh> 
C:  <laugh> 
A:  Yeah . 
B:  Performance art . 
F:  Alright , let 's try three at once you  you pick one in the middle . 
A:  The Aurora theater . <laugh> 
G:  <laugh> 
G:  OK . 
E:  <laugh> 
A:  <laugh> 
F:  Go . 
D:  Six one , six two , one eight , eight six , one O .  
F:  Zero zero nine , six six three , nine one nine .   
G:  Five , six O six , five five   
A:  <laugh> 
F:  <laugh> 
C:  <laugh> 
G:  <laugh> I 'm sorry . I 'm mean I think it 's doable , I 'm just  
D:  The poor transcribers they 're gonna hate us .  
F:  <laugh> 
A:  <laugh> 
G:  So , we  we could have a round like where you do two at a time , and then the next person picks up when the first guy 's done , or something . Like a , 
C:  <laugh> 
A:  So pairwise . 
F:  Oh like a round , yeah , like in a  a  yeah . 
A:  Yeah , just pairwise , or yeah . 
G:  what do you call it ? Li - a r like  yeah , like that . 
D:  A round . 
F:  Row , row , row your boat .  Yeah . 
C:  Round . 
D:  Mm - hmm .  
F:  OK . 
B:  It 's gonna require some coordination . 
G:  Then it would go like h twice as fast , or  a third as fast . 
C:  <laugh> 
G:  Anyway , it 's just a thought . I 'm actually sort of serious if it would help people do that kind o but the people who wanna work on it we should talk to them . So . 
E:  You have to have a similar pace . 
F:  Yeah . 
E:  <clears throat> 
F:  I don't think we 're gonna collect vast amounts of data that way , but I think having a little bit might at least be fun for somebody like Dan to play around with , yeah . 
D:  Mmm .  
G:  OK .  
A:  <laugh> 
C:  <laugh> 
D:  I think maybe if we wanted to do that we would do it as a separate session , something like that rather than 
G:  Yeah . 
D:  doing it during a real meeting and you know , do two people at a time then three people at a time and things like that . So . 
G:  Can try it out . If we have nothing  if we have no agenda we could do it some week . OK . 
D:  See  see what Dan thinks . 
D:  Yeah , right . 
F:  Yeah , yeah . Spend the whole time reading digits with different qu quantities . 
E:  <breath-laugh> 
C:  <laugh> 


E:  c c Can I can I have an another  another question w about this ? So , um , there are these digits , which are detached digits , but there are other words that contain 
D:  I thought this was gonna be fast . Oh well . 
E:  the same 
E:  general phon phoneme sequences . Like " wonderful " has " one " in it and  and Victor Borge had a  had a piece on this where he inflated the digits . Well , 
E:  I wonder if there 's , um , an if there would be a value in having digits that are in essence embedded in real words to 
E:  compare in terms of like the articulation of " one " in " wonderful " versus " one " as a digit being read . 
F:  That 's " two " bad . 
B:  <laugh> 
E:  <laugh> 
F:  Yeah . 
A:  <laugh> 
F:  <laugh> 
G:  I 'm all " four " it . 
E:  There you go . 
F:  <laugh> 
B:  <laugh> 
A:  <laugh> 
C:  <laugh> 
D:  Not after I " eight " though . <laugh> 
E:  <laugh> 
G:  <laugh> 
A:  <laugh> 
F:  Uh , they don't all work as well , do they ? <laugh> 
F:  Hmm . 
F:  What does nine work in ? Uh , 
D:  Uh .  
C:  Nein ! 
C:  You scream it . <laugh> 
F:  Oh . In German , yeah . <laugh> That 's right ! <laugh> 
D:  Nein ! You have to be German , yeah . 
G:  Oh , oh ! <laugh> 
B:  It 's great for the Germans . <laugh> 
A:  That 's German , yeah . 
E:  <laugh> Nein . <laugh> 
C:  <laugh> 
A:  Yeah . 
D:  Oh ! 
C:  It only sounds w good when you scream it , though . 
C:  So . 
F:  I think everybody 's a little punchy here <laugh> today . Yes . 
G:  <laugh> 
E:  Well , I mean , I just wanted to offer that as a possible task 
E:  because , you know , if we were to each read his embedded 
E:  numbers words in sent in sentences cuz it 's like an entire sketch he does and 
E:  I wouldn't take the inflated version . So he talks about the woman being " two - derful " , and  
E:  and  a But , you know , if it were to be deflated , just the normal word , it would be like a little story that we could read . 
F:  Mm - hmm . 
E:  I don't know if it would be useful for comparison , but it 's embedded numbers . 
F:  Well I don't know . 
D:  I think for something like that we 'd be better off doing like uh TIMIT . 
F:  Well I think the question is what the research is , so I mean , I presume that 
F:  the reason that you wanted to have these 
F:  digits this way is because you wanted to actually do some research 
D:  Hmm . 
F:  looking at the prosodic 
F:  form here .  
G:  Right , yeah . 
F:  Yeah OK . 
F:  So if somebody wanted to do that , if they wanted to look at the  the  the difference of 
F:  the uh phones in the digits in the context of a word versus uh 
F:  the digits  a  a non - digit word versus in digit word , uh that would be a good thing to do , but I think someone would have to express interest in that . 
E:  I see . OK . 
F:  I think , to  
F:  I mean if you were interested in it then we could do it , for instance . 
E:  OK , thank you . Huh . 


D:  Um , 
D:  We have ASR results from Liz , transcript status from Jane , and disk space and storage formats from Don . 
D:  Does  do we have any prefer preference on which way we wanna  we wanna go ? 
G:  Well I was actually gonna skip the ASR results part , in favor of getting the transcription stuff 
D:  Mm - hmm . 
G:  talked about since I think that 's more 
G:  important to moving forward , but I mean Morgan has this paper copy and if people have questions , 
G:  um , it 's pretty preliminary in terms of ASR results because we didn't do anything fancy , but I think 
G:  e just having the results there , and pointing out 
G:  some main conclusions like it 's not the speaking style that differs , it 's the fact that there 's overlap that causes recognition errors . 
G:  And then , the fact that it 's almost all insertion errors , which you would expect but you might also think that 
G:  in the overlapped regions you would get substitutions and so forth , 
G:  um , 
G:  leads us to believe that 
G:  doing a better segmentation , like your channel - based segmentation , or some kind of 
G:  uh , echo cancellation to get basically back down to the individual 
G:  speaker utterances would be probably all that we would need to be able to do good recognition on the  on the close - talking mikes . 
D:  Um , why don't you , if you have a hard copy , why don't you email it 
A:  So these  
G:  So , that 's about the summary  
D:  to the list . 
G:  But this is  Morgan has this paper . I mean he  he  it  it 's that paper . Yeah , yeah . 
A:  Yeah , yeah . 
F:  Yeah , so it 's the same thing ? It 's the same thing I mailed to every 
D:  Oh it 's in the paper . 
D:  OK . 
F:  everybody that w where it was , yeah . 
G:  So , we basically , um , 
D:  OK then , it 's already been mailed . 
G:  did a lot of work on that and it 's  
G:  Let 's see , th 
G:  I guess the other neat thing is it shows for sure w that the lapel , you know within speaker is 
D:  Horrible ?  
G:  bad . And it 's bad because it picks up the overlapping speech . 
A:  So , your  your ASR results were run on the channels synchronized , OK . 
G:  Yes , cuz that 's all that w had been transcribed at the time ,  um 
A:  OK . OK . 
G:  but as we  I mean I wanted to here more about the transcription . If we can get 
G:  the 
G:  channel asynchronous or the  the closer t that would be very interesting for us because we  
A:  Yeah . 
B:  So if  
F:  Yeah , that 's  that 's why I only 
A:  Yeah . 
F:  used the part from use which we had uh about uh about the alt over all the channels or mixed channel rather mixed signal . 
G:  Right . That 's  
A:  Yeah . 
A:  Yeah sure . Yeah . 
A:  Yeah . 
G:  cuz  
B:  So if there was a segment of speech this long 
A:  Yeah . 
D:  And someone said " oh " in the front  in the middle . 
B:  and 
B:  oh and someone said " oh , " the whole thing was passed to the recognizer ? That 's why there 's so many insertion errors ? 
A:  There were several speakers in it , yeah . 
G:  That 's right . In fact I  I pulled out a couple classic examples in case you wanna u use them in your talk of 
C:  Mm - hmm . 
G:  Chuck on the lapel , so Chuck wore the lapel three out of four times . 
E:  <inbreath> 
C:  Mmm . 
D:  I noticed that Chuck was wearing the lapel a lot . 
G:  Um , yeah , and I wore the lapel once , and for me the lapel was OK . I mean I still  
B:  Early on , yeah . 
C:  <clears throat> 
G:  and I don't know why . I 'm  But 
G:  um , 
G:  for you it was  Or who was next to me or something like that . 
D:  Probably how you wear it  wore it I would guess . 
C:  Yeah , where you were sitting probably affected it . 
A:  Yeah . 
G:  Right , but when Chuck wore the lapel and Morgan was talking there 're a couple really long utterances where Chuck is 
A:  <laugh> 
G:  saying a few things inside , and it 's picking up all of Morgan 's words pretty well 
D:  <laugh> 
G:  and so the rec you know , there 're error rates because of insertion  
G:  Insertions aren't bounded , so with a one - word utterance and ten insertions you know you got huge error rate . 
D:  Uh - huh . 
A:  Yeah . 
G:  And that 's  that 's where the problems come in . So I this is sort of what we expected , but it 's nice to be able to  to show it . 
D:  Right . 


G:  And also I just wanted to mention briefly that , um , 
G:  uh Andreas and I called up Dan Ellis who 's still stuck in Switzerland , and we were 
A:  <laugh> 
G:  gonna ask him if  if there 're  
G:  you know , what 's out there in terms of echo cancellation and things like that . Not that we were gonna do it , but we wanted to know 
D:  And he said , " Lots lots lots lots . "  
G:  what would need to be done . And 
G:  he  We 've given him the data we have so far , so these sychronous cases where there are overlap . 
A:  Yep . 
G:  And he 's gonna look into trying to run 
G:  some things that are out there and 
G:  see how well it can do 
G:  because right now we 're not able to actually report on recognition in a real paper , like a Eurospeech paper , because it would look sort of premature . 
B:  So  
B:  So  
B:  So the idea is that you would take this big hunk where somebody 's only speaking 
B:  a small amount in it , and then try to figure out 
B:  where they 're speaking  based on 
G:  Right . Or who 's  At any point in time who 's the foreground speaker , who 's the background speaker . 
B:  the other peopl  
B:  I thought we were just gonna move the boundaries in . 
A:  So yeah  
G:  So . 
A:  Yeah , should it  
D:  Well that 's with the hand stuff . 
G:  So there 's like  
D:  But how would you do that automatically ? 
G:  Well ther there 's  
B:  Right . 
A:  Uh , I 've actually done some experiments with cross - correlation and it seems to work pretty well to  to get rid of those  those overlaps , yeah . 
F:  Mm - hmm . 
D:  I mean that that 's the sort of thing that you would do . So . 
G:  Yeah . Yeah . Exactly , so it 's  it 's a  
B:  So why do you want to do echo cancellation ? 
G:  Um , it would be techniques used from adaptive  adaptive echo cancellation which I don't know enough about to talk about . Um . 
B:  Uh - huh . 
F:  It  just  it just to r to remove cross - talk . Yeah . 
G:  But , right , um , and that would be similar to what you 're also trying to do , but using 
C:  Yeah . 
G:  um , you know , more than energy  I  I don't know 
A:  Yeah . 
G:  what exactly would go into it . So the idea is to basically run this on the whole meeting . 
A:  Yeah , sure . 
B:  So it would be  
G:  and get the locations , which gives you also the time boundaries 
B:  OK . So do sort of what he 's already  what he 's trying to do . 
G:  of the individual speak 
G:  Right . Except that there are many techniques for the kinds of cues , um , that you can use to do that . 
B:  OK , I s I see . 
A:  Yeah , in another way , yeah . 
A:  Yeah . 
B:  Yeah . 
B:  I see . 
F:  Yeah , Dave  Dave uh is , um , also gonna be doin usin playing around with echo cancellation for the nearfield farfield stuff , so we 'll be  
G:  So . 
G:  And I guess Espen ? This  is  uh  is he here too ? May also be working  So it would just be ver that 's really the next step because we can't 
F:  Yeah . 
G:  do too much , you know , on term in terms of recognition results knowing that this is a big problem 
B:  Mm - hmm . 
G:  um , until we can do that kind of processing . 
G:  And so , once we have some  
A:  OK . 
A:  Yeah I 'm working on it . <laugh> 
G:  some of yours , and @ @ we 'll move on . 
B:  I think this also ties into one of the things that Jane is gonna talk about too . 
D:  Um , 
G:  OK .  
E:  Mm - hmm . Mm - hmm . <mike noise> 


D:  I also wanted to say I have done all this chopping up of digits , so I have some naming conventions that we should try to agree on . 
G:  Oh right . Yeah . Right . Definitely  
D:  So let 's do that off - line , we don't need to do it during the meeting . 
C:  OK . 
G:  Uh , and Don should  
D:  And  and I have scripts that will extract it out from " key " files and  
D:  and do all the naming automatically , so you don't have to do it by hand . 
G:  OK . 
C:  Alright . 
G:  Great . So that that 's it for the  
C:  You 've compiled the list of , uh , speaker names ? 
G:  Speakers and   OK . 
D:  Mm - hmm . 
C:  Not names , but 
D:  Yep . Yeah , names  names in the  names to I Ds , so you 
C:  I Ds . 
C:  OK . 
G:  Great . 
D:  and it does all sorts of matches because the way people filled out names is different on every single file so it does a very fuzzy sort of match . 
G:  Right . 
C:  Cool . 
G:  So at this point we can sort of finalize the naming , and so forth , and we 're gonna basically re 
D:  Yep . 
C:  Mm - hmm . 
G:  rewrite out these waveforms that we did because as you notice in the paper your " M O - four " in one meeting and " M O - two " in another meeting and it 's  we just need to standardize the 
C:  Yeah . 
C:  That was my fault .  <laugh> 
G:  um , no it 's  it 's  
F:  No , I didn't notice that actually . @ @ 
G:  um , that 's why those comments are s <laugh> are in there . So  
C:  <laugh> 
C:  Yeah . Then disregard it then . <laugh> 
D:  Yep . So th I now have a script that you can just say basically 
G:  Right . 
F:  Yeah . 
G:  OK . 
D:  look up Morgan , and it will give you his ID . So . 
G:  Great , great . Terrific . 


C:  OK . 
D:  Um , 
D:  alright . 
D:  Do we  
D:  Don , you had disk space and storage formats .  Is that something we need to talk about at the meeting ,  or should you just talk with Chuck 
C:  Um , 
D:  at some other time ? 
D:  So remind me afterward and I 'll  
G:  And  
D:  and we 'll look at your disk and see where to put stuff . 
C:  OK . 
C:  Alright . 
C:  I mean , I could just u do a DU on it right ? And just see which  how much is on each  
D:  Yep . 
C:  So . 
D:  Each partition . And you wanna use , either XA or scratch . 
C:  OK . 
D:  Well X question mark , anything starting with X is scratch . 
C:  OK . 
E:  With two  two digits . 
D:  Two digits , right , XA , XB , XC . 


C:  I had some general questions just about 
C:  the compression algorithms of shortening waveforms and I don't know exactly who to ask . I thought that maybe you would be the  
C:  the person to talk to . So , is it a lossless compression  when you compress , so  
D:  Mm - hmm . 
D:  Entropy coding . So . 
C:  It just uses entropy coding ? OK . So , I mean , I guess my question would be is I just got this new eighteen gig drive installed . 
G:  <laugh> 
C:  Um , yeah , which is  
D:  And I assume half of it is scratch and half of it is  ?  
C:  I 'm not exactly sure how they partitioned it . But um , 
D:  Probably , yeah . 
F:  That 's typical , huh .   
C:  yeah , I don't know what 's typical here , but um , 
C:  it 's local though , so  
D:  That doesn't matter . 
C:  But  
D:  You can access it from anywhere in ICSI . 
C:  OK . 
F:  In fact , this is an eighteen gig drive ,  or is it a thirty six gig drive with eighteen  
C:  Alright . How do you do that ? 
D:  N  
G:  Eigh - eighteen . It was a spare that Dave had around  
C:  Eighteen . 
F:  Oh OK . 
D:  Slash N slash machine name , slash X A in all likelihood . 
C:  Oh I see . OK . Alright , I did know that . 
D:  Um , so the  the only question is how much of it  The distinction between scratch and non - scratch is whether it 's backed up or not . 
C:  Mm - hmm . 
C:  Right . 
D:  So what you wanna do is use the scratch for stuff that you can regenerate . 
C:  OK . 
C:  <inbreath>  
D:  So , 
D:  the stuff that isn't backed up is not a big deal because disks don't crash very frequently , as long as you can regenerate it . 
C:  Right . 
C:  Right . I mean all of this stuff can be regenerated , it 's just a question  
G:  Yeah it 's  
G:  Well the  
D:  Then put it all on scratch because we 're  ICSI is  is bottlenecked by backup . 
G:  Yeah . 
E:  Mm - hmm , very good point . <mike noise> 
G:  Well I 'd leave all the  All the transcript stuff shouldn't  should be backed up , but all the waveform   
C:  OK . 
D:  So we wanna put  
E:  Mm - hmm . 
E:  <long breath> 
C:  Yeah , I guess  
G:  Sound files should not be backed up , the ones that you write out . 
C:  Right . 


C:  OK . So , I mean , I guess th the other question was then , 
C:  should we shorten them , downsample them , or keep them in their original form ? 
C:  Um  
D:  It just depends on your tools . 
D:  I mean , because it 's not backed up and it 's just on scratch , if your sc tools can't take shortened format , I would leave them expanded , 
C:  Right . 
D:  so you don't have to unshorten them every single time you wanna do anything . 
C:  OK . 
G:  We can downsample them , 
C:  Do you think that 'd be OK ? 
G:  so . 
G:  Yeah . 
C:  To downsample them ? 
G:  Yeah , we get the same performance . I mean the r the front - end on the SRI recognizer just downsamples them on the fly , so  
C:  OK . 
C:  Yeah , I guess the only argument against downsampling is to preserve just the original files in case we want to experiment with different filtering techniques . 
G:  So that 's   
F:  I  I  I 'm sorry  Yeah , l I mean over all our data , we  we want to not downsample . 
G:  Yeah , if 
G:  fe 
G:  You 'd  you wanna not . OK . So we 're  what we 're doing is we 're writing out  
C:  <inbreath> <mouth>  
F:  Yeah . 
G:  I mean , this is just a question .  
G:  We 're writing out these individual 
G:  segments , that wherever there 's a time boundary from Thilo , or  or Jane 's transcribers , you know , we  we chop it  there . 
C:  <long breath> 
F:  Yeah . 
F:  Mm - hmm . 
G:  And the reason is so that we can feed it to the recognizer , and throw out ones that we 're not using and so forth . 
F:  Mm - hmm . 
F:  Yeah . 
G:  And those are the ones that we 're storing . 
D:  Yeah , as I said , since that 's  it 's regeneratable , what I would do is take  
G:  So  
G:  Yeah . 
D:  downsample it , 
D:  and compress it however you 're e the SRI recognizer wants to take it in . 
G:  Yeah . 
G:  So we can't shorten them , but we can downsample them . So . 
F:  ye 
C:  Right . 
F:  Yeah , I mean  yeah , I 'm sorry . As  yeah , as long as there is a  a form that we can come from again , 
C:  r 
C:  Yeah . 
F:  that is not downsampled ,  then , 
G:  Oh yeah th 
C:  Yeah those are gonna be kept . 
G:  Yeah . 
G:  Yeah . 
G:  That  that 's why we need more disk space cuz we 're basically duplicating the originals , um  
F:  uuu  <laugh> 
F:  Yeah . Then it 's fine . But for  for  fu future research we 'll be doing it with different microphone positions and so on we would like to  
D:  Right . 
G:  Oh yeah . No . We always have the original long ones . 
D:  Yep . 
C:  Right . 
F:  <mouth> <inbreath>  
F:  Yeah . 


B:  So the SRI front - end won't take a uh  an  an  a large audio file name and then a  
B:  a list of segments to chop out  
B:  from that large audio file ?  They actually have to be chopped out already ?  
G:  Um , it 's better if they 're chopped out , and  and it  it will be  
B:  Uh - huh . 
G:  yeah , y we could probably write something to do that ,  but it 's actually convenient to have them chopped out cuz you can run them , 
G:  you know , in different orders . You c you can actually move them around . 
D:  And that 's the whole point about the naming conventions is that you could 
G:  Uh , you can get rid of  
G:  Yeah , it it 's a lot faster .  
D:  run all the English speaking ,  
D:  all the native speakers , and all the non - native speakers , and all the men , and all the women . Yeah . 
G:  Right . 
G:  You can grab everything with the word " the " in it , and it 's   
G:  That 's a lot quicker than actually trying to access the wavefile each time , find the time boundaries and  
G:  So in principle , yeah , you could do that , but it 's  
B:  I don't  I don't think that 's really right . 
G:  but it 's um  
D:  <laugh> 
D:  " That 's just not right , man . "   
B:  <laugh> 
C:  <laugh> 
G:  These are long  These are long  You know . This is an hour of speech . 
D:  The  the point  
D:  So  so s For example , what if you wanted to run  
D:  run all the native speakers . 
D:  Right , so if  if you did it that way you would have to generate a program that looks in the database somewhere , extracts out the language , finds the time - marks for that particular one , do it that way . 
D:  The way they 're doing it , you have that already extracted and it 's embedded in the file name . 
D:  And so , you know , you just say  
G:  We - yeah that 's  so that 's part of it is  
D:  y so you just say you know " asterisk E asterisk dot wave " , and you get what you want . 
G:  Right . 
G:  And the other part is just that once they 're written out it  it is a lot faster to  
G:  to process them . 
D:  Rather than doing seeks 
G:  So . 
D:  through the file . 
G:  Otherwise , you 're just accessing  
D:  This is all just temporary access , so I don't  I think  it 's all just  It 's fine . You know . 
D:  Fine to do it however is convenient . 
G:  Right . 
F:  I mean it just depends how big the file is . If the file sits in memory you can do extremely fast seeks but . 
G:  Right .  
G:  <inbreath> 
G:  The other thing is that , believe it or not  
F:  <laugh> 
D:  Yeah and they don't . 
G:  I mean , we have some  
D:  <laugh> 
D:  Two gig ? 
G:  So we 're also looking at these in Waves like for the alignments and so forth . 
G:  You can't load an hour of speech into X Waves . 
F:  Yeah . 
G:  You need to s have these small files , and in fact , even for the Transcriber program 
E:  <long breath> 
D:  Yes you can . 
G:  Um  
B:  Yeah , you  you can give Waves a start and an end time . 
G:  Yeah , if you try to load s really long waveform into X Waves , you 'll be waiting there for  
B:  And middle . 
B:  No , I  I 'm not suggesting you load a long wave file , I 'm just saying you give it a start and an end time . And it 'll just 
G:  Oh - 
D:  I th 
B:  go and pull out that section . 
D:  w The transcribers didn't have any problem with that did they Jane ?  
E:  What 's th u w in what respect ? 
G:  Loading the long  
D:  They loaded  they loaded the long 
A:  No , with the Transcriber tool , it 's no problem . 
D:  long files into X Waves . 
G:  It takes a very long ti 
E:  In the  in  
A:  Yeah just to load a transcription 
E:  Mm - hmm . 
A:  @ @ 
G:  Right . 
G:  It takes a l very long time . 
A:  takes a long time , but not for the wavefile . The wavefile is there immediately . 
E:  Mm - hmm . 
E:  Yeah . 
D:  Are you talking about Transcriber or X Waves ? 
G:  Huh . 
A:  Yeah . 
A:  Oh , I 'm tr talking about Transcriber . 
G:  Actually , 
G:  you 're talking about Transcriber , right ? 
A:  Yeah . 
E:  It was also true of the digits task which was X Waves .  
D:  Because  
D:  because i we used X Waves to do the digits . 
E:  Yeah . 
D:  And they were loading the full mixed files then , and it didn't seem to be any problem . 
E:  Very quickly .  
E:  I agree . 
G:  Huh . 
G:  Well we  we have a problem with that , 
G:  you know , time - wise on a  
G:  It - it 's a lot slower to load in a long file , and also to check the file ,  so if you have a 
D:  Hmm . 
D:  Seemed really fast . 
G:  transcript , um , 
D:  Well regardless , it 's  
G:  I mean it 's  
F:  Yeah . 
G:  I  I think 
G:  overall you could get everything to work by 
G:  accessing the same waveform and trying to find two  you know , the begin and end times . 
G:  Um , 
G:  but I think it 's more efficient , if we have the storage space , to have the small ones . 
D:  and , it 's no problem , right ? Because it 's not backed up . 
G:  Yeah , it 's   
G:  Yeah .  
G:  It 's  it 's just  
D:  So we just  
D:  If we don't have a spare disk sitting around we go out and we buy ourselves an eighty gigabyte drive and make it all scratch space . 
A:  <laugh> 
D:  You know , it 's not a big deal . 
E:  You 're right about the backup being  a bottleneck . It 's good to 
G:  Right . 
G:  Yeah , so these wouldn't be backed up , the  
E:  think towards scratch . 
E:  Yeah . 
F:  Yep .  
G:  Right . 


F:  So , @ @ . 
D:  OK ? Jane ? 
E:  OK . So I got a little print - out here . So three on this side , three on this side .  
D:  <laugh> 
E:  And I stapled them . 
E:  OK . 
E:  Alright so , first of all , um , there was a  
D:  <laugh> 
E:  an interest in the transcribe transcription , uh , checking procedures and  <inbreath> 
E:  and I can <outbreath> tell you first , uh , to go through the steps although you 've probably seen them . 
E:  <breath> 
E:  Um , as you might imagine , when you 're dealing with , 
E:  um , 
E:  r 
E:  really c a fair number of words , and uh , 
E:  @ @  
E:  natural speech which means s self - repairs and all these other factors , that there 're 
E:  lots of things to be , 
E:  um , s standardized and streamlined and checked on . 
E:  <breath> 
E:  And , um , 
E:  so , 
E:  I did a bunch of 
E:  checks , and the first thing I did was obviously a spell - check . And at that point I discovered certain things like , 
E:  um , " accommodate " with one " M " , that kind of thing . 
E:  And then , in addition to that , I did an exhaustive listing of the forms in the data file , which included n detecting things like f faulty punctuation and things  Yeah ?  
B:  I 'm  I 'm sorry to interrupt you could  could I just back up a little bit and  
E:  Sure , please , yeah , please , please . Yeah , yeah , yeah . 
B:  So you 're doing these  So  the whole process is that the transcribers get the conversation and they do their pass over it . 
E:  Yes . 
B:  And then when they 're finished with it , it comes to you , and you begin these sanit these quality checks . OK . OK . 
E:  That 's right . 
E:  Exactly . I do these checks . Uh - huh . Exactly . 
E:  Yeah . Thank you . 
E:  And so , uh , I do a  an exhaustive listing of the forms   
E:  Actually , I will go through this in  in order , so if  if we could maybe wait and stick 
E:  keep that for a second cuz we 're not ready for that . 
D:  So on the fifth page , seven down   <laugh> 
E:  Yeah , yeah , yeah , yeah . Exactly ! Exactly ! <laugh> 
B:  <laugh> 
A:  <laugh> 
E:  Alright so , 
E:  <breath> 
E:  a spelling check first then an exhaustive listing of the , uh  all the forms in the data with the punctuation attached 
E:  and at that point I pick up things like , 
E:  oh , you know , word followed by two commas . And th and 
E:  then another check involves , uh , being sure that every utterance has an identifiable speaker . 
E:  And if not , then that gets checked . 
E:  So the pronounceable acronyms get underscores , the things in curly brackets are viewed as comments . There 're comments of four types . So this is a good time to introduce that . 
E:  The four types . w And maybe we 'll expand that but the  but the comments are , um , of four types mainly right now . One of them is , um , 
D:  Um  
F:  <mike noise> 
F:  <yawn> 
E:  the gloss type we just mentioned . 
D:  Can  ca 
E:  Another type is , um  
D:  So a are we done with acronyms ? Cuz I had a question on what  what this meant . 
E:  I 'm still doing the overview . I haven't actually gotten here yet . <laugh> OK so , gloss is things like replacing the full form 
D:  Oh I 'm sorry . 
B:  <laugh> 
C:  <laugh> 
A:  <laugh> 
E:  u with the , um , 
E:  more abbreviated one to the left . 
E:  Uh , then you have if it 's  uh , there 're a couple different types of 
E:  elements that can happen that aren't really 
E:  properly words , and wo some of them are laughs and breathes , so we have  uh that 's prepended with a v a tag of " VOC " . 
A:  Whew !  
A:  @ @  
E:  And the non - vocal ones are like door - slams and tappings , and that 's prepended with a 
E:  no non - vocalization . 
B:  So then it  just an ending curly brace there , or is there something else in there . 
E:  <breath> 
E:  Oh yeah , so i e this would  
E:  Let 's just take one example . 
D:  A comment , basically . 
B:  Oh , oh , oh . 
E:  And then the no non - vocalization would be something like a door - slam . 
E:  They always end . So it 's like they 're paired curly brackets . And then the third type right now , 
E:  <mouth> 
E:  uh , is  m things that fall in the category of comments about what 's happening . So it could be something like , 
E:  you know , " referring to so - and - so " , " talking about such - and - such " , 
E:  uh , you know , " looking at so - and - so " .  Yeah .  
B:  So on the m 
B:  on the middle t So , in the first case that gloss applies to the word to the left . But in the middle two  
E:  Yeah , and this gets substituted here . 
D:  They 're impulsive . 
B:  Th - it 's not applying to anything , right ? OK . 
E:  Huh - uh .  
E:  No , they 're events . 
E:  They 're actually  They have the status of events . 
B:  OK . 
D:  Well the " QUAL " can be  The " QUAL " is applying to the left . 
B:  Right , I just meant the middle two ones , yeah . 
D:  Yep . 
E:  Well , and actually , um , it is true that , with respect to " laugh " , there 's another one 
E:  which is " while laughing " , and that is , uh , i i An argument could be made for this  
D:  " While laughing " . 
E:  tur turning that into a qualitative statement because it 's talking about the thing that preceded it , but at present we haven't been , um , 
E:  uh , coding the exact scope of laughing , you know , 
E:  and so to have " while laughing " , you know that it happened somewhere in there which could well mean that it occurred 
E:  separately and following , or , you know , including some of the utterances to the left . Haven't been awfully precise about that , but I have here , 
E:  now we 're about to get to the  to this now ,  I have frequencies . So you 'll see how often these different things occur . But , um , 
E:  uh , the very front page deals with this , uh , final 
E:  c pa uh , uh , aspect of the standardization which has to do with 
E:  the spoken forms like " mm - hmm " and " mm - hmm " and " ha " and " uh - uh " and 
E:  all these different types . And , um , uh , someone pointed out to me , 
E:  this might have been Chuck ,  about , um  about how a recognizer , if it 's looking for " mm - hmmm " with three M 's , <laugh> and it 's transcribed with two M 's , <laugh> 
F:  <mike noise> 
E:  that it might  uh , that it might increase the error rate which is  which would really be a shame because 
E:  um , I p I personally w would not be able to make a claim that those are dr dramatically different items . 
D:  <laugh> 
B:  <laugh> 
E:  So , right now I 've standardized across all the existing data with these spoken forms . I  I should say 
D:  Oh good . So it 's a small list .  
E:  all existing data except thirty minutes which got found today . So , I 'm gonna  <laugh> I 'm gonna  <laugh> I 'm gonna check  
D:  <laugh> That  that 's known as " found data " . <laugh> 
C:  <laugh> 
A:  <laugh> 
E:  <laugh> Yeah , yeah . Acsu - actually yeah . I got  It was stored in a place I didn't expect ,  
B:  <laugh> 
C:  <laugh> 
F:  <laugh> 
C:  It 's like the z Zapruder Film . 
E:  so  and  and um , 
C:  <laugh> 
E:  w we , uh , sh yea reconstructed how that happened . <laugh> 
F:  I wanna work with lost data . 
D:  Yeah . It 's much easier .  
C:  <laugh> 
F:  <laugh> 
E:  And this is  this 'll be great . So I 'll  I 'll be able to get through that tonight , and then everyth i well , actually later today probably . 
D:  Hmm . 
E:  And so then we 'll have everything following these conventions . But you notice it 's really rather a small set 
E:  of these kinds of things . And I made it so that these are , um , with a couple exceptions but , things that you wouldn't find in the spell - checker so that they 'll show up really easily . 
D:  Yeah . 
F:  <yawn> 
F:  <mike noise> 
E:  And , um  
C:  Jane , can I ask you a question ? What 's that very last one correspond to ? I don't even know how to pronounce that . 
E:  Sure . 
E:  Well , yeah . Now that  that s only occurs once , and I 'm thinking of changing that . 
A:  <laugh> 
G:  Yeah . 
G:  Right . 
E:  So - c I haven't listened to it so I don't know . 
D:  <laugh> 
C:  Uh , is that like someone 's like burning or some such thing ? Like their hair 's on fire ? 
E:  I haven't heard it actually . I n I need to listen to that one . 
D:  Ah ! 
C:  <laugh> Uh , it looks like that . 
G:  Actually we  we gave this to our pronunciation person , she 's like , " I don't know what that is either " . So . <laugh> 
A:  It 's the Castle of Ah ! 
C:  <laugh> 
D:  <quiet laugh> 
A:  <laugh> 
E:  Did she hear the th did she actually hear it ? Cuz I haven't heard it . 
G:  No , we just gave her a list of words 
G:  that , you know , weren't in our dictionary and so of course it picked up stuff like this , and she just 
G:  didn't listen so she didn't know . We just  
G:  we 're waiting on that  just to do the alignments . 
E:  Yeah . Yeah I 'm curious to se hear what it is , but I didn't know  wanna change it to something else until I knew . 
G:  Maybe it 's " argh " ? 
C:  Right . 
G:  @ @ <laugh> 
E:  Well , sss ,  you know  
C:  But that 's not really like  
E:  Hhh .  <inbreath> 
G:  Yeah . 
C:  No one really says " argh , " you know , it 's not  
E:  @ @  
G:  Right , no one say <laugh> 
D:  <laugh> 
F:  Well , you just did . 
G:  <laugh> 
B:  <laugh> 
F:  <laugh> 
C:  Well , 
E:  Yeah . <laugh> That 's right . 
D:  @ @  
C:  there 's another  there 's another word error .  
B:  Except for now !  
B:  <laugh> 
D:  Yes , that 's right . We 're gonna have a big problem when we talk about that . 
E:  <laugh> 
C:  <laugh> 
E:  <long breath> 
C:  Cha - ching .  
G:  Ah . 
C:  <laugh> 
B:  We 're gonna never recognize this meeting . 
E:  OK . 
D:  In Monty Python you say " argh " a lot . So . Well , or if you 're a C programmer . 
B:  <laugh> 
F:  <laugh> 
C:  Oh yeah ? 
A:  <laugh> 
E:  <inbreath>  
C:  Mmm . 
E:  Yeah , that 's right . That 's right . 
G:  <laugh> 
F:  Yeah . 
D:  You say arg - C and arg - V all the time . 
B:  <laugh> 
A:  <laugh> 
F:  Yeah 
C:  That 's true . 
G:  But it has a different prosody . 
E:  Yeah . 
F:  Arg . 
D:  It does . 
F:  Arg  arg - max , arg - min , yeah . 
C:  Mm - hmm . 
D:  Ah ! 
E:  Uh ,   
E:  functionally pretty , you know , also   It was fascinating , I was listening to some of these , uh , I guess two nights ago , and it 's just hilarious to liste to  to do a search for the " mm - hmm 's " . 
E:  And you get " mm - hmm "  and diff everybody 's doing it . 
D:  And just listen to them ? Yeah . 
E:  Just  I wanted to say  I w think it would be fun to make a montage of it because there 's a " Mm - hmm . Mm - hmm . Mm - hmm . "  
D:  <laugh> 
B:  <laugh> 
C:  <laugh> 
A:  <laugh> 
D:  Performance art , just extract them all . 
B:  <laugh> 
E:  <laugh> 
G:  Right . 
A:  <laugh> 
E:  It 's really  it 's really fun to listen to . 
B:  Morgan can make a song out of it . <laugh> 
D:  <laugh> 
E:  All these different vocal tracts , you know , but it 's  it 's the same item . It 's very interesting . OK . 
C:  Is this after  like did you do some uh replacements for all the different form of " OK " to this ? OK . 
F:  Seven hundred eighty . 
E:  Yeah . Of " OK " , yes . Mm - hmm . So that 's the single existing convention for " OK " . 
B:  Wait a minute , w s 
F:  So now we 're up to seven hundred and eighty eight . <laugh> 
D:  <laugh> 
E:  Yeah that 's   
C:  Although , what 's  there 's one with a slash after it . 
E:  <breath> Yeah . That 's  that 's  I looked for that one . I actually explicitly looked for that one , and I think that , um , 
C:  That 's kind of disturbing . 
D:  <door closes> 
D:  Yeah , we 'll have to look at it you know . 
G:  Yeah . 
C:  Anyway . Mm - hmm . 
E:  I  I 'm not exactly sure about that . 
B:  Was that somewhere where they were gonna say " new speaker " or something ? 
E:  No , I looked for that , but that doesn't actually exist . And it may be , I don't  I can't explain that . 
C:  That 's alright . I 'm just pointing that out . There 's  
E:  I i it 's the only  
E:  it 's the only pattern that has a slash after it , and I think it 's  it 's an epiphenomenon . 
G:  Well there 's not @ @ .  
D:  So I 'll just  I was just looking at the bottom of page three there , is that " to be " or " not to be " . <laugh> 
B:  <laugh> 
E:  Yeah . <laugh> Oh that 's cute . That 's funny . <laugh> 
F:  <laugh> 
B:  <breath> There 's no tilde in front of it , so . <laugh> 
D:  <laugh> 
E:  Yeah . 
D:  <breath> 
E:  OK . 
D:  OK anyways , sorry .  
C:  <outbreath> 
E:  There is th one  
D:  " Try to stay on topic , Adam . " <laugh> 
E:  Y well , no , that 's r 
E:  that 's legitimate . So now , uh , comments , you can see they 're listed again , same deal , with exhaustive listing of everything found in everything except for these final th 
F:  Don and I were just noticing , love this one over on page three , " vocal  vocal gesture mimicking sound of screwing something into head to hold mike in place . "  <laugh> 
C:  <laugh> 
C:  <laugh> 
E:  <laugh> 
G:  <laugh> 
C:  <laugh> 
D:  It 's this , " rrre - rrre - rrre " .  
B:  <laugh> 
C:  That 's great . 
C:  <clears throat> 
D:  <laugh> 
E:  <laugh> 
D:  It was me . <laugh> 
E:  It was ! In fact , it was ! 
E:  Yeah ! 
D:  A lot of these are me the  the " beep is said with a high pit high pitch and lengthening . " 
E:  He  he s he said  he said get  
A:  <laugh> To head .  
C:  <laugh> 
E:  Yeah , that 's it . 
D:  That was the  I was imitating uh , beeping out  
F:  Beep .  
E:  Perfect . Yeah that 's it . That 's it . 
G:  Oh there is something spelled out " BEEEEEEP "  
F:  Yeah . 
C:  Um  
C:  Yeah .  
E:  Yeah , that 's  that 's been changed . 
G:  in the old  
G:  Thank you . <laugh> 
D:  <laugh> 
F:  <laugh> 
G:  Because he was saying , " How many E 's do I have to allow for ? " <laugh> 
D:  What I meant was " beep " .  
C:  You need a lot of  
B:  <laugh> 
C:  You need a lot of qualification Adam .  <laugh> 
E:  That 's been changed . So , exactly , that 's where the lengthening comment c came in . 
D:  I guess so . Anyway . 
G:  Right , thanks , yeah . 
C:  Subtext . 
E:  s chan brought it down . 
D:  So they 're vocalization , 
G:  Right . 
E:  And those of course get  get picked up in the frequency check because you see " beep "  and you know  I mean it gets kicked out in the spelling , and it also gets kicked out in the , uh , freq frequency listing . 
D:  glosses . 
G:  Right . 
G:  Right . 
G:  Right . 
E:  I have the  there 're various things like " breathe " versus " breath " versus " inhale " and , hhh ,  
E:  you know , I don't know . I  I think they don't have any implications for anything else so it 's like I 'm tempted to leave them for now an and  
E:  It 's easy enough to find them when they 're in curly brackets . We can always get an exhaustive listing of these things and find them and change them . 
G:  Yeah . 
F:  " Sings finale - type song " that 's  that 's good . <laugh> 
G:  Yeah . <laugh> 
D:  <laugh> 
C:  Yeah , that was in the first meeting . 
D:  Um , 
E:  Yeah , but I don't actually remember what it was . But that was  Eric did that . Yeah . 
D:  <laugh> 
F:  Yeah .  
F:  <laugh> 
D:  So on  
F:  Tah - dah !  I don't know . Something like that maybe , yeah . <laugh> 
D:  <laugh> 
E:  I think maybe something like that . 
E:  Well , that 'd qualify . <laugh> 
A:  <noise> 
C:  <laugh> 


E:  Then there 's this issue of glossing s w so - called " spoken - forms " . 
E:  So there  
E:  mo for the most part , we 're keeping it standard wo word level transcription . But there 's  
E:  w And that that 's done with the assumption that  pronunciation variants can be handled . So for things like " and " , 
E:  the fact that someone doesn't say the " D " , 
E:  uh that 's not important enough to capture in the transcription because a  a good pronunciation , uh , 
E:  you know , model would be able to handle that . However , things like " cuz " where you 're lacking an entire very prominent first syllable , 
E:  and furthermore , it 's a form that 's specific to spoken language , 
E:  those are r reasons  f for those reasons I  I kept that separate , and used the convention of using " CUZ " for that form , 
E:  however , glossing it so that it 's possible with the script to plug in the full 
E:  orthographic form for that one , and a couple of others , not many . So " wanna " is another one , " going  " uh , " gonna " is another one , 
E:  with just the assumption , again , that this  th these are things which it 's not really fair to a c consider  expect that  a pronunciation model , to handle . 
E:  And Chuck , you in you indicated that " cuz " is  
E:  is one of those that 's handled in a different way also , didn't you ? Did I  
B:  I don't remember . 
E:  OK . So  so it might not have been  <laugh> It might not have been you , but someone told me that in fact " cuz " is treated differently 
B:  Hmm . 
E:  in , um , i u in this context because of that r reason that , um , it 's a little bit farther than a pronunciation variant . 
E:  OK , so after that , let 's see , um . <outbreath> 
B:  So that was part of the spell - check ,  or was that  that was after the spell - check ? 
E:  Well so when I get the exhau So the spell - check picks up those words because they 're not in the dictionary . So it gets " cuz " and " wanna " and that  
B:  Uh - huh . 
D:  And then you gloss them ? 
E:  Yeah , mm - hmm . Run it through  I have a sed  You know , so I do sed script saying whenever you see " gonna " 
E:  you know , " convert it to gonna " , you know , " gloss equals quote going - to quote " , 
E:  you know . And with all these things being in curly brackets so they 're always distinctive . OK , I also wrote a script which will , 
D:  Mm - hmm . 
E:  um , retrieve anything in curly brackets , 
E:  <mouth> 
E:  or anything which I 've classified as an acronym , 
E:  and  
E:  a pronounced acronym . 
E:  And the way I tag ac pronounced acronyms is that 
E:  I have underscores between the components . So if it 's " ACL " 
E:  then it 's " A " underscore " C " underscore " L " . 
E:  And the th 
D:  And so  so your list here , are these ones that actually occurred in the meetings ? 
E:  Yes . Uh - huh , yeah . 
D:  Whew !  
E:  OK , so now . 
E:  Uh and  a 
D:  We are acronym - loaded . 
G:  Um , can I ask a question about the glossing , uh before we go on ? So , 
E:  Yeah . 
G:  for a word like " because " 
G:  is it that it 's always predictably " because " ? 
G:  I mean , is " CUZ " always meaning " because " ? 
E:  Yes , but not the reverse . So sometimes people will say " because " in the meeting , and if  if they actually said " because " , 
E:  then it 's written as " because " with no  w " cuz " doesn't even figure into the equation . 
G:  Beca - because   
F:  But  but in our meetings people don't say " hey cuz how you doing ? " 
G:  Right .  
C:  <laugh> 
E:  <laugh> 
D:  <laugh> 
B:  <laugh> 
F:  <laugh> 
G:  <inbreath> 
G:  Right . 
D:  Except right there . 
E:  Yeah . 
D:  <very long laugh> 
F:  Yeah . 
G:  Um , so , I guess  So , from the point of view of  
F:  <very long laugh> 
A:  <laugh> 
B:  <laugh> 
E:  That 's a good point . 
G:  The  the only problem is that with  for the recognition we  we map it to " because " , and so if we know that " CUZ "  
D:  <laugh> 
D:  Well , 
E:  That 's fine . Well Don has a script . 
D:  but they have the gloss . You have the gloss form so you always replace it . 
G:  but , we don't  
C:  Yeah . 
E:  Exactly . 
D:  If that 's how  what you wanna do . 
E:  Uh - huh . And Don knows this , and he 's bee he has a glo he has a script that  
C:  Yeah . 
F:  <laugh> 
C:  I replace the " cuz " with " because " if it 's glossed . 
G:  S 
G:  Right . But , 
G:  if it 's  
G:  OK . 
C:  And  
G:  But then there are other glosses that we don't 
G:  replace , right ? 
G:  Because  
E:  Yes . And that 's why there 're different tags on the glosses , 
G:  OK . So , then it 's fine . 
E:  on the different  on the different types of comments , which we 'll  which we 'll see in just a second . 
C:  Right . 
G:  OK . 


G:  So , Jane , what 's the  d I have one question about the 
D:  Maybe he died while dictating . 
E:  so . 
G:  the " EH " versus like the " AH " and the " UH " . 
E:  That 's partly a nonnative - native thing , but I have found " EH " in native speakers too . 
G:  @ @ 
G:  OK . 
E:  But it 's mostly non - native  
A:  H  
G:  S OK . 
B:  That 's " eh " versus " ah " ? 
E:  Eh . 
G:  " Eh , " yeah right , cuz there were  were some speakers that did definite " eh 's " but right now we  
D:  Eh ? 
E:  Mm - hmm . 
B:  They were the Canadians , right ? 
F:  Canadians , yeah , yeah , yeah . 
E:  <laugh> That 's right . 
C:  <laugh> 
G:  <laugh> 
A:  <laugh> 
G:  So , it  it 's actually probably good for us to know the difference between the real " eh " 
F:  <laugh> 
C:  <laugh> 
G:  and the one that 's just like " uh " or transcribed " aaa "  cuz in  like in Switchboard , you would see 
E:  Exactly . 
G:  e all of these forms , but they all were like " uh " . 
B:  <laugh> 
D:  You mean just the single letter " a "  as in the particle ? 
A:  The transcription or  
B:  <cough> 
G:  No , no , I mean like the  the " UH " , or  the " UH " , " EH " , " AH " were all the same . And then , we have this additional non - native version of  
D:  Article . 
E:  " UH " . 
D:  Oh . 
G:  uh , like " eeh " .  
A:  <laugh> 
C:  All the " EH " 's I 've seen have been like that . They 've been like " eh "  like that have bee has been transcribed to " EH " . 
E:  Mm - hmm , that 's right . 
C:  And sometimes it 's stronger , like " eeh "  which is like closer to " EH " . But . 
E:  Mmm . 
G:  Right .  
A:  <laugh> 
B:  <laugh> 
E:  Yeah . 
D:  I 'm just  these poor transcribers , they 're gonna hate this meeting . <laugh> 
C:  I know . We should go off - line . 
A:  <laugh> 
E:  Well , <laugh> we 're not doing  We 're not doing length . 
B:  <laugh> 
F:  Quick Thilo , do a  do a filled pause for us . <laugh> 
D:  <laugh> 
B:  <laugh> 
E:  Yeah , that 's right .  
A:  Ooo  no . 
G:  But you 're a native German speaker so it 's not a  
B:  <laugh> 
E:  <laugh> 
F:  <laugh> 
A:  Yeah .  
G:  not a issue for  It 's only  
A:  <laugh> 
D:  @ @ Them Canadians . <laugh> 
E:  <laugh> 
A:  <laugh> 
G:  Onl - yeah . <mike noise> No , only if you don't have 
F:  <laugh> 
B:  <laugh> 
D:  <laugh> 
G:  lax vowels , I guess . Right . So it 's  like Japanese and Spanish and  
D:  Oh . 
E:  This makes sense . Yeah I  I think you 've  uh - huh , yeah . 
F:  Uh - huh . 
D:  Oh I see . I didn't get that , OK . 
E:  That makes sense . 
G:  <loud outbreath> 
E:  Yeah , and so , you know , I mean , th th I have  there are some , um , Americans who  who are using this " eh " too , and I haven't listened to it systematically , maybe with some of them , uh , they 'd end up being " uh 's " but , uh , I my spot - checking has made me think that we do have " eh " in 
E:  also , um , American e e data represented here . But 
E:  any case , that 's the  this is reduced down from really quite a long a much longer list , and this is 
G:  Yeah this is great . This is really really helpful . 
C:  Mm - hmm . 
D:  Yeah , it 's good , yeah . 


E:  <breath> Uh , then the acronyms y and the ones in parentheses are ones which the transcriber wasn't sure of , and I haven't been able to listen to to  to clarify , but you can see that 
D:  Oh I see . 
E:  the parenthesis convention makes it very easy to find them cuz it 's the only place where  where they 're used . 
D:  o 
D:  How about question mark ? 
A:  The question marks , yeah . What are those ? 
E:  Question mark is punctuation . So it  they said that @ @  
D:  Oh . 
C:  Mm - hmm . 
E:  um , " DC ? " 
D:  So they  so it 's " PLP ? " 
A:  Ah .  
E:  Exactly . <laugh> Exactly . 
A:  <laugh> 
D:  <laugh> 
C:  <laugh> 
E:  <breath> Yeah , so the only  Well , and I do have a stress marker here . Sometimes the contrastive stress is showing up , and , um  
F:  I 'm sorry , I  I got lost here . What - w what 's the difference between the parenthesized acronym and the non - parenthesized ? 
E:  The parenthesized is something that the transcriber thought was ANN , but wasn't entirely sure . 
E:  So I 'd need to go back or someone needs to go back , and say , you know , yes or no , and then get rid of the parentheses . But the parentheses are used only in that context in the transcripts , of 
F:  Ah . 
G:  Right . 
E:  of noti noticing that there 's something uncertain . 
D:  Yeah , P - make is  That 's a good one . That 's correct . 
G:  Yeah I mean cuz they  they have no idea , right . If you hear CTPD , I mean , they do pretty well but it 's  
F:  Yeah . 
C:  Mm - hmm . 
F:  I  I don't recognize a lot of these . I  <laugh> 
G:  you know how are  how are they gonna know ? <mike noise from laugh> 
D:  I know ! I  I was saying that I think a lot of them are the Networks meeting . 
C:  Yeah . <laugh> 
E:  <breath> I think that 's true . Yeah , absolutely . NSA , a lot of these are  are coming from them . I listened to some of that . 
G:  <laugh> 
F:  Maybe . 
G:  Yeah . 
D:  I see a few . 
A:  <laugh> 
D:  Although I see  I see plenty of uh  
C:  Yeah , we don't have that many acronyms comparatively in this meeting . It 's not so bad . 
E:  Yeah . 
E:  Yeah . I agree . 
G:  <mike noise from laugh> Right . <mike noise from laugh> 
E:  And Robustness has a fair amount , but the NSA group is just very very many . 
A:  Yeah . 
C:  Mmm . 
G:  The recognizer , it is funny . Kept getting PTA for PDA . 
B:  <laugh> 
C:  <laugh> That 's not bad . 
G:  This is close , right , and the PTA was in these , uh , topics about children , so , anyway . 
F:  Yeah . 
D:  Yeah , that 's pretty close . 
B:  <laugh> 
E:  Yeah . 
B:  <laugh> 
C:  <laugh> 
E:  That 's interesting . <laugh> 
F:  <laugh> 
B:  <laugh> 
G:  <laugh> Is the P - PTA working ? 
B:  <laugh> 
F:  <laugh> 
E:  Right and sometimes , I mean , you see a couple of these that are actually " OK 's " 
E:  so it 's  it 's  may be that they got to the point where  I mean it was low enough understandable  understandability that they weren't entirely sure the person said " OK . " 
E:  You know , so it isn't really necessarily a 
E:  an undecipherable acronym , but just n needs to be double checked . Now we get to the comments . This  
C:  There 's a lot of " OK 's " .  
F:  The number to the left is the number of incidences ? Uh - huh . 
D:  Count . Yep . 
E:  Number of times out of the entire database , w except for that last thirty minutes I haven't checked yet . 
F:  So CTS is really big here , yeah . 
D:  Yeah , I wonder what it is . <laugh> 
F:  Yeah . 
A:  So what is the difference between " papers rustling " and " rustling papers " ? 
F:  IP , I know what IP is . 
E:  <breath> I 'd have to listen . I  I I agree . I w I 'd like to standardize these down farther but , um , 
E:  uh , 
E:  uh , to me that sounds equivalent . 
A:  Yeah . 
E:  But , I  I 'm a little hesitant to  to collapse across categories unless I actually listen to them . 
A:  Seems so . 
F:  OK . 
D:  Oh I 'm sure we 've said XML more than five times . <laugh> 
A:  <laugh> 
A:  Now it 's at least six times , yeah . <laugh> 
E:  Well , then , at least now . Yeah .  Six . <laugh> 
F:  S s six now , yeah . <laugh> 
D:  <laugh> 
G:  <laugh> 
C:  <laugh> 
F:  <laugh> 
E:  OK well  
F:  Wh - the self - referential aspect of these  these p 
G:  I 'm wai 
D:  Yes , it 's very bad . 
C:  Yeah . 
A:  <laugh> 
G:  Well this is exactly how people will prove that these meetings do differ because we 're recording , right ? 
D:  Yes . 
G:  Y no normally you don't go around saying , " Now you 've said it six times . Now you 've said " <laugh> 
F:  <laugh> 
D:  Yeah  that 's right . 
A:  <laugh> 
C:  <laugh> 
D:  <laugh> 
E:  But did you notice that there were seven hundred and eighty five instances of " OK " ? And that 's just without the  without 
D:  Yep . 
F:  No , I didn't . Yeah . 
A:  Seven hundred eighty - five instances .  
C:  Yeah . 
E:  punc punctuation . Extra forty one if it 's questioned . <laugh> 
D:  And that 's an underestimate cuz they 're 
B:  Where 's that ? 
F:  So th 
D:  Yep . 
E:  On the page two of acronyms . 
F:  Yeah . 


D:  OK so , um , on some of these QUALs , 
E:  thirty minutes . 
E:  Yeah . 
D:  are they really QUALs , or are they glosses ? So like there 's a " QUAL TCL " . 
E:  " TCL " . Where do you see that ? 
D:  Uh  
E:  Oh , oh . The reason is because w it was said " tickle " . 
F:  What 's a QUAL ?  
D:  Oh I see , I see . So it 's not gloss . OK , I see . 
C:  Hmm . 
E:  Yep . 
D:  It wasn't said " TCL " . Of course . 
C:  Sh - shouldn't it be " QUAL TICKLE " or something ? Like  it 's not  
E:  On the  in the actual script  in the actual transcript , I s I  
E:  So this  this happens in the very first one .  
E:  I actually wrote it as " tickle " .  
C:  Mm - hmm . 
C:  OK . 
E:  Because we  they didn't say " TCL " , they said " tickle " . 
C:  Yeah . 
G:  Right .  
E:  And then , following that is " QUAL TCL " . 
C:  Oh I see . OK . 
F:  I f I forget , what 's QUAL ? 
E:  Qual - qualifier . 
B:  It 's just comment about what they said . 
E:  Comment . Comment or contextual comment . 
C:  Yeah . It 's not something you wanna replace  with but   
B:  So they didn't mean " tickle " as in 
F:  Yeah . 
B:  Elmo , they meant " tickle " as in  <laugh> 
A:  Tickle ? 
D:  Yeah . <laugh> 
G:  Huh . 
C:  <laugh> 
E:  <laugh> 
F:  Right . 
A:  <laugh> 
G:  But at some point  I mean , we probably shoul 
D:  We 'll probably add it to the language model . 
G:  But we should add it to the dictionar 
G:  No , to the pronunciation model . 
D:  Yeah . 
D:  What did I say ? 
G:  Language , uh  
A:  To the language model  model .  
D:  Well both . We can go on lan lan add it to both dictionary and language model . 
G:  Oh lan Oh OK - we OK - it 's in the language model , 
B:  Add what , Liz ? 
A:  Yeah . 
E:  <mike noise> 
G:  w yeah , but it so it 's the pronunciation model that has to have a pronunciation of 
G:  " tickle " . 
D:  Well " tickle " was pronounced " tickle " . 
D:  Right ?  
G:  <laugh> 
B:  What are you saying ? 
D:  It 's pronounced the same  it 's pronounced the same as the verb . So I think it 's the language model that makes it different . 
A:  <laugh> " tickle " is pronounced " tickle " ? <laugh> 
G:  I 'm sorry !  
G:  Oh , sorry . What I meant is that there should be a pronunciation 
G:  " tickle " for TCL as a word . And that word in the  in , you know , it stays in the language model wherever it was . 
D:  Oh I see . 
A:  Yeah . 
F:  Mm - hmm . 
D:  Right . Right . 
G:  Yeah you never would put " tickle " in the language model in that form , yeah . 
F:  Right . 
E:  @ @ 
D:  Right . 
G:  Right . There 's actually a bunch of cases like this with people 's names and  
B:  So how w there 'd be a problem for doing the language modeling then with our transcripts the way they are . 
E:  <long breath> 
G:  Yes . Yeah . 
G:  Yeah so th th there there 's a few cases like that where the 
D:  <outbreath> 
G:  um , 
G:  the word needs to be spelled out in  in a 
G:  consistent way as it would appear in the language , but there 's not very many of these . Tcl 's one of them . 
D:  And  and you 'll ha you 'll have to do it sychronously . 
F:  <laugh> 
G:  Um , y yeah . 
D:  Right , so y so , whoever 's creating the new 
E:  <inbreath>  
C:  It 's just disturbing .  
D:  models , will have to also go through the transcripts and change them synchronously . 
F:  <laugh> 
G:  Right . 
G:  Right . We have this  there is this 
E:  <inbreath>  
B:  Hmm . 


G:  thing I was gonna talk to you about at some point about , you know , what do we do with the dictionary 
G:  as we 're up updating the dictionary , these changes have to be consistent with what 's in the  Like spelling people 's names and so forth . 
G:  If we make a spelling correction to their 
G:  name , like someone had Deborah Tannen 's name mispelled , and since we know who that is , you know , we could correct it , but  
D:  You can correct it .  Yeah . 
G:  but we need to make sure we have 
G:  the mispel If it doesn't get corrected we have to have a pronunciation as a mispelled word in the dictionary . Things like that . 
E:  Mm - hmm . 
D:  These are so funny to read . 
E:  Well , of course now the  the Tannen corre the spelling c change .  Uh , that 's what gets  I  I picked those up in the frequency check . 
G:  So . 
G:  Right . Right . So if there 's things that get corrected before we get them , it 's  it 's not an issue , but if there 's things that 
E:  Mm - hmm .  
G:  um , we change later , then we always have to keep 
G:  our  the dictionary up to date . And then , yeah , in the case of " tickle " I guess we would just have a , 
G:  you know , word " TCL " which  
B:  Mm - hmm . 
D:  You add it to the dictionary .  
G:  which normally would be an acronym , 
G:  you know , " TCL "  
D:  Right . 
G:  but just has another pronunciation . 
D:  Yep . 
E:  " ICSI " is  is one of those that sometimes people pronounce and sometimes they say " ICSI . " So , 
D:  Mm - hmm . 
G:  Oh yeah . 
E:  those that are l are listed in the acronyms , I actually know they were said as letters . The others , um , 
E:  e those really do need to be listened to cuz I haven't been able to go to all the IC ICSI things , and   
G:  Right , exactly . 
E:  and until they 've been listened to they stay as " ICSI " . 
D:  Mm - hmm . 
G:  Right . 


D:  On the glosses for numbers , 
E:  Yeah . 
D:  it seems like there are lots of different ways it 's being done . There 's a  
E:  OK . Interesting question . 
E:  Yes . OK , now first of all  
E:  Ooo - ooo ! Very important . Uh Chuck  Chuck led to a refinement here which is to add " NUMS " if these are parts of the read numbers . Now you already know i 
D:  " Ooo - ooo . "  
E:  that I had , uh , in places where they hadn't transcribed numbers , I put " numbers " in place of any kind of numbers , but there are places where they , 
E:  um , it  th this convention came later an and at the very first digits task in some transcripts they actually transcribed numbers . 
E:  And , um , 
E:  d 
E:  Chuck pointed out that this is read speech , and it 's nice to have the option of 
E:  ignoring it for certain other prob uh p uh , things . And that 's why there 's this other 
E:  tag here which occurs a hundred and five  or three hundred and five times right now which is just  
E:  well n n " NUMS " by itself which means this is part of the numbers task . I may change it to " digits " . I mean , i with the sed command you can really just change it however you want 
D:  " NUMS " , yeah .  
D:  <laugh> 
E:  because it 's systematically encoded , you know ? Have to think about what 's the best for  for the overall purposes , but in any case , 
D:  Yep . 
E:  um , " numbers " and " NUMS " are a part of this digits task thing . 
E:  Um , now th Then I have these numbers that have quotation marks around them . 
E:  Um , I didn't want to put them in as gloss comments because then you get the substitution . And actually , 
E:  th um , <laugh> the reason I b did it this way was because I initially started out with the other 
E:  version , you have the numbers and you have the full form and the parentheses ,  however sometimes people stumble over 
E:  these numbers they 're saying . So you say , " Seve - seventy eight point two " , or whatever . 
E:  And there 's no way of capturing that if you 're putting the numbers off to the side . You can't have the seven and  
D:  So what 's to the left of these ? 
E:  The left is i so example the very first one ,  it would be , spelled out in words , 
D:  Mm - hmm . 
D:  OK , that 's what I was asking . 
E:  " point five " . 
D:  Right . 
E:  Only it 's spelled out in words . So i this is also spelled out in  in words . " Point five . " 
D:  Point FIVE , yeah . 
C:  <laugh> 
B:  <cough> 
D:  Good . 
E:  And then , in here , " NUMS " , so it 's not going to be mistaken as a gloss . 
E:  It comes out as " NUMS quote dot five " . 
D:  OK now , the other example is , in the glosses right there , 
E:  Thank you .  
D:  " gloss one one one dash one three zero " . What  what 's to the left of that ? 
E:  Well now  
C:  Right . 
E:  In that case it 's people saying things like " one one one dash so - and - so " or they 're saying 
E:  uh " two  I mean zero " whatever . And in that case , it 's part of the numbers task , and it 's not gonna be included in the read digits anyway , so  I m in the uh  
D:  OK . 
A:  <breath> 
B:  So there will be a " NUMS " tag on those lines ? 
E:  There is . Yeah . I 've added that all now too . 
B:  Yeah . 
D:  Good . 
C:  There 's a " numbers " tag  I 'm sorry I 'm  I didn't follow that last thing . 
G:  Wait . 
E:  So , so gloss  in the same line that would have " gloss quote one one one dash one thirty " , you 'd have a gloss at the end of the line saying , 
C:  Right . 
E:  uh , " curly bracket NUMS curly bracket " . 
E:  So if you  if you did a , 
E:  uh , a " grep minus V nums " and you get rid of anything that was read . 
G:  Oh , so you could do " grep minus V nums " . So that 's the  yeah . So there wouldn't be something like 
C:  OK . 
G:  i if somebody said something like , " Boy , I 'm really tired , OK . " and then started reading that would be on a separate line ? 
E:  Yes . 
G:  OK great . Cuz I was doing the " grep minus V " quick and dirty and 
G:  looked like that was working OK , but  
E:  Mm - hmm . Good . 
G:  Great . 
E:  Yep . 
G:  Now why do we  what 's the reason for having like the point five have the " NUMS " on it ? Is that just like when they 're talking about their data or something ? Or  
E:  This is more because  
E:  Yeah . Oh these are all these , the " NUMS point " , this all where they 're saying " point " something or other . 
G:  These are all like 
G:  inside the 
G:  spontaneous  
E:  And the other thing too is for readability of the transcript . I mean if you 're trying to follow this while you 're reading it 
E:  it 's really hard to read , you know  eh , " so in the data column five has " , 
E:  you know , " one point five compared to seventy nine point six " , it 's like when you see the words it 's really hard to follow the argument . 
E:  And this is just really a  a way of someone who would handle th the data in a more discourse - y way 
E:  to be able to follow what 's being said . So this is where Chuck 's , um , overall h architecture comes in , where 
G:  Oh OK . 
D:  Label it . 
G:  I see . 
E:  we 're gonna have a master file of the channelized data . Um , there will be scripts that are written 
E:  to convert it into these t these main two uses and th some scripts will take it down th 
E:  e into a f a for ta take it to a format that 's usable for the recognizer an uh , other scripts will take it to a form that 's usable for the  
E:  for linguistics an and discourse analysis . And , um , the 
E:  implication that  that I have is that th the master copy will stay unchanged . These will just be things that are generated , and 
D:  Right 
G:  OK . 
E:  e by using scripts . 
D:  Master copies of superset . 
E:  When things change then the  the script will cham change but the  but there won't be stored copies of  in different versions of things . 
D:  Good . 
G:  So , I guess I 'd have one request here which is just , um , maybe to make it more robust , th 
G:  that the tag , whatever you would choose for this type of " NUMS "  where it 's inside the spontaneous speech , is different than the tag that you use for the read speech . 
B:  Right . 
B:  Right . That would argue for changing the other ones to be " digits " or something . 
G:  Um , that way w if we make a mistake parsing , or something , we don't see the " point five " , or  or it 's not there , then we 
B:  Mm - hmm . 
G:  a Just  an And actually for things like 
G:  " seven eighths " , or people do fractions too I guess , you  maybe you want one overall tag for sort of 
E:  Except  
G:  that would be similar to that , or  
E:  <inbreath>  
G:  As long as they 're sep as they 're different strings that we  that 'll make our p sort of 
E:  <inbreath> Well  
G:  processing more robust . Cuz we really will get rid of everything that 
G:  has the " NUMS " string in it . 
B:  I suppose what you could do is just make sure that you get rid of everything that has " curly brace NUMS curly brace " . 
E:  Well  
E:  Ex - exactly . 
E:  Exactly . 
B:  I mean that would be the  
E:  That was  that was my motivation . 
G:  Yeah . 
E:  And i these can be changed , like I said . You know , I mean , as I said I was considering changing it to " digits " . 
E:  And , it just  i you know , it 's just a matter of deciding on whatever it is , and being sure the scripts know . 
B:  Right . 
G:  It would probably be safer , if you 're willing , to have a separate tag just because 
G:  um , then we know for sure . And we can also do counts on them without having to do the processing . But you 're right , we could do it this way , it  
G:  it should work . Um , 
B:  Yeah , and it makes it  I guess the thing about  
G:  but it it 's probably not hard for a person to tell the difference because one 's in the context of a  
B:  Yeah . 
G:  you know , a transcribed word string , and  
B:  Right . 
E:  The other thing is you can get really so minute with these things and increase the size of the files and the re and decrease the readability to such an extent by 
G:  So  
E:  simply something like " percent " . Now I  I could have adopted a similar convention for " percent " , but somehow 
E:  percent is not so hard , you know ? i It 's just 
D:  Hmm . 
E:  when you have these points and you 're trying to figure out where the decimal places are   And we could always add it later . Percent 's easy to detect . Point however is  is 
E:  uh a word that has a couple different meanings . And you 'll find both of those in one of these meetings , 
E:  where he 's saying " well the first point I wanna make is so - and - so " and he goes through four points , and also has all these decimals . 
E:  <laugh> 
B:  So Liz , what does the recognizer do , 
E:  So . 
B:  uh , 
F:  Hmm . 
B:  what does the SRI recognizer output for things like that ? " seven point five " . Does it output the word  
G:  " Seven point five " . 
B:  Right , the word " seven " ? The number " seven " ? 
D:  Well , the numbers ? 
G:  The word . 
B:  The word " seven " , OK . 
F:  Yeah . 
G:  Yeah . 
F:  So I 'd  so " I 'd like  I 'd like to talk about point five " .  
G:  And  and actually , you know the language  
G:  it 's the same point , actually , the  the p you know , the word " to " and the word 
F:  Yeah . 
E:  <laugh> 
F:  <laugh> 
G:  y th " going to " and " to go to " those are two different " to 's " and so there 's no distinction there . 
B:  Mm - hmm . 
G:  It 's just  just the word " point " 
G:  has  Yeah , every word has only one , 
G:  yeah e one version even if  
G:  even if it 's  
G:  A actually even like the word " read "  and " read "  . Those are two different words . They 're spelled the same way , right ? And they 're still gonna be transcribed as READ . 
B:  Mm - hmm . 
F:  Right . 
B:  Mm - hmm . 
G:  So , yeah , I  I like the idea of having this in there , I just  I was a little bit worried that , um , 
G:  the tag for removing the read speech  because i What if we have like 
G:  " read letters " or , I don't know , like " read something " like " read " yeah , basically . 
D:  We might wanna  just a separate tag that says it 's read . 
C:  Mm - hmm . 
G:  But other than that I it sounds great . 
D:  Yeah . 


D:  OK ? 
D:  Are we done ? 
E:  <breath> Well I wanted to say also regarding the channelized data , that , um , Thilo requested , um , that 
D:  Oh , I guess we 're not done . 
C:  <laugh> 
B:  Yeah . 
E:  we ge get some segments done by hand to e e s reduce the size of the time bins wh like was Chuc - Chuck was mentioning earlier that , um , 
E:  that , um , if you  if you said , " Oh " 
E:  and it was in part of a really long , s complex , overlapping segment , that the same start and end times would be held for that one as for the longer utterances , and  
D:  Well  
D:  We did that for one meeting , right , so you have that data don't you ? 
A:  Yeah , that 's the training data . 
E:  And he requested that there be , uh , similar , uh , samples done for five minute stretches c involving a variety of speakers and overlapping secti sections . 
E:  He gave me  he did the  very nice , he  he did some shopping through the data and found segments that would be useful . 
A:  Yeah . 
D:  <laugh> 
E:  And at this point , all four of the ones that he specified have been done . In addition the 
E:  I 've  I have the transcribers expanding the amount that they 're doing actually . So right now , um , 
A:  Oh great . 
E:  I know that as of today we got an extra fifteen minutes of that type , and I 'm having them expand the realm on either side of these places where they 've already started . 
A:  Oh great . 
A:  OK . 
E:  But if  if  you know , and I  and he 's gonna give me some more sections that  that he thinks would be useful for this purpose . 
A:  Yeah . 
A:  Yeah . 
E:  Because it 's true , I mean , if we could do the  
E:  the more fine grained tuning of this , uh , using an algorithm , that would be so much more efficient . And , um . 
E:  So this is gonna be  useful to expand this .  
A:  So I  I thought we  we sh we sh perhaps we should try to  to start with those channelized versions just to  just to try it . Give it  
A:  Give one tr transcriber the  the channelized version of  of my speech - nonspeech detection and 
A:  look if  if that 's helpful for them , or just let them try if  if that 's better or 
A:  If they  if they can  
E:  You mean to start from scratch f in a brand new transcript ? That 'd be excellent . Yeah , that 'd be really great . 
A:  Yeah . Yeah . 
A:  Yeah . 
E:  As it stands we 're still in the phase of sort of , um , 
E:  cleaning up the existing data getting things , uh , in i m more tight tightly time  uh , aligned . I also wanna tell  um , I also wanted to r 
E:  raise the issue that  OK so , there 's this idea we 're gonna have this master copy of the transcript , 
E:  it 's gonna be modified by scripts t into these two different functions . And actually the master  
B:  Two or more . Two or more different functions . 
E:  Two  two or more . 
E:  And that the master is gonna be the channelized version . 
B:  Right . 
E:  So right now we 've taken this i initial one , it was a single channel basically the way it was input . And now , uh , 
E:  thanks to the advances made in the interface , we can from now on use the channelized part , 
E:  and , um , any changes that are made get made in the channelized version kind of thing . But I wanted to get all the finished  all the checks  
B:  Yeah , so that has implications for your script . 
C:  Yeah . So , uh , have those  e e the vis the ten hours that have been transcribed already , have those been channelized ? 
E:  Yes , they have . 
C:  And I know  I 've seen @ @  I 've seen they 've been channelized , but 
D:  All ten hours ? 
E:  Except for the missing thirty minutes . 
C:  have they uh  have they been  has the time  have the time markings been adjusted , uh , p on a per channel  
D:  Great . 
E:  <laugh> 
E:  Uh , for  for a total of like twenty m 
E:  f for a total of  
E:  Let 's see , four times    
E:  total of about an   thirty minutes . 
E:  That 's  that 's been the case . And plus the training , whatever you have . 
C:  So , 
C:  I guess , I mean , I don't know if we should talk about this now , or not , but I 
D:  Well it 's just we 're  missing tea . So . 
C:  Yeah , I know . No , but I mean my question is like should I wait 
C:  until all of those are processed , and channelized , like the time markings are adjusted before I do all the processing , and we start like branching off 
C:  into the  into the  our layer of uh 
E:  Well , you know the problem  the problem is that some  some of the adjustments that they 're making are to bring  are to combine 
C:  transcripts . 
E:  bins that were  time bins which were previously separate . And the reason they do that is sometimes there 's a word that 's cut off . 
C:  Right . 
E:  And so , i 
E:  i i it 's true that it 's likely to be adjusted in the way that the words are more complete . 
E:  And , 
C:  OK . No I know  I know that adjusting those things are gonna  is gonna make it better . 
E:  so I  it 's gonna be a more reliable thing and I 'm not sure  
E:  Yeah . 
C:  I mean I 'm sure about that , but do you have like a time frame when you can expect like all of it to be done , or when you expect them to finish it , or  
E:  Well partly it depends on how  um , how e 
E:  effective it will be to apply an algorithm because 
C:  Yeah . 
E:  i this takes time , you know , it takes a couple hours t to do , uh , ten minutes . 
C:  Yeah . 
C:  Yeah , I don't doubt it . Um , 
C:  so . 
B:  So right now the  what you 're doing is you 're taking the  uh , the o original version and you 're sort of channelizing yourself , right ? 
E:  <mike noise> 
C:  Yeah . I 'm doing it myself . I mean i if the time markings aren't different across channels , like the channelized version really doesn't 
C:  have any more information .  
B:  Mm - hmm . 
C:  So , I was just  I mean , originally I had done before like the channelized versions were coming out . Um , 
B:  Right . 
B:  Right . 
C:  and so it 's a question of like what  
B:  So I  I th I think probably the way it 'll go is that , you know , when we 
B:  make this first general version and then start working on the script , that script 
C:  Mm - hmm . 
B:  @ @ that will be ma you know primarily come from what you 've done , um , we 'll need to work on a channelized version of those originals . 
E:  Mm - hmm . 
C:  Mm - hmm . 
B:  And so it should be pretty much identical to what you have t except for the one that they 've already tightened the boundaries on . 
E:  Yep . Mm - hmm . 
C:  Right . 
B:  Um , 
E:  Yeah , I mean  yeah . 
B:  So 
B:  uh , and then probably what will happen is as the transcribers finish tightening more and more , you know , that 
B:  original version will get updated and then we 'll rerun the script and produce better 
C:  OK . 
B:  uh versions . But the  I guess the ef the effect for you guys , because you 're pulling out 
B:  the little wave forms into separate ones , that would mean these boundaries are constantly changing you 'd have to constantly re rerun that , so , maybe  
C:  I know . 
C:  Right . 
G:  But that  that 's not hard . 
E:  But that  Mm - hmm . 
G:  I I think the harder part is making sure that the transc the transcription  
C:  No . 
B:  OK . 
G:  So if you b merge two things , then you know that it 's the sum of the transcripts , but if you split 
G:  inside something , you don't where the word  which words moved . 
B:  Mm - hmm . 
B:  Mm - hmm . 
G:  And that 's wh that 's where it becomes a little bit  
G:  uh , having to rerun the processing . The cutting of the waveforms is pretty trivial . 
B:  Mm - hmm . 
C:  Yeah . I mean as long as it can all be done automatically , 
C:  I mean , then that 's not a concern . You know , if I just have to run three scripts to extract it all and let it run on my computer 
G:  Right . 
B:  Mm - hmm . 
B:  Yeah . 
B:  Uh - huh . 
C:  for an hour and a half , or however long it takes to parse and 
C:  create all the reference file , that 's not a problem . 
B:  Mm - hmm . 
C:  Um , 
C:  so yeah . As long as we 're at that point . And I know exactly like what the steps will work  what 's going on , in the editing process , so . 
B:  Yeah . 
C:  OK . 
E:  So that 's  I I mean I could  there were other checks that I did , but it 's  I think that we 've  unless you think there 's anything else , I think that I 've covered it . 
F:  Yeah . 
B:  I can't think of any of the  other ones . 
E:  OK . 
E:  Great . 


F:  OK . 
D:  <breath> Oop !  
D:  <outbreath> Man !  


