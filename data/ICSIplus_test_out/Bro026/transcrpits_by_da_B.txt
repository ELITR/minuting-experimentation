B:  That 's all folks . 
B:  OK , 
B:  so  We  we had a meeting with , uh  with Hynek , um , in  in which , uh , uh , Sunil and Stephane , uh <mouth> summarized where they were and  and , uh , talked about where we were gonna go . 
B:  So that  that happened sort of mid - week . 
B:  Uh . 
B:  What was the update ? 
B:  Yeah . 
B:  I think it more likely that what it means is that when Sunil is up there <laugh> he will grab it . 
B:  They 're  
B:  Yeah . They 're working on a different task . 
B:  But what 'll happen is  is he 'll go back up there and , uh , Pratibha will come back from  from , uh , the east coast . 
B:  Uh . 
B:  And , uh  and  and I guess actually , uh , after Eurospeech for a little bit , uh , he 'll go up there too . 
B:  So , actually everybody <laugh> who 's working on it  will be up there for at least a little while . 
B:  So they 'll remotely access it <laugh> from there . 
B:  Yeah . 

B:  Good idea . 
B:  Yeah . 
B:  Yeah . 
B:  Yeah , for this stuff I don't think we 're  quite up to that . 
B:  I mean , we 're still so much in development . 
B:  We want to have just the insiders . 
B:  Yeah . 
B:  Yeah . 
B:  So , uh  
B:  Well , I mean , I think maybe the thing to me might be  I me I 'm sure you 've just been working on  on , uh , details of that since the meeting , 
B:  right ? 
B:  And so  
B:  That was  that was Tuesday . 
B:  OK . 
B:  But I guess maybe the thing  since you weren't  yo you guys weren't at that  that meeting , might be just  just to , um , sort of recap , uh , the  the conclusions of the meeting . 
B:  So . 
B:  Yeah . 
B:  Cuz that was sort of , uh  we  we 'd sort of been working up to that , that  that , uh , he would come here this week and  and we would sort of  
B:  Since he 's going out of town like now , and I 'm going out town in a couple weeks , uh , and time is marching , sort of , given all the mu many wonderful things we could be working on , what  what will we actually focus on ? 
B:  And , uh  and what do we freeze ? 
B:  And , you know , what do we  ? 
B:  So , um . 
B:  I mean , this  software that these guys created was certainly a  a key part . 
B:  So then there 's something central 
B:  and there aren't at least a bunch of different versions going off in  in ways that  differ  trivially . 
B:  Uh , um , and , um , 
B:  and then within that , I guess the idea was to freeze a certain set of options for now , to run it , uh , a particular way , and decide on what things are gonna be experimented with , as opposed to just experimenting with everything . 
B:  So keep a certain set of things constant . 
B:  So , um . 
B:  Uh , maybe describe roughly what  what we are keeping constant for now , 
B:  or  ? 
B:  This  this smoothing is done on the estimate , um , of what you 're going to subtract ? Or on the thing that has already had something subtracted ? 
B:  Oh , it 's on the transfer function for the Wiener filter . 
B:  Yeah , OK . 
B:  Actually , let me int eh , Dave isn't here to talk about it , but let me just interject . 
B:  This module , in principle , i I mean , you would know whether it 's <laugh> true in fact , is somewhat independent from the rest of it . 
B:  I mean , because you  you re - synthesize speech , 
B:  right ? 
B:  So , um . 
B:  Uh , well you don't  I guess you don't re - synthesize speech , but you could  
B:  Uh , but you could . 
B:  But you have a re - synthesized thing that you  that 's an  an option here . 
B:  Yeah , I gu I guess my point is that , um , i in some of the work he 's doing in reverberation , one of the things that we 're finding is that , uh , it 's  it 's  for the  for an artificial situation , we can just deal with the reverberation and his techniques work really well . 
B:  But for the real situation uh , problem is , is that you don't just have reverberation , you have reverberation in noise . 
B:  And if you don't include that in the model , it doesn't work very well . 
B:  So in fact it might be a very nice thing to do , to just take the noise removal part of it and put that in front of what he 's looking at . And , uh , generate new files or whatever , and  and , uh , uh  and then do the reverberation part . 
B:  So it 's  
B:  Anyway . 
B:  No , no . He 's  I mean , e 
B:  Yeah , prelims , right . 
B:  Yeah . 
B:  So . 
B:  Uh , but  but , you know , that 'll  
B:  uh , it 's clear that we , uh  we are not  with the real case that we 're looking at , we can't just look at reverberation in isolation 
B:  because the interaction between that and noise is  is considerable . 
B:  And that 's I mean , in the past we 've looked at , uh , and this is hard enough , the interaction between channel effects and  and , uh  and additive noise , uh , so convolutional effects and  and additive effects . 
B:  And that 's hard enough . 
B:  I mean , I don't think we really  
B:  I mean , we 're trying to deal with that . 
B:  In a sense that 's what we 're trying to deal with in this Aurora task . 
B:  And we have , uh , the , uh , uh , LDA stuff that in principle is doing something about convolutional effects . 
B:  And we have the noise suppression that 's doing something about noise . 
B:  Uh , even that 's hard enough . 
B:  And  and the on - line normalization as well , in that s category . 
B:  i i There 's all these interactions between these two and that 's part of why these guys had to work so hard on  on juggling everything around . 
B:  But now when you throw in the reverberation , it 's even worse , 
B:  because not only do you have these effects , but you also have some long time effects . 
B:  And , um , so Dave has something which , uh , is doing some nice things under some conditions with  with long time effects 
B:  but when it 's  when there 's noise there too , it 's  it 's  it 's pretty hard . 
B:  So we have to start  
B:  Since any  almost any real situation is gonna have  uh , where you have the microphone distant , is going to have both things , 
B:  we  we actually have to think about both at the same time . 
B:  So , 
B:  um  So there 's this noise suppression thing , which is sort of worked out 
B:  and then , uh , maybe you should just continue telling what  what else is in the  the form we have . 
B:  So that 's  again , that  that 's the Wiener filtering , followed by , uh  uh , that 's done at the FFT level . 
B:  Then  
B:  Mm - hmm . 
B:  Mm - hmm . 
B:  The  the  the filtering is done in the frequency domain ? 
B:  Yeah , 
B:  OK . 
B:  And then the mel and then the log , and then the 
B:  LDA filter . 
B:  And then uh 
B:  downsample , 
B:  DCT , 
B:  on - line norm , 
B:  Right , and then in parallel with  an  a neural net . And then following neural net , some  probably some orthogonalization . 
B:  Uh  
B:  Um . 
B:  Mm - hmm . 
B:  So that 's sort of  most of this stuff is  yeah , is operating parallel with this other stuff . 
B:  Yeah . 
B:  So the things that we , um , uh , 
B:  I guess we sort of  uh , 
B:  There 's  there 's some , uh , neat ideas for <clears throat> V A 
B:  So , I mean , in  
B:  I think there 's sort of like  There 's a bunch of tuning things to improve stuff . 
B:  There 's questions about  various places where there 's an exponent , if it 's the right exponent , or  ways that we 're estimating noise , that we can improve estimating noise . 
B:  And there 's gonna be a host of those . 
B:  But structurally it seemed like the things  the main things that  that we brought up that , uh , are  are gonna need to get worked on seriously are , uh , uh , a  <clears throat> a significantly better VAD , uh , putting the neural net on , um , which , you know , we haven't been doing anything with , the , uh , neural net at the end there , and , uh , the , uh , <breath> opening up the second front . 
B:  Uh . 
B:  Yeah , yeah , I mean , cuz we  we have  we have , uh , uh , half the  the , uh , data rate that they allow . 
B:  And , uh , so the initial thing which came from , uh , the meeting that we had down south was , uh , that , um , we 'll initially just put in a mel spectrum as the second one . 
B:  It 's , you know ,  cheap , easy . 
B:  Uh . 
B:  There 's a question about exactly how we do it . 
B:  We probably will go to something better later , 
B:  but the initial thing is that cepstra and spectra behave differently , 
B:  so . 
B:  Um ,  I think Tony Robinson used to do  I was saying this before . I think he used to do mel , uh , spectra and mel cepstra . 
B:  He used them as alternate features . 
B:  Put them together . 
B:  Uh . 
B:  Although you  you know , you haven't tested it actually on the German and Danish , 
B:  have you ? 
B:  Yeah . 
B:  Yeah . 
B:  Would it  I mean  But  
B:  When you 're saying second , you 're comparing to the numbers that the , uh  that the best system before got on , uh  also without German and Danish ? 
B:  Yeah , OK . 
B:  Well ranking didn't before , but I 'm just asking where this is to where theirs was without the German and Danish , 
B:  right ? 
B:  So . 
B:  Oh , we were also esp essentially second , although there were  there were  I mean , we had a couple systems and they had a couple systems . 
B:  And so , I guess by that  we were third , 
B:  but I mean , there were two systems that were pretty close , that came from the same place . 
B:  Uh , so institutionally we were  <laugh> we were second , with , uh , the third  third system . 
B:  See  
B:  Uh , no I think it 's also institutional , 
B:  isn't it ? 
B:  Right ? 
B:  I mean , I think both of their systems probably  
B:  Oh , are we ? 
B:  Is it ? 
B:  Yeah , so  so basically they 're all  they 're all pretty close . 
B:  And  and , <clears throat> um , you know , in some sense we 're all doing fairly similar things . 
B:  Uh , I mean , one could argue about the LDA and so forth 
B:  but I  I think , you know , in a lot of ways we 're doing very similar things . 
B:  But what  what  
B:  Um , why are we using half ? 
B:  Well , so you could  you c 
B:  Yeah , so I  I think  uh , you guys are closer to it than me , so correct me if I 'm wrong , but I  I think that what 's going on is that in  in both cases , some kind of normalization is done to deal with convola convolutional effects . 
B:  Uh , they have some cepstral  modification , 
B:  right ? 
B:  In our case we have a couple things . 
B:  We have the on - line normalization and then we have the LDA RASTA . 
B:  And  they seem to comple complement each other enough and be different enough that they both seem to help  help us . 
B:  But in any event , they 're both doing the same sort of thing . 
B:  But there 's one difference . 
B:  The LDA RASTA , uh , throws away high modulation frequencies . 
B:  And they 're not doing that . 
B:  So that if you throw away high modulation frequencies , then you can downsample . 
B:  So  
B:  Yeah . 
B:  I think it doesn't affect it , 
B:  does it ? 
B:  Yeah . 
B:  So I think the thing is , since we 're not evidently throwing away useful information , let 's try to put in some useful information . 
B:  And , uh , so I  you know , we  we 've found in a lot of ways for quite a while that having a second stream uh , helps a lot . 
B:  So that 's  that 's put in , and you know , it may even end up with mel spectrum even though I 'm saying I think we could do much better , just because it 's simple . 
B:  Um . 
B:  And you know , in the long run having something everybody will look at and say , " oh , yeah , I understand " , is  is very helpful . 
B:  Well , that 's a question . 
B:  I mean , we were talking about that . 
B:  It looks like it 'd be straightforward to  to , uh , remove the noise , 
B:  um , and , uh , 
B:  Yeah . 
B:  So , I mean , to do it after the mel conversion  uh , after the noise removal , after the mel conversion . 
B:  There 's even a question in my mind anyhow of whether th you should take the log or not . 
B:  Uh . 
B:  I sort of think you should , 
B:  but I don't know . 
B:  Right . 
B:  Uh . 
B:  Well , but normalizing spectra instead of cepstra ? 
B:  Yeah , probably . 
B:  Some kind would be good . 
B:  You know ? 
B:  I would think . 
B:  If you do or don't normalize ? 
B:  Right . 
B:  Yes , so I mean , one would think that you would want to normalize . 
B:  But I  I  w w 
B:  My thought is , uh , particularly if you take the log , try it . 
B:  And then if  if normalization helps , then y you have something to compare against , and say , " OK , this much effect "  I mean , you don't want to change six things and then see what happens . 
B:  You want to change them one at a time . 
B:  So adding this other stream in , that 's simple in some way . 
B:  And then  saying , oh  uh  particularly because we 've found in the past there 's all these  these  these different results you get with slight modifications of how you do normalization . 
B:  Normalization 's a very tricky , sensitive thing and  you learn a lot . 
B:  So , I would think you would wanna  have some baseline that says , " OK , we don't normalize , this is what we get " , when we do this normalization , when we do that normalization . 
B:  But  but the other question is  
B:  So I think ultimately we 'll wind up doing some normalization . 
B:  I agree . 
B:  No , it 's in parallel . 
B:  We 're not talking about computation time here . 
B:  We 're ta I think we 're pretty far out . 
B:  So it 's just in terms of what data it 's depending on . 
B:  It 's depending on the same data as the other . 
B:  So it 's in parallel . 
B:  Uh - huh . 
B:  Yeah . 
B:  Well , there 's the delays and the storage , 
B:  yeah . 
B:  But I don't think the storage is so big for that . 
B:  I think th the biggest we 've run into for storage is the neural net . 
B:  Right ? 
B:  Yeah . 
B:  Um . 
B:  And so I guess the issue there is , are we  are we using neural - net - based TRAPS , 
B:  and  and how big are they ? 
B:  So that 'll  that 'll be , you know , an issue . 
B:  Maybe they can be little ones . 
B:  Mini - TRAPS . 
B:  Right . 
B:  And maybe for VAD they would be OK . 
B:  Yeah . 
B:  Yeah . 
B:  That 's true . 
B:  Or a simple neural net , 
B:  right ? 
B:  I mean , the thing is , if you 're doing correlation , you 're just doing a simple  uh , uh  uh , dot product , you know , with some weights which you happened to learn from this  learn from the data . 
B:  And so , 
B:  uh , putting a nonlinearity on it is ,  you know , not that big a deal . 
B:  It certainly doesn't take much space . 
B:  So , uh , the question is , how complex a function do you need ? 
B:  Do you need to have an added layer or something ? 
B:  In which case , uh , potentially , you know , it could be big . 
B:  So . 
B:  So , uh , 
B:  uh  So what 's next ? 
B:  Maybe s s remind us . 
B:  What to freeze and then what to do after we froze . 
B:  Yeah . 
B:  And like I was saying , I think the  you know , the basic directions are , uh , uh  I mean , there 's lots of little things , such as improve the noise estimator but the bigger things are adding on the neural net and , uh , the second stream . And then , uh , improving the VAD . 
B:  Uh . 
B:  So . 
B:  Right . 
B:  Right . 
B:  Um . 
B:  Have you ever  ? 
B:  Very good question . 
B:  Have you ever worked with the Mississippi State h uh , software ? 
B:  Oh . 
B:  Well you  you may be called upon to help , uh , uh , on account of , uh , all the work in this stuff here has been , uh , with small vocabulary . 
B:  Do we already have it ? 
B:  Maybe you could , uh , point it  at Chuck , 
B:  because , I mean  
B:  Cuz one of the things that might be helpful , if you 've  if you 've got time in all of this is , is if  if these guys are really focusing on improving , uh , all the digit stuff , uh , maybe  and you got the front - end from them , maybe you could do the runs for the  
B:  and  and , you know , iron out hassles that  that you have to , uh , tweak Joe about or whatever , 
B:  because you 're more experienced with running the large vocabulary stuff . 
B:  S 
B:  Yeah , so I th th certainly the thing that I would want to know about is whether we get really hurt , uh , on in insertion penalty , language model , scaling , sorts of things . 
B:  Yeah , 
B:  yeah . 
B:  Uh , in which case , um , H Hari or Hynek will need to , you know , push the case  more about  about this . 
B:  Um . 
B:  Yes . In this case , 
B:  that 's right . 
B:  That 's right . 
B:  Um , some of that may be , uh , a last minute rush thing because if the  if our features are changing  
B:  Uh . 
B:  Uh . But , um . 
B:  Yeah , the other thing is that even though it 's months away , uh , it 's starting to seem to me now like November fifteenth is right around the corner . 
B:  And , um , if they haven't decided things like this , like what the parameters are gonna be for this , uh , when " deciding " is not just somebody deciding . I mean , in fact there should be some understanding behind the , uh , <breath-laugh> deciding , which means some experiments and  and so forth . It  it  it seems pretty tight to me . 
B:  That 's when the evaluation is . 
B:  Yeah . 
B:  So , yeah , so 
B:  after  But , you know , they may even decide in the end to push it off . 
B:  It wouldn't , you know , entirely surprise me . 
B:  But , uh , due to other reasons , like some people are going away , I 'm  I 'm hoping it 's not pushed off for <laugh> a l a long while . 
B:  That would be , uh  put us in an awkward position . 
B:  But  
B:  Anyway . 
B:  Great . 
B:  Yeah , I think that 'll be helpful . 
B:  There 's  there 's not anybody OGI currently who 's  who 's , uh , working with this 
B:  and  and 
B:  I  I think it 's  it 's , um  it depends how badly <laugh> you do . 
B:  I mean , I think that it  it is  Uh . 
B:  Yeah . 
B:  Well , I mean , it 's  it 's  Conceptually , it  my impression , again , you guys correct me if I 'm wrong , but  my impression is that , um , they want it as a double check . 
B:  That you haven't come across  you haven't invented features which are actually gonna do badly for a  a significantly different task , particularly one with larger vocabulary . 
B:  And , um , but it 's not the main emphasis . 
B:  I mean , the truth is , most of the applications they 're looking at are pretty small vocabulary . 
B:  So it 's  it 's a double check . 
B:  So they 'll probably assign it some sort of low weight . 
B:  Yeah . 
B:  But , I mean , we 'll  we 'll  we 'll see what they come up with . 
B:  Uh , but in  in the current thing , for instance , where you have this well - matched , moderately - matched , and  and mis highly - mismatched , uh , the emphasis is somewhat on the  on the well - matched , but it 's only a  a marginal , 
B:  right ? 
B:  It 's like forty , thirty - five , twenty - five , or something like that . 
B:  So you still  if you were way , way off on the highly - mismatched , it would have a big effect . 
B:  And , um , it wouldn't surprise me if they did something like that with this . 
B:  So again , if you 're  if you get  If it doesn't help you much , uh , for noisy versions of this  of large vocabulary data , then , uh , you know , it may not hurt you that much . 
B:  But if it  if you don't  if it doesn't help you much at all , um , or to put it another way , if it helps some people a lot more than it helps other people , uh , if their strategies do , then  
B:  That 's it . 
B:  Yeah . 
B:  Yeah . 
B:  So  we have the data , just not the recognizer . 
B:  OK . 
B:  Uh , well there 's training and test , 
B:  right ? 
B:  No , I mean , if it 's like the other things , there 's  there 's data for training the H M Ms and  and data for testing it . 
B:  So I wouldn't  
B:  So it  it 's  
B:  So , training the recognizer , 
B:  but , um 
B:  Um . 
B:  But I think it 's trained on clean and  
B:  Is it trained on clean and  and test on  ? 
B:  Yeah . 
B:  OK . 
B:  I see . 
B:  Yeah . 
B:  Yeah . I mean , I wouldn't imagine that the amount of testing data was that huge . 
B:  They probably put training  uh , almost certain they put training data there too . 
B:  Maybe not . 
B:  So . 
B:  That 's that . 
B:  Anybody have anything else ? 
B:  Oh , well that 's pretty soon . 
B:  You know , their  their  They have a lot of options  in their recognizer and  and the SVM is one of the things they 've done with it , but it 's not their more standard thing . 
B:  For the most part it 's  it 's Gaussian mixtures . 
B:  Yeah . 
B:  Yeah . 
B:  Yeah , the SVM thing was an HMM also . 
B:  It was just a  it  it  it was like a hybrid , like  
B:  what ? 
B:  Yeah . 
B:  Hmm . 
B:  Yeah , um . 
B:  In fact , I mean , if you look into it a little bit , it might be reasonable  
B:  You know Joe , 
B:  right ? 
B:  Yeah . 
B:  Just to sort of ask him about the issue of , um , different features having different kinds of , uh , scaling characteristics and so on . 
B:  So that , you know , w w possibly having entirely different optimal values for  for the usual twiddle factors 
B:  and what 's  what 's the plan about that ? 
B:  Yeah . 
B:  Is that OK ? 
B:  Uh , yeah , and just , um , se maybe see . 
B:  Do you have Hari 's , uh  ? 
B:  Yeah , so maybe just CC Hari and say that you 've just been asked to handle the large vocabulary part here , 
B:  and , uh , you know , 
B:  Uh . 
B:  Why don't you just ask Joe but CC Hari , and then in the note say , " Hari , hopefully this is OK with you " . 
B:  And then if Joe feels like he needs a confirmation , Hari can answer it . 
B:  That way you can get started asking  Joe quickly while he 's  while he 's maybe still , you know , putting in nails and screws and 

B:  Yeah . 
B:  Have you thought about  how long  would be uh , most useful for you to go up to OGI ? 
B:  Oh , so you 're  you 're imagining more that you would come back here first for a while and then  and then go up there ? 
B:  I mean , it 's to you . 
B:  I ju you guys are 
B:  Well , y anyway , you don't have to decide this second but thi think about it  about what  what you would think would be the  the best way to work it . I 'll 
B:  support it either way , so . 
B:  OK . 
B:  Uh . 
B:  Got anything to tell us ? 
B:  Mm - hmm . 
B:  Are you looking at these in narrow bands ? 
B:  Cuz that 's what you 're gonna be using , 
B:  right ? 
B:  Yeah , I mean , it seems somehow that needs th uh , there 's a couple things that I wonder about with this . 
B:  I mean , so one is  is ,  again , looking at the same representation , 
B:  I mean , if you 're going for this sort of thing where you have  uh , little detectors that are looking at narrow bands , then what you 're going to be looking for should be some category that you can find with the narrow bands . 
B:  That  that seems to be kind of fundamental to it . 
B:  Um , and then the other thing , uh , is  that I wonder about with it , and  and don't take this in the wrong way , like I  I know what I 'm doing or anything , 
B:  but , I mean . <laugh> Um , just wondering really . 
B:  Um , the sort of standard answer about this sort of thing is that if you 're trying to find  the right system in some sense , whether you 're trying by categories or  or parameters  um , and your goal is discrimination , then having choices based on discrimination as opposed to , um , unsupervised nearness of things , um , is actually better . 
B:  Um , and I don't know if that  I mean , since you 're dealing with issues of robustness , you know , maybe  maybe this isn't right , but it 'd be something I 'd be concerned about . 
B:  Because , for instance , you can imagine , uh , uh , i i if you remember from  from , uh  from your  your quals , John Ohala saying that , uh , " buh "  and " puh "  differed , uh , not really cuz of voicing but because of aspiration . 
B:  I mean , in as far as wha what 's really there in the acoustics . 
B:  So , um , if you looked  if you were doing some coarse clustering , you probably would put those two sounds together . 
B:  And yet , I would gue I would guess that many of your recognition errors were coming from , uh , um , pfft ,  screwing up on this distinction . 
B:  So , in fact , it 's a little hard because recognizers , to first order , sort of work . 
B:  And the reasons we 're doing the things we 're doing is because they don't work as well as we 'd like . 
B:  And since they sort of work , uh , it means that they are already doing  
B:  if you go and take any recognizer that 's already out there and you say , " how well is it distinguishing between  schwas and stops ? " 
B:  Boy , I bet they 're all doing nearly perfectly on this , 
B:  right ? 
B:  So these  these big categories that differ in huge obvious ways , we already know how to do . 
B:  So , what are we bringing to the party ? 
B:  I mean , in fact what we wanna do is have something that , particularly in the presence of noise , uh , is better at distinguishing between , uh , categories that are actually close to one another , and hence , would probably be clustered together . 
B:  So that 's th that 's the hard thing . 
B:  I mean , I understand that there 's this other constraint that you 're considering , is that you wanna have categories that , uh  that would be straightforward for , say , a human being to mark if you had manual annotation . 
B:  And it 's something that you really think you can pick up . 
B:  But I think it 's also essential that you wanna look at what are the <breath> confusions that you 're making and how can you come up with , uh , categories that , uh , can clarify these confusions . 
B:  So , I mean , the standard sort of way of doing that is take a look at the algorithms you 're looking at , but then throw in some discriminative aspect to it . 

B:  Y y this is more like , you know , how does LDA differ from PCA ? 
B:  I mean , they 're the same sort of thing . 
B:  They 're both orthogonalizing . 
B:  But , you know  
B:  and  and , um , this is a little harder because you 're not just trying to find parameters . You 're actually trying to find the  the  the  the categories themselves . 
B:  Uh , so a little more like brain surgery , I think 
B:  on yourself . 
B:  Uh . 
B:  So , uh 
B:  Um , 
B:  anyway . That 's my  thought . 
B:  You 've been thinking about this problem for a long time actually . 
B:  I mean , well  W actually , you stopped thinking about it for a long time , but you used to think about it <laugh> a lot . 
B:  And you 've been thinking about it more now , 
B:  these categories . 
B:  Mm - hmm . 
B:  Mm - hmm . 
B:  Right . 
B:  Well , here 's a  here 's a , uh , uh Here 's a generic and possibly useless thought , which is , <laugh> um , what do you really  I mean , in a sense the only s s systems that make sense , uh , are ones that  that have something from top - down in th in them . 
B:  Right ? 
B:  Because if e even the smallest organism that 's trying to learn to do anything , if it doesn't have any kind of reward for doing  or penal penalty for doing anything , then it 's just going to behave randomly . 
B:  So whether you 're talking about something being learned through evolution or being learned through experience , it 's gotta have something come down to it that gives its reward or , you know , at least some reinforcement learning , 
B:  right ? 
B:  And 
B:  Right , but I me I  I think that maybe in some ways part of the difficulty is  is trying to deal with the  with these phonemes . 
B:  You know , and  and  and i it 's almost like you want categories if  if our  if our , uh , um , <mouth> metric of  of goodness , uh , i if our  
B:  correction  if our metric of badness <laugh> is word error rate then , um , maybe we should be looking at words . 
B:  I mean , for  for  for very nice , uh , reasons we 've looked for a while at syllables , and they have a lot of good properties , 
B:  but i i i if you go all the way to words , I mean , that 's really  I mean , d w In many applications you wanna go further . 
B:  You wanna go to concepts or something , or have  have  have concepts , actions , this sort of thing . 
B:  But , 
B:  words aren't bad , yeah . 
B:  And  and 
B:  Yeah . 
B:  But  but  but we 're not trying for models of words here . 
B:  See , so her here 's maybe where  
B:  If the issue is that we 're trying to come up with , um , some sort of intermediate categories which will then be useful for later stuff , uh , then  maybe it doesn't matter that we can't have enough  
B:  I mean , what you wanna do is  is build up these categories that are  that are best for word recognition . 
B:  And  and somehow if that 's built into the loop of what the categories  
B:  I mean , we do this every day in this very gross way of  of running o a thousand experiments 
B:  because we have fast computers and picking the thing that has the best word error rate . 
B:  In some way  I mean , we derive that all the time . 
B:  In some ways it 's really not  a bad  bad thing to do 
B:  because it tells you in fact how your adjustments at the very low level affect the  the final goal . 
B:  Um , so maybe there 's a way to even put that in in a much more automatic way , 
B:  where you take , you know , something about the error at the level of the word or some other  it could be syllable  but in some large unit , 
B:  uh , and uh  yeah , you may not have word models , you have phone models , whatever , 
B:  but you sort of  don't worry about that , and just somehow feed it back through . 
B:  You know , so that 's , uh , wh what I called a useless comments because I 'm not really telling you how to do it . 
B:  But I mean , it 's a  <laugh> it 's  it 's , you know  it 
B:  Right . 
B:  Yeah . 
B:  Yeah . 
B:  Now , that being said , I think that  that if you have something that is , um  i 
B:  Once you start dealing with spontaneous speech , all the things you 're saying are  are really true . 
B:  If you  have read speech that 's been manually annotated , like TIMIT , then , you know , i i you the phones are gonna be right , actually , <outbreath> for the most part . 
B:  So  so , uh , it doesn't really hurt them to  to do that , to put in discrimination at that level . 
B:  Um , if you go to spontaneous speech then it 's  it 's trickier 
B:  and  and  and , uh , the phones are  
B:  uh , you know , it 's gonna be based on bad pronunciation models that you have of  
B:  and , um  And it won't allow for the overlapping phenomenon 
B:  Yeah , 
B:  I mean , I guess the other thing i is  is to think of a little bit  
B:  I mean , we when y when you start looking at these kind of results I think it usually is  is pretty intuitive , 
B:  but start looking at um , what are the kinds of confusions that you do make , uh , you know , between words if you want or  or  or , uh , even phones in  in  in  in read speech , say , uh , when there is noise . 
B:  You know , so is it more across place or more across manner ? 
B:  Or is it cor you know , is it  ? 
B:  I mean , I know one thing that happens is that you  you  you , uh , you lose the , um , uh , low energy phones . 
B:  I mean , if there 's added noise then low energy phones <sniff> sometimes don't get heard . 
B:  And if that  if that is  if it  uh , if that turns it into another word or  or different  you know , or another pair of words or something , then it 's more likely to happen . 
B:  But , um , I don't know , I w I would  I would guess that you 'd  
B:  W I don't know . 
B:  Anyway , that 's  
B:  Mm - hmm . 
B:  Well that  
B:  Oh , sure , that 's really big . 
B:  Uh , but I mean , even if you do um , uh , diagnostic rhyme test kind of things , you know , where there really isn't an any information like that , uh , people are still better in noise than they  than they are in  in , uh  uh , than the machines are . 
B:  So , I mean , that 's  i 
B:  Right . We can't  we can't get it at all without any language models . 
B:  Language models are there and important 
B:  but  but , uh  
B:  Uh . 
B:  If we 're not working on that then <laugh> we should work on something else and improve it , 
B:  but  especially if it looks like the potential is there . 
B:  So  
B:  Should we do some digits ? 
B:  Since we 're here ? 
B:  OK . 
B:  That 's all folks . 
