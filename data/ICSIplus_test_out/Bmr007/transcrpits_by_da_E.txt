E:  Yeah . 
E:  OK . 

E:  Mm - hmm . 
E:  Mm - hmm . 
E:  Mm - hmm . 
E:  Mm - hmm . 
E:  Yeah <laugh> Yeah 
E:  Yeah , yeah . 
E:  Yeah , yeah . 
E:  He 's  Yeah , yeah , yeah . 
E:  Yeah 
E:  Yes , yes ! 
E:  Yeah . 
E:  Yeah . 
E:  Yeah , yeah , I h I have this that infor I have th that information now . 
E:  The  the duration of eh  of each of the overlaps . 
E:  M I  I haven't averaged it now 
E:  but , uh  I  I will , uh I will do the  the study of the   with the  with the program with the  uh , the different , uh  the , nnn ,  distribution of the duration of the overlaps . 
E:  mmm ,  Because the  the uh , @ @ is @ @ . 
E:  The duration is , uh  the variation  the variation of the duration is uh , very big on the dat 
E:  but eh  
E:  Yeah . 
E:  Because , on your surface eh  a bit of zone of overlapping with the duration eh , overlapped and another very very short . 
E:  Uh , i probably it 's very difficult to  to  because the  the overlap is , uh on is only the  in the final " S " of the  of the  the fin the  the end  the end word of the , um  previous speaker <inbreath> with the  the next word of the  the new speaker . 
E:  Um , I considered  that 's an overlap but it 's very short , it 's an " X " with a  and  the idea is probably , eh  when eh  when eh , we studied th th that zone , eh   eh , we h we have eh eh  confusion with eh eh noise . 
E:  With eh  that fricative sounds , but uh  I have new information but I have to  to study . 
E:  Yeah . 
E:  Yeah . 
E:  Yeah . 
E:  Yeah . 
E:  Mmm . 
E:  Yeah . 
E:  Yeah . 
E:  Yeah . 
E:  Yeah , yeah , yeah . 
E:  More , yeah . 
E:  Yeah . 
E:  Yeah . 
E:  Yeah . 
E:  Yeah . 
E:  Voting for  
E:  Yeah . 
E:  Is the same . 
E:  Yeah . 
E:  Yeah . 
E:  Yeah Yeah . 
E:  Yeah . 
E:  Yeah . 
E:  Yeah . 
E:  Is possible to get information from the rhythmic  f from the ge , eh  uh , files . 
E:  Yeah . 
E:  The chair  Yeah . 
E:  A video , yeah . 
E:  Only with eh uh , 
E:  but eh I  I  I think , eh when  when , y I  <inbreath> I saw the  the  the  the speech from PDA and , eh  close  <inbreath> talker . 
E:  I  I think the there is a  a great difference in the  in the signal . 
E:  Um but eh I  but eh I  I  I mean that eh eh  in the  in the mixed file <inbreath> you can find , uh  zone with , eh  great different , eh  level of energy . 
E:  Um <inbreath> I  I think for , eh  algorithm based on energy ,  eh , that um h mmm ,  more or less , eh , like eh  eh , mmm , first sound energy detector . 
E:  eh nnn . 
E:  When y you the detect the  the  the first at  at the end of  of the <inbreath> detector of , ehm princ um . 
E:  What is the  the name in English ? 
E:  the  the , mmm ,  <inbreath> the de detector of , ehm of a word in the  in the s in  an isolated word in  in the background That , uh 
E:  I mean that when  when you use , eh  eh  any 
E:  Yeah . 
E:  I  I think it 's probably to work well eh , because , eh  you have eh , in the mixed files a great level of energy . 
E:  eh  and great difference between the sp speaker . 
E:  And probably is not so easy when you use the  the PDA , eh that  Because the signal is , eh  the  in the e energy level . 
E:  in  in that , eh  eh  speech file <inbreath> is , eh  more similar . 
E:  between the different eh , speaker , <inbreath> um  I  I think is  eh , it will  i is my opinion . 
E:  It will be , eh  more difficult to  to detect bass - tone energy . 
E:  the  the change . 
E:  I think that , um 
E:  In the PDA . 
E:  Yeah . 
E:  Yeah . 
E:  And the  the another question , that when I review the  the  the work of Javier . 
E:  I think the , nnn , the , nnn ,  that the idea of using a  neural network <inbreath> to  to get a broad class of phonetic , eh  from , eh uh a candidate from the  the  the speech signal . 
E:  If you have , eh <mouth> uh , I 'm considering , only because Javier , eh  only consider , eh  like candidate , the , nnn , eh  the silence , because it is the  the only model , eh  eh , he used that , eh  <inbreath> eh  nnn , to detect the  the possibility of a  a change between the  between the speaker , 
E:  Um  another  another research thing , different groups , eh  working , eh  on Broadcast News <inbreath> prefer to , eh  to consider hypothesis eh  between each phoneme . 
E:  Because , I  I  I think it 's more realistic that , uh  only consider the  <inbreath> the <mouth> the  the silence between the speaker . 
E:  Eh  there  there exists eh  silence between  between , eh  a speaker . 
E:  is  is , eh  eh  acoustic , eh  event , important to  to consider . 
E:  I  I found that the , eh  silence in  in many occasions in the  in the speech file , 
E:  but , eh  when you have , eh  eh , two speakers together without enough silence between  between them , eh  <inbreath> I think eh  is better to use the acoustic change detector basically and I  I  I IX or , mmm , BIC criterion for consider all the frames in my opinion . 
E:  Yeah . 
E:  Yeah . 
E:  Yeah , yeah , yeah , yeah . 
E:  Yeah . 
E:  Yeah , yeah , yeah , yeah . 
E:  Uh - huh . 
E:  But , eh  do  do you think that if you consider all the frames to apply <inbreath> the  the , eh  the BIC criterion to detect the  the  the different acoustic change , <inbreath> eh  between speaker , 
E:  without , uh  with , uh  silence or <inbreath> with overlapping , 
E:  uh , 
E:  I think like  like , eh  eh a general , eh  eh  way of process the  the acoustic change . 
E:  In a first step , I mean . 
E:  An - and then , eh  <mouth> eh  without considering the you  you  you , um  you can consider the energy <inbreath> like a another parameter in the  in the feature vector , 
E:  eh . 
E:  This  this is the idea . 
E:  And if , if you do that , eh  eh , with a BIC uh criterion for example , or with another kind of , eh  of distance in a first step , <inbreath> and then you , eh  you get the , eh  the hypothesis to the  this change acoustic , <inbreath> eh  <swallow> to po process 
E:  Because , eh  eh , probably you  you can find the  the <mouth> eh  a small gap of silence between speaker <inbreath> with eh  eh  a ga mmm ,  <mouth> small duration Less than , <inbreath> eh  two hundred milliseconds for example 
E:  and apply another  another algorithm , another approach like , eh  eh  detector of ene , eh detector of bass - tone energy to  to consider that , eh <inbreath> that , eh  zone . of s a small silence between speaker , 
E:  or <mouth> another algorithm to  to process , <inbreath> eh  the  the segment between marks eh  founded by the  the <inbreath> the BIC criterion and applied for  for each frame . 
E:  I think is , eh  nnn , it will be a an  an  a more general approach <inbreath> the  if we compare  with use , eh  a neural net or another , eh  speech recognizer with a broad class or  or narrow class , 
E:  because , in my opinion eh  it 's in my opinion , <inbreath> eh if you  if you change the condition of the speech , I mean , if you adjust to your algorithm with a mixed speech file and to , eh <mouth> to , eh  <mouth> adapt the neural net , eh  used by Javier with a mixed file . 
E:  uh With a m mixed file , 
E:  with a  the mix , mix . 
E:  Sorry . 
E:  And  and then you  you , eh you try to  to apply that , eh , eh , eh , speech recognizer to that signal , to the PDA , eh  speech file , <inbreath> I  I think you will have problems , because the  the  the  the  condition <inbreath> you  you will need t t I  I suppose that you will need to  to  to retrain it . 
E:  Really ? 
E:  Yeah . 
E:  Yeah . 
E:  Yeah . 
E:  Yeah . 
E:  Yeah ! 
E:  the candidate . 
E:  Yeah . 
E:  Yeah . 
E:  Yeah  Yeah . 
E:  But , eh 
E:  I  I Sorry . 
E:  I  I have found that when  when I I analyzed the  the speech files from the ,  eh  mike , eh  from the eh close eh  microphone , eh  I found zones with a  a different level of energy . 
E:  including overlap zone . 
E:  including . 
E:  because , eh  eh  depend on the position of the  of the microph of the each speaker <inbreath> to , eh , to get more o or less energy <inbreath> i in the mixed sign in the signal . 
E:  and then , <inbreath> if you consider energy to  to detect overlapping in  in , uh , and you process the  the  in  the  the  the speech file from the  the  the mixed signals . 
E:  The mixed signals , eh . 
E:  I  I think it 's  it 's difficult , um <mouth>  only to en with energy to  to consider that in that zone We have eh , eh , overlapping zone Eh , if you process only the the energy of the , of each frame . 
E:  Yeah . 
E:  Yeah . 
E:  Yeah . 
E:  Yeah . 
E:  Yeah . 
E:  Yeah . 
E:  Yeah . 
E:  Yeah . 
E:  Yeah . 
E:  Yeah . 
E:  Yeah  Yeah . 
E:  Yeah . 
E:  Yeah . 
E:  Ah , yeah . 
E:  Yeah 
E:  Yeah . 
E:  Yeah . 
