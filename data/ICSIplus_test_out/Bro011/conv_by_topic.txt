A:  - st .  
E:  <spikes> 
A:  Am I on ? I guess so . 
A:  <inbreath> 
B:  <mike sound> 
E:  <outbreath> <spikes> 
A:  Radio two . 
A:  Hmm . 
B:  <mike sound> 
A:  Radio two . 
E:  Hello ?  
B:  Video killed the radio star . 
C:   
B:  <mike sound> 
E:  <outbreath> 
A:  <inbreath> 
A:  Wow . 
E:  Mm - hmm . <spikes> 
A:  <breath-laugh> 
E:  Hi ? 
A:  <laugh> 
B:  Blow into it , it works really well . 
D:  <clear throat> 
E:  <outbreath> <spikes> 
F:  Channel B . 
A:  <inbreath> 
A:  People say the strangest things when their microphones are on . 
B:  <blowing into microphone> 
E:  <outbreath> <spikes> 
D:  Channel four . 
B:  <blowing into microphone> 
E:  <spikes> 
A:  <inbreath> <outbreath> 
E:  <spikes> 
B:  <blowing into microphone> 
D:  Test . 
C:  Uh - oh .  
D:  OK . 
B:  <blowing into microphone> 
C:  <blowing into microphone> 
E:  <mike sounds> 
B:  <blowing into microphone> 
B:  <blowing into microphone> 
C:  Radio four . 
E:  <outbreath> <whistling> 
E:  <mike sounds> 
A:  <humming> 
A:  <inbreath> <outbreath> 
E:  <mike sounds> 
E:  Hello ?  
D:  Today 's 
A:  So everybody everybody 's on ? Yeah . 
E:  <mike sounds> 
A:  So y you guys had a  a meeting with uh  
A:  with Hynek which I unfortunately had to miss . 
A:  <inbreath> 
A:  Um 
C:  <clear throat> 
A:  <inbreath> 
C:  Mmm . 
A:  and uh somebody 
A:  <inbreath> 
A:  eh e 
A:  and uh I guess Chuck you weren't there either , so the uh 
B:  I was there . 
A:  Oh you were there ? 
A:  <inbreath> 
B:  With Hynek ? 
A:  Yeah . 
B:  Yeah . 
A:  <inbreath> 
A:  So everybody knows what happened except me . 
A:  OK . <laugh> 
B:  <laugh> 
C:  <laugh> 
A:  Maybe somebody should tell me . 
A:  <laugh> 
E:  <laugh> 
B:  <laugh> 
C:  Oh yeah . 
D:  <laugh> 
C:  <laugh> 


C:  Alright . 


C:  Well . Uh first we discussed about some of the points 
C:  that I was addressing in the mail I sent last week . 
C:  <inbreath> 
A:  Uh - huh . 
C:  So . 
C:  <inbreath> 
C:  Yeah . 
C:  About the um , well  
C:  the downsampling problem . 
C:  <inbreath> 
A:  Yeah . 
C:  Uh and about the f the length of the filters 
C:  and  
C:  <inbreath> 
C:  Yeah . 
C:  So we had  
A:  What was the  w what was the downsampling problem again ? I forget . 
C:  So the fact that there  there is no uh low - pass filtering before the downsampling . 
C:  Well . 
A:  Uh - huh . 
C:  There is because there is LDA filtering but 
C:  that 's perhaps not 
C:  uh the best w m Well . 
A:  Depends what it 's 
A:  frequency characteristic is , yeah . 
C:  Mm - hmm . 
C:  <inbreath> 
D:  System on  
A:  So you could do a  you could do a stricter one . 
C:  <clear throat> 
A:  Maybe . Yeah . 
C:  Yeah . 
C:  <inbreath> 
C:  So we discussed about this , about the um  <papers rustling> 
A:  Was there any conclusion about that ? 
C:  Uh " try it " . Yeah . <laugh> 
A:  <laugh> I see . <laugh> 
B:  <laugh> 
E:  <laugh> 
D:  <laugh> 
C:  I guess .  
C:  Uh . 
A:  Yeah . So again this is th this is the downsampling 
A:  <inbreath> 
A:  uh of the uh  the feature vector stream 
A:  and 
A:  <inbreath> 
A:  um 
A:  Yeah I guess the  
A:  the uh LDA filters they were doing do have 
A:  um 
A:  <mouth> 
A:  uh let 's see , so the  the  
A:  the feature vectors are calculated every ten milliseconds so 
A:  <inbreath> 
A:  uh the question is how far down they are at fifty  fifty hertz . Uh . 
C:  Yeah . 
A:  <inbreath> 
C:  Mm - hmm . 
A:  Um . 
D:  <mike sound> 
A:  Sorry at twenty - five hertz since they 're downsampling by two . 
A:  <inbreath> 
A:  So . Does anybody know what the 
A:  frequency characteristic is ? 
A:  <inbreath> 
C:  We don't have yet 
C:  um 
A:  Oh OK . 
C:  <inbreath> 
C:  So , yeah . 
C:  We should have a look first at , perhaps , 
A:  OK . 
A:  Yeah . 
C:  <inbreath> 
C:  the modulation spectrum . 
C:  <inbreath> 
C:  Um . 


C:  So there is this , 
C:  there is 
C:  the um length of the filters . 
C:  <mouth> 
C:  Um . 
C:  <mouth> <inbreath> 
C:  So the i this idea of trying to find filters with shorter delays . 
C:  <inbreath> 
C:  Um . 
A:  Hmm - hmm . 
C:  We started to work with this . 
C:  Mmm . 
C:  <mouth> <inbreath> 


C:  And the third point um 
C:  <mouth> <inbreath> 
C:  was the um , 
C:  yeah , 
C:  <inbreath> 
C:  the on - line normalization where , 
C:  well , the recursion f 
C:  recursion for the mean estimation 
C:  <inbreath> 
C:  is a filter with some kind of delay 
C:  <inbreath> 
A:  Yeah . 
C:  and that 's not taken into account right now . 
C:  <inbreath> 
C:  Um . 
C:  Yeah . 
C:  And there again , yeah . 
C:  For this , the conclusion of Hynek was , well , 
C:  " we can try it but  " 
C:  <laugh> 
A:  Uh - huh . 
C:  Um . 
A:  Try  try what ? 
C:  So try 
C:  to um 
C:  <inbreath> <mouth> 
C:  um 
C:  take into account the delay of the recursion for the mean estimation . 
A:  OK . 
C:  <inbreath> 
C:  <clear throat> 
C:  Mmm . 
C:  And this  we 've not uh worked on this yet . 
C:  <inbreath> 
C:  Um , yeah . 
C:  <inbreath> 


C:  And so while discussing about these  these LDA filters , 
C:  some i issues appeared , like 
C:  <inbreath> 
C:  well , 
C:  the fact that 
C:  if we look at the frequency response of these filters it 's 
C:  <inbreath> 
C:  uh , 
C:  well , we don't know really what 's the important part 
C:  in the frequency response and there is the fact that 
C:  <inbreath> 
C:  in the very low frequency , 
C:  these filters don't  don't 
C:  really remove a lot . 
C:  <inbreath> 
C:  compared to the  
A:  <inbreath> <mouth> 
C:  to the uh standard RASTA filter . 
C:  <inbreath> 
C:  Uh and that 's 
C:  probably a reason why , yeah , on - line normalization helps because 
A:  Right . 
C:  it  it , yeah , it removed this mean . <laugh> 
A:  <laugh> 
C:  <inbreath> 
C:  Um . 
C:  Yeah , but perhaps everything could  
C:  should be  
C:  could be in the filter , I mean , 
C:  uh the  the mean normalization and  
C:  <inbreath> 
C:  Yeah . So . 
C:  <laugh> 
C:  Yeah . So basically that was  
C:  that 's 
C:  <inbreath> 
C:  all we discussed about . We discussed about 
C:  <inbreath> 
C:  good things to do also uh 
C:  well , generally good stuff 
C:  <laugh> 
A:  Mm - hmm . 
C:  to do for the research . 
C:  <inbreath> 
C:  And this was this LDA uh tuning perhaps and 
C:  <inbreath> 
C:  Hynek proposed again to 
C:  his uh TRAPS , so . 
C:  <inbreath> 
A:  <inbreath> <mouth> 
A:  OK . 
C:  Yeah , um . 
A:  <inbreath> 


A:  I mean I g I guess the key thing for me is  
A:  is figuring out how to better coordinate between the two sides cuz  because um 
C:  <sniff> 
C:  Mm - hmm . 
A:  <inbreath> 
A:  uh I was talking with Hynek about it later and the  the  sort of had 
A:  the sense sort of that  that neither group of people wanted to  to bother the other 
A:  group too much . 
C:  <laugh> 
A:  <laugh> 
E:  <spikes> 
A:  And  and I don't think anybody is , you know , 
E:  <spikes> 
E:  <spikes> 
A:  closed in in their 
A:  thinking or are unwilling to talk about things but I think that 
E:  <spikes> 
A:  <inbreath> 
A:  you were sort of 
A:  waiting for them to 
A:  <inbreath> 
A:  tell you that they had something for you and  and that  
A:  and expected 
E:  <spikes> 
A:  that they would do certain things and they were sor they didn't wanna bother you and 
C:  Mm - hmm . 
A:  <inbreath> 
A:  they were sort of waiting for you and  and  and uh we ended up with this thing where they  
A:  they were filling up 
A:  all of the 
E:  <spikes> 
A:  possible latency themselves , and they just had 
A:  hadn't thought of that . So . 
E:  <spikes> 
A:  <inbreath> 
A:  Uh . <outbreath> 
C:  Yeah . Well , but . Yeah . 
A:  <laugh> 
A:  <inbreath> 
A:  <outbreath> 
C:  Yeah . 
A:  <inbreath> 
A:  I mean it 's true that maybe  maybe no one really thought about that  that this latency thing would be such a  a strict issue 
E:  <spikes> 
C:  Well  
A:  <inbreath> 
A:  in  in uh  
A:  the other  
C:  Yeah I don't know what happened really , but 
C:  <inbreath> 
A:  Yeah . 
C:  I guess it 's  it 's also so uh 
C:  the time constraints . Because , 
C:  <inbreath> 
C:  well , we discussed about that  about this problem and 
C:  they told us " well , we will do 
C:  all that 's possible to have enough space for a network " 
E:  <spikes> 
E:  <spikes> 
C:  <inbreath> 
C:  but then , yeah , 
A:  Then they couldn't . 
C:  perhaps they were 
E:  <spikes> 
C:  too short with the time and 
A:  I see . 
C:  <inbreath> 
C:  uh yeah . 
C:  But there was also problem  
C:  perhaps a problem of communication . So , yeah . 
E:  <spikes> 
C:  Now we will try to  
A:  Just talk more . 
A:  <laugh> 
C:  Yeah , slikes and send mails . 
E:  <spikes> 
A:  <inbreath> 
C:  u s o o 
A:  Yeah . 
C:  Yeah . 
A:  Yeah . 
C:  Uh . 
C:  OK . 
C:  <laugh> 
A:  <inbreath> 


A:  So there 's um  
A:  <mouth> 
A:  Alright . Well maybe we should just 
A:  uh I mean you 're  you 're bus other than that you 
A:  folks are busy doing all the  all the things that you 're trying that we talked about before right ? And this  machines are busy and 
E:  <spikes> 
A:  <inbreath> 
C:  Yeah . 
A:  you 're busy and 
C:  <inbreath> 
A:  <laugh> 
C:  <laugh> 
E:  <spikes> 
C:  <inbreath> 
C:  Basically .  
A:  <inbreath> 
A:  Yeah . 
A:  OK . 
C:  Um . 
A:  Oh . 
A:  <inbreath> 


A:  Let 's  let 's , I mean , I think that 
A:  as  as we said before that 
A:  one of the things that we 're imagining is that uh there  
A:  there will be 
A:  <inbreath> 
A:  uh in the system we end up with there 'll be something to explicitly uh uh 
A:  do something about noise 
A:  <inbreath> 
A:  in addition to the 
C:  Mm - hmm . 
A:  uh other things that we 're talking about 
A:  and that 's probably the best thing to do . And there was that one email that said that 
A:  <inbreath> 
A:  it sounded like uh uh things looked very promising up there 
A:  <inbreath> 
A:  in terms of uh I think they were using Ericsson 's 
E:  <spikes> 
A:  <inbreath> 
A:  approach or something and 
A:  <inbreath> 
A:  in addition to  
A:  They 're doing some noise removal thing , right ? 
C:  Yeah , yeah . 
C:  <inbreath> 
C:  So yeah we 're  will start to do this also . 
A:  Yeah . 
C:  Uh so Carmen is just looking at the Ericsson  Ericsson code . 
D:  Yeah . We modif 
C:  <inbreath> 
A:  Mm - hmm . 
D:  Yeah , I modified it  well , modifying  
C:  And 
D:  <inbreath> 
D:  I studied Barry 's sim code , more or less . 
D:  <inbreath> 
D:  to take @ @ the first step the spectral subtraction . 
D:  <inbreath> 
D:  and we have some  the feature for Italian database 
D:  and we will try with this feature with the filter 
A:  Mm - hmm . 
A:  Mm - hmm . 
D:  to find the result . But we haven't result until this moment . 
A:  Yeah , sure . 
D:  But well , we are working in this also and maybe try another type of spectral subtraction , I don't  
A:  Yeah . 
C:  <clear throat> 
A:  <inbreath> When you say you don't have a result yet you mean it 's  it 's just that it 's in process or that you  
E:  <spikes> 
A:  <inbreath> it finished and it didn't get a good result ? 
D:  No . 
D:  No , no n we have n we have do the experiment 
E:  <spikes> 
D:  only have the feature  the feature but 
C:  Yeah .  
E:  <spikes> 
D:  the experiment have 
D:  we have not make the experiment and 
A:  Oh . 
A:  OK . 
D:  maybe will be good result or bad result , we don't know . <laugh> 
A:  Yeah . 
C:  Yeah .  
A:  Yeah . 
C:  <inbreath> 
A:  OK . 


A:  So um I suggest actually now we  we  
A:  we sorta move on and  and hear what 's  
A:  what 's  what 's 
A:  happening in  in other areas like 
A:  <inbreath> 
A:  what 's  what 's happening with your 
A:  <inbreath> 
A:  investigations 
A:  <inbreath> 
F:  Oh um 
A:  about echos and so on . 
F:  Well um 
F:  I haven't started writing the test yet , I 'm meeting with Adam today 
F:  <inbreath> 
A:  Mm - hmm . 
F:  um and he 's going t show me the scripts he has for um 
F:  <mouth> <inbreath> 
F:  running recognition on mee Meeting Recorder digits . 
E:  <spikes> 
A:  Mm - hmm . 
F:  Uh <inbreath> 
F:  I also um 
E:  <spikes> 
F:  <inbreath> <mouth> 
F:  haven't got the code yet , I haven't asked Hynek for  for the  for his code yet . 
F:  <inbreath> 
F:  Cuz I looked at uh Avendano 's thesis and 
F:  <mouth> 
F:  I don't really understand what he 's doing yet but it  
E:  <spikes> 
F:  <inbreath> 
F:  it  it sounded like um 
F:  <inbreath> 
F:  the channel normalization 
E:  <spikes> 
F:  part 
F:  <inbreath> 
F:  um 
F:  of his thesis um 
E:  <spikes> 
F:  <inbreath> 
F:  was done in a  a bit of 
E:  <spikes> 
F:  I don't know what 
F:  the word is , a  a bit of a rough way um 
F:  <inbreath> 
F:  it sounded like he um 
E:  <spikes> 
F:  <inbreath> 
F:  <outbreath> <inbreath> 
F:  he  he  it  it wasn't really fleshed out and maybe he did something that was 
F:  <inbreath> 
F:  interesting for the test situation 
F:  but I  I 'm not sure if it 's 
F:  <inbreath> 
E:  <spikes> 
F:  what I 'd wanna use so I have to  I have to read it more , I don't really understand what he 's doing yet . 
A:  OK . 
D:  It 's my 
A:  Yeah I haven't read it in a while so I 'm not gonna be too much help unless I read it again , so . 
D:  I know this is mine here . 
C:  Oh yeah ? 
A:  <inbreath> 
A:  OK . 
A:  <inbreath> 
A:  Um . 
A:  <inbreath> 
A:  The um  
A:  so you , and then <outbreath> 
A:  you 're also gonna be doing this echo cancelling between the  
A:  the close mounted and the  
E:  <spikes> 
A:  <inbreath> 
A:  and the  the  the  
A:  what we 're calling a cheating experiment 
A:  uh of sorts 
A:  <inbreath> 
F:  Uh I 
A:  between the distant  
F:  I 'm ho 
F:  Right . Well  
F:  <inbreath> 
F:  or I 'm hoping  
E:  <spikes> 
F:  I 'm hoping Espen will do it . 
F:  Um 
A:  Ah ! 
A:  OK . 
A:  <inbreath> 
A:  F um 
F:  u 
E:  <spikes> 
A:  Delegate . 
A:  That 's good . 
F:  <laugh> 
A:  <laugh> 
A:  It 's good to delegate . 
F:  I  I think he 's at least 
F:  planning to do it for the 
F:  cl close - mike cross - talk and so maybe I can just take whatever setup he has and use it . 
A:  Great . 
A:  Great . 
A:  <inbreath> 


A:  Yeah actually um 
A:  he should uh 
E:  <spikes> 
A:  <inbreath> 
A:  I wonder who else is 
A:  <inbreath> 
A:  I think maybe it 's Dan Ellis is going to be doing uh a different cancellation . Um . 
A:  <inbreath> 
A:  One of the things that 
A:  people working in the meeting task wanna get at 
A:  is they would like to have cleaner 
A:  <inbreath> 
A:  close - miked recordings . 
A:  <inbreath> 
A:  So uh this is especially true for the lapel  but even for the close  close - miked 
A:  uh cases 
A:  <inbreath> 
A:  um we 'd like to be able to have 
A:  <inbreath> 
A:  um 
A:  other sounds from 
A:  other people and so forth removed from  So when someone isn't speaking you 'd like the part where they 're not speaking to actually be  
A:  So 
A:  <inbreath> 
A:  what they 're talking about doing is using ec 
A:  uh 
A:  echo cancellation - like 
A:  techniques . It 's not really echo but 
A:  <inbreath> 
A:  uh just um 
A:  uh 
A:  taking the input from other mikes and using uh 
A:  <inbreath> 
A:  uh 
A:  a uh  
A:  <mouth> 
A:  an adaptive filtering approach to remove the effect of that 
A:  uh other speech . 
A:  So . 
A:  <inbreath> 
A:  Um what was it , there was  there was some  some  
A:  some point where 
A:  <inbreath> 
A:  eh uh Eric or somebody was  was speaking and he had lots of 
A:  <inbreath> 
A:  silence in his channel and I was saying something to somebody else uh 
A:  <inbreath> 
A:  which was in the background and it was not  
A:  it was recognizing my words , 
A:  which were the background speech 
F:  Hmm . 
A:  <inbreath> 
A:  on the close  
A:  <laugh> 
A:  close mike . 
B:  Oh the  What we talked about yesterday ? Yeah that was actually my  I was wearing the  
A:  Yes . 
E:  <spikes> 
A:  Oh you  it was you I was 
B:  I was wearing the lapel and you were sitting next to me , 
B:  <inbreath> 
A:  <inbreath> 
A:  Yeah . 
B:  and I only said one thing but you were talking and it was picking up all your words . 
E:  <spikes> 
A:  <laugh> 
B:  <laugh> 
A:  Yeah . <laugh> 
E:  <laugh> 
A:  Yeah . 
A:  <inbreath> 
A:  So they would like clean channels . 
E:  <spikes> 
A:  Uh and for that  
A:  mmm uh  
A:  that purpose uh 
A:  they 'd like to pull it out . 
A:  So I think  
A:  <inbreath> 
A:  I think Dan Ellis or somebody who was working with him was going to uh 
A:  work on that . 
A:  <click> 
A:  So . 
A:  OK . 
A:  <inbreath> 
A:  Right ? <outbreath> 


A:  Um . 
A:  <inbreath> 
A:  And uh I don't know if we 've talked lately about 
A:  the  the plans you 're developing that we talked about this morning 
A:  uh 
A:  I don't remember if we talked about that last week or not , but 
A:  <inbreath> 
A:  maybe just a quick reprise of  of what we 
E:  Yeah . 
E:  OK .  
A:  were saying this morning . Uh . 
E:  Um .  
E:  So continuing to um extend  
E:  uh 
E:  Larry Saul 's work um just reading  reading how  how we can take 
E:  <spikes> 
E:  <spikes> 
E:  that as a front - end cuz it  it detects these features and they plug it into um back - end so I 've been looking at a lot of 
E:  um back - end stuff people have been doing articulatory features 
E:  and seeing  seeing what I can  
E:  what I can pull off the shelf and plug into um Larry Saul 's work . 
B:  What about the stuff that um 
B:  Mirjam 
B:  has been doing ? 
E:  Oh yeah , sh 
B:  And  
E:  And Shawn ? 
B:  and S Shawn , yeah . 
E:  Yeah . They 're  they 're doing uh neural nets , just  just training up a whole bunch of neural nets and 
B:  Oh . 
E:  I  I think they 're trying to understand um 
E:  <spikes> 
E:  what 's good 
E:  about neural nets in  in terms of , you know , their patterns of errors and 
B:  <mouth> <inbreath> 
B:  So they 're training up nets to try to recognize these acoustic features ? 
E:  Yeah . 
B:  I see . 
A:  <inbreath> 
E:  Yeah . 
B:  <inbreath> 
A:  But that 's uh uh all  that 's  is a  a certainly relevant  
A:  <inbreath> 
A:  uh study and , you know , what are the features that they 're finding . 
A:  <inbreath> 
A:  We have this problem with the overloading of the term " feature " <breath-laugh> so 
B:  Yeah . <laugh> 
A:  <inbreath> 
E:  <laugh> 
A:  uh <breath-laugh> what are the variables , 
E:  <laugh> 
A:  what we 're calling this one , what are the variables that they 're found  finding useful 
C:  Hmm . 
A:  <inbreath> 
A:  um for  
B:  And their  their targets are based on 
B:  canonical mappings of phones to 
B:  acoustic f 
A:  Right . And that 's certainly one thing to do and we 're gonna try and do something more f more fine than that 
B:  features . 
B:  <inbreath> 
A:  but uh 
A:  <inbreath> 
A:  um 
A:  so 
A:  <inbreath> 
A:  um 
A:  <mouth> <inbreath> 
A:  So I guess you know what , I was trying to remember some of the things we were saying , 
A:  do you ha still have that  ? 
E:  Oh yeah . <spikes> 
A:  Yeah . 
A:  <inbreath> 
A:  There 's those 
A:  <inbreath> 
A:   that uh 
A:  yeah , some of  some of the issues we were talking about was in j 
E:  <spikes> 
E:  <spikes> 
A:  just 
A:  getting a good handle on  
A:  on uh 
E:  <spikes> 
A:  <inbreath> 
A:  what " good features " are and  
B:  <inbreath> <mouth> 


B:  What does  what did um Larry Saul use for  it was the sonorant 
E:  <spikes> 
B:  uh detector , right ? 
E:  He di he did uh yeah . 
B:  How did he  
B:  H how did he do that ? Wh - what was his detector ? 
E:  We - oh . 
E:  Um yeah , it was uh sonorance and he also had a paper on voicing too . 
B:  Mm - hmm . 
E:  Um and basically um 
E:  in his variables that he used 
E:  um or measures of SNR at  at sub - bands . Actually critical bands like 
B:  Mm - hmm . 
F:  <paper rustling> 
E:  um the um measures of correlation and covariance 
B:  Oh , OK . 
E:  um within the sub - bands and um and at the upper level detecting uh sonorance and voicing . 
B:  Mm - hmm . 
B:  So how did he combine all these features ? What  what r mmm 
E:  Oh . 
B:  classifier did he u 
E:  Um he used uh um uh 
E:  <spikes> 
E:  a  a belief - net 
E:  where the lower levels of the belief - net are  correspond to individual tests of 
E:  whether there is sonorance within this critical band 
B:  Hmm . 
E:  and then at an upper - level um there 's like this soft " OR " gate so if  
B:  <inbreath> 
B:  Oh right . You were talking about that , yeah . 
E:  so if yeah . Yeah . 
B:  I see . 
B:  <inbreath> 


A:  And the other thing you were talking about is  is  is where we get the targets from . 
A:  <inbreath> 
A:  So I mean , there 's these issues of what are the  what are the variables that you use 
A:  <inbreath> 
A:  and 
A:  do you combine them using the soft " AND - OR " or you do something , you know , more complicated 
A:  <inbreath> 
A:  um 
A:  and then the other thing was so where do you get the targets from ? 
A:  <inbreath> 
A:  The initial thing is just the obvious that 
A:  we 're discussing is 
A:  starting up with phone labels 
A:  <inbreath> 
A:  from somewhere and then 
A:  uh doing the transformation . 
A:  <inbreath> 


A:  But then the other thing is to do something better and eh w 
A:  why don't you tell us again about this  this database ? 
A:  This is the  
E:  Oh OK . Um 
A:  <inbreath> 
E:  Yeah , so there 's uh a group at um Edinburgh 
E:  is working on um <mouth> this MOCHA database where 
E:  um they have measurements of um articulatory positions . So you  you put some  some pellets on people 's tongues and lips 
B:  Hmm ! 
C:  <sniff> 
E:  and  and they can tell 
C:  <sniff> 
A:  And then tell them to talk naturally ? 
B:  <laugh> 
A:  Yeah , yeah . <laugh> 
E:  and they <laugh> 
C:  <laugh> 
E:  Well I guess if you got people who had like um 
A:  <inbreath> 
E:  you know , tongue rings  
B:  Pierced tongues and 
E:  Pierced tongues , or  
B:  Yeah . 
B:  <inbreath> 
A:  <laugh> 
B:  You could just mount it to that and they wouldn't even notice . 
E:  Yeah it doesn't matter . <laugh> 
F:  <laugh> 
A:  <laugh> 
B:  <laugh> 
E:  <spikes> 
C:  <laugh> 
E:  Yeah . 
B:  Weld it . Zzz .  
B:  <laugh> 
E:  But I  I don't  I don't think they 're doing that though . <laugh> 
A:  Maybe you could go to these parlors and  and you could , you know  you know have  have , you know , reduced rates if you  
B:  <laugh> 
B:  Yeah . I 
A:  <laugh> 
A:  if you can do the measurements . 
B:  That 's right . 
A:  <laugh> 
B:  You could  what you could do is you could sell little rings and stuff with embedded 
A:  Yeah . 
B:  you know , transmitters in them and things and 
B:  <inbreath> 
A:  Yeah , be cool and help science . 
B:  <laugh> 
E:  Yeah . 
A:  <laugh> 
E:  Ye - cool . <laugh> 
B:  Yeah . 
B:  <laugh> 
C:  <laugh> 
A:  <inbreath> 
A:  OK . 
E:  Yeah , so they  they  they have this  they 're working on the database , it 's still  it 's still being  being uh transcribed and produced . 
E:  <spikes> 
E:  Um where either you have um acoustic features at the same or  or just uh the acoustic waveform 's being recorded for frame and then 
E:  at each frame you have a measurement of  of the different positions of um uh articulators . 
B:  Hmm ! 
B:  <inbreath> 


B:  There 's a bunch of data that l around , 
B:  that  people have done studies like that w way way back right ? I mean 
B:  <inbreath> 
B:  I can't remember where  uh Wisconsin or someplace that used to have a big database of  
E:  Yeah they have a X  X - ray  
E:  <spikes> 
B:  <inbreath> 
B:  Yeah . 
E:  X - ray database . 
E:  Yeah . 
E:  It 's 
B:  I remember there was this guy at A T - andT , Randolph ? or r 
B:  What was his name ? Do you remember that guy ? 
B:  <inbreath> 
B:  Um , 
B:  <mouth> <inbreath> 
B:  researcher at A T - andT a while back that was studying , 
B:  trying to do speech recognition from these kinds of features . 
B:  <inbreath> 
E:  Hmm . 
B:  I can't remember what his name was . 
B:  Dang . Now I 'll think of it . 
B:  <inbreath> 
E:  Hmm . 
B:  That 's interesting .  
A:  Do you mean eh  but you  I mean  Mar - you mean 
C:  Well he was the guy  
C:  the guy that was using  
A:  when 
A:  was  was Mark Randolph there , or  ?  
B:  Mark Randolph . 
A:  <inbreath> 
A:  Yeah he 's  he 's  he 's at Motorola now . 
B:  Oh is he ? Oh OK . 
A:  Yeah . 
A:  Yeah . 
B:  Yeah . 
C:  Is it the guy that was using the 
C:  pattern of pressure on the tongue or  ?  
B:  <mouth> 
B:  I can't remember exactly what he was using , now . 
B:  But I know  I just remember it had to do with you know 
C:  What  
B:  <inbreath> 
C:  Yeah . 
B:  uh positional 
E:  <spikes> 
B:  parameters <outbreath> and trying to m you know 
C:  Mm - hmm . 
B:  do speech recognition based on them . 
A:  Yeah . 
C:  <mouth> <inbreath> 
A:  <inbreath> 
B:  <inbreath> 


A:  So the only  the only 
A:  uh hesitation I had about it since , I mean I haven't see the data is it sounds like 
A:  it 's  it 's 
A:  <inbreath> 
A:  continuous variables 
A:  and a bunch of them . 
A:  <mouth> 
B:  Hmm . 
A:  And so 
A:  <mouth> 
A:  <mouth> 
A:  I don't know how complicated it is to go from there  
A:  <inbreath> 
A:  What you really want are these binary  labels , 
E:  <spikes> 
A:  and just a few of them . 
A:  <mouth> 
A:  <inbreath> 
A:  And maybe there 's a trivial mapping if you wanna do it and it 's e but it  
A:  I  I  I worry a little bit that this is a research project in itself , 
A:  <inbreath> 
A:  whereas um 
A:  <inbreath> 
A:  if you did something instead that  like 
A:  um 
A:  having some manual annotation 
A:  by 
A:  <inbreath> 
A:  uh you know , linguistics students , 
A:  <inbreath> 
A:  this would  
A:  there 'd be a limited s 
A:  set of things that you could do a as per our discussions with  with John before 
B:  Mm - hmm . 
A:  <inbreath> 
A:  but 
A:  the things that you could do , like nasality and voicing and a couple other things 
A:  you probably could do reasonably well . 
B:  Mm - hmm . 
A:  And then there would  it would really be uh this uh 
A:  uh binary variable . 
A:  Course then , that 's the other question is do you want binary variables . So . 
A:  <inbreath> 
A:  I mean the other thing you could do is 
A:  <inbreath> 
A:  boot trying to  
A:  to uh 
A:  get those binary variables 
A:  <inbreath> 
A:  and take the continuous variables from 
A:  <inbreath> 
A:  uh 
A:  the uh 
A:  <inbreath> 
A:  uh the data itself there , but 
A:  I  I 'm not sure  
A:  <inbreath> 
B:  Could you cluster the  
B:  just do some kind of clustering ? 
B:  <inbreath> 
A:  Guess you could , yeah . 
B:  <uncodeable, possibly serving as a backchannel> 
B:  Bin them up into different categories and  
A:  Yeah . 
A:  <inbreath> 
A:  So anyway that 's  that 's uh  that 's another whole 
A:  direction that cou could be looked at . 
E:  Mm - hmm . 
A:  Um . 
A:  <inbreath> 
A:  Um . 
A:  <inbreath> 
A:  I mean in general it 's gonna be  for new data that you look at , it 's gonna be hidden variable because we 're not gonna get everybody sitting in these meetings to 
A:  <inbreath> 
B:  <laugh> 
A:  wear the pellets and  <laugh> 
E:  Right . 
A:  Um . 
A:  So . 
E:  Right . 
B:  <inbreath> 


B:  So you 're talking about using that data to get 
C:  <breath-laugh> 
B:  uh  
B:  instead of using canonical mappings 
E:  Right . 
B:  of phones . So you 'd use that data to give you 
B:  sort of what the  
B:  <inbreath> 
B:  the true mappings are for each phone ? 
E:  Mm - hmm . 
B:  I see . 
E:  Mm - hmm . 
B:  <inbreath> 
A:  Yeah . 
A:  So wh yeah , where this 
A:  fits into the rest in  in my mind , I guess , is that um 
A:  <inbreath> 
A:  we 're looking at different 
A:  ways that we can combine 
A:  <inbreath> 
A:  uh different kinds of  
A:  of rep 
A:  front - end representations 
A:  <inbreath> 
A:  um in order to get robustness under difficult or even , 
A:  you know , 
A:  typical conditions . 
A:  <inbreath> 
A:  And part of it , this robustness , seems to come from 
A:  <inbreath> 
A:  uh 
A:  multi - stream or multi - band sorts of things and Saul seems to have 
A:  <inbreath> 
A:  a reasonable way of looking at it , at least for one  
A:  <click> <inbreath> 
A:  one um articulatory feature . 
A:  <inbreath> 
A:  The question is is can we learn from that 
A:  <inbreath> 
A:  to change some of the other methods we have , since  
A:  <inbreath> 
A:  I mean , one of the things that 's nice about what he had I thought was that  
A:  that it  
A:  it um  
A:  <inbreath> 
A:  the decision about how 
A:  strongly to train the different pieces is based on 
A:  uh a  a reasonable criterion with hidden variables rather than 
A:  <inbreath> 
A:  um 
A:  just assuming 
A:  <inbreath> 
A:  that you should train e e every 
A:  detector 
A:  uh 
A:  with equal strength 
A:  <inbreath> 
A:  towards uh it being this phone or that phone . 
B:  Hmm . 
A:  Right ? 
A:  So it  so um 
A:  <inbreath> 
A:  he 's got these 
A:  um 
A:  uh 
A:  uh 
A:  he " AND 's " between these different 
A:  <inbreath> 
A:  features . 
A:  It 's a soft " AND " , I guess but in  in principle 
A:  <inbreath> 
A:  you  you wanna get a strong concurrence of all the different things that indicate something 
A:  <inbreath> 
A:  and then he " OR 's " across the different  soft " OR 's " across the different uh 
A:  <inbreath> 
A:  multi - band channels . 
A:  <inbreath> 
A:  And um 
A:  <mouth> 
A:  the weight 
A:  <inbreath> 
A:  yeah , the target 
A:  for the training of the " AND "  " AND ' ed " things 
A:  <inbreath> 
A:  is something that 's kept 
A:  <inbreath> 
A:  uh as a hidden variable , 
A:  and is learned with EM . 
A:  <inbreath> 
B:  <inbreath> 
B:  So he doesn't have  
A:  Whereas what we were doing is  
A:  is uh 
A:  <inbreath> 
A:  taking 
A:  <inbreath> 
A:  the phone target and then just back propagating 
A:  from that 
A:  which means that it 's  
A:  <inbreath> 
A:  it 's uh 
A:  i It could be for instance 
A:  <inbreath> 
A:  that 
A:  for a particular 
A:  point in the data 
A:  <inbreath> 
A:  you don't want to um 
A:  uh 
A:  train a particular band  train the 
A:  detectors for a particular band . You  you wanna ignore 
A:  <inbreath> 
A:  that band , cuz that 's a  Ban - band is a noisy  noisy measure . 
B:  Mm - hmm .  
A:  <inbreath> 
A:  And we don't  
A:  We 're  we 're still gonna try to train it up . 
A:  <inbreath> 
A:  In our scheme we 're gonna try to train it up 
A:  to do as well  well as it can at predicting . 
A:  <inbreath> 
A:  Uh . Maybe that 's not the right thing to do . 
B:  <inbreath> 
B:  So he doesn't have to have 
B:  truth marks 
B:  or  Ho - 
E:  F right , and uh he doesn't have to have hard labels . 
A:  Well at the  at the 
A:  tail end , yeah , he has to know what 's  where it 's sonorant . 
A:  <inbreath> 
E:  Right . For the full band . 
A:  But he 's  but what he 's - but what he 's not training up  uh what he doesn't 
B:  <inbreath> 
A:  depend on as truth is 
A:  <inbreath> 
A:  um 
A:  I guess one way of describing would be 
A:  if  
A:  if a sound is sonorant 
A:  is it sonorant in this band ? Is it sonorant in that band ? Is it sonorant in that band ? 
E:  Right . 
E:  <spikes> 
A:  <inbreath> 
A:  i It 's hard to even answer that what you really mean is that the whole sound is sonorant . So 
B:  Mm - hmm . OK . 
A:  <inbreath> 
A:  then it comes down to , you know , to what extent should you make use of information from particular band 
A:  <inbreath> 
A:  towards making your decision . 
B:  I see . 
A:  And um 
A:  <inbreath> 
A:  uh 
A:  we 're making 
A:  in a sense sort of this hard decision that you should  you should use everything 
A:  <inbreath> 
A:  uh with  
A:  with uh equal strength . 
A:  <inbreath> 
A:  And uh because in the ideal case we would be going for posterior probabilities , if we had 
A:  <inbreath> 
A:  uh 
A:  enough data to really get 
E:  <spikes> 
A:  posterior probabilities 
A:  <inbreath> 
A:  and if the  if we also had enough data so that it was representative of the test data 
A:  <inbreath> 
A:  then we would in fact be doing the right thing to train everything as hard as we can . 
A:  <inbreath> 
A:  But um 
A:  this is something that 's more built up along an idea of robustness from  
A:  from the beginning and so you don't necessarily want to train everything up towards the  
A:  <inbreath> 
B:  <inbreath> 


B:  So where did he get his  uh 
E:  <spikes> 
B:  his tar his 
B:  uh high - level targets about what 's sonorant and what 's not ? 
E:  From uh canonical mappings  
B:  OK . 
E:  um at first and then 
A:  Yeah . 
E:  it 's unclear um eh using TIMIT right , right .  
B:  Using TIMIT ? or using  
B:  Uh - huh . 
A:  Yeah . 
E:  And then uh 
E:  he does some fine tuning 
E:  um 
E:  for um special cases .  
E:  Yeah .  
A:  Yeah . 
A:  <inbreath> 
A:  I mean we ha we have a kind of 
A:  <inbreath> 
A:  iterative training 
E:  <spikes> 
A:  because we do this embedded Viterbi , 
A:  <inbreath> 
A:  uh so there is some 
B:  <inbreath> 
A:  something that 's suggested , 
A:  based on the data but it 's  
E:  <spikes> 
A:  it 's not  
A:  <inbreath> 
A:  I think it s doesn't seem like it 's quite the same , 
A:  cuz of this  cuz then whatever 
A:  <inbreath> 
A:  that 
A:  alignment is , it 's that for all  
B:  Mm - hmm . 
A:  all bands . Well no , that 's not quite right , we did actually do them separate  tried to do them separately 
A:  <inbreath> 
A:  so that would be a little more like what he did . 
A:  <inbreath> 
A:  Um . 
A:  But it 's still 
A:  <inbreath> 
A:  not quite the same because then it 's  
E:  <spikes> 
A:  it 's um 
A:  setting targets based on where you would say 
A:  <inbreath> 
A:  the sound begins 
A:  in a particular band . 
A:  Where he 's s this is not a labeling per se . 
E:  <spikes> 
A:  <inbreath> 
E:  Mm - hmm . 
A:  Might be closer I guess if we did a 
E:  <spikes> 
A:  <inbreath> 
A:  soft  soft target uh 
A:  <inbreath> 
A:  uh 
A:  embedded 
A:  <inbreath> 
A:  neural net training like we 've done a few times uh 
A:  <inbreath> 
A:  f the forward um  
A:  do the forward calculations to get the gammas and 
A:  train on those . 
A:  <inbreath> 
A:  Mmm . 


A:  Uh 
A:  what 's next ? 
A:  <laugh> 
B:  I could say a little bit about w 
B:  stuff I 've been 
B:  playing with . 
B:  <inbreath> 
A:  Oh . 
B:  I um 
A:  You 're playing ? 
A:  <laugh> 
B:  Huh ? 
E:  <laugh> <spikes> 
A:  You 're playing ? 
A:  <laugh> 
B:  Yes , I 'm playing . 
B:  <laugh> 
C:  <breath-laugh> 
B:  Um 
B:  <inbreath> 
B:  so I 
B:  wanted to do this experiment to see um 
B:  <mouth> 
B:  uh what happens if we 
B:  try to 
B:  uh improve the performance of the back - end 
B:  recognizer for the Aurora task 
E:  <mike sound> 
B:  <inbreath> 
B:  and see how that affects things . 
B:  <inbreath> 
B:  And so I had this um  
B:  I think I sent around last week a  
B:  <inbreath> 
B:  this 
B:  plan I had for an experiment , this matrix where 
C:  <sniff> 
B:  <inbreath> 
B:  I would take the um  
B:  the original 
B:  um 
B:  the original system . So there 's the original system trained on 
B:  the mel 
B:  cepstral features 
B:  <inbreath> 
B:  and then com and then uh 
B:  optimize the b 
B:  HTK system and run that again . 
B:  So look at the difference there 
B:  <inbreath> 
B:  and then 
B:  uh 
B:  do the same thing for 
B:  <inbreath> 
B:  the ICSI - OGI 
B:  front - end . 
B:  <inbreath> 
A:  What  which test set was this ? 
B:  <inbreath> <mouth> 
B:  This is  that I looked at ? 
A:  Mm - hmm . 
B:  Uh I 'm looking at the Italian 
A:  Mm - hmm . 
B:  right now . 
B:  <inbreath> 
B:  So as far as I 've gotten is I 've 
B:  uh 
B:  <two mouth clicks> been able to go through from beginning to end the um 
B:  full HTK 
B:  <inbreath> 
B:  system for the Italian 
B:  data and got the same results that um  
B:  that uh 
B:  <inbreath> 
B:  Stephane had . 
B:  <inbreath> 
B:  So um 
B:  I started looking  
B:  to  and now I 'm  
B:  I 'm sort of lookin 
B:  at the point where I wanna know what should I change 
B:  in the HTK back - end in order to try to  
B:  uh 
B:  to improve it . 
B:  So . 
B:  <inbreath> 
B:  <mouth> 


B:  One of the first things I thought of was the fact that they use 
B:  <inbreath> 
B:  the same number of states for all of the 
B:  models 
B:  <inbreath> 
A:  Mm - hmm . 
B:  and so I went on - line and I 
B:  uh found a pronunciation 
B:  dictionary for Italian digits 
A:  Mm - hmm . 
B:  <inbreath> 
B:  and just looked at , you know , the number of phones in each 
C:  <sniff> 
B:  one of the digits . 
B:  <inbreath> 
B:  Um 
B:  you know , sort of the 
B:  canonical way of 
B:  setting up a  an HMM system is that you use 
B:  <inbreath> 
B:  um 
B:  three states per phone 
B:  and um 
C:  <sniff> 
B:  <inbreath> 
B:  so then the  the total number of states for a word would just be , you know , the number of phones times three . 
B:  <inbreath> 
B:  And so when I did that for the 
B:  Italian digits , I got 
B:  a number of states , 
B:  ranging on the low end from nine 
B:  to the high end , eighteen . 
B:  <inbreath> 
C:  <sniff> 
B:  Um . 
B:  <mouth> 
B:  Now you have to really add two to that because in HTK there 's an initial null and a final null 
B:  so when they use 
B:  <inbreath> 
B:  uh 
B:  models that have eighteen states , there 're really sixteen 
B:  states . They 've got those initial and final null states . 
B:  <inbreath> 
B:  And so um 
C:  <sniff> 
B:  <mouth> <inbreath> 
B:  their 
B:  guess of eighteen states seems to be pretty well matched to 
B:  the two longest words of the Italian digits , the four and five 
B:  <inbreath> 
A:  Mm - hmm . 
B:  which um , according to my , 
B:  you know , sort of off the cuff calculation , should have eighteen states each . 
B:  And so they had sixteen . So that 's pretty close . 
B:  <inbreath> 
B:  Um 
B:  <mouth> <inbreath> 
B:  but for the  
B:  most of the words 
B:  are sh much shorter . 
B:  So the majority of them 
B:  wanna have nine states . 
B:  <inbreath> 
B:  And so theirs are s 
B:  sort of twice as long . 
B:  So 
B:  <inbreath> 
B:  my guess  
B:  uh 
B:  And then if you  
B:  I  I printed out a confusion matrix 
C:  <sniff> 
B:  um 
B:  <inbreath> 
B:  uh for the well - matched 
B:  case , 
B:  and it turns out that the longest words are actually the ones that do the best . 
B:  <inbreath> 
B:  So my guess about what 's happening is that 
B:  <inbreath> 
B:  you know , if you assume a fixed  
B:  the same amount of training data for each of these 
B:  digits 
B:  <inbreath> 
B:  and 
B:  a fixed length model for all of them 
C:  <sniff> 
B:  <inbreath> 
B:  but the actual words for some of them are 
C:  <sniff> 
B:  half as long 
B:  <inbreath> 
B:  you really 
B:  um 
B:  have , 
B:  you know , 
B:  half as much training data for those models . 
B:  <inbreath> 
B:  Because if you have a long word 
B:  and you 're training it to eighteen states , 
C:  <sniff> 
C:  <sniff> 
B:  <inbreath> 
B:  <mouth> 
B:  uh 
B:  you 've got  
A:  Mm - hmm . 
B:  you know , you 've got the same number of 
B:  Gaussians , you 've gotta train in each case , but 
B:  for the shorter words , 
B:  you know , the total number of frames is actually half as many . 
C:  <sniff> 
B:  <inbreath> 
A:  Mm - hmm . 
B:  So 
B:  <inbreath> 
B:  it could be that , 
B:  you know , for the short words there 's  
B:  because you have so many states , you just don't have enough data to train all those Gaussians . 
B:  <inbreath> 
B:  So um 
B:  I 'm going to try to um create more word - specific 
B:  <inbreath> 
B:  um 
B:  uh 
B:  prototype H M Ms to start training from . 
C:  <sniff> 
A:  Yeah , I mean , it 's not at all uncommon you do worse on long word on short words than long words anyway just because you 're accumulating more evidence for the  
B:  Mm - hmm . 
A:  for the longer word , but . 
B:  <inbreath> 


B:  Yeah so I 'll  I 'll , 
C:  <sniff> 
B:  the next experiment I 'm gonna try is to just um you know 
B:  create 
B:  <inbreath> 
B:  uh models that seem to be more w matched to 
A:  Mm - hmm . 
B:  my guess about how long they should be . 
C:  <sniff> 
B:  <inbreath> 
B:  And as part of that 
B:  um 
B:  I wanted to see sort of 
B:  how the um  
B:  how these models were 
B:  coming out , you know , what w 
B:  <inbreath> 
B:  when we train up uh th you know , the model for " one " , which wants to have 
B:  nine states , you know , 
B:  <inbreath> 
B:  what is the  
B:  uh what do the transition 
B:  probabilities look like  in the self - loops ,  look like in  in those models ? 
B:  <inbreath> 
B:  And so I talked to Andreas and 
B:  he 
B:  explained to me how you can 
B:  <inbreath> 
B:  calculate the expected duration 
B:  of an HMM just 
A:  Mm - hmm . 
B:  by looking at the transition 
B:  matrix 
B:  <inbreath> 
B:  and so I wrote a little Matlab 
B:  script that calculates that and 
B:  <inbreath> 
B:  so I 'm gonna 
B:  sort of print those out for each of the words 
A:  Mm - hmm . 
B:  to see 
C:  <sniff> 
B:  what 's happening , you know , how these models are training up , you know , the long ones versus the short ones . 
A:  Mm - hmm . 
B:  <inbreath> 


B:  I d I did  
B:  quickly , I did the silence model and  
B:  <inbreath> 
B:  and um 
B:  that 's coming out with about one point two 
B:  seconds as its average duration and the silence model 's the one that 's used at the beginning and the end of each of the 
E:  <spikes> 
A:  Wow . 
B:  <inbreath> 
B:  string of digits . 
B:  <inbreath> 
A:  Lots of silence . 
E:  <spikes> 
B:  Yeah , yeah . 
B:  <inbreath> 
B:  And so the 
B:  S P model , which is what they put in between digits , I  I haven't calculated that for that one yet , 
C:  <sniff> 
B:  but um . 
E:  <spikes> 
B:  <inbreath> 
B:  So they basically  their  
B:  <inbreath> 
B:  their model for a whole digit string is silence 
B:  <inbreath> 
B:  digit , 
B:  SP , digit , 
B:  SP blah - blah - blah and then silence at the end . 
E:  <spikes> 
B:  <inbreath> 
B:  And so . 
A:  Are the SP 's optional ? I mean skip them ? 
E:  <spikes> 
B:  <mouth> <inbreath> 
C:  <sniff> 
B:  I have to look at that , 
B:  but I 'm not sure that they are . 
E:  <spikes> 
B:  Now the one thing about the S P model is really it only has 
B:  a single 
C:  <sniff> 
B:  s emitting state to it . 
E:  <spikes> 
B:  <inbreath> 
A:  Mm - hmm . 
B:  So if it 's not optional , 
B:  you know , it 's  it 's not gonna hurt a whole lot 
A:  I see . 
B:  and it 's tied to the center state of the silence model so it 's not its own  
B:  <inbreath> 
B:  um 
B:  It doesn't require its own training data , it just shares that state . 
A:  Mm - hmm . 
B:  <inbreath> 
A:  Mm - hmm . 
B:  So it , I mean , it 's pretty good 
B:  the way that they have it set up , 
B:  but um 
E:  <spikes> 
B:  i 


B:  So I wanna play with that a little bit more . 
E:  <spikes> 
B:  I 'm curious about looking at , 
B:  you know 
B:  <inbreath> 
B:  how these models have trained and looking at the expected durations 
C:  <sniff> 
E:  <spikes> 
B:  of the models 
B:  <inbreath> 
B:  and I wanna compare that 
B:  in the  the well - matched case f 
B:  to the unmatched case , and see 
B:  if you can get an idea of   
B:  just from looking at the 
B:  <inbreath> 
B:  durations of these models , you know , what what 's happening . 
B:  <inbreath> 
E:  <spikes> 
A:  Yeah , I mean , I think that uh , as much as you can , it 's good to 
C:  <sniff> 
A:  d 
A:  sort of not do anything really tricky . 
B:  Mm - hmm . 
A:  Not do anything that 's really finely tuned , but just sort of 
B:  Yeah . 
A:  eh you know you t you i z 
A:  The premise is kind of you have a  a good person look at this for a few weeks and what do you come up with ? 
B:  Mm - hmm . 
B:  Mm - hmm . 
A:  And uh 
B:  <inbreath> 
B:  And Hynek , when I wa told him 
B:  about this , he had an interesting point , and that was th um 
E:  <spikes> 
C:  <sniff> 
B:  <inbreath> 
B:  the  the final models that they end up training up have 
B:  I think 
B:  probably something on the order of six 
B:  Gaussians per state . 
B:  <inbreath> 
B:  So they 're fairly , you know , hefty models . And Hynek was saying that 
B:  well , probably in a real application , 
B:  <inbreath> 
E:  <spikes> 
B:  you wouldn't 
B:  have enough compute 
B:  to handle models that are very big or complicated . 
B:  <inbreath> 
B:  So in fact what we may want 
B:  are simpler models . 
C:  <sniff> 
A:  Could be . 
B:  And compare how they 
B:  perform to that . But 
B:  <inbreath> 
B:  you know , it depends on what 
B:  the actual application is and it 's really hard to know 
B:  what your 
B:  limits are in terms of how many Gaussians you can have . 
B:  <inbreath> 
A:  Right . And that , I mean , at the moment that 's not the limitation , so . 
B:  Mm - hmm . 
A:  <inbreath> 
A:  I mean , I  I  I  what I thought you were gonna say i but which I was thinking was um 
A:  <inbreath> 
A:  where did six come from ? Probably came from the same place eighteen came from . You know , so . 
B:  Yeah . Right .  
B:  <inbreath> 
A:  Uh <laugh> that 's another parameter , right ? that  
B:  Yeah , yeah . 
A:  that maybe , you know , uh  you really want three or nine or  
B:  <inbreath> 
B:  Well one thing  I mean , if I  
B:  if  
B:  if I start 
C:  <sniff> 
B:  um 
B:  reducing the number of states 
B:  for some of these shorter models 
B:  <inbreath> 
B:  that 's gonna reduce the total number of Gaussians . So in a sense it 'll be a simpler 
A:  Right . 
B:  system . 
A:  Yeah . 
B:  <inbreath> 
A:  Yeah . 
A:  <inbreath> 
A:  But I think right now again the idea is doing 
A:  just very simple things 
B:  Yeah . 
A:  <inbreath> 
A:  how much better can you make it ? And um 
B:  Mm - hmm . 
A:  since they 're only simple things there 's nothing that you 're gonna do that is going to blow up the amount of computation um so 
B:  Right . 
B:  Right . 
A:  <inbreath> 
A:  if you found that nine was better than six that would be O K , I think , actually . 
B:  Mm - hmm . 
B:  Yeah . 
A:  Doesn't have to go down . 
B:  <inbreath> 
B:  I really wasn't even gonna play with that part of the system yet , I was just gonna 
A:  Mm - hmm , OK . 
B:  change the  
A:  Yeah , just work with the models , yeah . 
B:  the t 
B:  yeah , just look at the length of the models and just see what happens . 
B:  <inbreath> 
A:  Yeah . 
B:  So . 
A:  Cool . 
A:  <inbreath> 


A:  OK . 
A:  So uh 
A:  <inbreath> 
C:  <sniff> 
A:  what 's uh 
A:  I guess your plan for  
A:  You  you  you guys ' plan for the next  next week is 
A:  <inbreath> 
A:  just continue on these  these same things we 've been talking about 
A:  for Aurora and 
C:  Yeah , I guess we can try to 
C:  <inbreath> 
C:  have some kind of new baseline for next week perhaps . 
C:  <inbreath> 
C:  with all these minor things 
C:  <inbreath> 
C:  <mouth> 
C:  modified . 
C:  <inbreath> 
C:  And then do 
C:  other things , 
C:  play with the spectral subtraction , 
C:  <inbreath> 
C:  and 
C:  <mouth> 
C:  retry the MSG and things like that . 
C:  <inbreath> 
A:  Yeah . 
C:  <laugh> 
A:  Yeah . 
D:  <laugh> 
A:  <inbreath> 
A:  Yeah we  we have a big list . <laugh> 
C:  Big list ? 
A:  <inbreath> 
A:  You have a big list of  <laugh> of things to do . <laugh> 
C:  <laugh> 
A:  So . 
C:  <sniff> 
A:  <inbreath> 
A:  Well that 's good . I think 
A:  <inbreath> 
A:  that after all of this uh 
A:  um 
A:  confusion settles down in another  
C:  <sniff> 
A:  some point 
A:  a little later next year there will be some sort of standard and it 'll get out there and 
A:  <inbreath> 
A:  hopefully it 'll have some effect from something <laugh> that  
C:  <laugh> 
C:  <laugh> 
A:  <inbreath> 
A:  that has uh 
A:  been done by our group of people but 
A:  uh 
A:  e even if it doesn't there 's  
A:  <inbreath> 
A:  there 's go there 'll be standards after that . 
A:  So . 
B:  <inbreath> 


B:  Does anybody know how to um 
B:  <inbreath> 
E:  <spikes> 
B:  run Matlab 
B:  sort of in batch mode like 
B:  you c send it 
B:  <inbreath> 
B:  s a bunch of commands to run and it 
E:  <spikes> 
C:  <sniff> 
B:  gives you the output . Is it possible to do that ? 
E:  I  I think uh Mike tried it  
B:  Yeah ? 
E:  and he says it 's impossible so he went to Octave .  
E:  Octave is the um UNIX clone of  of Matlab which you can batch .  
B:  Octave . 
B:  Ah ! 
B:  OK . 
B:  Great . 
B:  Thanks . 
E:  Yeah . 
B:  <inbreath> 
B:  <laugh> 
B:  I was going crazy trying to do that . 
B:  <laugh> 
E:  <laugh> 
A:  <inbreath> 
A:  Huh . 
E:  Yeah . 
C:  What is Octave so ? 
E:  What 's that ? 
C:  It 's 
C:  a free software ? 
E:  Uh , Octave ? Yeah it 's  it 's  it 's free . I think we have it here  
C:  Yeah . 
E:  r running somewhere . 
B:  Great ! 
E:  Yeah . 
C:  And it does the same syntax and everything eh 
E:  <spikes> 
E:  Um <mouth>  
C:  like Matlab , or  ?  
E:  i it 's a little behind , it 's the same syntax but it 's a little behind in that  
E:  Matlab went to these like um you can have cells and you can  you can  
E:  uh implement object - oriented type things with Matlab . 
E:  Uh Octave doesn't do that yet , so I think you , Octave is kinda like Matlab 
E:  um four point something or . 
B:  <inbreath> 
B:  If it 'll do like 
B:  a lot of the basic 
E:  The basic stuff , right . 
B:  matrix and vector stuff 
B:  that 's 
B:  perfect . 
B:  <inbreath> 
E:  Yeah . 
B:  Great ! 
C:  <outbreath> 
A:  <inbreath> 


A:  OK , guess we 're done . 
E:  OK . 
F:  Well , although by the way .  
E:   
D:  <mike sound> 
E:  <spikes> 
B:   
C:  <mike goes dead> 
A:   
D:  <mike sound> 
E:  <mike sound> 


