{"dialogue": "so where are we onon uh <laugh> our runs ? uh so . uhwesoas i was already said , wewe mainly focused on uh four kind of features . the plp , the plp with jrasta , the msg , and the mfcc from the baseline aurora . uh , and we focused for thethe test part on the english and the italian . um . we 've trained uh several neural networks on soon the ti - digits englishand on the italian data and also on the broad uhenglish uh french and uh spanish databases . and um , actually what wewe @ @ observed is that if the network is trained on the task data it works pretty well .", "summary": "abstract: the meeting was dominated by a discussion of the first results coming in ."}
{"dialogue": "the first testing iswith task data the second test is trained on a single language um with broad database , but the same language as the t task data . but for italian we choose spanish whichwe assume is close to italian . the third test is by using , um the three language database that 's including the w thethe the one that it 's yeah . it 's the broaddata . and the fourth test is uhexcluding from these three languages the languagethat isthe task language .", "summary": "abstract: there have been four types of test , in which the training data varies , and a variety of input features have been tried ."}
{"dialogue": "but actually we did n't train network onuh both types of data we only did either tasktask data oruh broaddata . and then when we jump to the multilingual data it 's uh it become worse uh . the error rate increase u ofofof ten percent , relative . exampleuh when we go from ti - digits training totimit traininguh we loseuh around ten percent , twenty toto thirty percent further . ok , but i think thatgiven the pressure of time we probably want to drawbecause of thatespecially , we wan na draw some conclusions from this , and make some strong decisions for what we 're gon na do testing on before next week .", "summary": "abstract: the process and results were explained to the group , the implications of the results discussed , and plans for moving forward were made ."}
{"dialogue": "so they 'rethey 're doingthethe vad i guess they mean voice activity detection so again , it 's the silence so um their uhthe results look pretty good . so um i think that it 'sit 's nice to do that in this because in fact , it 's gon na give a better word error result and therefore will help within an evaluation . um . uh , as you know , part of the problem with evaluation right now is that theword models are pretty bad and nobody wantshashas approached improving them . so um the question we 're gon na wan na gothrough next week when hynek shows up i guess is given that we 've been we 're uh looking atuh , by then i guess , combinations of features and multi - band uh , and we 've been looking atcross - language , crosstaskissues . but they 've been looking at uhat these issues . at the on - line normalization and the uhvoice activity detection . and i guess when he comes here we 're gon na have to start deciding aboutum what do we choosefrom what we 've looked atto um blend withsome group of things in what they 've looked at and once we choose that , how do we split up theeffort ?", "summary": "abstract: there was also discussion of some of the work being conducted by research partners ogi , including how the two groups should best work together ."}
{"dialogue": "we have thelittle tiny ibm machine <laugh> that might someday grow up to be a bigibm machine . it 's got s slots for eight , i think we only got two so far , yeah , i mean you can check with uhdave johnson . andsomebody could doyou know , uh , check outuh the multi - threadinglibraries . i mean , i guess the prudent thing to do would be for somebody to do the work onon getting our code runningon that machine with two processorseven though there are n't five or eight .", "summary": "abstract: the group also briefly touched upon resource issues ."}
{"dialogue": "uh so , act actually we have discussed uh @ @ um , these andandwe were thinking perhaps thatuhthe way we use the tandem is not if we trained the networks on theona language and a t or a specifictask , um , what we ask isto the networkis to put the bound the decision boundaries somewhere in the space . and uhmmm and ask the network to put one , at one side of theforfor a particular phoneme at one side of the boundarydecision boundary andso there is kind of reduction of the information there that 's not correct because if we change taskand if the phonemes are not in the same context in the new task , obviously thedecision boundaries are notshould not be at the sameplace . but the way the feature givesthethe way the network gives the features is that it reduce completely theit removes completely the informationa lot of information from thethe featuresby uhuhplacing the decision boundaries atoptimal places forone kind ofdata the way wewe do it now is that we have a neural network andbasicallythe net network is trained almost to give binary decisions .", "summary": "decisions: speaker mn007 would like to investigate increasing the context of the phonemes ."}
{"dialogue": "and once youthe other thing is that once you representstart representing more and more contextit isuhmuch moreum specificto a particular task in language . for instance you may have some kinds of contexts that will never occurin one language and will occur frequently in the other , the issue of getting enough trainingfor a particular kind of context becomes harder . we already actually do n't have a huge amount of training data the way wewe do it now is that we have a neural network andbasicallythe net network is trained almost to give binary decisions . but it would still be even more of a binary decision . that would be eveneven more distinct of a binary decision . i mean wewe could disagree about it at length but thethe real thing is if you 're interested in it you 'll probably try it andandwe 'll see .", "summary": "decisions: speaker mn013 does agree with mn007s assessment of the outcome , and points out the lack of data , but acknowledges that if mn007 is interested he will go ahead with it ."}
{"dialogue": "so i think hynek will be here monday . so i think , you know , we need tochoose thechoose the experiments carefully , so we can get uh keykey questions answereduh before then so um the question we 're gon na wan na gothrough next week when hynek shows up i guess is given that we 've been", "summary": "decisions: must be careful in choosing which experiments to perform as an important visitor is coming soon ."}
{"dialogue": "so um the question we 're gon na wan na gothrough next week when hynek shows up i guess is given that we 've been we 're uh looking atuh , by then i guess , combinations of features and multi - band uh , and we 've been looking atcross - language , crosstaskissues . but they 've been looking at uhat these issues . at the on - line normalization and the uhvoice activity detection . and i guess when he comes here we 're gon na have to start deciding aboutum what do we choosefrom what we 've looked atto um blend withsome group of things in what they 've looked at and once we choose that , how do we split up theeffort ?", "summary": "decisions: also need to come up with a stronger plan for collaboration with ogi ."}
{"dialogue": "and i guess when he comes here we 're gon na have to start deciding aboutum what do we choosefrom what we 've looked atto um blend withsome group of things in what they 've looked at and once we choose that , how do we split up theeffort ?", "summary": "decisions: must decide what from both can be brought together , and how then can the work be divided ."}
{"dialogue": "yeah , i mean you can check with uhdave johnson . andsomebody could doyou know , uh , check outuh the multi - threadinglibraries . but . notice how i said somebody and <laugh> turned my head your direction . that 's one thing you do n't get in these recordings . and then we 'd be set for when we did have five or eight , to have it really be useful . there 'sthere 'sthere 's gon na be debugging hassles i mean , i guess the prudent thing to do would be for somebody to do the work onon getting our code runningon that machine with two processorseven though there are n't five or eight .", "summary": "decisions: someone ( implied with gestures in the meeting ) must speak to a person outside the group with regards to using a multiprocessor linux machine that is available ."}
{"dialogue": "andsomebody could doyou know , uh , check outuh the multi - threadinglibraries . i mean , i guess the prudent thing to do would be for somebody to do the work onon getting our code runningon that machine with two processorseven though there are n't five or eight . there 'sthere 'sthere 's gon na be debugging hassles and then we 'd be set for when we did have five or eight , to have it really be useful .", "summary": "decisions: debugging the process while there are just two processors bodes well for when they have 8 to multi-thread ."}
{"dialogue": "so , um i could try to getum the train the neural network trainings or the htk stuff running under linux , and to start with i 'mwondering which one i should pick first . uh , probably the neural net", "summary": "decisions: speaker mn026 volunteers to get some training running under linux ."}
{"dialogue": "uh , probably the neural net", "summary": "decisions: it is agreed that he should start with the neural net training , then work on htk ."}
{"dialogue": "butactually there is something important , is thatum we made a lot of assumption concerning the on - line normalization and we just noticeduh recently thatuh theapproach that we were usingwas notuhleading to very good resultswhen weused the straight features to htk . sowhat we see thatisthere is that umuh the way we were doing this was not correct , when we use the networksour number are better thatuh pratibha results . andbasically , the first thing is the mmm , alpha uhvalue . um , i used point five percent , which was the default value in thein the programs here . and pratibha used five percent . i assume that this was not important becauseuh previous results fromfrom dan andshow that basicallythebothboth values g give the samesameuh results . it was true on uhti - digits but it 's not true on italian . uh , second thing is the initialization of thestuff . actually , uh what we were doing is to start the recursion from the beginning of theutterance . and using initial values that are the global mean and variancesmeasured across the whole database . and pratibha did something different is that heuh she initialed the um values of the mean and varianceby computingthis on thetwenty - five first frames of each utterance . mmm . there were other minor differences , so . uh , i changed the code uh and now we have a baseline that 's similar to the ogi baseline . well , thethethe networks are retaining with these newfeatures .", "summary": "problems: incorrect assumptions were made when considering the on-line normalization for the main task . members used different values to a previous study , and whilst it was believed not to make a difference , it does , so networks are being retrained ."}
{"dialogue": "therethere isanother difference , is that the noisethe noises are different . well , forfor the italian part i mean theuhthe umnetworks are trained with noise fromaurorati - digits , and perhaps the noise arequite different from the noisesin the speech that italian . uh <laugh> <inbreath> um now , what 's the noise conditionumof the training data the noise condition is the same so there 's not astatisticalsta a strong ststatistically differentnoise characteristic betweenuh the training and test no these are the s s s same noises , at leastat least for the firstfor the well - matched ,", "summary": "problems: currently working with noise conditions being the same in training and test data , but there is nothing which matches the noise on the italian test data ."}
{"dialogue": "none", "summary": "problems: in fact no other language matches the noise from aurora data ."}
{"dialogue": "yeah , so for the italian the results are <outbreath> uhstranger so what appears is that perhaps spanish isnot very close to italian because uh , well , when using thethe network trained only on spanish it 'sthe error rate isalmost uh twicethe baseline error rate .", "summary": "problems: spanish was being used to train for italian as it was assumed they were the most similar , but that may not be as close a match as thought ."}
{"dialogue": "so they 'rethey 're doingthethe vad i guess they mean voice activity detection so again , it 's the silence so um their uhthe results look pretty good . so um i think that it 'sit 's nice to do that in this because in fact , it 's gon na give a better word error result and therefore will help within an evaluation . um . uh , as you know , part of the problem with evaluation right now is that theword models are pretty bad and nobody wantshashas approached improving them .", "summary": "problems: ogi have an interesting approach to voice activation detection for removing blocks of silence , that shows good results , but currently the word model being used is too poor to make good use of this and no one is working on improving it ."}
