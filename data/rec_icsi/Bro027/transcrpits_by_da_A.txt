A:  OK . 
A:  OK , 
A:  we 're going . 
A:  This is for 
A:  ASRU . 
A:  You mean , from the actual , uh , recordings ? 
A:  It 's nine DB ? 
A:  Hmm . 
A:  So that 's on th that 's on the f the far field ones though , right ? 
A:  Yeah . 
A:  So wha what is , uh  what 's causing that ? 
A:  Yeah . 
A:  Uh - huh . 
A:  Yeah . 
A:  Hmm . 
A:  Mm - hmm . 
A:  I see . 
A:  Mmm . 
A:  When are his prelims ? 
A:  Oh . 
A:  Wow . 
A:  So , I 
A:  Huh . 
A:  I  I guessed that they were gonna do it some time during the semester 
A:  but they 'll do it any time , huh ? 
A:  Is it already ? 
A:  Yikes . 
A:  Yeah . 
A:  I , um  <mouth> uh , started working on the uh  Mississippi State recognizer . 
A:  So , I got in touch with Joe and  and , uh , from your email and things like that . 
A:  And , uh , they added me to the list  
A:  uh , the mailing list . 
A:  And he gave me all of the pointers and everything that I needed . 
A:  And so I downloaded the , um  
A:  There were two things , uh , that they had to download . 
A:  One was the , uh , I guess the software . 
A:  And another wad  was a , um , sort of like a sample  a sample run . 
A:  So I downloaded the software and compiled all of that . 
A:  And it compiled fine . 
A:  No problems . 
A:  And , um , I grabbed the sample stuff 
A:  but I haven't , uh , compiled it . 
A:  No  
A:  Well , I haven't grabbed that one yet . 
A:  So there 's two . 
A:  There was another short one , 
A:  yeah . 
A:  And so I haven't grabbed the latest one that he just , uh , put out yet . 
A:  So . 
A:  Um , but , the software seemed to compile fine and everything , 
A:  so . 
A:  And , um , 
A:  So . 
A:  No , 
A:  I  I d 
A:  You asked me to write to him 
A:  and I think I forgot to ask him about that . 
A:  Or if I did ask him , he didn't reply . 
A:  I  I don't remember yet . 
A:  Uh , I 'll  I 'll d I 'll double check that and ask him again . 
A:  Yeah . 
A:  Yeah . 
A:  Maybe I 'll send it to the list . 
A:  Yeah . 
A:  Uh - huh . 
A:  OK , I haven't seen that one yet . 
A:  So . 
A:  OK . 
A:  And so they 've picked  the values . 
A:  Oh , OK . 
A:  OK . 
A:  Yeah . 
A:  Yeah , 
A:  OK . 
A:  Do you think that 's something I should just send to him 
A:  or do you think I should send it to this  there 's an  a m a mailing list . 
A:  OK . 
A:  Yeah . 
A:  OK . 
A:  Yeah . 
A:  Right . 
A:  OK . 
A:  Yeah . 
A:  OK . 
A:  Yeah . 
A:  Yep . 
A:  Yeah . 
A:  Yeah , 
A:  i that was a particular version . 
A:  Yeah , 
A:  SUSI or whatever it was 
A:  but we don't have that . 
A:  So . 
A:  Should be OK . 
A:  Yeah , it compiled fine actually . 
A:  No  no errors . 
A:  Nothing . 
A:  So . 
A:  Hmm . 
A:  Who 's the second Jeff ? 
A:  No . 
A:  Oh , OK . 
A:  Oh , OK . 
A:  Wow . 
A:  That would be neat . 
A:  Hmm . 
A:  Is that nine frames u s uh , centered around the current frame ? Or  
A:  So , I 'm  I 'm  s 
A:  so what is different between this and  and what you  
A:  Ah . 
A:  OK . 
A:  Wow . 
A:  What if you used a smaller window for the delta ? 
A:  Could that help a little bit ? 
A:  I mean , I guess there 's a lot of things you could do to  
A:  Is two hundred the d 
A:  i a hun 
A:  uh  
A:  Wh - what 's the baseline you need to be under ? 
A:  Two hundred ? 
A:  Oh . 
A:  So , how do you know that what you have is too much if they 're still deciding ? 
A:  Uh - huh . 
A:  Oh , OK , 
A:  I see . 
A:  Ah , OK . 
A:  But still , that 's  that 's a pretty big , uh , win . 
A:  And it doesn't seem like you 're  in terms of your delay , you 're , uh , that  
A:  Yeah , 
A:  that 's what it seems like to me . 
A:  It 's pretty good . 
A:  Where  where is this  where is this fifty - seven point O two in  in comparison to the last evaluation ? 
A:  Oh , is that right ? 
A:  Oh . 
A:  Wow . 
A:  So this is almost ten percent . 
A:  Wow . 
A:  This is  this is really good . 
A:  Yeah . 
A:  What was that ? 
A:  Say that last part again ? 
A:  Mmm . 
A:  So that would be even  That wouldn't change this number down here to sixty - two ? 
A:  Yeah . 
A:  Yeah . 
A:  So that 's sort of the best you could hope for . 
A:  I see . 
A:  Those are th those are th what is going into the tandem net ? 
A:  Those two ? 
A:  Yeah ? 
A:  Oh , oh . 
A:  OK . 
A:  I see . 
A:  Uh - huh . 
A:  Right . 
A:  OK . 
A:  Compared to these numbers ? 
A:  That 's how you get down to twenty - eight ? 
A:  Why twenty - eight ? 
A:  Oh . 
A:  Ah . 
A:  I see . 
A:  Yeah . 
A:  That makes sense . 
A:  So , it seems funny that  I don't know , maybe I don't u quite understand everything ,  but that adding features  
A:  I guess  I guess if you 're keeping the back - end fixed . 
A:  Maybe that 's it . 
A:  Because it seems like just adding information shouldn't give worse results . 
A:  But I guess if you 're keeping the number of Gaussians fixed in the recognizer , then  
A:  Yeah . 
A:  Uh - huh . 
A:  Oh , yeah , I wasn't necessarily saying it should be better . 
A:  I 'm just surprised that you 're getting fifteen percent relative worse on the wel 
A:  On the highly mismatch . 
A:  Yeah . 
A:  Huh . 
A:  What if you did the  
A:  Would it make sense to do the KLT on the full set of combined features ? 
A:  Instead of just on the  
A:  Oh , I see . 
A:  So you tried the global KLT before 
A:  and it didn't really  
A:  I see . 
A:  Uh - huh . 
A:  Uh - huh . 
A:  What is the  
A:  You said there was a limit of sixty features or something ? 
A:  What 's the relation between that limit and the , um , forty - eight  uh , forty eight hundred bits per second ? 
A:  So I  I  I don't understand , 
A:  because i 
A:  I mean , if you 're only using h 
A:  Uh - huh . 
A:  So you 're saying , add the Macrophone data to the training of the neural net ? The tandem net ? 
A:  Yeah . 
A:  Right . 
A:  What  what was it trained on again ? 
A:  The one that you used ? 
A:  Uh - huh . 
A:  And  and did  an other numbers stay the same ? 
A:  Insertion substitutions stay the same ? 
A:  Roughly ? 
A:  Uh - huh . 
A:  Well that  that says that , you know , the , um  the models in  in , uh , the recognizer are really paying attention to the neural net features . 
A:  Uh . 
A:  You know , I 've been wondering about something . 
A:  In the , um  a lot of the , um  the Hub - five systems , um , recently have been using LDA . 
A:  and  and they , um  They run LDA on the features right before they train the models . 
A:  So there 's the  the LDA is  is right there before the H M 
A:  So , you guys are using LDA 
A:  but it seems like it 's pretty far back in the process . 
A:  Yeah . 
A:  Uh - huh . 
A:  Yeah , you c you c you can . 
A:  I mean , it 's  you know , you 're just basically i 
A:  You 're shifting the feature space . 
A:  Yeah . 
A:  Ah . OK . 
A:  So what i what about , um  i u what i w 
A:  I mean , I don't know if this is a good idea or not , 
A:  but what if you put  ran the other kind of LDA , uh , on your features right before they go into the HMM ? 
A:  Yeah . 
A:  Right , 
A:  it 's the  It 's  
A:  Right . 
A:  The  So  
A:  Yeah , so it 's sort of like  
A:  The tandem stuff is kind of like i nonlinear LDA . 
A:  I g 
A:  Yeah . 
A:  But I mean , w but the other features that you have , um , th the non - tandem ones , 
A:  Uh - huh . 
A:  Yeah . 
A:  Right . 
A:  Uh - huh . 
A:  Yeah . 
A:  Uh - huh . 
A:  Yeah . 
A:  Mm - hmm . 
A:  Right . 
A:  So you wouldn't necessarily then want to do LDA on the non - tandem features because now you 're doing something to them that  
A:  Yeah , 
A:  right . 
A:  Right . 
A:  Right . 
A:  Yeah . 
A:  Well  y 
A:  Yeah . 
A:  Exactly . 
A:  I mean , we , uh  we were getting ready to do the tandem , uh , stuff for the Hub - five system , 
A:  and , um , Andreas and I talked about it , 
A:  and the idea w the thought was , " Well , uh , yeah , that i you know  th the neural net should be better , 
A:  but we should at least have uh , a number , you know , to show that we did try the LDA in place of the neural net , 
A:  so that we can you know , show a clear path . 
A:  You know , that you have it without it , 
A:  then you have the LDA , 
A:  then you have the neural net , 
A:  and you can see , theoretically . 
A:  So . 
A:  I was just wondering  
A:  I  I  
A:  Yeah . 
A:  Um . No . 
A:  That 's what  that 's what we 're gonna do next 
A:  as soon as I finish this other thing . 
A:  So . 
A:  We just want to show . 
A:  I mean , it  everybody believes it , 
A:  but you know , we just  
A:  Yeah . 
A:  Yeah . 
A:  Mm - hmm . 
A:  Yeah . 
A:  Yeah , 
A:  and everybody 's putting that on their <outbreath> systems now , 
A:  and so , I 
A:  that 's what made me wonder about this , 
A:  but . 
A:  Yeah , what I mean is it 's  it 's like in the Hub - five evaluations , you know , 
A:  and you read the system descriptions and everybody 's got , <laugh> you know , LDA on their features . 
A:  And so . 
A:  Uh . 
A:  Yeah , so it 's different . 
A:  Yeah , 
A:  exactly . 
A:  Cuz they don't have these , you know , mismatches that  that you guys have . 
A:  So that 's why I was wondering if maybe it 's not even a good idea . 
A:  I don't know . 
A:  I  I don't know enough about it , 
A:  but  Um . 
A:  What  
A:  Do y do you have that feature available for the test data ? 
A:  Oh , oh , I see . 
A:  I see . 
A:  OK . 
A:  OK . 
A:  So you 're saying , feed that , also , into  the neural net . 
A:  Yeah . 
A:  Yeah . 
A:  Right . 
A:  But in principle wouldn't it be better to feed it in ? 
A:  And let the net do that ? 
A:  Hmm . 
A:  Yeah . 
A:  What  
A:  what if you  
A:  Right . 
A:  So , what if you then , uh  since you know this , what if you only use the neural net on the speech portions ? 
A:  Well , I guess that 's the same . 
A:  Uh , that 's similar . 
A:  But I mean  I mean , train the net only on  
A:  But I mean , if you 're gonna  if you 're going to multiply the output of the net by this other decision , uh , would  then you don't care about whether the net makes that distinction , right ? 
A:  Ah . 
A:  Right , 
A:  OK . 
A:  That 's a good point . 
A:  Be interesting to look at the  
A:  Yeah , 
A:  for the  
A:  I wonder if you could do this . 
A:  But if you look at the , um , highly mism high mismat the output of the net on the high mismatch case and just look at , you know , the distribution versus the  the other ones , do you  do you see more peaks or something ? 
A:  Yeah . 
A:  But if you were gonna put it in as a feature it means you already have it by the time you get to the tandem net , 
A:  right ? 
A:  Ah . 
A:  OK . 
A:  Right . 
A:  For the tandem net you mean ? 
A:  Hmm . 
A:  So if , 
A:  uh  
A:  if the , uh , high mismatch case had been more like the , uh , the other two cases  in terms of giving you just a better performance ,  how would this number have changed ? 
A:  y Like sixty ? 
A:  Uh - huh . 
A:  Yeah . 
A:  So this would be sixty - two ? 
A:  Which is  
A:  All the other ones were five percent , 
A:  the  
A:  Yeah . 
A:  Hmm . 
A:  When  
A:  When do you leave ? 
A:  But you 're  
A:  are you  
A:  you 're not gonna be around this afternoon ? 
A:  Oh . 
A:  Uh - huh . 
A:  Ah , 
A:  OK , 
A:  OK . 
A:  What 's September sixth ? 
A:  Oh , oh , right . 
A:  OK . 
A:  So , 
A:  uh , you 're gonna be gone for the next three weeks or something ? 
A:  So that 's  you won't be at the next three of these meetings . 
A:  Is that right ? 
A:  Oh , right . 
A:  Right . 
A:  OK . 
A:  When do you go back ? 
A:  When is the evaluation ? 
A:  November , 
A:  or something ? 
A:  Yeah . 
A:  Should we do digits ? 
A:  OK . 
