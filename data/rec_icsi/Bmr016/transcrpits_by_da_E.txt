E:  Great . 
E:  Interesting . 
E:  Hmm . 
E:  Yeah . 
E:  Mm - hmm . 
E:  Yeah . 
E:  Yeah . 
E:  I agree . 
E:  Mm - hmm . 
E:  Mm - hmm . 
E:  Mm - hmm . 
E:  And i actually it 's no more artificial than what we 've been doing with words . 
E:  I 'm sure people can adapt to this , 
E:  read it single . 
E:  The spaces already bias it toward being separated . 
E:  And I know I 'm gonna find this easier than words . 
E:  I think that i it 's fine . 
E:  I it  it  to me it looks like you 've got the func the idea of grouping and you have the grou the idea of separation 
E:  and , you know , it 's just a matter of u i the instructions , that 's all . 
E:  I did  
E:  Mm - hmm . 
E:  Go ahead . 
E:  Mm - hmm . 
E:  Yeah , I also would like to argue for that 
E:  cuz it  it seems to me that , um , there 's a real strength in having the same test replicated in  a whole bunch of times 
E:  and adding to that basic test bank . 
E:  Hmm ? 
E:  Cuz then you have , you know , more and more , u chances to get away from random errors . 
E:  And I think , um , the other thing too is that right now we have sort of a stratified sample with reference to dialect groups , 
E:  and it might be  there might be an argument to be made for having uh f for replicating all of the digits that we 've done , 
E:  which were done by non - native speakers 
E:  so that we have a core that totally replicates the original data set , 
E:  which is totally American speakers , 
E:  and then we have these stratified additional language groups overlapping certain aspects of the database . 
E:  Except that if you have the stimuli  comparable , then it says something about the  the contribution of setting 
E:  and  
E:  OK . 
E:  What 's an example of a  of m some of the other differences ? 
E:  Any other a difference ? 
E:  OK . 
E:  OK . 
E:  OK , fine . 
E:  OK . 
E:  Great . 
E:  I think it was numbers , 
E:  but I 'm not sure . 
E:  You have to have a similar pace . 
E:  c c Can I can I have an another  another question w about this ? 
E:  So , um , there are these digits , 
E:  which are detached digits , 
E:  but there are other words that contain the same general phon phoneme sequences . 
E:  Like " wonderful " has " one " in it 
E:  and  and Victor Borge had a  had a piece on this where he inflated the digits . 
E:  Well , I wonder if there 's , um , an if there would be a value in having digits that are in essence embedded in real words to compare in terms of like the articulation of " one " in " wonderful " versus " one " as a digit being read . 
E:  There you go . 
E:  Nein . 
E:  Well , I mean , I just wanted to offer that as a possible task 
E:  because , you know , if we were to each read his embedded numbers words in sent in sentences 
E:  cuz it 's like an entire sketch he does 
E:  and I wouldn't take the inflated version . 
E:  So he talks about the woman being " two - derful " , 
E:  and  
E:  and  a But , you know , if it were to be deflated , just the normal word , it would be like a little story that we could read . 
E:  I don't know if it would be useful for comparison , 
E:  but it 's embedded numbers . 
E:  I see . 
E:  OK . 
E:  OK , thank you . 
E:  Huh . 
E:  Mm - hmm . Mm - hmm . 
E:  Mm - hmm , very good point . 
E:  Mm - hmm . 
E:  What 's th u w in what respect ? 
E:  In the  in 
E:  Mm - hmm . 
E:  Mm - hmm . Yeah . 
E:  It was also true of the digits task which was X Waves . 
E:  Yeah . 
E:  Very quickly . 
E:  I agree . 
E:  You 're right about the backup being  a bottleneck . 
E:  It 's good to think towards scratch . 
E:  Yeah . 
E:  With two  two digits . 
E:  OK . So I got a little print - out here . 
E:  So three on this side , 
E:  three on this side . 
E:  And I stapled them . 
E:  OK . 
E:  Alright so , first of all , um , there was a  an interest in the transcribe transcription , uh , checking procedures 
E:  and  <inbreath> and I can <outbreath> tell you first , uh , to go through the steps 
E:  although you 've probably seen them . 
E:  Um , as you might imagine , when you 're dealing with , um , r really c a fair number of words , and uh , @ @  natural speech 
E:  which means s self - repairs and all these other factors , that there 're lots of things to be , um , s standardized and streamlined and checked on . 
E:  And , um , so , 
E:  I did a bunch of checks , 
E:  and the first thing I did was obviously a spell - check . 
E:  And at that point I discovered certain things 
E:  like , um , " accommodate " with one " M " , 
E:  that kind of thing . 
E:  And then , in addition to that , I did an exhaustive listing of the forms in the data file , 
E:  which included n detecting things like f faulty punctuation and things  
E:  Yeah ? 
E:  Sure , please , 
E:  yeah , please , please . 
E:  Yeah , yeah , yeah . 
E:  Yes . 
E:  That 's right . 
E:  Exactly . 
E:  I do these checks . 
E:  Uh - huh . 
E:  Exactly . 
E:  Yeah . 
E:  Thank you . 
E:  And so , uh , I do a  an exhaustive listing of the forms  
E:  Actually , I will go through this in  in order , 
E:  so if  if we could maybe wait and stick keep that for a second 
E:  cuz we 're not ready for that . 
E:  Yeah , yeah , yeah , yeah . Exactly ! Exactly ! 
E:  Alright so , <breath> a spelling check first 
E:  then an exhaustive listing of the , uh  all the forms in the data with the punctuation attached 
E:  and at that point I pick up things like , oh , you know , word followed by two commas . 
E:  And th and then another check involves , uh , being sure that every utterance has an identifiable speaker . 
E:  And if not , then that gets checked . 
E:  Then there 's this issue of glossing s w so - called " spoken - forms " . 
E:  So there  
E:  mo for the most part , we 're keeping it standard wo word level transcription . 
E:  But there 's  
E:  w And that that 's done with the assumption that  pronunciation variants can be handled . 
E:  So for things like " and " , the fact that someone doesn't say the " D " , uh that 's not important enough to capture in the transcription 
E:  because a  a good pronunciation , uh , you know , model would be able to handle that . 
E:  However , things like " cuz " where you 're lacking an entire very prominent first syllable , 
E:  and furthermore , it 's a form that 's specific to spoken language , 
E:  those are r reasons  f for those reasons I  I kept that separate , 
E:  and used the convention of using " CUZ " for that form , 
E:  however , glossing it 
E:  so that it 's possible with the script to plug in the full orthographic form for that one , 
E:  and a couple of others , 
E:  not many . 
E:  So " wanna " is another one , 
E:  " going  " uh , " gonna " is another one , 
E:  with just the assumption , again , that this  th these are things which it 's not really fair to a c consider  expect that  a pronunciation model , to handle . 
E:  And Chuck , you in you indicated that " cuz " is  is one of those that 's handled in a different way also , didn't you ? 
E:  Did I  
E:  OK . 
E:  So  so it might not have been  <laugh> It might not have been you , 
E:  but someone told me that in fact " cuz " is treated differently in , um , i u in this context 
E:  because of that r reason that , um , it 's a little bit farther than a pronunciation variant . 
E:  OK , so after that , 
E:  let 's see , 
E:  um . 
E:  Well so when I get the exhau 
E:  So the spell - check picks up those words 
E:  because they 're not in the dictionary . 
E:  So it gets " cuz " and " wanna " and that  
E:  Yeah , mm - hmm . 
E:  Run it through  
E:  I have a sed  You know , so I do sed script saying whenever you see " gonna " you know , " convert it to gonna " , you know , " gloss equals quote going - to quote " , 
E:  you know . 
E:  And with all these things being in curly brackets 
E:  so they 're always distinctive . 
E:  OK , I also wrote a script which will , um , retrieve anything in curly brackets , <mouth> or anything which I 've classified as an acronym , 
E:  and  a pronounced acronym . 
E:  And the way I tag ac pronounced acronyms is that I have underscores between the components . 
E:  So if it 's " ACL " then it 's " A " underscore " C " underscore " L " . 
E:  And the th 
E:  Yes . Uh - huh , yeah . 
E:  OK , so now . Uh and  a 
E:  Yeah . 
E:  Yes , but not the reverse . 
E:  So sometimes people will say " because " in the meeting , 
E:  and if  if they actually said " because " , then it 's written as " because " with no  w 
E:  " cuz " doesn't even figure into the equation . 
E:  Yeah . 
E:  That 's a good point . 
E:  That 's fine . 
E:  Well Don has a script . 
E:  Exactly . 
E:  Uh - huh . 
E:  And Don knows this , 
E:  and he 's bee he has a glo he has a script that  
E:  Yes . And that 's why there 're different tags on the glosses , 
E:  on the different  on the different types of comments , 
E:  which we 'll  which we 'll see in just a second . 
E:  So the pronounceable acronyms get underscores , 
E:  the things in curly brackets are viewed as comments . 
E:  There 're comments of four types . 
E:  So this is a good time to introduce that . 
E:  The four types . 
E:  w And maybe we 'll expand that 
E:  but the  but the comments are , um , of four types mainly right now . 
E:  One of them is , um , the gloss type we just mentioned . 
E:  Another type is , um  
E:  I 'm still doing the overview . 
E:  I haven't actually gotten here yet . 
E:  OK so , gloss is things like replacing the full form u with the , um , more abbreviated one to the left . 
E:  Uh , then you have if it 's  uh , there 're a couple different types of elements that can happen that aren't really properly words , 
E:  and wo some of them are laughs and breathes , 
E:  so we have  uh that 's prepended with a v a tag of " VOC " . 
E:  And the non - vocal ones are like door - slams and tappings , 
E:  and that 's prepended with a no non - vocalization . 
E:  Oh yeah , so i e this would  
E:  Let 's just take one example . 
E:  And then the no non - vocalization would be something like a door - slam . 
E:  They always end . 
E:  So it 's like they 're paired curly brackets . 
E:  And then the third type right now , <mouth> uh , is  m things that fall in the category of comments about what 's happening . 
E:  So it could be something like , you know , " referring to so - and - so " , 
E:  " talking about such - and - such " , 
E:  uh , you know , " looking at so - and - so " . 
E:  Yeah . 
E:  Yeah , and this gets substituted here . 
E:  Huh - uh . 
E:  No , they 're events . 
E:  They 're actually  They have the status of events . 
E:  Well , and actually , um , it is true that , with respect to " laugh " , there 's another one 
E:  which is " while laughing " , 
E:  and that is , uh , i i An argument could be made for this  tur turning that into a qualitative statement 
E:  because it 's talking about the thing that preceded it , 
E:  but at present we haven't been , um , uh , coding the exact scope of laughing , you know , 
E:  and so to have " while laughing " , you know that it happened somewhere in there 
E:  which could well mean that it occurred separately and following , 
E:  or , you know , including some of the utterances to the left . 
E:  Haven't been awfully precise about that , 
E:  but I have here , 
E:  now we 're about to get to the  to this now , 
E:  I have frequencies . 
E:  So you 'll see how often these different things occur . 
E:  But , um , uh , the very front page deals with this , uh , final c pa uh , uh , aspect of the standardization 
E:  which has to do with the spoken forms like " mm - hmm " and " mm - hmm " and " ha " and " uh - uh " and all these different types . 
E:  And , um , uh , someone pointed out to me , 
E:  this might have been Chuck ,  about , um  about how a recognizer , if it 's looking for " mm - hmmm " with three M 's , <laugh> and it 's transcribed with two M 's , <laugh> that it might  uh , that it might increase the error rate 
E:  which is  which would really be a shame 
E:  because um , I p I personally w would not be able to make a claim that those are dr dramatically different items . 
E:  So , right now I 've standardized across all the existing data with these spoken forms . 
E:  I  I should say 
E:  all existing data except thirty minutes which got found today . 
E:  So , I 'm gonna  <laugh> I 'm gonna  <laugh> I 'm gonna check  
E:  Yeah , yeah . 
E:  Acsu - actually yeah . 
E:  I got  It was stored in a place I didn't expect , 
E:  so  and  and um , 
E:  w we , uh , sh yea reconstructed how that happened . 
E:  And this is  this 'll be great . 
E:  So I 'll  I 'll be able to get through that tonight , 
E:  and then everyth i well , actually later today probably . 
E:  And so then we 'll have everything following these conventions . 
E:  But you notice it 's really rather a small set of these kinds of things . 
E:  And I made it so that these are , um , with a couple exceptions but , things that you wouldn't find in the spell - checker 
E:  so that they 'll show up really easily . 
E:  And , um  
E:  Sure . 
E:  Well , yeah . Now that  that s only occurs once , 
E:  and I 'm thinking of changing that . 
E:  So - c I haven't listened to it 
E:  so I don't know . 
E:  I haven't heard it actually . 
E:  I n I need to listen to that one . 
E:  Did she hear the th did she actually hear it ? 
E:  Cuz I haven't heard it . 
E:  Yeah . 
E:  Yeah I 'm curious to se hear what it is , 
E:  but I didn't know  wanna change it to something else until I knew . 
E:  Well , sss ,  you know  
E:  Hhh . 

E:  Yeah . 
E:  That 's right . 
E:  OK . 
E:  Yeah , that 's right . 
E:  That 's right . 
E:  Yeah . 
E:  Uh , 
E:  so . 
E:  That 's partly a nonnative - native thing , 
E:  but I have found " EH " in native speakers too . 
E:  But it 's mostly non - native  
E:  Eh . 
E:  Mm - hmm . 
E:  That 's right . 
E:  Exactly . 
E:  " UH " . 
E:  Mm - hmm , that 's right . 
E:  Mmm . 
E:  Yeah . 
E:  Well , <laugh> we 're not doing  We 're not doing length . 
E:  Yeah , that 's right . 
E:  This makes sense . 
E:  Yeah I  I think you 've  
E:  uh - huh , yeah . 
E:  That makes sense . 
E:  Yeah , and so , you know , I mean , th th I have  there are some , um , Americans who  who are using this " eh " too , 
E:  and I haven't listened to it systematically , 
E:  maybe with some of them , uh , they 'd end up being " uh 's " 
E:  but , uh , I my spot - checking has made me think that we do have " eh " in also , um , American e e data represented here . 
E:  But 
E:  any case , that 's the  this is reduced down from really quite a long a much longer list , 
E:  and this is 
E:  functionally pretty , you know , also  
E:  It was fascinating , I was listening to some of these , uh , I guess two nights ago , 
E:  and it 's just hilarious to liste to  to do a search for the " mm - hmm 's " . 
E:  And you get " mm - hmm " 
E:  and diff everybody 's doing it . 
E:  Just  I wanted to say  I w think it would be fun to make a montage of it 
E:  because there 's a " Mm - hmm . 
E:  Mm - hmm . 
E:  Mm - hmm . " 
E:  It 's really  it 's really fun to listen to . 
E:  All these different vocal tracts , you know , 
E:  but it 's  it 's the same item . 
E:  It 's very interesting . 
E:  OK . 
E:  Uh , then the acronyms 
E:  y and the ones in parentheses are ones which the transcriber wasn't sure of , 
E:  and I haven't been able to listen to to  to clarify , 
E:  but you can see that the parenthesis convention makes it very easy to find them 
E:  cuz it 's the only place where  where they 're used . 
E:  Question mark is punctuation . 
E:  So it  they said that @ @  
E:  um , " DC ? " 
E:  Exactly . 
E:  Exactly . 
E:  Yeah , so the only  
E:  Well , and I do have a stress marker here . 
E:  Sometimes the contrastive stress is showing up , 
E:  and , um  
E:  The parenthesized is something that the transcriber thought was ANN , but wasn't entirely sure . 
E:  So I 'd need to go back or someone needs to go back , and say , you know , yes or no , 
E:  and then get rid of the parentheses . 
E:  But the parentheses are used only in that context in the transcripts , of of noti noticing that there 's something uncertain . 
E:  I think that 's true . 
E:  Yeah , absolutely . 
E:  NSA , 
E:  a lot of these are  are coming from them . 
E:  I listened to some of that . 
E:  Yeah . 
E:  Yeah . I agree . 
E:  And Robustness has a fair amount , 
E:  but the NSA group is just very very many . 
E:  Yeah . 
E:  That 's interesting . 
E:  Right and sometimes , I mean , you see a couple of these that are actually " OK 's " 
E:  so it 's  it 's  may be that they got to the point where  I mean it was low enough understandable  
E:  understandability that they weren't entirely sure the person said " OK . " 
E:  You know , so it isn't really necessarily a an undecipherable acronym , 
E:  but just n needs to be double checked . 
E:  Now we get to the comments . 
E:  This  
E:  Number of times out of the entire database , 
E:  w except for that last thirty minutes I haven't checked yet . 
E:  I 'd have to listen . 
E:  I  I I agree . 
E:  I w I 'd like to standardize these down farther 
E:  but , um , uh , 
E:  uh , to me that sounds equivalent . 
E:  But , I  I 'm a little hesitant to  to collapse across categories unless I actually listen to them . 
E:  Well , then , at least now . 
E:  Yeah . 
E:  Six . 
E:  OK well  
E:  But did you notice that there were seven hundred and eighty five instances of " OK " ? 
E:  And that 's just without the  without punc punctuation . 
E:  Extra forty one if it 's questioned . 
E:  On the page two of acronyms . 
E:  Yeah . 
E:  Of " OK " , yes . 
E:  Mm - hmm . 
E:  So that 's the single existing convention for " OK " . 
E:  Yeah that 's  
E:  Yeah . 
E:  That 's  that 's  I looked for that one . 
E:  I actually explicitly looked for that one , 
E:  and I think that , um , 
E:  I  I 'm not exactly sure about that . 
E:  No , I looked for that , 
E:  but that doesn't actually exist . 
E:  And it may be , 
E:  I don't  I can't explain that . 
E:  I i it 's the only  
E:  it 's the only pattern that has a slash after it , 
E:  and I think it 's  it 's an epiphenomenon . 
E:  Yeah . 
E:  Oh that 's cute . 
E:  That 's funny . 
E:  Yeah . 
E:  OK . 
E:  There is th one  
E:  Y well , no , that 's r that 's legitimate . 
E:  So now , uh , comments , you can see they 're listed again , 
E:  same deal , with exhaustive listing of everything found in everything except for these final th thirty minutes . 
E:  Yeah . 
E:  " TCL " . 
E:  Where do you see that ? 
E:  Oh , oh . 
E:  The reason is because w it was said " tickle " . 
E:  Yep . 
E:  On the  in the actual script  in the actual transcript , I s I  
E:  So this  this happens in the very first one . 
E:  I actually wrote it as " tickle " . 
E:  Because we  they didn't say " TCL " , they said " tickle " . 
E:  And then , following that is " QUAL TCL " . 
E:  Qual - qualifier . 
E:  Comment . 
E:  Comment or contextual comment . 

E:  Mm - hmm . 
E:  Well , of course now the  the Tannen corre the spelling c change . 
E:  Uh , that 's what gets  I  I picked those up in the frequency check . 
E:  Mm - hmm . 
E:  " ICSI " is  is one of those that sometimes people pronounce and sometimes they say " ICSI . " 
E:  So , those that are l are listed in the acronyms , I actually know 
E:  they were said as letters . 
E:  The others , um , e those really do need to be listened to 
E:  cuz I haven't been able to go to all the IC ICSI things , 
E:  and   and until they 've been listened to they stay as " ICSI " . 
E:  It was ! 
E:  In fact , it was ! 
E:  Yeah ! 
E:  He  he s he said  he said get  
E:  Yeah , that 's it . 
E:  Perfect . 
E:  Yeah that 's it . 
E:  That 's it . 
E:  Yeah , that 's  that 's been changed . 
E:  That 's been changed . 
E:  So , exactly , that 's where the lengthening comment c came in . 
E:  s chan brought it down . 
E:  And those of course get  get picked up in the frequency check 
E:  because you see " beep " 
E:  and you know  I mean it gets kicked out in the spelling , 
E:  and it also gets kicked out in the , uh , freq frequency listing . 
E:  I have the  there 're various things like " breathe " versus " breath " versus " inhale " and , hhh , 
E:  you know , I don't know . 
E:  I  I think they don't have any implications for anything else 
E:  so it 's like I 'm tempted to leave them for now 
E:  an and  It 's easy enough to find them when they 're in curly brackets . 
E:  We can always get an exhaustive listing of these things and find them and change them . 
E:  Yeah , but I don't actually remember what it was . 
E:  But that was  Eric did that . 
E:  Yeah . 
E:  I think maybe something like that . 
E:  Well , that 'd qualify . 
E:  Yeah . 
E:  OK . 
E:  Interesting question . 
E:  Yes . 
E:  OK , now first of all  
E:  Ooo - ooo ! 
E:  Very important . 
E:  Uh Chuck  Chuck led to a refinement here 
E:  which is to add " NUMS " if these are parts of the read numbers . 
E:  Now you already know i that I had , uh , in places where they hadn't transcribed numbers , I put " numbers " in place of any kind of numbers , 
E:  but there are places where they , 
E:  um , it  th this convention came later 
E:  an and at the very first digits task in some transcripts they actually transcribed numbers . 
E:  And , um , 
E:  d 
E:  Chuck pointed out that this is read speech , 
E:  and it 's nice to have the option of ignoring it for certain other prob uh p uh , things . 
E:  And that 's why there 's this other tag here which occurs a hundred and five  or three hundred and five times right now 
E:  which is just  well n n " NUMS " by itself 
E:  which means this is part of the numbers task . 
E:  I may change it to " digits " . 
E:  I mean , i with the sed command you can really just change it however you want 
E:  because it 's systematically encoded , you know ? 
E:  Have to think about what 's the best for  for the overall purposes , 
E:  but in any case , um , " numbers " and " NUMS " are a part of this digits task thing . 
E:  Um , now th Then I have these numbers that have quotation marks around them . 
E:  Um , I didn't want to put them in as gloss comments 
E:  because then you get the substitution . 
E:  And actually , th um , <laugh> the reason I b did it this way was because I initially started out with the other version , 
E:  you have the numbers and you have the full form and the parentheses , 
E:  however sometimes people stumble over these numbers they 're saying . 
E:  So you say , " Seve - seventy eight point two " , or whatever . 
E:  And there 's no way of capturing that if you 're putting the numbers off to the side . 
E:  You can't have the seven and  
E:  The left is i 
E:  so example the very first one , 
E:  it would be , spelled out in words , " point five " . 
E:  Only it 's spelled out in words . 
E:  So i this is also spelled out in  in words . 
E:  " Point five . " 
E:  And then , in here , " NUMS " , 
E:  so it 's not going to be mistaken as a gloss . 
E:  It comes out as " NUMS quote dot five " . 
E:  Thank you . 
E:  Well now  
E:  In that case it 's people saying things like " one one one dash so - and - so " 
E:  or they 're saying uh " two  I mean zero " whatever . 
E:  And in that case , it 's part of the numbers task , 
E:  and it 's not gonna be included in the read digits anyway , 
E:  so  I m in the uh  
E:  There is . 
E:  Yeah . 
E:  I 've added that all now too . 
E:  So , so gloss  in the same line that would have " gloss quote one one one dash one thirty " , you 'd have a gloss at the end of the line saying , uh , " curly bracket NUMS curly bracket " . 
E:  So if you  if you did a , uh , a " grep minus V nums " 
E:  and you get rid of anything that was read . 
E:  Yes . 
E:  Mm - hmm . 
E:  Good . 
E:  Yep . 
E:  This is more because  
E:  Yeah . 
E:  Oh these are all these , the " NUMS point " , this all where they 're saying " point " something or other . 
E:  And the other thing too is for readability of the transcript . 
E:  I mean if you 're trying to follow this while you 're reading it it 's really hard to read , you know  
E:  eh , " so in the data column five has " , you know , " one point five compared to seventy nine point six " , 
E:  it 's like when you see the words it 's really hard to follow the argument . 
E:  And this is just really a  a way of someone who would handle th the data in a more discourse - y way to be able to follow what 's being said . 
E:  So this is where Chuck 's , um , overall h architecture comes in , 
E:  where we 're gonna have a master file of the channelized data . 
E:  Um , there will be scripts that are written to convert it into these t these main two uses 
E:  and th some scripts will take it down th e into a f a for ta take it to a format that 's usable for the recognizer 
E:  an uh , other scripts will take it to a form that 's usable for the  for linguistics an and discourse analysis . 
E:  And , um , the implication that  that I have is that th the master copy will stay unchanged . 
E:  These will just be things that are generated , 
E:  and 
E:  e by using scripts . 
E:  When things change then the  the script will cham change 
E:  but the  but there won't be stored copies of  in different versions of things . 
E:  Except  
E:  Well  
E:  Well  
E:  Ex - exactly . 
E:  Exactly . 
E:  That was  that was my motivation . 
E:  And i these can be changed , like I said . 
E:  You know , I mean , as I said I was considering changing it to " digits " . 
E:  And , it just  i you know , it 's just a matter of deciding on whatever it is , and being sure the scripts know . 
E:  The other thing is you can get really so minute with these things 
E:  and increase the size of the files and the re and decrease the readability to such an extent by simply something like " percent " . 
E:  Now I  I could have adopted a similar convention for " percent " , 
E:  but somehow percent is not so hard , you know ? 
E:  i It 's just when you have these points and you 're trying to figure out where the decimal places are  
E:  And we could always add it later . 
E:  Percent 's easy to detect . 
E:  Point however is  is uh a word that has a couple different meanings . 
E:  And you 'll find both of those in one of these meetings , 
E:  where he 's saying " well the first point I wanna make is so - and - so " 
E:  and he goes through four points , 
E:  and also has all these decimals . 
E:  So . 
E:  Well I wanted to say also regarding the channelized data , 
E:  that , um , Thilo requested , um , that we ge get some segments done by hand to e e s reduce the size of the time bins 
E:  wh like was Chuc - Chuck was mentioning earlier 
E:  that , um , that , um , if you  if you said , " Oh " and it was in part of a really long , s complex , overlapping segment , that the same start and end times would be held for that one 
E:  as for the longer utterances , 
E:  and  
E:  And he requested that there be , uh , similar , uh , samples done for five minute stretches c involving a variety of speakers and overlapping secti sections . 
E:  He gave me  he did the  very nice , he  he did some shopping through the data 
E:  and found segments that would be useful . 
E:  And at this point , all four of the ones that he specified have been done . 
E:  In addition the I 've  I have the transcribers expanding the amount that they 're doing actually . 
E:  So right now , um , I know that as of today we got an extra fifteen minutes of that type , 
E:  and I 'm having them expand the realm on either side of these places where they 've already started . 
E:  But if  if  you know , and I  and he 's gonna give me some more sections that  that he thinks would be useful for this purpose . 
E:  Because it 's true , 
E:  I mean , if we could do the  the more fine grained tuning of this , uh , using an algorithm , that would be so much more efficient . 
E:  And , um . 
E:  So this is gonna be  useful to expand this . 
E:  You mean to start from scratch f in a brand new transcript ? 
E:  That 'd be excellent . 
E:  Yeah , that 'd be really great . 
E:  As it stands we 're still in the phase of sort of , um , cleaning up the existing data 
E:  getting things , uh , in i m more tight tightly time  uh , aligned . 
E:  I also wanna tell  um , I also wanted to r raise the issue that  OK so , there 's this idea we 're gonna have this master copy of the transcript , 
E:  it 's gonna be modified by scripts t into these two different functions . 
E:  And actually the master  
E:  Two  two or more . 
E:  And that the master is gonna be the channelized version . 
E:  So right now we 've taken this i initial one , it was a single channel basically the way it was input . 
E:  And now , uh , thanks to the advances made in the interface , we can from now on use the channelized part , 
E:  and , um , any changes that are made get made in the channelized version kind of thing . 
E:  But I wanted to get all the finished  all the checks  
E:  Yes , they have . 
E:  Except for the missing thirty minutes . 
E:  Uh , for  for a total of like twenty m 
E:  f for a total of  
E:  Let 's see , four times  
E:  total of about an   thirty minutes . 
E:  That 's  that 's been the case . 
E:  And plus the training , whatever you have . 
E:  Well , you know the problem  the problem is that some  some of the adjustments that they 're making are to bring  are to combine bins that were  time bins which were previously separate . 
E:  And the reason they do that is sometimes there 's a word that 's cut off . 
E:  And so , i i i it 's true that it 's likely to be adjusted in the way that the words are more complete . 
E:  And , 
E:  so I  it 's gonna be a more reliable thing 
E:  and I 'm not sure  
E:  Yeah . 
E:  Well partly it depends on how  um , how e effective it will be to apply an algorithm 
E:  because i this takes time , 
E:  you know , it takes a couple hours t to do , uh , ten minutes . 
E:  Mm - hmm . 
E:  Yep . 
E:  Mm - hmm . 
E:  Yeah , I mean  
E:  yeah . 
E:  But that  
E:  Mm - hmm . 
E:  So that 's  I I mean I could  there were other checks that I did , 
E:  but it 's  I think that we 've  unless you think there 's anything else , I think that I 've covered it . 
E:  OK . 
E:  Great . 
