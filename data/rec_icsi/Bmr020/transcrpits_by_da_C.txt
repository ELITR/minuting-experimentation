C:  I didn't this time . 
C:  Cur - curly brackets . 
C:  Channel two . 
C:  Yeah . 
C:  Uh  
C:  Not ri not right now . 
C:  I mean  No . 
C:  That 's interesting . 
C:  Hmm . 
C:  Yeah I 'm  
C:  Yeah . 
C:  I think so too . 
C:  Um , I haven't gotten over to there yet , 
C:  but what  our discussion yesterday , I really  I  I wanna submit one . 
C:  Yeah . 
C:  And , you offered to  to join me , if you want me to . 
C:  Yeah . 
C:  Yeah , that 's right . 
C:  Uh - huh . 
C:  In  in terms of what ? 
C:  In term 
C:  One ? 
C:  Wow ! 
C:  OK . 
C:  Do you mean , 
C:  because  
C:  is it partly , eh , c correctly identified words ? 
C:  Or is it  
C:  or just overall volume ? 
C:  Oh . OK . 
C:  OK . 
C:  Mm - hmm . 
C:  Yeah . 
C:  Yeah . 
C:  Oh , 
C:  that 's interesting . 
C:  Yeah . 
C:  Mm - hmm . 
C:  Mm - hmm . 
C:  Well , of course , no , it doesn't necessarily go against what he said , 
C:  cuz he said " generally speaking " . In order to  to go against that kind of a claim you 'd have to big canvassing . 
C:  Yeah . 
C:  Exactly . 
C:  It 's  i it 's not against his conclusion , 
C:  it just says that it 's a bi bell curve , and that , <breath> you have something that has a nice range , in your sampling . 
C:  Mm - hmm . 
C:  Mm - hmm . 
C:  Yeah . 
C:  Yeah , 
C:  that 's a good point . 
C:  Yeah . 
C:  Good idea . 
C:  Uh - huh . 
C:  Yes , that 's right . 
C:  Mm - hmm . 
C:  Hmm . 
C:  Di - did you use upper - lower case also , or not ? 
C:  U upper lower case or no ? 
C:  OK . 
C:  Yeah . 
C:  That 's OK 
C:  but  
C:  Comma also or not ? 
C:  I have a reference for that though . 
C:  Uh - huh . 
C:  Well , I didn't know about Liz 's finding on that , 
C:  but I know of another paper that talks about something 
C:  that  
C:  OK . 
C:  He still has his Unix account here , you know . 
C:  Yeah . 
C:  And he  and he 's  
C:  I 'd hafta add him to Meeting Recorder , I guess , 
C:  but  
C:  OK . 
C:  OK . 
C:  That 's good . 
C:  OK . 
C:  So , um you know that Adam created um , a b a script to generate the beep file ? 
C:  To then create something to send to IBM . 
C:  And , um , 
C:  you  you should probably talk about that . 
C:  But  but you were gonna to use the  originally transcribed file 
C:  because I tightened the time bins 
C:  and that 's also the one that they had already <breath> in trying to debug the first stage of this . 
C:  And uh , 
C:  my understanding was that , 
C:  um  
C:  I haven't  <breath> I haven't listened to it yet , 
C:  but it sounded very good 
C:  and  and I understand that you guys <breath> were going to have a meeting today , before this meeting . 
C:  Excellent . 
C:  OK . 
C:  Mm - hmm . 
C:  Oh ! 
C:  OK . 
C:  Ah , interesting . 
C:  Yeah . 
C:  Yeah . 
C:  Oh , sure . 
C:  Yeah , sure . 
C:  Makes sense . 
C:  Yeah . 
C:  Ah ! 
C:  Clever . 
C:  Yes . 
C:  Clever . 
C:  Yeah . 
C:  Excellent . 
C:  And that 's the purpose . 
C:  Yeah . 
C:  Great idea ! 
C:  OK , 
C:  now one thing that prevented us from apply you  you from applying  
C:  Exactly . 
C:  The training  
C:  So that is the training meeting . 
C:  OK . 
C:  Uh - huh . 
C:  Oh , interesting . 
C:  Ah ! 
C:  OK . 
C:  Interesting idea . 
C:  Great . 
C:  I went back and hand - marked the  ba the bins , 
C:  I ment I mentioned that last week . 
C:  Hmm . 
C:  Yeah . 
C:  Sure . 
C:  Sure . 
C:  Yeah , 
C:  I thought that was  
C:  Yeah . 
C:  Yeah . 
C:  They were , um , reasonably tight , but not excruciatingly tight . 
C:  That would 've taken more time . 
C:  I just wanted to get it so tha So that if you have like " yeah "  in a  swimming in a big bin , then it 's  
C:  I can't answer that , 
C:  but  but my main goal was  um , in these areas where you have a three - way overlap <breath> and one of the overlaps involves " yeah " , <laugh> and it 's swimming in this huge bin , <breath> I wanted to get it so that it was clo more closely localized . 
C:  I  I wanted to  
C:  I wanted it to be able to  l he be heard normally , 
C:  so that if you  if you play  back that bin and have it in the mode where it stops at the boundary , <breath> it sounds like a normal word . 
C:  It doesn't sound like the person  
C:  i it sounds normal . 
C:  It 's as if the person could 've stopped there . 
C:  And it wouldn't have been an awkward place to stop . 
C:  Now sometimes you know , it 's  these are involved in places where there was no time . 
C:  And so , <breath> <breath> there wouldn't be  a gap afterwards because  
C:  I mean some cases , there 're some people  um , who  who have very long  segments of discourse where , <breath> you know , they 'll  they 'll breath  and then I put a break . 
C:  But other than that , it 's really pretty continuous 
C:  and this includes things like going from one sentence into the  u one utterance into the next , one sentence into the next , 
C:  um , 
C:  w without really stopping . 
C:  I mean  i they , i 
C:  you know in writing you have this <breath> two spaces and a big gap 
C:  you know . 
C:  But  but uh  <breath> i some people are planning 
C:  and , you know , I mean , a lot  we always are planning  what we 're going to say next . 
C:  But uh , in which case , the gap between  these two complete syntactic units , <breath> um , which of course n spoken things are not always complete syntactically , 
C:  but  <breath> but it would be a shorter p shorter break <breath> than <breath> maybe you might like . 
C:  But the goal there was to  not have <breath> the text be so  so crudely  parsed in a time bin . 
C:  I mean , because <breath> from a discourse m purpose  it 's  <breath> it 's more  <breath> it 's more useful to be able to see  
C:  and also you know , from a speech recognition purpose my impression is that <breath> if you have too long a unit , it 's  it doesn't help you very much either , 
C:  cuz of the memory . 
C:  So , that means that <breath> the amount of time after something is variable depending partly on context , 
C:  but my general goal <breath> when there was  sufficient space , room , pause  after it  to have it be  kind of a natural feeling  gap . 
C:  Which I c I don't know what it would be quantified as . 
C:  You know , Wally Chafe says that <breath> um , <breath> in producing narratives , the spurts that people use <breath> tend to be , <breath> uh , that the  the  what would be a pause might be something like two  two seconds . 
C:  And um , that would be , you know one speaker . 
C:  The discourse  <breath> the people who look at turn taking often do use  
C:  I was interested that you chose uh , <breath> you know um ,  the  you know that you use 
C:  cuz I think that 's a unit that would be more consistent with sociolinguistics . 
C:  Yeah . 
C:  Mm - hmm . 
C:  Mm - hmm . 
C:  Mm - hmm . 
C:  In any case , this  this uh , meeting  that I hand  
C:  I  I hand - adjusted two of them 
C:  I mentioned before , 
C:  and I sent  I sent email , 
C:  so  
C:  And I sent the   path . 
C:  But I like this idea of  uh , for our purposes for the  for the IBM preparation , <breath> uh , n having these  joined together , 
C:  and uh  
C:  It makes a lot of sense . 
C:  And in terms of transcription , it would be easy to do it that way . 
C:  The way that they have with the longer units , 
C:  not having to fuss with adding these units at this time . 
C:  Mm - hmm . 
C:  Yes . 
C:  I see . 
C:  Yeah . 
C:  Well , 
C:  that 's  that 's right , 
C:  but you know , thi this brings me to the other f stage of this which I discussed with you earlier today , 
C:  which is <breath> the second stage is <breath> um , w what to do  in terms of the transcribers adjustment of these data . 
C:  I discussed this with you too . 
C:  Um , the tr 
C:  so the idea initially was , we would get <breath> uh , for the new meetings , 
C:  so the e EDU meetings , that <breath> Thilo ha has now presegmented all of them for us , on a channel by channel basis . 
C:  And um , 
C:  so , I 've assigned  I 've  I 've assigned them to our transcribers 
C:  and um , 
C:  so far I 've discussed it with one , 
C:  with uh  
C:  And I had a  about an hour discussion with her about this yesterday , 
C:  we went through <breath> uh EDU - one , at some extent . 
C:  And it occurred to me that <breath> um  that <breath> basically what we have in this kind of a format is  you could consider it as a staggered mixed file , 
C:  we had some discussion over the weekend a about  at  at this other meeting that we were all a at  
C:  um , <breath> about whether the tran the IBM transcribers should hear a single channel audio , or a mixed channel audio . 
C:  And um , <breath> in  in a way , by  by having this  this chunk and then the backchannel <breath> after it , it 's like a stagal staggered mixed channel . 
C:  And um , <breath> it occurred  to me in my discussion with her yesterday that um , 
C:  um , 
C:  the   the  the maximal gain , it 's  from the IBM  people , may be in long stretches of connected speech . 
C:  So it 's basically a whole bunch of words <breath> which they can really do , because of the continuity within that person 's turn . 
C:  So , what I 'm thinking , and it may be that not all meetings will be good for this ,  but  but what I 'm thinking is that <breath> in the EDU meetings , they tend to be <breath> driven by a couple of dominant speakers . 
C:  And , if the chunked files focused on the dominant speakers , <breath> then , when  when it got s patched together when it comes back from IBM , we can add the backchannels . 
C:  It seems to me <breath> that <breath> um , you know , the backchannels per - se wouldn't be so hard , 
C:  but then there 's this question of the time  @ @  uh , marking , and whether the beeps would be <breath> uh y y y 
C:  And I 'm not exactly sure how that  how that would work with the  with the backchannels . 
C:  And , 
C:  so um  
C:  And certainly things that are <breath> intrusions of multiple words , <breath> taken out of context and displaced in time from where they occurred , <breath> that would be hard . 
C:  So , m my <breath> thought is  i I 'm having this transcriber go through <breath> the EDU - one meeting , and indicate a start time <noise> f for each dominant speaker , endpoi end time for each dominant speaker , 
C:  and the idea that <breath> these units would be generated for the dominant speakers , <breath> and maybe not for the other channels . 
C:  Well , it  
C:  OK . 
C:  I think  <breath> I  I think um , you know , the original plan was that the transcriber would adjust the t the boundaries , and all that for all the channels 
C:  but , <breath> you know , that is so time - consuming , 
C:  and since we have a bottleneck here , we want to get IBM things that are usable s as soon as possible , 
C:  then this seemed to me it 'd be a way of gett to get them a flood of data , 
C:  which would be useful when it comes back to us . 
C:  And um  
C:  Oh also , at the same time she  when she goes through this , she 'll be <breath> uh  If there 's anything that <breath> was encoded as a pause , but really has something transcribable in it , <breath> then she 's going to <breath> uh , make a mark  
C:  w uh , so you know , so <breath> that  that bin would be marked as it  as double dots 
C:  and she 'll just add an S . 
C:  And in the other  in the other case , if it 's marked as speech , <breath> and really there 's nothing transcribable in it , then she 's going to put a s dash , 
C:  and I 'll go through and it  and um , you know , with a  <breath-laugh> <breath> with a substitution command , get it so that it 's clear that those are the other category . 
C:  I 'll just , you know , recode them . 
C:  But um , <breath> um , the transcribable events  that um , I 'm considering in this , <breath> uh , continue to be <breath> laugh , as well as speech , and cough and things like that , 
C:  so I 'm not stripping out anything , 
C:  just  just you know , being very lenient in what 's considered speech . 
C:  Yeah ? 
C:  Oh , OK . 
C:  So what it  what it  what it involves is  is really a s uh , <breath> uh , the original pr procedure , 
C:  but <breath> only applied to  uh , a certain  strategically chosen  s aspect of the data . 
C:  So  
C:  You got it . 
C:  Yes ! 
C:  Yes ! 
C:  Oh yeah ! 
C:  OK . 
C:  We start with your presegmented version  
C:  We start with the presegmented version  
C:  Yeah . 
C:  And then um , <breath> the transcriber , <breath> instead of going painstakingly through all the channels and moving the boundaries around , and deciding if it 's speech or not , but not transcribing anything . 
C:  OK ? 
C:  Instead of doing that , which was our original plan , <breath> the tra They focus on the dominant speaker  
C:  Yeah . 
C:  So what they do is they identify who 's the di dominant speaker , and when the speaker starts . 
C:  So I mean , you 're still gonna  
C:  So we 're  
C:  It 's based on your se presegmentation , 
C:  that 's the basic  thing . 
C:  Yeah . 
C:  Exactly . 
C:  Mm - hmm . 
C:  Uh No . No , no . 
C:  Huh - uh . 
C:  S 
C:  That 's  that 's why she 's notating the start and end points of the dominant speakers . 
C:  So , on a  you know , so <breath> i in EDU - one , i as far as I listened to it , you start off with a  a s section by Jerry . 
C:  So Jerry starts at minute so - and - so , 
C:  and goes until minute so - and - so . 
C:  And then Mark Paskin comes in . 
C:  And he starts at <breath> minute such - and - such , 
C:  and goes on till minute so - and - so . 
C:  OK . 
C:  And then <breath> meanwhile , she 's listening to <breath>  both of these guys ' channels , 
C:  determining if there 're any cases of misclassification of speech as nothing , and nothing as speech , 
C:  and <breath> a and adding a tag if that happens . 
C:  But you know , I wanted to say , his segmentation is so good , that <breath> um , the part that I listened to with her yesterday <breath> didn't need any adjustments of the bins . 
C:  So far we haven't . 
C:  So this is not gonna be a major part of the process , 
C:  at least  least not in  not on ones that  that really  
C:  Mm - hmm ? 
C:  Well there 's the question o of  whether  
C:  Well , OK . 
C:  She i It 's a question of how much time we want our transcriber to invest here <breath> when she 's gonna have to invest that when it comes back from IBM anyway . 
C:  So if it 's only inserting " mm - hmm "s here and there , then , wouldn't that be something that would be just as efficient to do at this end , instead of having it go through I B M , then be patched together , then be double checked here . 
C:  Well , I guess  
C:  I 'm  I 'm open to that , 
C:  it was  
C:  Well yea 
C:  OK , good . 
C:  I mean the detector , this  
C:  Now , you were saying that they  they differ in how well they work depending on channel s sys systems and stuff . 
C:  But EDU is great . 
C:  How interesting . 
C:  You know  
C:  Yeah . 
C:  Yeah ? 
C:  Yeah ? 
C:  Is intelligible . 
C:  That 's interesting ! 
C:  Cuz that 's  that 's directly related to the e end task . 
C:  How interesting ! 
C:  Well , <breath> eh , listening does take time too . 
C:  How interesting ! 
C:  Well EDU  
C:  So I was gonna say , EDU - one is good enough , 
C:  maybe we could include it in this  in this set of uh , this stuff we send . 
C:  Mm - hmm . 
C:  Hmm . 
C:  Oh , OK . 
C:  Oh , I see . 
C:  Know what numbers . 
C:  Oh , that 'd be great . 
C:  Yeah . 
C:  Mm - hmm . 
C:  They do already . 
C:  Yeah . 
C:  Well , we have the unintelligibility  convention . 
C:  And actually they have one also , 
C:  which  
C:  Certainty . 
C:  Was is it in a  in a  what  what is the t 
C:  In a good meeting , 
C:  what ? 
C:  Yeah . 
C:  Oh I see , 
C:  the characteristics . 
C:  Uh - huh . 
C:  OK . 
C:  OK . 
C:  Just 
C:  Hmm ! 
C:  The other problem is , that when it  when it uh d i on the breathy ones , where you get <breath> <breath> breathing , uh , inti indicated as speech . 
C:  And I guess we could just indicate to the transcribers not to  encode that if they  
C:  We could still do the beep file . 
C:  OK . 
C:  OK . 
C:  OK . 
C:  OK . 
C:  That would be great . 
C:  Wow , that 's a great idea . 
C:  Excellent . 
C:  Oh , I 'd be delighted with that , 
C:  I  I was very impressed with the  with the result . 
C:  Yeah . 
C:  Oh yeah , 
C:  interesting . 
C:  Oh yeah . 
C:  Oh yeah , 
C:  I pr I much prefer this , 
C:  I was just trying to find a way  
C:  Cuz I  I don't think the staggered mixed channel is awfully good as a way of handling overlaps . 
C:  But  
C:  but uh  
C:  Yeah . 
C:  Mm - hmm . 
C:  Yeah . 
C:  Oh , I 'd be delighted . 
C:  Yeah . 
C:  Well you were suggesting  You suggested maybe just not sending that part of the meeting . 
C:  But  
C:  Do you  
C:  Would you  would  
C:  Yeah , go ahead . 
C:  Well , 
C:  so  
C:  I mean  
C:  So my standard approach has been if it 's not someone close - miked , then , they don't end up on one of the close - miked channels . 
C:  They end up on a different channel . 
C:  And we have any number of channels available , 
C:  I mean it 's an infinite number of channels . 
C:  So just put them on some other channel . 
C:  Yeah , 
C:  that 's right . 
C:  Well , they have a convention , in their own procedures , <breath> which is for a background  sound . 
C:  Yeah . 
C:  Oh , I think  I think it 'd be easy to to say " background laptop " . 
C:  Well because one of them  
C:  Oh , I s 
C:  background laptop or , background LT <laugh> <breath> wouldn't take any time . 
C:  And  
C:  Oh , you can tell . 
C:  Acoustically , can't you tell ? 
C:  Oh is it ? 
C:  Oh ! 
C:  Yeah . 
C:  OK . 
C:  That sounds good . 
C:  That sounds good . 
C:  OK . 
C:  Yeah , 
C:  s a 
C:  Well , as it comes back , we have a uh  when we can use the channelized interface for encoding it , then it 'll be easy for us to handle . 
C:  But  <breath> but if  if out of context , they can't tell if it 's a channeled speak uh , you know , a close - miked speaker or not , <breath> then that would be confusing to them . 
C:  I don't know , 
C:  I  it doesn't  
C:  I don't  
C:  Either way would be fine with me , 
C:  I don't really care . 
C:  I have o I have one question . 
C:  Do you think we should send the um  that whole meeting to them and not worry about pre - processing it ? 
C:  Or  
C:  Uh , what I mean is <breath> we  we should <breath> leave the <breath> part with the audio in the uh , beep file that we send to IBM for that one , 
C:  or should we <breath> start after the  that part of the meeting is over 
C:  in what we send . 
C:  So , the part where they 're using sounds from their  from their laptops . 
C:  w If we have speech from the laptop should we just uh , excise that from what we send to IBM , 
C:  or should we <breath> i give it to them and let them do with it what they can ? 
C:  OK , 
C:  that 'd be nice to have a  a uniform procedure . 
C:  Good . 
C:  And see how well they do . 
C:  And give them freedom to  <breath> to indicate if it 's just not workable . 
C:  Yeah , 
C:  OK , 
C:  excellent . 
C:  Yeah , 
C:  yeah . 
C:  OK . 
C:  Alright . 
C:  That 's great . 
C:  Oh , interesting . 
C:  OK , 
C:  alright . 
C:  Digits . 
C:  OK , so we read the transcript number first , 
C:  right ? 
C:  Uh , quarter to four . 
C:  Mm - hmm . 
C:  It 's kind of interesting if there 're any more errors in these , <laugh> than we had the first set . 
C:  I usually do . 
C:  I didn't this time . 
