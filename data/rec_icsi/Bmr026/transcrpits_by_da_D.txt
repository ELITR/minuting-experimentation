D:  So . 
D:  That 's our system . 
D:  Mmm . 
D:  Speaking  
D:  Hmm . 
D:  So does she have transcribers right now who are basically sitting idle because there 's no data back from IBM 
D:  no ? 
D:  Oh . 
D:  Oh , OK . 
D:  Because I  I need to ask Jane whether it 's  it would be OK for her  um , s some of her people to transcribe uh some of the initial data we got from the SmartKom data collection , which is these short like five or seven minute sessions . 
D:  Um and we want it  You know , we need  
D:  The  Again , we  we have a similar uh logistic set - up where we are supposed to send the data to Munich 
D:  and get it transcribed and get it back . 
D:  But to get going we would like some of the data transcribed right away so we can get started . 
D:  And so um I wanted to ask Jane if  if uh , you know , maybe one of their transcribers could  could do  
D:  I mean since these are very short , that should really be uh , 
D:  um  It 's  
D:  Yeah . 
D:  It 's only two  
D:  Right , s 
D:  Yeah . 
D:  So  So it 's basically one channel to transcribe . 
D:  And it 's  
D:  One session is only uh like seven  
D:  Right . 
D:  And some of it is read speech , so we could give them the  the thing that they 're reading 
D:  and they just may  
D:  And so um , 
D:  um , I guess since she 's  
D:  I was gonna ask her but since she 's not around I  maybe I 'll  
D:  Uh if  if that 's OK with you to  to , you know , get that stuff uh  to ask her for that , then I 'll do that . 
D:  Yeah . 
D:  OK , yeah . 
D:  Alrighty . 
D:  Mm - hmm . 
D:  Really ? 
D:  So is that  
D:  Because there 's some people um  
D:  It would be cool if we could uh get that to work uh at  at SRI 
D:  because the um  
D:  we have m m We have more Windows machines to run the  
D:  Right . 
D:  Mmm . 
D:  I  I wonder if  if we should contribute our changes back to the authors so that they maintain those changes along  
D:  We have ? 
D:  Oh . 
D:  Oh , OK . 
D:  So  So  Well  
D:  But  But it would be cool if the Transcriber interface had like another window for the  you know , maybe above the waveform where it would show some arbitrary valued function that is  that is you know time synchron ti ti time synchronous with the wavform . 
D:  Right . 
D:  Right . 
D:  But it would almost be like having another waveform displayed . 
D:  S 
D:  Right . 
D:  Mm - hmm . 
D:  Mmm . 
D:  Yeah . 
D:  But you still need to store the disks somehow . 
D:  So  
D:  Oh you mean you put them inside the pizza boxes for the  
D:  Oh . 
D:  Mmm . 
D:  Plus we 're talking about buying a second dis uh , file server . 
D:  I see <laugh>  Oh , I see . 
D:  You mean he won't set up the  
D:  mmm . 
D:  XG ? 
D:  That 's also where we store the  The uh Hub - five training set waveforms , 
D:  right ? 
D:  Right . 
D:  But I 've also been storing  I 've been storing the feature files there 
D:  and I guess I can s start deleting some because we now know what the best features are 
D:  and we won't be using the old ones anymore . 
D:  Uh  Oh thats XA  Oh that 's X  
D:  Maybe I 'm confu 
D:  Oh no I 'm sorry . 
D:  Oh OK . 
D:  I think you 're right . 
D:  It 's XH and D  
D:  The b 
D:  I 'm also using DG 
D:  I got that confused . 
D:  OK . 
D:  Th - The  
D:  One  
D:  Mmm . 
D:  One  One On - One thing to in to um t to do when you need to conserve space is 
D:  I bet there are still some old , uh , like , nine gig disks , uh , around 
D:  and you can probably consolidate them onto larger disks 
D:  and  and you know recover the space . 
D:  Right . 
D:  Mm - hmm . 
D:  Mmm . 
D:  Mmm . 
D:  Maybe we can put some disks in the  in that back room there . 
D:  To the machine that collects the data . 
D:  So then you could , at least temporarily , store stuff there . 
D:  The only  
D:  What do you mean it 's not on the net ? 
D:  Oh because it 's  because it 's an ACIRI machine ? 
D:  Oh , oh oh . 
D:  But that can't be that hard . 
D:  I mean  
D:  Oh , 
D:  Mm - hmm . 
D:  Is this gotta be in the morning ? 
D:  Or  
D:  Because you know I  Fridays I have to leave uh like around uh two . 
D:  So if it could be before that would be be 
D:  Oh , OK , alright . 
D:  Oh I 'm sorry , I misunderstood . 
D:  I thought you are  
D:  OK . 
D:  Alright . 
D:  Mm - hmm . 
D:  OK . 
D:  Mmm . 
D:  Um  Uh  One thing  I mean  we  <inbreath> <clear throat> in past meetings we had um also a you know various  variously talked about the um work that w uh was happening sort of on the  on the recognition side 
D:  um but isn't necessarily related to meetings uh specifically . 
D:  So . Um . And I wondered whether we should maybe have um a separate meeting 
D:  and between you know , whoever 's interested in that 
D:  because I feel that uh there 's plenty of stuff to talk about 
D:  but it would be sort of um maybe the wrong place to do it in this meeting if uh  
D:  Well , it 's that  It 's just gonna be ver very boring for people who are not you know , sort of really interested in the details of the recognition system . 
D:  Well I know  Well , Jane an 
D:  Well you mean in a separate meeting or ha ha talking about it in this  
D:  OK . 
D:  So , 
D:  uh , uh , 
D:  Liz and Jane probably . 
D:  Uh . <laugh> Uh , if you wanna put it that way . 
D:  Right . 
D:  I mean it it 's sort of  I mean when  when the talk is about data collection stuff , sometimes I 've  you know , I  I 'm bored . 
D:  So it 's I c I can sympathize with them not wanting to  i to  to be uh  you know  If  I cou you know  this could  
D:  I 'm 
D:  not sure I wanna  
D:  Yeah 
D:  and  
D:  Mm - hmm . 
D:  And we don't have to do it every week . 
D:  We could do it every other week or so . 
D:  You know , whatev or whenever we feel like we  
D:  We could do that , yeah . 
D:  I  I  Personally I 'd  I 'm not in favor of more meetings . 
D:  Um . <laugh> Because , uh . 
D:  You know . 
D:  Right . 
D:  We feel  We feel obligated to collect more data . 
D:  ummh .  ummh .  OK . 
D:  Mm - hmm . 
D:  Mm - hmm . 
D:  Mm - hmm . 
D:  Mm - hmm . 
D:  Right . 
D:  So um . 
D:  So  so we could talk a little bit about that now if  if there 's some time . 
D:  Um I jus So the latest result was that um 
D:  um yot I tested the uh  the sort of final version of the PLP configuration um on development test data for  for this year 's Hub - five test set . 
D:  And the recognition performance was exactly , and I mean exactly up to the  you know , the first decimal , same as with the uh Mel Cepstra front - end . 
D:  Yes . 
D:  Uh , well i there was a little bit of a  
D:  i overall . 
D:  They  They were  The males I think were slightly better and the females were slightly worse but nothing really . 
D:  I mean definitely not significant . 
D:  And then the really nice thing was that if  if we combine the two systems we get a one and a half percent improvement . 
D:  So . 
D:  t 
D:  With N - best ROVER , which is like our <breath> new and improved version of ROVER . 
D:  Which u actually uses the whole N - best list from both systems  to  mmm , uh  c combine that . 
D:  Yeah . 
D:  And , the  
D:  And  And so uh after I told the  my uh colleagues at SRI about that , you know , now they definitely want to , you know , uh , have a  
D:  Next time we have an evaluation they want to do uh , you know , basically a at least the system combination . 
D:  Um , and , you know , why not ? 
D:  Uh . <laugh> So . 
D:  Uh w what do you mean ? 
D:  More features in the sense of front - end features or in the sense of just bells and whistles ? 
D:  Oh I mean  
D:  Yeah . 
D:  Well 
D:  Right . 
D:  So , we cou 
D:  Yeah . 
D:  That 's  the  the the  
D:  There 's one thing uh  I mean you don't want to overdo it because y every front - end  
D:  You know , if you  you know you basically multiply your effort by N , where N is a number of different systems 
D:  and  Um . 
D:  So . So one  one compromise would be to  only to have the  everything up to the point where you generate lattices be basically one system 
D:  and then after that you rescore your lattices with the multiple systems 
D:  and combine the results and that 's a fairly painless um thing . 
D:  So . 
D:  I  I think so . 
D:  Yeah . 
D:  Maybe a little less because at that point the error rates are lower 
D:  and so if  
D:  You know , maybe it 's only one percent or something but that would still be worthwhile doing . 
D:  So . 
D:  Um  Jus - You know , just wanted to let you know that that 's working out very nicely . 
D:  And then we had some results on  digits , uh , with um  
D:  We  We  
D:  So this was uh really   really sort of just to get Dave going with his um experiments . 
D:  And so , uh . 
D:  But as a result , um , you know , we were sort of wondering why is the Hub - five system doing so well on the digits . 
D:  And the reason is basically there 's a whole bunch of read speech data in the Hub - five training set . 
D:  And you c 
D:  And  
D:  Not all of  
D:  No it 's actually , digits is only a maybe a fifth of it . 
D:  The rest is  is read  is read TIMIT data and uh ATIS data and Wall Street Journal and stuff like that . 
D:  A fifth would be maybe uh two hours something . 
D:  Right . 
D:  But it definitely helps to have the other read data in there 
D:  because we 're doing  
D:  You know the error rate is half of what you do if you train only on ti uh TIMIT   uh not TIMIT uh TI - digits , 
D:  which is only what 
D:  two hours something ? 
D:  So . Uh , more read speech data definitely helps . 
D:  And you can leave out all the conversational data with no performance penalty . 
D:  That 's e 
D:  That was e 
D:  Right , right . 
D:  Right . 
D:  Oh , yeah . 
D:  So we only  for the Hub - five training , we 're only using uh a fairly small subset of the Macrophone  database . 
D:  Um , so , you could beef that up and probably do even better . 
D:  Yeah . 
D:  Yeah . 
D:  Right . 
D:  Well , I mean that 's plenty of read speech data . 
D:  I mean , Wall Street Journal ,  uh , take one example . 
D:  But um . 
D:  So , you know that might be useful for the people who train the  the digit recognizers to  to use uh something other than TI - digits . 
D:  OK . 
D:  Mm - hmm . 
D:  Mmm . 
D:  Mm - hmm . 
D:  Mm - hmm . 
D:  Mm - hmm . 
D:  Right . 
D:  Well , that was that . 
D:  And then I th guess Chuck and I had some discussions about how to proceed with the tandem uh system 
D:  and  You wanna  <laugh> You wanna see where that stands ? 

D:  An - And one side effect of that would be that it 's  um that the phone set would change . 
D:  So the MLP would be trained on I think only forty - six or forty - eight  
D:  forty - eight phones ? 
D:  Uh which is smaller than the um than the phone set that  that we 've been using so far . 
D:  And that  that  that will probably help , actually , 
D:  because um the fewer dimensions uh e the less trouble probably with the  as far as just the um , um  
D:  Just  
D:  You know we want to try things like deltas on the tandem features . 
D:  And so you h have to multiply everything by two or three . 
D:  And so , you know , fewer dimensions in the  phone set would be actually helpful just from a logistics point of view . 
D:  Right . 
D:  Exactly . 
D:  So  so that was the other thing . 
D:  And then we wanted to s just limit it to maybe uh something on the same order of dimensions as we use in a standard um front - end . 
D:  So that would mean just doing the top I don't know ten or twelve or something of the KLT dimensions . 
D:  Right . 
D:  But then  
D:  And then something  
D:  Once we have the new M L P trained up , uh one thing I wanted to try just for the fun of it was to actually run uh like a standard hybrid system that is based on you know , those features 
D:  uh and uh retrain MLP and also the you know , the dictionary that we use for the Hub - five system . 
D:  Exactly . 
D:  Yeah . 
D:  So that would basically give us a , um , more  hopefully a  a better system 
D:  um because  you know , compared to what Eric did a while ago , where he trained up , I think , a system based on Broadcast News 
D:  and then uh tra retraining it on Switchboard 
D:  or s uh and  
D:  But he  I think he d he didn't  he probably didn't use all the training data that was available . 
D:  And his dictionary probably wasn't as tuned to um conversational speech as  as the  as ours is . 
D:  So . 
D:  And the dictionary made a huge difference . 
D:  Uh . We  we made some improvements to the dictionary 's uh  to the dictionary about two years ago 
D:  which resulted in a  uh something like a four percent absolute error rate reduction on Switchboard , 
D:  which  
D:  Mm - hmm . 
D:  Mmm . 
D:  Mm - hmm . 
D:  Mm - hmm . 
D:  Yeah . 
D:  Mm - hmm . 
D:  Yeah . 
D:  OK . 
D:  Yeah . 
D:  Right . 
D:  Yeah . 
D:  Mmm . 
D:  But that w 
D:  Even that  that number  
D:  Right . 
D:  And  And that number I think was on Switchboard - one data , 
D:  right ? 
D:  Where the error rate now is in the twenties . 
D:  So , um . 
D:  That 's yet s 
D:  Right . 
D:  So it would be  So it would be good t to sort of r re uh  
D:  just at least to give us an idea of how well the hybrid system would do . 
D:  Mm - hmm . 
D:  Right . 
D:  And the other thing that that would help us to evaluate is to see how well the M L P is trained up . 
D:  Right ? 
D:  Because it 's a pretty good um indicator of that . 
D:  So it 's sort of a sanity check of the M L P outputs  before we go ahead and train up the  uh you know , use them as a basis for the tandem system . 
D:  No . 
D:  Sure . 
D:  Not  
D:  But  
D:  Oh  oh that 's a good question . 
D:  Yeah , we  we weren't sure whether it 's worth to just use the alignments um from the S R I recognizer 
D:  or whether to actually go through one or more iterations of embedded training where you realign . 
D:  Mm - hmm . 
D:  Mm - hmm . 
D:  Right . 
D:  OK . 
D:  Alright . 
D:  But  But so I  
D:  Well but i 
D:  But in your experience I mean uh have you seen big improvements in s on some tasks with embedded training ? 
D:  Or was it sort of small - ish uh improvements that you got 
D:  Right . 
D:  That are from another  
D:  Right . 
D:  Right . 
D:  So you  you started training with outputs from a  with alignments that were generated by the Cambridge uh system ? 
D:  And then  
D:  Uh . 
D:  Hmm . Well , that might probably just  
D:  Hmm . 
D:  That was probably because your initial system  I mean your system was ba worse than Cambridge 's . 
D:  And you  Um . 
D:  It wasn't ? 
D:  Really ? 
D:  That 's weird . 
D:  That 's  That 's weird . 
D:  No I mean it 's weird that it did  
D:  I 'm sorry . 
D:  It 's w 
D:  It 's weird that it got worse . 
D:  Oh actually it 's not that weird 
D:  because we have seen  
D:  We have seen cases where acoustic  retraining the acoustic models after some other change made matters worse rather than better . 
D:  Yeah . 
D:  Mm - hmm . 
D:  You mean with soft targets ? 
D:  Or  ? 
D:  Sorry , I 'm sor 
D:  I missed  
D:  What  What 's the key issue here ? 
D:  Yeah . 
D:  Mm - hmm . 
D:  OK . 
D:  Uh , I think that has about  
D:  Well i you 'd  would be gender - dependent training , 
D:  right ? 
D:  So  So I think it 's  uh that 's about mmm , something like thirty hours . 
D:  Thirty hours per gender . 
D:  I  I think so . 
D:  I 'll  
D:  It 's definitely less than a hundred  
D:  You know , it 's more like  like thirty forty hours 
D:  something like that . 
D:  Yeah . 
D:  Mm - hmm . 
D:  Remember you 'll have a smaller output layer so there 's gonna be fewer parameters there . 
D:  And then  
D:  OK . 
D:  Yeah . 
D:  Oh I see , 
D:  I see , 
D:  yeah , of course . 
D:  Yeah . 
D:  It 's negligible , OK . 
D:  Uh - huh . 
D:  Was that gender - dependent or independent ? 
D:  Mm - hmm . 
D:  Mm - hmm . 
D:  OK . 
D:  Right . 
D:  I actually have to go . 
D:  So . 
