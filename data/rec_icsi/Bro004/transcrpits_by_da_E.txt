E:  Yes . 
E:  Ah 
E:  Five , five . 
E:  Mmm , channel five ? 
E:  Doesn't work ? 
E:  No ? Ah , 
E:  era el cuatro . 
E:  Yeah . 
E:  Yeah yeah yeah . 
E:  OK . 
E:  I saw that . 
E:  Ah  yeah , it 's OK . 
E:  Channel  <clear throat> I decided to talk about that . 
E:  No . 
E:  Not yet . 
E:  The early experiment that  
E:  Yeah . 
E:  Aurora - two . 
E:  Mmm , no . 
E:  Fifty - one ? 
E:  This  
E:  We improve . 
E:  I  I  I 'm trying the HTK with eh ,  PLP twelve on - line delta - delta and MSG filter  together . 
E:  The combination , yeah . 
E:  But I haven't result <laugh> at this moment . 
E:  Yeah . 

E:  Ye - Uh , with the old  older , 
E:  yeah . 
E:  Yeah . 
E:  But  We can 
E:  know soon . 
E:  Maybe . 
E:  I don't know . 
E:  Mm - hmm . 

E:  Begin to work in this . 
E:  We are @ @ . 
E:  Yeah . 
E:  Yeah . 
E:  Mu . 
E:  No 
E:  transform the PLP 
E:  and only transform the other 
E:  I 'm not sure . 
E:  Two e @ @ it 's one . 
E:  Yeah , I have one . 

E:  We have one . 

E:  But they have a question of the result . 
E:  Um how are trained the  the LDA filter ? 
E:  How obtained the LDA filter ? 
E:  Yes , 
E:  um the LDA filter  needs some  training set  to obtain the filter . 
E:  Maybe 
E:  I don't know exactly how  they are obtained . 
E:  Training , with the training test of each  
E:  You understand me ? 
E:  Yeah , 
E:  uh for example ,  LDA filter  need a set of   a set of training  to obtain the filter . 
E:  And maybe  for the Italian , for the TD  TE on for Finnish , these filter are  are obtained with their own training set . 
E:  Yeah . 
E:  Yeah , because maybe it the same situation that the neural network training with their own 
E:  set . 
E:  I don't understand also 
E:  what 
E:  is   what is the difference between ASP and uh baseline over ? 
E:  This is  
E:  Yeah . 
E:  Yeah . 
E:  Ah , OK , mm - hmm . 
E:  yeah . 
E:  Temporal LDA . 
E:  No . 
E:  Yes . 
