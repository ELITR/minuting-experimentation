D:  <mike noise> 
C:  Yeah , we had a long discussion about 
C:  how much w how easy we want to make it for people to bleep things out . So  
D:  <mike noise> 
F:  Right . 
C:  <breath> <mike noise> 
F:  OK . So this is  
C:  Morgan wants to make it hard . <laugh> 
D:  <mike noise> 
F:  The , uh , counter is not  moving again . It  
A:  <breath-laugh> 
D:  It  it doesn't  
F:  It doesn't like me , but  
D:  <mike noise> 
C:  Did  did  did it  ? I didn't even check yesterday whether it was moving . 
D:  It didn't move yesterday either when I started it . 
F:  Oh , it didn't ? OK . 
C:  So . 
D:  So I don't know if it doesn't like both of us  
F:  It didn't move on me on one other meeting and it did on one and both recorded the same so . 
C:  Channel three ? 
D:  <mike noise> 
C:  Channel three ? 
C:  <breath> 
D:  You know , I discovered something yesterday on these , um , wireless ones .  
F:  <mike noise> 
B:  <mike noise> 
B:  Channel two . <breath> 
C:  Mm - hmm ? 
D:  You can tell if it 's picking up  breath noise and stuff . 
B:  <clears throat> 
C:  Yeah , it has a little indicator on it  on the AF . 
D:  Mm - hmm . 
F:  Oh , really ? 
B:  <breath> 
F:  Oh that 's  the gains I 've left here as the sort of normal ones , but  
D:  So if you  yeah , if you breathe under  breathe and then you see AF go off , then you know  it 's p picking up your mouth noise . 
F:  <mike noise> 
F:  Oh , that 's good . Cuz we have a lot of breath noises . 
A:  <mike noise> 
C:  Yep . Test . 
F:  In fact , if you listen to just the channels of people not talking , it 's like " @ @ " .  <laugh> 
D:  <mike noise> <laugh> <mike noise> 
C:  <laugh> 
A:  <breath-laugh> 
F:  It 's very disgust Sorry .  
C:  <inbreath> What ? Did you see Hannibal recently or something ?  
F:  Exactly .  It 's very disconcerting . OK . 
C:  <breath-laugh> 
F:  So , um , <mouth> I was gonna try to get out of here , like , in half an hour , um , cuz I 
C:  @ @  
B:  <mike noise> 
D:  <mike noise> 
topic_description:	opening


F:  really appreciate people coming , and <breath> the main thing that I was 
F:  gonna ask people to help with today is  to 
A:  <mike noise> 
A:  <mike noise> 
F:  give input on what kinds of database format we should  use in 
A:  <mike noise> 
F:  starting to link up things like word transcripts and annotations of word transcripts , so anything that 
F:  transcribers or discourse coders or whatever put in the signal , <breath> 
B:  <pages shuffling> 
F:  with time - marks for , like , words and phone boundaries and all the stuff we get out of the forced alignments and the recognizer . 
A:  <sniff-breath> 
F:  So , we have this , um  
F:  <mouth> I think a starting point is clearly the  the channelized  output of Dave Gelbart 's program , which Don brought a copy of ,  
C:  <inbreath> Yeah . <outbreath> 
F:  OK . So , I mean , that seems  
C:  <click noise, as cap is put back on marker> 
A:  <breath> 
F:  that seems g 
F:  great for all of the 
C:  <breath-laugh> 
C:  <mike noise> 
F:  encoding of things with time and , 
C:  Oh , well . 
F:  um  
topic_description:	database format


C:  Yeah , I 'm  I 'm familiar with that . I mean , we  I sort of already have developed an XML format 
F:  um , which  
D:  Can I see it ? 
C:  for this sort of stuff . And so the only question  
C:  is it the sort of thing that you want to use or not ? 
C:  Have you looked at that ? I mean , I had a web page up . 
F:  <inbreath> Right . So , 
F:  <faint creaky vocal vibrations> 
F:  I actually mostly need to be able to link up , or  
C:  So   
C:  You mean , this  
F:  I it 's  it 's a question both of what the representation is and  
C:  I guess I am gonna be standing up and drawing on the board . <laugh> 
F:  OK , yeah . So you should , definitely . 
C:  Um , so  so it definitely had that as a concept . So tha it has a single time - line , 
D:  <mike noise> 
F:  Mm - hmm . 
C:  and then you can have lots of different sections , each of which have I Ds attached to it , and then you can refer from other sections to those I Ds , 
C:  if you want to . 
C:  So that , um  
C:  so that you start with  with a time - line tag . 
C:  <writing on whiteboard> 
C:  " Time - line " .  
C:  <writing on whiteboard> 
C:  And then you have a bunch of times . 
C:  I don't e I don't remember exactly what my notation was , but it  
A:  <mouth> Oh , I remember seeing an example of this . Yeah . 
F:  Right , right . 
C:  Yeah , " T equals one point 
C:  three two " , uh  
C:  And then I  I also had optional things like accuracy , 
C:  and then " ID equals T one , uh , one seven " .  And then , 
C:  <writing on whiteboard> 
C:  I also wanted to  to be i to be able to not specify specifically what the time was and just have a stamp . 
F:  Right . 
C:  <writing on whiteboard> 
A:  <breath> 
C:  Yeah , so these are arbitrary , assigned by a program , not  not by a user . So you have a whole bunch of those . 
C:  <inbreath> And then somewhere la further down you might have something like an utterance tag 
C:  which has " start 
C:  equals T - seventeen , end equals T - eighteen " . 
C:  So what that 's saying is , we know it starts at this particular time . We don't know when it ends . 
F:  <inbreath> OK . 
C:  Right ? But it ends at this T - eighteen , which may be somewhere else . We say there 's another utterance . 
C:  We don't know what the t time actually is but we know that it 's the same time as this end time . 
C:  <writing on whiteboard> 
A:  Mmm . 
C:  You know , thirty - eight , whatever you want . 
A:  <inbreath> So you 're essentially defining a lattice . 
C:  OK . 
C:  Yes , exactly . 
A:  Yeah . 
C:  And then , uh  and then these also have I Ds . 
C:  <writing on whiteboard> 
C:  Right ? So you could  you could have some sort of other  other tag later in the file that would be something like , um , 
D:  <mike noise> 
C:  oh , I don't know ,  uh , 
C:  <writing on whiteboard> 
C:  " noise - type equals 
C:  <writing on whiteboard> 
C:  door - slam " . You know ?  
C:  <writing on whiteboard> 
C:  And then , uh , 
C:  <writing on whiteboard> 
C:  you could either say " time equals a particular time - mark " or you could do other sorts of references . <breath> 
C:  So  or  or you might have a prosody  
C:  <writing on whiteboard> 
C:  " Prosody "  right ? D ? T ?  <breath> 
F:  <laugh> 
F:  It 's an O instead of an I , but the D is good . 
C:  <writing on whiteboard> 
B:  <laugh> 
C:  You like the D ? That 's a good D .  
F:  <breath-laugh> Yeah . 
D:  <breath-laugh> 
C:  <inbreath> Um , 
C:  you know , so you could have some sort of type here , 
C:  <tapping or writing on whiteboard> 
C:  and then you could have , um  
C:  the utterance that it 's referring to could be U - seventeen or something like that . 
B:  <breath> 
topic_description:	me011's XML format


F:  <inbreath> I  I guess my question is more , 
F:  uh , what d what do you do with , say , a forced alignment ? I mean you 've got all these phone labels , and what do you do if you  
A:  How - how 
F:  just conceptually , if you get , um , transcriptions where the words are staying 
F:  but the time boundaries are changing , cuz you 've got a new recognition output , or s sort of  what 's the , um , 
A:  <sniff> 
F:  sequence of going from the 
F:  waveforms that stay the same , the transcripts that may or may not change , and then the 
F:  utterance which  where the time boundaries that may or may not change  ? 
A:  <mouth> Oh , that 's  
A:  That 's actually very nicely handled here because you could  you could  all you 'd have to change is the , <breath> 
F:  Um . 
A:  um , time - stamps in the time - line without  without , uh , changing the I Ds . 
F:  And you 'd be able to propagate all of the  
C:  Right . That 's , the who that 's why you do that extra level of indirection . 
F:  the information ? 
C:  So that you can just change the time - line . 
A:  <inbreath> Except the time - line is gonna be huge . If you say  suppose you have a phone - level alignment . You 'd have  you 'd have  
B:  <mike noise> 
C:  Yes . 
F:  Yeah , yeah , especially at the phone - level . The  we  we have phone - level backtraces .  
C:  Yeah , this  I don't think I would do this for phone - level . 
F:  Um  
C:  I think for phone - level you want to use some sort of binary representation because it 'll be too dense otherwise . 
F:  OK . So , if you were doing that and you had this sort of companion , uh , thing that gets called up for phone - level , uh , what would that look like ? How would you  ? 
C:  <inbreath> I would use just an existing  
A:  Why - 
A:  Mmm . But  but why not use it for phone - level ? It 's just a matter of  it 's just a matter of it being bigger . But if you have  
F:  H h 
C:  an existing way of doing it . 
A:  <breath> 
A:  you know , barring memory limitations , or uh  I w I mean this is still the m 
C:  It 's parsing limitations . I don't want to have this text file that you have to read in the whole thing to do something very simple for . 
A:  Oh , no . You would use it only  for  purposes where you actually want the phone - level information , I 'd imagine . 
F:  So you could have some file that configures how much information you want in your  in your XML or something . 
C:  Right . I mean , you 'd  y I  I am imagining you 'd have multiple versions of this depending on the information that you want . 
A:  <inbreath> You  
F:  Um , cuz th it does get very bush with  
F:  Right . 
C:  <breath> Um , I 'm just  what I 'm wondering is whether  I think for word - level , this would be OK . 
F:  <inbreath> Yeah . Yeah . Definitely . 
C:  For word - level , it 's alright . <breath> 
A:  Mm - hmm . 
C:  For lower than word - level , you 're talking about so much data that I just  I don't know . I don't know if that  
F:  <inbreath> I mean , we actually have  So , one thing that Don is doing , is we 're  we 're running  
D:  Lattices are big , too . 
F:  For every frame , you get a pitch value , and not only one pitch value but different kinds of pitch values depending on  
C:  <inbreath> Yeah , I mean , for something like that I would use P - file or  or any frame - level stuff I would use P - file . 
D:  <sniff> 
F:  Meaning  ?  
C:  Uh , that 's a  well , or something like it . It 's ICS uh , ICSI has a format for frame - level representation of features . 
D:  <inbreath> 
F:  OK . That you could call  that you would tie into this representation with like an ID . 
C:  Um . 
C:  Right . 
C:  Right . Or  or there 's a  there 's a particular way in XML to refer to external resources . 
F:  And  
F:  OK . 
C:  So you would say " refer to this external file " . 
C:  Um , so that external file wouldn't be in  
F:  So that might  that might work . 
D:  But what  what 's the advantage of doing that versus just putting it into this format ? 
A:  <breath> 
C:  <inbreath> @ @ More compact , which I think is  is better . I mean , if you did it at this  
D:  Uh - huh . 
F:  I mean these are long meetings and with  for every frame , um  
C:  You don't want to do it with that  Anything at frame - level you had better encode binary or it 's gonna be really painful . 
A:  <mouth> Or you just compre I mean , I like text formats . Um , b you can always , uh , G - zip them , <breath> 
A:  and , um , you know , c decompress them on the fly if y if space is really a concern . 
D:  <inbreath> Yeah , I was thi 
D:  I was thinking the advantage is that we can share this with other people . 
C:  <inbreath> Well , but if you 're talking about one per frame , 
C:  you 're talking about gigabyte - size files . You 're gonna actually run out of space in your filesystem for one file . 
F:  These are big files . These are really  I mean  
C:  Right ? Because you have a two - gigabyte limit on most O Ss . 
A:  <mouth> Right , OK . I would say  OK , so frame - level is probably not a good idea . But for phone - level stuff it 's perfectly  
F:  <inbreath> And th it 's  
B:  <breath-laugh> 
A:  Like phones , or syllables , or anything like that . 
F:  Phones are every five frames though , so . 
F:  Or something like that . 
A:  But  but  but most of the frames are actually not speech . <breath-laugh> 
B:  <breath> 
A:  So , you know , people don't  
F:  <inbreath> 
F:  Yeah , but we actually  
A:  v Look at it , words times the average  The average number of phones in an English word is , I don't know ,  five maybe ? 
B:  <mike noise> 
C:  <clears throat> 
A:  <breath> 
A:  So , look at it , t number of words times five . That 's not  that not  
F:  Oh , so you mean pause phones take up a lot of the  long pause phones . 
C:  Yep . 
A:  Exactly . Yeah . 
F:  Yeah . OK . That 's true . But you do have to keep them in there . Y yeah . OK . 
C:  <breath> So I think it  it 's debatable whether you want to do phone - level in the same thing . But I think , a anything at frame - level , even P - file , 
F:  OK . 
F:  So  
C:  is too verbose . I would use something tighter than P - files . 
topic_description:	forced alignment at different output levels


F:  Do you  Are you familiar with it ? I haven't seen this particular format , but  
C:  So . 
A:  I mean , I 've  I 've used them . I don't know what their structure is . I 've forgot what the str 
F:  OK . 
D:  <inbreath> But , wait a minute , P - file for each frame is storing a vector of cepstral or PLP values , right ? 
C:  It 's whatever you want , actually . So that  what 's nice about the P - file  It  i 
D:  Right . 
C:  Built into it is the concept of  frames , utterances , sentences , that sort of thing , that structure .  
A:  <pages turning> 
A:  <pages turning> 
C:  <breath> 
C:  And then also attached to it is an arbitrary vector of values . 
F:  Oh . 
C:  And it can take different types . So it  th they don't all have to be floats . You know , you can have integers and you can have doubles , and all that sort of stuff . 
A:  <pages turning> 
A:  <pages turning> 
F:  So that  that sounds  that sounds about what I w 
C:  Um . 
C:  Right ? And it has a header  it has a header format that  describes it  to some extent . So , <inbreath> 
C:  the only problem with it is it 's actually storing the  utterance numbers and the  frame numbers in the file ,  
C:  even though they 're always sequential .  And so it does waste a lot of space . 
A:  Hmm . 
C:  But it 's still a lot tighter than  than ASCII . And we have a lot of tools already to deal with it . 
F:  You do ? OK . Is there some documentation on this somewhere ? OK , great . So , 
C:  Yeah , there 's a ton of it . Man - pages and , uh , source code , and 
F:  I mean , that sounds good . I  I was just looking for something  I 'm not a database person ,  but something sort of standard enough that , 
C:  me . <laugh> 
D:  <breath-laugh> 
F:  you know , if we start using this we can give it out , other people can work on it , or   Is it  ? 
C:  <inbreath> Yeah , it 's not standard . I mean , it 's something that we developed at ICSI . 
A:  <breath> 
C:  But , uh  
F:  But it 's  been used here and people 've  
C:  But it 's been used here and  and , you know , we have a  well - configured system that you can distribute for free , and  
topic_description:	P-file format


D:  <inbreath> I mean , it must be the equivalent of whatever you guys used to store feat your computed features in , right ? 
F:  OK .  
A:  Yeah , th we have  
A:  Actually , we  we use a generalization of the  the Sphere format .  <breath> 
D:  Mmm . 
A:  Um , <mouth> but  
A:  Yeah , so there is something like that but it 's , um , probably not as sophist 
D:  And I think there 's  
C:  Well , what does H T K do for features ? Or does it even have a concept of features ? 
A:  They ha it has its own  
A:  I mean , Entropic has their own feature format that 's called , like , S - SD or some so SF or something like that . 
F:  Yeah . 
D:  Yeah . 
C:  I 'm just wondering , would it be worth while to use that instead ? 
A:  Hmm ? 
B:  <mike noise> 
F:  Yeah . Th - this is exactly the kind of decision  It 's just whatever  
D:  <inbreath> But , I mean , people don't typically share this kind of stuff , right ? I mean  
F:  <inbreath> 
A:  Right . 
C:  They generate their own . <outbreath> 
F:  Actually , I  
D:  Yeah . 
F:  I just  you know , we  we 've done this stuff on prosodics and 
B:  <mike noise> 
F:  three or four places have asked for those prosodic files , and we just have an ASCII , 
F:  uh , output of frame - by - frame . Which is fine , 
C:  Ah , right . 
F:  but it gets unwieldy to go in and  and query these files with really huge files . 
C:  Right . 
F:  I mean , we could do it . I was just thinking if there 's something that  where all the frame values are  Hmm ? 
C:  And a and again , if you have a  
C:  if you have a two - hour - long meeting , that 's gonna  
F:  They 're  they 're fair they 're quite large . And these are for ten - minute Switchboard conversations , and  <breath> 
C:  Yeah , I mean , they 'd be emo enormous . 
C:  Right . 
F:  So it 's doable , it 's just that you can only store a feature vector at frame - by - frame and it doesn't have any kind of , 
F:  um  
D:  Is  is the sharing part of this a pretty important  consideration or does that just sort of , uh  a nice thing to have ? 
A:  <breath> 
F:  I  I don't know enough about what we 're gonna do with the data .  But I thought it would be good to get something that 
A:  <mike noise> 
A:  <breath> <mike noise> 
A:  <breath> 
F:  we can  that other people can use or adopt for their own kinds of 
F:  encoding . And just , I mean we have to use some we have to make some decision about what to do . And especially for the prosody work , what  
A:  <breath> 
C:  Yeah . 
F:  what it ends up being is you get 
F:  features from the signal , and of course those change every time your alignments change . So you re - run a recognizer , you want to recompute 
F:  your features , um , and then keep the database up to date . Or you change a word , or you change a <mouth> 
C:  Right . 
F:  utterance boundary segment , which is gonna happen a lot . 
A:  <mike noise> <breath> 
F:  And so I wanted something where  all of this can be done in a elegant way and that if somebody 
F:  wants to try something or compute something else , that it can be done flexibly . 
F:  Um , it doesn't have to be pretty , it just has to be , 
F:  you know , easy to use , and  
topic_description:	other sound file feature formats


C:  <breath> Yeah , the other thing  
C:  We should look at ATLAS , the NIST thing , 
A:  <breath> 
F:  Oh . 
A:  Mmm . 
F:  <inbreath> Uh   
C:  and see if they have anything at that level . I mean , I 'm not sure what to do about this with ATLAS , because they chose a different route . 
C:  <breath> 
C:  I chose something that  Th - there are sort of two choices . Your  your file format 
B:  <mike noise> 
C:  can know about  
C:  know that you 're talking about language  and speech , which is what I chose , and time , 
C:  <inbreath> or your file format can just be a graph representation . 
D:  <yawn> 
C:  And then the application has to impose the structure on top . 
C:  <breath> 
C:  So what it looked like ATLAS chose is , they chose the other way , which was their file format is just 
C:  nodes and links , and you have to interpret what they mean yourself . 
F:  And why did you not choose that type of approach ? 
C:  <inbreath> Uh , because I knew that we were doing speech , and I thought it was better 
F:  OK . 
C:  if you 're looking at a raw file to be  t for the tags to say " it 's an utterance " , as opposed to the tag to say " it 's a link " . 
B:  <mike noise> 
F:  OK . 
F:  But other than that , are they compatible ? I mean , you could sort of  
C:  So , but  
C:  Yeah , they 're reasonably compatible . 
F:  I mean , you  you could  
D:  You could probably translate between them . 
F:  Yeah , that 's w So , OK . 
C:  Yep . 
C:  <inbreath> So , well , the other thing is 
C:  if we choose to use ATLAS , which maybe we should just do , we should just throw this out before we invest a lot of time in it . 
F:  I don't  
F:  So this is what the meeting 's about , just sort of how to  Um , cuz we need to come up with a database like this just to do our work . And I actually don't 
C:  Yeah . 
F:  care , as long as it 's something useful to other people , what we choose . So maybe it 's  
C:  Yeah . 
F:  maybe oth you know , if  if you have any idea of how to choose , cuz I don't . 
C:  <breath> The only thing  
C:  <breath> Yeah . 
A:  Do they already have tools ? 
C:  <breath> I mean , I  I chose this for a couple reasons . One of them is that it 's easy to parse . 
A:  <breath> 
C:  You don't need a full XML parser . It 's very easy to just write a Perl script  to parse it . 
A:  As long as uh each tag is on one line . <laugh> 
C:  Exactly . Exactly . Which I always do . <laugh> 
B:  <breath> 
F:  And you can have as much information in the tag as you want , right ? 
A:  <mike noise> 
C:  <breath> Well , I have it structured . Right ? So each type tag has only particular items that it can take . 
F:  Can you  But you can add to those structures 
C:  Sure . 
F:  if you  
C:  If you have more information .   So what  
F:  Yeah . So  
C:  What NIST would say is that instead of doing this , you would say something like " link 
C:  <writing on whiteboard> 
C:  start equals , um , you know , some node ID , end equals some other node ID " , 
C:  and then " type " would be " utterance " .  
C:  <writing on whiteboard> 
A:  Hmm . 
B:  <mike noise> 
C:  You know , so it 's very similar . 
F:  So why would it be a  a waste to do it this way if it 's similar enough that we can always translate it ? 
B:  <mike noise> 
D:  It probably wouldn't be a waste . It would mean that at some point if we wanted to switch , we 'd just have to 
C:  Write a translator . But it se 
D:  translate everything . 
F:  But it  but that sounds  
C:  Since they are developing a big  
D:  But that 's  I don't think that 's a big deal . 
F:  As long as it is  
C:  they 're developing a big infrastructure . And so it seems to me that if  
C:  if we want to use that , we might as well go directly to what they 're doing , rather than  
A:  If we want to  
A:  Do they already have something that 's  that would be useful for us in place ? 
D:  Yeah . See , that 's the question . I mean , how stable is their  
D:  Are they ready to go , or  ?  
C:  The  I looked at it  The last time I looked at it was a while ago , probably a year ago , 
D:  Hmm . 
C:  uh , when we first started talking about this . And at that time at least 
C:  <breath> 
C:  it was still not very  complete . <breath> 
C:  And so , specifically they didn't have any external format representation at that time . 
C:  <breath> 
C:  They just had the sort of conceptual  node  
C:  uh , annotated transcription graph , which I really liked . And that 's exactly what this stuff is based on . 
C:  <breath> 
C:  Since then , they 've developed their own external file format , 
B:  <mike noise> 
C:  <breath> 
C:  which is , uh , you know , this sort of s this sort of thing . 
C:  <breath> 
C:  Um , and apparently they 've also developed a lot of tools , but I haven't looked at them . Maybe I should . 
A:  @ @ We should  we should find out . 
F:  I mean , would the tools  would the tools run on something like this , if you can translate them anyway ? 
B:  <breath> 
D:  <sniff> 
B:  <clears throat> 
C:  <mouth> Um , th what would  would  would  what would worry me is that maybe we might miss a little detail 
F:  I mean , that  I guess it 's a question that  uh , yeah . 
A:  It 's a hassle 
A:  if   
C:  that would make it very difficult to translate from one to the other . 
F:  OK . 
A:  I  I think if it 's conceptually close , and they already have or will have tools that everybody else will be using , I mean , 
F:  OK . 
A:  <breath> 
C:  Yeah , we might as well . 
A:  it would be crazy to do something s you know , separate that  
C:  Yep . 
F:  Yeah . 
C:  <inbreath> So I 'll  I 'll take a closer look at it . 
F:  Actually , so it 's  that  that would really be the question , is just what you would feel is in the long run the best thing . Cuz <inbreath> 
C:  And  
C:  Right . 
C:  The  
F:  once we start , sort of , doing this I don't  we don't actually have enough time to probably have to rehash it out again and  
C:  Yep . 
C:  <inbreath> 
D:  <yawn> 
C:  The other thing  the other way that I sort of established this was as easy translation to and from the Transcriber format . 
F:  s <outbreath> 
F:  Right . Right . 
C:  Um , but  
F:  I mean , I like this . This is sort of intuitively easy to actually r read , as easy it could  as it could be . But , 
C:  Yep . 
F:  I suppose that  as long as they have a type here that specifies " utt " , 
F:  um , 
C:  It 's almost the same . The  the  the  the point is  with this , though , is that you can't really add any supplementary information . 
F:  it 's  yeah , close enough that  
D:  <sniff> 
A:  <yawn> 
C:  Right ? So if you suddenly decide that you want  
F:  <breath> 
F:  You have to make a different type .   
C:  Yeah . You 'd have to make a different type . 
F:  So  Well , if you look at it and  
B:  <mike noise> 
F:  Um , I guess in my mind I don't know enough  Jane would know better ,  about 
F:  the  types of annotations and  and  
F:  But I imagine that those are things that would  well , you guys mentioned this ,  that could span any  
B:  <mike noise> 
B:  <breath> 
A:  <sniff> 
F:  it could be in its own channel , it could span time boundaries of any type , it could be instantaneous , things like that . Um , 
C:  Right . 
F:  and then from the recognition side we have 
F:  backtraces at the phone - level . If  if it can handle that , it could handle states or whatever . <inbreath> 
C:  Right . 
F:  And then at the prosody - level we have 
F:  frame  sort of like cepstral 
C:  Yep . 
F:  feature files , uh , like these P - files or anything like that . And that 's sort of the world of things that I  
F:  And then we have the aligned channels , of course , and  
C:  Right . 
A:  It seems to me you want to keep the frame - level stuff separate . 
F:  Yeah . I  I definitely agree and I wanted to find actually a f a nicer format or a  maybe a more compact format than what we used before . Just cuz you 've got 
A:  And then  
A:  <outbreath> 
C:  Right . 
F:  <breath> 
F:  ten channels or whatever and two hours of a meeting . It 's  it 's a lot of  
A:  <breath> <mouth> Now  now how would you  
C:  Huge .  
A:  how would you represent , um , multiple speakers in this framework ? Were  You would just represent them as  <breath> 
C:  Um , 
A:  You would have like a speaker tag or something ? 
C:  <inbreath> there 's a spea speaker tag up at the top which identifies them and then each utt 
C:  the way I had it is each turn or each utterance ,  I don't even remember now , had a speaker ID tag attached to it . 
A:  Mm - hmm . 
C:  <inbreath> And in this format you would have a different tag , 
A:  OK . 
C:  which  which would , uh , be linked to the link . 
C:  <laugh> 
F:  Yeah . 
C:  So  so somewhere else you would have another thing  that would be , um  
C:  Let 's see , would it be a node or a link ? Um  
A:  <mouth> <yawn> 
C:  And so  so this one would have , um , an ID is link   
C:  link seventy - four or something like that . And then somewhere up here you would have a link that  that , uh , 
A:  Mm - hmm . 
C:  you know , was referencing L - seventy - four and had speaker Adam .  
A:  <breath> Is i ? 
F:  Actually , it 's the channel , I think , that  
C:  You know , or something like that . 
A:  Well , channel or speaker or whatever . It doesn't  
F:  I mean , w yeah , channel is what the channelized output out 
C:  This isn't quite right . I have to look at it again . 
F:  See , I think the kinds of questions , at least in the next  to the end of this year , are  
F:  there may be a lot of different ones , but they 'll all have a similar nature . They 'll be 
F:  looking at either a word - level prosodic , 
D:  <sniff> 
F:  uh , an  a value , like a continuous value , like the slope of something . But 
C:  Mm - hmm . 
F:  you know , we 'll do something where we  
F:  some kind of data reduction where the prosodic features are sort o uh , either at the word - level or at the 
A:  <sniff> 
F:  segment - level , or  or something like that . They 're not gonna be at the phone - level and they 're no not gonna be at the frame - level when we get done with 
C:  Right . 
A:  <breath> 
F:  sort of giving them simpler shapes and things . 
F:  And so the main thing is just being able  
F:  Well , I guess , the two goals . Um , one that Chuck mentioned is 
F:  starting out with something that we don't have to start over , that we don't have to throw away if other people want to extend it for other kinds of questions , 
C:  Right . 
F:  and being able to at least get enough , uh , information out on  
F:  where we condition the location of features on information that 's in the kind of file that you  put up there . 
F:  And that would  that would do it , I mean , for me . 
C:  Yeah . I think that there are quick and dirty solutions , and then there are long - term , big - infrastructure solutions . And so <inbreath> 
C:  we want to try to pick something that lets us do a little bit of both . 
F:  In the between , right . And especially that the representation doesn't have to be thrown away , even if your tools change . 
C:  Um  
C:  Right . 
C:  <inbreath> And so it seems to me that  I mean , I have to look at it again to see whether it can really do what we want , <inbreath> 
F:  <clears throat> 
C:  but if we use the ATLAS external file representation , 
C:  um , 
C:  it seems like it 's rich enough that you could do quick tools just as I said in Perl , <inbreath> 
F:  Yeah . 
C:  and then later on if we choose to go up the learning curve , we can use the whole ATLAS inter infrastructure , 
A:  <mike noise> 
F:  I mean , that sounds good to me . I  I don't  
C:  which has all that built in . 
F:  So if  if you would l look at that and let us know what you think .  I mean , 
A:  <mike noise> 
C:  Sure . 
topic_description:	compare me011's with Atlas system


A:  Right . <breath> But  but  so how in the NIST format do we express <breath> 
F:  Yeah , but  
D:  <sniff> 
B:  <breath> 
A:  a hierarchical relationship between , um , say , an utterance and the words within it ? 
A:  So how do you  tell  that  these are the words that belong to that utterance ? 
C:  Um , you would have another structure lower down than this that would be saying they 're all belonging to this ID . 
D:  <yawn> 
A:  Mm - hmm . 
D:  <squeak noise> 
D:  So each thing refers to the  utterance that it belongs to . 
C:  Right . 
D:  So it 's  it 's not hi it 's sort of bottom - up . 
C:  And then each utterance could refer to a turn , and each turn could refer to something higher up . 
F:  <inbreath> And what if you actually have  
F:  So right now what you have as utterance , um , the closest thing that comes out of the channelized is the 
F:  stuff between the segment boundaries that the transcribers put in or that Thilo put in , 
F:  which may or may not actually be , like , a s it 's usually not  um , the beginning and end of a sentence , say . 
C:  Well , that 's why I didn't call it " sentence " . <laugh> 
F:  So , right . <laugh> Um , so it 's like a segment or something . So , 
C:  Yeah . 
F:  I mean , I assume this is possible , that if you have  someone annotates the punctuation or whatever when they transcribe , 
A:  <mike noise> 
F:  you can say , you know , from  
A:  <yawn> 
D:  <sniff> 
F:  for  from the c beginning of the sentence to the end of the sentence , from the annotations , this is a unit , even though it never actually  
F:  i It 's only a unit by virtue of the annotations  at the word - level . 
C:  Sure . I mean , so you would  you would have yet another tag . 
F:  And then that would get a tag somehow . OK . 
C:  You 'd have another tag which says this is of type " sentence " . 
F:  OK . 
C:  And , what  <outbreath> 
F:  But it 's just not overtly in the  
A:  <inbreath> OK .  
F:  Um , cuz this is exactly the kind of  
A:  So  
F:  I think that should be  possible as long as the  
F:  But , uh , what I don't understand is where the  where in this type of file  that would be expressed . 
D:  <sniff> 
C:  Right . You would have another tag somewhere . 
C:  <breath> It 's  well , there 're two ways of doing it . 
F:  S so it would just be floating before the sentence or floating after the sentence without a time - mark . 
C:  You could have some sort of link type  
C:  <writing on whiteboard> 
C:  type equals " sentence " , 
C:  <writing on whiteboard> 
C:  <inbreath> and ID is " S - whatever " . 
C:  And then lower down you could have an utterance . So the type is " utterance "  
C:  equals " utt " . And you could either say that  
C:  No . I don't know  I take that back . 
A:  <mouth> So here 's the thing . Um  
F:  See , cuz it 's  
C:  Can you  can you say that this is 
A:  Hhh .  
F:  it 's   
B:  <breath> 
D:  You would just have a r 
C:  part of this , or do you say this is part of this ? I think  
F:  S 
F:  But they 're  
D:  You would refer up to the sentence . 
A:  Well , the thing  
F:  they 're actually overlapping each other , sort of . 
C:  So  
D:  <mike noise> 
A:  the thing is that some something may be a part of 
C:  Right . <outbreath> 
A:  one thing for one purpose and another thing of another purpose . 
F:  You have to have another type then , I guess . 
A:  So f 
A:  s 
A:  Um , well ,  s let 's  let 's ta so let 's  
C:  <mouth> Well , I think I 'm  I think w I had better look at it again because I  I 'm  
F:  Yeah .  
F:  OK . OK . 
A:  so  
C:  <breath> There 's one level  there 's one more level of indirection that I 'm forgetting . 
A:  y So for instance @ @  sup 
A:  Suppose you have a word sequence and you have two different segmentations of that same word sequence . f Say , one segmentation is in terms of , 
B:  <breath> 
A:  um , 
A:  you know , uh , sentences . And another segmentation is in terms of , um , <mouth> I don't know ,  prosodic phrases . 
A:  And let 's say that they don't  nest . So , you know , a prosodic phrase may cross 
C:  Right . 
A:  two sentences or something . I don't know if that 's true or not but <breath> let 's as 
F:  Well , it 's definitely true with the segment . That 's what I  exactly what I meant by the utterances versus the sentence could be sort of  
A:  Right . 
A:  Yeah . 
A:  So , you want to be s you want to say this  this word is part of that sentence and this prosodic phrase . 
F:  Yeah . 
F:  Yeah . 
A:  But the phrase is not part of the sentence and neither is the sentence part of the phrase . 
F:  Right . 
C:  I I 'm pretty sure that you can do that , but I 'm forgetting the exact level of nesting . 
A:  So , you would have to have <breath> two different pointers from the word up  one level up , one to the sent 
C:  <inbreath> So  so what you would end up having is a tag saying " here 's a word , and it starts here and it ends here " . <breath> 
A:  @ @ Right . 
C:  And then lower down you would say " here 's a prosodic boundary and it has these words in it " . 
C:  And lower down you 'd have " here 's a sentence , and it has these words in it " . 
F:  An - Right . 
A:  Right . 
F:  So you would be able to go in and say , you know , " give me all the words in the bound in the prosodic phrase and give me all the words in the  "  Yeah . 
C:  Yep . 
A:  <inbreath>  <outbreath> 
C:  So I think that 's  that would wor Let me look at it again . <breath> 
F:  Um , OK . 
A:  Mm - hmm .  <inbreath> 
F:  OK . 
topic_description:	hierachical relationships


A:  The  the o the other issue that you had was , how do you actually efficiently extract , um  
C:  So . 
F:  That 's good .  
A:  find and extract information in a structure of this type ? 
A:  So you gave some examples like  
F:  <inbreath> Well , uh , and , I mean , you guys might  
F:  I don't know if this is premature because I suppose once you get the representation you can do this , but the kinds of things I was worried about is , 
F:  uh  
A:  No , that 's not clear . I mean , yeah , you c sure you can do it , but can you do it 
F:  Well , OK . So i if it  
F:  I I mean , I can't do it , but I can  <laugh> um , 
A:  sort of l l you know , 
C:  <laugh> 
A:  it  
A:  y y you gotta  you gotta do this  you  you 're gonna want to do this very quickly 
C:  Well  
A:  or else you 'll spend all your time sort of searching through very <breath> complex data structures  
F:  Right . You 'd need a p sort of a paradigm for how to do it . But an example would be 
F:  " find all the cases in which Adam 
F:  started to talk while Andreas was talking and his pitch was rising , Andreas 's pitch " . That kind of thing . 
C:  <mouth> Right . I mean , that 's gonna be  
C:  Is the rising pitch a  feature , or is it gonna be in the same file ? 
F:  Well , the rising pitch will never be  hand - annotated . So the  all the prosodic features are going to be automatically  So they 're gonna be in those  
C:  <mouth> But the  
C:  I mean , that 's gonna be hard regardless , right ? Because you 're gonna have to write a program that goes through your feature file and looks for rising pitches . 
A:  Yeah . 
F:  <inbreath> So  Right . So normally what we would do is we would say 
F:  " what do we wanna assign rising pitch to ? " Are we gonna assign it to words ? Are we gonna just assign it to sort of  
F:  when it 's rising we have a begin - end rise representation ? But suppose we dump out this file and we say , 
B:  <breath> 
F:  uh , for every word we just classify it as , w you know , rise or fall or neither ? 
C:  OK . Well , in that case you would add that to this  format r 
F:  OK . 
F:  So we would basically be sort of , um , 
F:  taking the format and enriching it with things that we wanna 
A:  <sniff> 
F:  query in relation to the words that are already in the file , and then querying it . OK . 
C:  Right . 
A:  <inbreath> You want sort of a grep that 's  that works at the structural  
C:  <mouth> You have that . 
A:  on the structural representation .  
C:  There 's a  standard again in XML , specifically for searching XML documents  structured X - XML documents , where you can specify both the content and the structural position . 
A:  <inbreath> Yeah , but it 's  it 's not clear that that 's  
F:  <inbreath> If  
A:  That 's relative to the structure of the XML document , not to the structure of what you 're representing in the document . 
C:  You use it as a tool . 
C:  You use it as a tool , not an end - user . It 's not an end - user thing . It 's  it 's  you would use that to build your tool to do that sort of search . 
A:  Right . 
A:  Right . 
A:  Be - 
F:  <inbreath> Uh  
A:  Because here you 're specifying a lattice . So the underlying  
A:  that 's the underlying data structure . And you want to be able to search in that lattice . 
F:  <inbreath> 
F:  But as long as the  
C:  It 's a graph , but  
A:  That 's different from searching through the text . 
F:  But it seems like as long as the features that  
C:  Well , no , no , no . The whole point is that the text and the lattice are isomorphic . 
C:  They  represent each other  completely . 
A:  Um  
C:  So that  
C:  I mean th 
F:  That 's true if the features from your acoustics or whatever that are not explicitly in this are at the level of these types . 
A:  Hhh .  
F:  That  that if you can 
A:  <mike noise> 
C:  Yeah , but that 's gonna be the trouble no matter what . 
F:  do that  
C:  Right ? No matter what format you choose , you 're gonna have the trou you 're gonna have the difficulty of relating 
F:  That 's right . That 's true . That 's why I was trying to figure out what 's the best format for this representation . And it 's still gonna be  
C:  the  the frame - level features  
C:  Yep . 
F:  it 's still gonna be , uh , not direct . You know , it  
A:  Hmm . 
C:  Right . 
F:  Or another example was , you know , uh , where in the language  where in the word sequence 
A:  <mike noise> 
C:  <laugh> 
A:  <mike noise> 
B:  <breath> 
F:  are people interrupting ? So , 
F:  I guess that one 's actually easier . 
D:  <inbreath> What about  what about , um , 
D:  the idea of using a relational database to , uh , store the information from the XML ? So you would have  XML basically would  
B:  <breath> 
A:  <mike noise> 
D:  Uh , you  you could use the XML to put the data in , 
D:  and then when you get data out , you put it back in XML . So use XML as sort of the  
C:  Transfer .  
D:  the transfer format , uh , but then you store the data in the database , which 
C:  The , uh  
D:  allows you to do all kinds of  good search things in there . 
C:  One of the things that ATLAS is doing is they 're trying to define an API which is independent of the back store , 
F:  Huh . 
C:  so that , uh , you could define a single API and the  the storage could be flat XML files or a database . <breath> 
D:  Mm - hmm . <sniff> 
C:  My opinion on that is for the s sort of stuff that we 're doing ,  I suspect it 's overkill to do a full relational database , that , um , 
A:  But   <outbreath> 
C:  just a flat file and , uh , search tools I bet will be enough . 
C:  But that 's the advantage of ATLAS , is that if we actually take  
C:  decide to go that route completely and we program to their API , then if we wanted to add a database later it would be pretty easy . 
D:  Mm - hmm . 
D:  Mm - hmm . 
F:  It seems like the kind of thing you 'd do if  I don't know , if people start adding all kinds of s bells and whistles to the data . And so that might be  
B:  <mike noise> 
F:  I mean , it 'd be good for us to know  to use a format where 
F:  we know we can easily , um , input that to some database if other people are using it . 
C:  Yep . 
F:  Something like that . 
C:  <inbreath> I guess I 'm just a little hesitant to try to go whole hog on sort of the  
F:  So   
C:  the whole framework that  that NIST is talking about , with ATLAS and a database and all that sort of stuff , cuz it 's a big learning curve , 
D:  Hmm . 
C:  just to get going . Whereas if we just do a flat file format , 
A:  Hmm . 
C:  sure , it may not be as efficient but everyone can program in Perl and  and use it . 
F:  @ @ OK . 
C:  <laugh> 
C:  Right ? So , as opposed to  
A:  But this is  I  I 'm still , um , <breath-laugh> 
A:  not convinced that you can do much at all on the text  on the flat file that  that  you know , the text representation . 
A:  e 
A:  Because the text representation is gonna be , 
A:  uh , not reflecting the structure of  of your words and annotations . 
A:  It 's just  it 's  
C:  Well , if it 's not representing it , then how do you recover it ? Of course it 's representing it . That 's the whole point . <laugh> 
A:  No . You  you have to  what you have to do is you have to basically  <breath> 
A:  Y yeah . You can use Perl to read it in and construct a internal representation that is essentially a lattice . 
A:  But , 
D:  @ @ Yeah . 
A:  the  and then  
C:  OK . Well , that was a different point . Right ? So what I was saying 
A:  Right . <outbreath> 
C:  is that   
A:  But that 's what you 'll have to do . 
C:  For Perl  if you want to just do Perl . If you wanted to use the structured XML query language , that 's a different thing . And it 's a set of tools <breath> that let you specify given the D - DDT  DTD of the document , 
A:  Bec - be 
C:  um , what sorts of structural searches you want to do . 
C:  So you want to say that , you know , you 're looking for , 
C:  um , a tag within a tag within a particular tag that has this particular text in it , 
C:  um , and , uh , refers to a particular value . 
C:  <breath> And so the point isn't that an end - user , who is looking for a query like you specified , wouldn't program it in this language . What you would do is , 
C:  someone would build a tool that used that as a library . 
C:  So that they  so that you wouldn't have to construct the internal representations yourself . 
F:  Is a  
F:  <inbreath> <inbreath> 
topic_description:	extracting information


F:  I think we 're sort of guinea pigs , cuz I  I want to get the prosody work done but I don't want to waste time , you know , 
A:  Oh , maybe  
F:  getting the  Yeah ? 
A:  um  
C:  Well , I wouldn't wait for the formats , because anything you pick we 'll be able to translate 
A:  Well  <outbreath> 
C:  to another form . 
A:  <mike noise> 
A:  <inbreath> Ma - well , maybe you should actually look at it yourself too to get a sense of 
F:  OK . 
A:  what it is you 'll  you 'll be dealing with , because , 
A:  um , 
A:  you know , Adam might have one opinion but you might have another , so  
C:  <laugh> 
B:  Yeah . 
F:  Yeah , definitely . 
B:  <clears throat> 
A:  I think the more eyes look at this the better . 
F:  Especially if there 's , e um  you know , if someone can help with at least the  
F:  the setup of the right  <clears throat> 
F:  Oh , hi . <laugh>  
C:  Hi , Jane . 
A:  Mmm . 
F:  the right representation , then , i you know , I hope it won't  We don't actually need the whole full - blown thing to be ready , so . <breath> 
C:  Can you  Oh , well . 
F:  Um , so maybe if you guys can look at it and sort of see what ,  
C:  Sure . 
B:  Yeah . 
F:  um  
F:  I think we 're  we 're  <laugh> we 're actually just  yeah , wrapping up , but , um  
B:  <clears throat> <breath> Hmm . 
C:  We 're about done .  <laugh> 
D:  <laugh> 
E:  Oh you are ? Oh . 
F:  Yeah , sorry , it 's a uh short meeting , but , um  
A:  <breath> 
F:  Well , I don't know . Is there anything else , like  
F:  I mean that helps me a lot , but  
A:  <mike noise> 
F:  And that isn't really , I guess , as important as the  the main  I don't know what you call it , the  
A:  @ @ 
B:  <mike noise> 
F:  the main sort of word - level  
C:  Neither do I . 
D:  Probably stands for " Phil " . 
C:  <breath-laugh> 
D:  Phil Kohn . 
A:  <mouth> <inbreath> 
C:  It 's a Phil file ? <laugh> 
B:  <laugh> 
D:  Yeah . 
F:  <laugh> 
D:  That 's my guess . <laugh> 
F:  Huh . 
F:  OK . Well , that 's really useful . I mean , this is exactly the kind of thing that I wanted to settle . Um , so  
C:  Yeah , I 've been meaning to look at the ATLAS stuff again anyway . So , just keep  
A:  <mike noise> 
F:  Great . 
F:  Yeah . 
F:  I guess it 's also sort of a political deci I mean , if  if you feel like that 's a community that would 
F:  be good to tie into anyway , then it 's  
F:  sounds like it 's worth doing . 
C:  Yeah , I think it  it w 
A:  j I think there 's  
C:  And , w uh , as I said , I  what I did with this stuff  I based it on theirs . It 's just they hadn't actually come up with an external format yet . 
C:  <breath> 
C:  So now that they have come up with a format , 
A:  <inbreath> Mmm .  
C:  it doesn't  it seems pretty reasonable to use it . 
C:  But let me look at it again . 
F:  OK , great . 
C:  As I said , that  
F:  Cuz we actually can start  
C:  There 's one level  there 's one more level of indirection and I 'm just blanking on exactly how it works . 
C:  <inbreath> I gotta look at it again . 
F:  I mean , we can start with , um , I guess , this input from Dave 's , which you had printed out , the channelized input . Cuz he has all of the 
F:  channels , you know , with the channels in the tag and stuff like that . So that would be i directly , 
C:  Yeah , I 've seen it . 
E:  <mike noise> 
C:  Yep . 
F:  um  
C:  Easy  easy to map . 
topic_description:	decisions to be made


C:  <inbreath> Well , I think the other thing we might want to look at is alternatives to P - file . I mean , th the reason I like P - file is I 'm already familiar with it , we have expertise here , 
A:  <breath> 
B:  <breath> 
C:  <breath> 
C:  and so if we pick something else , there 's the learning - curve problem . But , I mean , it is just something we developed at ICSI . 
E:  <mike noise> 
C:  And so  
A:  Is there an  is there an IP - API ? 
C:  Yeah . There 's an API for it . And , uh , 
A:  OK . 
A:  <inbreath> There used to be a problem that they get too large , 
C:  a bunch of libraries , P - file utilities . 
D:  <breath> 
A:  <breath> 
A:  and so  basically the  uh the filesystem 
C:  <inbreath> Well , that 's gonna be a problem no matter what . You have the two - gigabyte limit on the filesystem size . 
A:  wouldn't  
C:  And we definitely hit that with Broadcast News . 
A:  <inbreath> Maybe you could extend the API to , uh , support , uh , like splitting up , 
E:  <mike noise> 
A:  you know , conceptually one file into smaller files on disk so that you can essentially , 
C:  Yep . 
A:  you know , have arbitrarily long f 
C:  Most of the tools can handle that . So that 
A:  Yeah .  
C:  we didn't do it at the API - level . We did it at the t tool - level . That  that  most  many of them can s you can specify several P - files and they 'll just be done sequentially . 
A:  OK . 
C:  So . 
F:  So , I guess , yeah , if  if you and Don can  if you can show him the P - file stuff and see . So this would be like for the F - zero  
C:  Sure . 
C:  <inbreath> I mean , if you do " man P - file " or " apropos P - file " , you 'll see a lot . 
B:  True . 
B:  <inbreath> I 've used the P - file , I think . I 've looked at it at least , briefly , I think when we were doing 
C:  <hiccup> 
A:  What does the P stand for anyway ? 
B:  s something . 
C:  I have no idea . <laugh> 
F:  <laugh> 
B:  Oh , in there . 
A:  <laugh> 
C:  I didn't de I didn't develop it . You know , it was  I think it was Dave Johnson . 
C:  So it 's all part of the Quicknet library . It has all the utilities for it . 
A:  No , P - files were around way before Quicknet . <breath> 
C:  Oh , were they ? 
A:  P - files were  were around when  w with , um , <mouth> RAP . 
D:  Mm - hmm . 
F:  It 's like the history of ICSI . Like   <laugh> 
A:  Right ? 
B:  <laugh> 
A:  You worked with P - files . I worked with P - files . <laugh> 
C:  Mm - hmm . 
D:  No . 
F:  Yeah ? 
B:  <laugh> 
D:  I don't remember what the " P " is , though . 
E:  Is it related to P - make ? 
C:  <breath-laugh> 
A:  No . 
C:  But there are ni they 're  
C:  The  Quicknet library has a bunch of things in it to handle P - files , so it works pretty well . 
A:  Yeah . 
topic_description:	P-file format?


F:  Yeah . And so then it would just be a matter of getting  
F:  making sure to handle the annotations that are , you know , not at the word - level and , um , 
B:  Where are those annotations coming from ? 
F:  t to import the  
F:  Well , right now , I g Jane would  <laugh> would  
C:  Mm - hmm .  
E:  <mike noise> <clears throat> 
F:  Yeah . 
E:  Are you talking about the overlap a annotations ? 
F:  Yeah , any kind of annotation  that , like , isn't already there . Uh , you know , anything you can envision . 
E:  <inbreath> Yeah . 
E:  So what I was imagining was  um , so Dave says we can have unlimited numbers of green ribbons . 
C:  <laugh> 
E:  And so put , uh , a  a green ribbon on for an overlap code . 
E:  <inbreath> And since we w we  I  I think it 's important to remain flexible regarding the time bins for now . 
E:  And so it 's nice to have  
E:  However , you know , you want to have it , uh , time time uh , located in the discourse . So , um , 
E:  if we  if we tie the overlap code to the first word in the overlap , 
E:  then you 'll have a time - marking . It won't  it 'll be independent of the time bins , 
E:  however these e evolve , shrink , or whatever , increase , or  Also , you could have different time bins for different purposes . 
E:  <inbreath> And having it tied to the first word in an overlap segment is unique , uh , you know , anchored , clear . 
E:  And it would just end up on a separate ribbon . 
E:  So the overlap coding is gonna be easy with respect to that . 
C:  Right . 
E:  <breath> 
E:  You look puzzled .  
D:  <inbreath> I  I just  I don't quite understand what these things are . Uh . 
E:  <laugh> 
E:  <breath> OK . What , the codes themselves ? Or the  ?  <breath> 
D:  Well , th overlap codes . I 'm not sure what that @ @  
C:  Well , I mean , is that  
E:  Well , we don't have to go into the codes . We don't have to go into the codes . But let me just  
D:  It probably doesn't matter . No , I d 
C:  I mean , it doesn't . I mean , that  not for the topic of this meeting . 
E:  No . W the idea is just to have a separate green ribbon , 
E:  you know , and  and  and let 's say that this is a time bin . There 's a word here . This is the first word of an overlapping segment of any length , 
E:  overlapping with any other , uh , word  uh , i segment of any length . And , um , 
E:  then you can indicate that this here was perhaps a ch a backchannel , 
E:  or you can say that it was , um , a usurping of the turn , or you can  you know , any  any number of categories . But the fact is , you have it time - tagged 
E:  in a way that 's independent of the , uh , sp particular time bin that the word ends up in . 
A:  <breath> 
E:  If it 's a large unit or a small unit , or we sh change the boundaries of the units , 
A:  Mm - hmm . 
F:  Right . 
E:  it 's still unique and  and , uh , fits with the format , 
A:  <inbreath> 
E:  flexible , all that . 
topic_description:	overlap annotations


A:  Um , 
A:  it would be nice  um , 
A:  eh , gr this is sort of r regarding  
A:  uh , uh it 's related but not directly germane to the topic of discussion , but , when it comes to annotations , um , 
E:  <mike noise> 
A:  you often find yourself in the situation where you have  different annotations  of the same , say , word sequence . 
E:  Yeah .  
A:  OK ? And sometimes the word sequences even differ slightly because they were edited s at one place but not the other . <breath> 
E:  Yeah .  
A:  So , once this data gets out there , some people might start annotating this for , 
A:  I don't know , dialogue acts or , um , 
A:  you know , topics or what the heck . You know , there 's a zillion things that people might annotate this for . <breath> 
A:  And the only thing that 
A:  is really sort of common among all the versi the various versions of this data is the word sequence , 
E:  Yep .  
A:  or approximately . 
F:  Or the time . 
A:  <breath> 
A:  Or the times . But , see , if you 'd annotate dialogue acts , you don't necessarily want to  or topics  you don't really want to be dealing with time - marks . 
F:  I guess .  
A:  You 'd  it 's much more efficient for them to just see the word sequence , right ? 
F:  Mm - hmm . 
A:  <breath> 
A:  I mean , most people aren't as sophisticated as  as we are here with , you know , uh , time alignments and stuff . So  
C:  <laugh, mike interaction> 
B:  <breath> 
F:  <laugh> 
A:  <mouth> <laugh> 
B:  <breath> 
A:  So the  the  the point is  
B:  <breath> 
F:  <mike noise> 
C:  Should  should we mention some names on the people who are n ?  
F:  <laugh> 
D:  <laugh> 
B:  <laugh> 
A:  Right . 
A:  So , um , the p my point is that  you 're gonna end up with , 
D:  <laugh> 
A:  uh , word sequences that are differently annotated . And  you want some tool , 
F:  <mike noise> 
A:  uh , that is able to sort of merge these different annotations back into a single , 
A:  uh , version . 
A:  <mouth> OK ? 
A:  Um , and we had this problem very massively , uh , at SRI when we worked , uh , a while back on , 
A:  <mouth> 
A:  uh  
A:  well , on dialogue acts as well as , uh , you know , um , what was it ?  uh , 
F:  Well , all the Switchboard in it . Yeah . 
A:  utterance types . There 's , uh , automatic , uh , punctuation and stuff like that . <breath> 
D:  <breath> 
A:  Because we had one set of  annotations that were based on , 
A:  uh , one version of the transcripts with a particular segmentation , and then we had another version that was based on , 
A:  uh , a different s slightly edited version of the transcripts with a different segmentation . So , 
A:  <breath> 
A:  we had these two different 
A:  versions which were  you know , you could tell they were from the same source but they weren't identical . So it was extremely hard 
A:  <breath> 
A:  to reliably merge these two back together to correlate the information from the different annotations . 
C:  Yep . I  I don't see any way that file formats are gonna help us with that . It 's  it 's all a question of semantic . 
A:  No . 
F:  <breath-laugh> 
A:  <mouth> No . But once you have a file format , I can imagine writing  
F:  Mm - hmm . 
A:  not personally , but someone writing a tool that is essentially an alignment tool , 
F:  <breath-laugh> 
B:  <breath-laugh> 
C:  Yeah . 
A:  um , that mediates between various versions , and  
A:  uh , sort of like th uh , you know , you have this thing in UNIX where you have , uh , 
C:  Diff .  
F:  W - diff or diff . Yeah . 
A:  diff . 
A:  <breath> 
A:  There 's the , uh , diff that actually tries to reconcile different  
E:  Is it S - diff ?  
A:  two diffs f  based on the same original .  
C:  Yep . 
E:  Mmm .  
A:  <breath> 
A:  Something like that , 
A:  um , but operating on these lattices that are really what 's behind this  uh , this annotation format . <breath> 
C:  Yep . 
A:  So  
F:  You could definitely do that with the  
C:  There 's actually a diff library you can use  to do things like that that  
A:  So somewhere in the API you would like to have like a merge or some  some function that merges two  
C:  so you have different formats . 
C:  Yeah , I think it 's gonna be very hard . Any sort of structured 
A:  two versions . 
E:  <mike noise> 
A:  Right . 
C:  anything when you try to merge is really , really hard because you ha i 
C:  The hard part isn't the file format . The hard part is specifying what you mean by " merge " . <breath> 
A:  Is  
A:  Exactly . <outbreath> 
F:  But the one thing that would work here actually for i that is more reliable than the utterances is the  
C:  And that 's very difficult . <outbreath> 
E:  <mike noise> 
F:  the speaker ons and offs . So if you have a good , um  
C:  But this is exactly what I mean , is that  that the problem i 
F:  Yeah . 
E:  <mike noise> 
F:  You just have to know wha what to tie it to . 
C:  Yeah , exactly . The problem is saying " what are the semantics , what do you mean by " merge " ? " So . 
F:  And  
F:  Right , right . 
A:  Right . 
A:  So  so just to let you know what we  where we kluged it by , uh , doing  
A:  uh , by doing  Hhh .  
A:  Both were based on words , so , bo we have two versions of the same words intersp you know , sprinkled with  with different tags for annotations . 
C:  And then you did diff . <laugh> Yeah , that 's just what I thought .  
A:  <breath> And we did diff . Exactly ! 
F:  <breath> 
A:  And that 's how  Yeah . <breath> 
C:  That 's just wh how I would have done it .  <laugh> 
A:  But , you know , it had lots of errors and things would end up in the wrong order , and so forth . Uh , so , 
C:  Yep . 
A:  um , if you had a more  
A:  Uh , it  it was a kluge because it was basically reducing everything to  uh , to  uh , uh , to textual alignment . 
C:  A textual   
F:  <inbreath> <inbreath> 
A:  Um , so  
F:  But , d isn't that something where whoever  if <clears throat>  if the people 
A:  <breath> 
F:  who are making changes , say in the transcripts , cuz this all happened when the transcripts were different  
F:  ye um , if they tie it to something , like if they tied it to the acoustic segment  if they  
F:  You know what I mean ? Then  Or if they tied it to an acoustic segment and we had the time - marks , that would help . But the problem is exactly as Adam said , that you get , 
A:  <breath> 
C:  Yep . 
F:  you know , y you don't have that information or it 's lost in the merge somehow , so  
E:  <inbreath> Well , can I ask one question ? It  it seems to me that , um , we will have o an official version of the corpus , which will be only one  
B:  <breath> 
E:  one version in terms of the words  where the words are concerned . 
E:  We 'd still have the  the merging issue maybe if coding were done independently of the  
A:  <mouth> And you 're gonna get that because if the data gets out , people will do all kinds of things to it . 
E:  But  but  
E:  <inbreath>  
A:  And , uh , s you know , several years from now you might want to look into , um , 
A:  the prosody of 
A:  referring expressions . And someone at the university of who knows where has annotated the referring expressions . 
C:  Right . 
A:  So you want to get that annotation and bring it back in line with your data . 
E:  <inbreath> OK , then  
C:  But unfortunately they 've also hand - edited it . 
A:  OK ? 
F:  But they 've also  Exactly . And so that 's exactly what we should  somehow when you distribute the data , say that  you know , 
A:  Yeah . 
C:  Yep . 
A:  Right . 
E:  Well , then the  
A:  <breath> 
F:  that  have some way of knowing how to merge it back in and asking people to try to do that . 
D:  What 's  what 's wrong with  doing times ? I  
E:  I agree . That was what I was wondering . 
F:  Uh , yeah , time is the  <breath> Time is passing ! <laugh> 
E:  Time is unique . You were saying that you didn't think we should  Andreas was saying  Yeah . 
C:  Well , 
B:  <laugh> 
A:  Time  time  times are 
C:  what if they haven't notated with them , times ? 
F:  Yeah .  
A:  ephemeral . 
F:  He  he 's a language modeling person , though .  
A:  <laugh> 
B:  <breath-laugh> 
A:  Um  
C:  So  so imagine  I think his  his example is a good one . Imagine that this person who developed the corpus of the referring expressions didn't include time . 
A:  Mm - hmm . 
A:  Yeah . 
E:  Ach !  
C:  He included references to words . He said that at this word is when  when it happened . Or she . 
E:  Well , then  
A:  Yeah . 
A:  Or she . 
E:  But then couldn't you just indirectly figure out the time  tied to the word ? 
A:  <laugh> 
F:  But still they  
F:  Exactly . Yeah . 
C:  Sure . But what if  what if they change the words ? 
E:  Not  Well , but you 'd have some anchoring point . He couldn't have changed all the words . 
C:  <laugh> 
D:  But can they change the words without changing the time of the word ? 
C:  <mouth> Sure . But they could have changed it a little . 
C:  The  the point is , that  that they may have annotated it off a word transcript that isn't the same as our word transcript , so how do you merge it back in ? I understand what you 're saying . <breath> 
A:  Mmm . Mm - hmm . 
C:  And I  I guess the answer is , 
A:  <mike noise> <breath> 
F:  <inbreath> 
C:  um , it 's gonna be different every time . 
F:  <inbreath> 
C:  It 's j it 's just gonna be  <breath> 
F:  Yeah . 
E:  Yeah .  
F:  You only know the boundaries of the  
C:  I it 's exactly what I said before , which is that " what do you mean by " merge " ? " 
C:  So in this case where you have the words and you don't have the times , well , what do you mean by " merge " ? 
F:  Right . 
C:  If you tell me what you mean , I can write a program to do it . 
F:  <inbreath> Right . You can merge at the level of the representation that the other person preserved and that 's it . 
C:  Right . And that 's about all you can do . 
F:  And beyond that , all you know is  is relative ordering and sometimes even that is wrong . 
A:  <breath> 
C:  <inbreath> So  so in  so in this one you would have to do a best match between the word sequences , 
F:  So . 
B:  <mike noise> 
A:  Mm - hmm .  
C:  extract the times f from the best match of theirs to yours , and use that . 
F:  And then infer that their time - marks are somewhere in between . Yeah , exactly . 
C:  Right . 
E:  <inbreath> But it could be that they just  uh , I mean , it could be that they chunked  they  they lost certain utterances and all that stuff , or  
C:  Right , exactly . So it could get very , very ugly . <laugh> 
A:  <breath> 
F:  Definitely . Definitely . 
E:  Yeah .  
F:  <inbreath> 
topic_description:	merging different annotations


F:  Alright . Well , I guess , w I  I didn't want to keep people too long and Adam wanted t people  I 'll read the digits . If anyone else offers to , that 'd be great . And 
E:  That 's interesting .  
A:  <breath> 
C:  <breath-laugh> 
A:  Ah , well .  For th for the  <noise> for the benefit of science we 'll read the digits . 
F:  if not , I guess  
C:  Yeah . 
C:  More digits , the better . OK , this is 
F:  Thanks  thanks a lot . <spike on "lot"> It 's really helpful . I mean , Adam and Don <spike on "Don"> will sort of meet and I think that 's great . Very useful . 
A:  <breath> 
B:  <breath> 
A:  <breath-laugh> 
B:  <mike noise>  
E:  <mike noise> 
topic_description:	closing


C:  transcript two seven three one , two seven five O .  
C:  eight five O five one  
C:  nine five zero six one  
C:  O seven eight  
C:  zero  
F:  Go next .  
C:  one  
B:  <breath> 
C:  two zero two  
C:  four four three four four two seven  
C:  five five six  
C:  six six O O nine eight five  
C:  seven six five  
C:  eight eight four  
C:  nine  
C:  O O one nine one  
C:  one five six one four  
C:  two seven four eight five six zero  
C:  three four  
C:  four five O  
C:  five  
C:  six  
C:  seven .  
D:  Transcript one five one one dash one five three zero .  
F:  Let me  
D:  zero  
D:  one O six six seven three nine  
D:  three one zero five eight eight one  
D:  four five three eight  
D:  five nine four three four  
C:  <mike noise> 
D:  six six O one three four eight  
D:  seven  
D:  eight zero one one two four three  
D:  eight O seven two nine .  
D:  Scratch that . <inbreath> 
D:  nine O seven two nine  
D:  zero one  
D:  one three nine four  
D:  two two five  
D:  three eight seven O  
E:  <mike noise> 
D:  four  
D:  five  
D:  seven two two  
B:  <mike noise> 
D:  eight one zero  
D:  nine five one  
D:  O nine eight  
D:  zero .  
E:  Transcript one four five one , one four seven O .  
E:  nine five two O  
E:  O three O four seven  
E:  s 
E:  zero seven one three six  
E:  one nine O two  
E:  two  
E:  three O six O seven three two  
C:  Oh , right .  
E:  four zero one zero four  
E:  six two O one  
E:  seven five one  
E:  eight five one two four five five .  
E:  nine five seven one  
E:  O O four nine  
E:  zero  
E:  one zero eight one seven nine zero  
E:  three three six one three  
E:  four four five eight zero  
E:  five two five one  
E:  six six zero  
E:  seven seven four three seven  
E:  eight .  
F:  <mouth> 
F:  Transcript number three three three one , three three five zero .  
F:  one three seven seven eight one zero  
F:  two five nine five five  
F:  three eight  
F:  four eight nine two  
F:  five  
F:  six  
F:  seven zero five one  
F:  nine one  
F:  O three three  
F:  zero eight five eight three  
F:  one four O one  
F:  two  
F:  three O three six  
F:  four zero  
F:  six one three zero  
F:  seven six five  
F:  eight three seven  
F:  nine nine three  
F:  O  
F:  zero .  
A:  <mouth> Transcript s thirty - six eleven , thirty - six thirty .  
A:  two two five two five nine O  
A:  three four two  
A:  four  
A:  five  
A:  six  
A:  seven O eight  
A:  nine four eight two six  
A:  O three  
A:  zero eight eight zero  
A:  one  
A:  two  
A:  three  
A:  four  
A:  six one  
A:  seven five seven  
A:  eight four five three seven nine one  
A:  nine five seven zero .  
A:  O O two five  
A:  zero  
A:  one O .  
B:  Transcript two nine seven one dash two nine nine zero .  
B:  seven seven nine  
B:  eight nine  
B:  nine O two  
B:  O  
B:  one one zero one  
B:  two four five two  
B:  three seven  
B:  four four  
B:  five  
B:  six  
B:  seven O  
F:  <mike noise> 
B:  nine one four six zero  
B:  O three nine four  
B:  zero  
B:  one eight one nine nine five eight  
B:  two eight three seven five nine O  
B:  three  
B:  four O seven three  
B:  six two six two six  
A:   
B:  seven three , zero one .  
topic_description:	digit task


