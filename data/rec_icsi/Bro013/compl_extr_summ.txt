A:  Um . <mouth> <breath> What are we talking about today ? 

E:  Uh , well , first there are perhaps these uh Meeting Recorder digits that we tested . 

A:  The  both the uh  <breath> the SRI System and the oth 
A:  And for one thing that  that sure shows the <breath> difference between having a lot of uh training data <laugh> or not , 
A:  uh , the uh  <breath> The best kind of number we have on the English uh  on near microphone only is  is uh three or four percent . 
A:  And uh it 's significantly better than that , using fairly simple front - ends <breath> on  <laugh> on the uh  <breath> uh , with the SRI system . 

A:  But that 's  that 's using uh a  a pretty huge amount of data , 

A:  In fact , mostly not digits for the actual training the H M Ms whereas uh in this case we 're just using digits for training the H M 

E:  because it 's their very d huge , their huge system . 

A:  But  but uh what  what I think I 'd be interested to do given that , is that we  we should uh <breath> take  

A:  is to take some of these tandem things and feed it into the SRI system , 

E:  But I guess the main point is the data because 

E:  Our back - end is  is fairly simple 
E:  but until now , well , the attempts to improve it or  have fail 

A:  I mean so to  <breath> So there 's  there 's  there 's two things being affected . 
A:  I mean . One is that  that , you know , there 's something simple that 's wrong with the back - end . 
A:  We 've been playing a number of states 
A:  uh I  I don't know if he got to the point of playing with the uh number of Gaussians yet 

A:  But , yeah , so far he hadn't gotten any big improvement , 
A:  but that 's all with the same amount of data which is pretty small . 

E:  So , yeah , we could retrain some of these tandem on  on huge  

A:  Well , you could do that , but I 'm saying even with it not  with that part not retrained , 
A:  just  just using  having the H M Ms  much better H M 

E:  perhaps it 's not related , the amount of data but the um recording conditions . 

E:  The  the fact that  the result with the tandem and Aurora system are <breath> uh so much worse . 

A:  What  what is the problem that you 're trying to explain ? 

A:  I uh but I 'm  I 'm almost certain that it  it  <breath> I mean , that it has to do with the um amount of training data . 
A:  It  it 's  it 's orders of magnitude off . 

A:  let 's see , in the  in these multi - train things did we include noisy data in the training ? 
A:  I mean , that could be hurting us actually , for the clean case . 

A:  You know , I don't think there 's anything magical here . 
A:  It 's , you know , we used a simple HTK system with a modest amount of data . 
A:  And this is a  a , you know , modern <breath> uh system 
A:  uh has  has a lot of nice points to it . 

A:  So . I mean , the HTK is an older HTK , even . 

A:  But to me it just  it just meant a practical <breath> point that um if we want to <breath> publish results on digits that  that people pay <breath> attention to we probably should uh  
A:  Cuz we 've had the problem before that you get  show some <breath> nice improvement on something that 's  that 's uh , uh  it seems like too large a number , 
A:  and uh <breath> uh people don't necessarily take it so seriously . 

A:  I mean , there 's  <breath> even though it 's close - miked there 's still  there really is background noise . 
A:  Um . And <breath> uh I suspect when the TI - digits were recorded if somebody fumbled or said something wrong or something that they probably made them take it over . 
A:  It was not  I mean there was no attempt to have it be realistic in any  in any sense at all . 

E:  TI - digit is  it 's very , very clean and it 's like studio recording 
E:  whereas these Meeting Recorder digits sometimes you have breath noise 

E:  Perhaps the point is that we 've been working on <breath> is , 
E:  yeah , we have put the um the good VAD in the system 
E:  and <breath> it really makes a huge difference . 

E:  I think , yeah , this is perhaps one of the reason why our system was not  <breath> not the best , 
E:  because with the new VAD , it 's very  the results are similar to the France Telecom results and perhaps even better sometimes . 

E:  Uh . The problem is that it 's very big and <breath> <mouth> we still have to think how to  where to put it 

E:  uh either some delay 
E:  and we  if we put it on the server side , it doesn't work , 
E:  because on the server side features you already have LDA applied <breath> from the f from the terminal side 
E:  and <breath> so you accumulate the delay 

A:  So wha where did this good VAD come from ? 

E:  It 's um from OGI . 

A:  This is the one they had originally ? 

A:  Yeah , but they had to  get rid of it because of the space , 

E:  But the abso assumption is that we will be able to make a VAD that 's small and that works fine . 

A:  But the other thing is uh to use a different VAD entirely . 

A:  I  I don't know what the thinking was amongst the  the  the <breath> the ETSI folk 
A:  but um if everybody agreed sure let 's use this VAD and take that out of there  

E:  They just want , apparently  they don't want to fix the VAD because they think there is some interaction between feature extraction and  and VAD or frame dropping 
E:  But they still <mouth> want to  just to give some um <breath> requirement for this VAD 
E:  because it 's  it will not be part of  they don't want it to be part of the standard . 

E:  So there just will be some requirements that are still not  uh not yet uh ready I think . 

A:  but I don't think we need to be stuck on using our or OGI 's  VAD . 
A:  We could use somebody else 's if it 's smaller 

A:  You know , as long as it did the job . 

E:  Uh I designed a new  a new filter 
E:  because when I designed other filters with shorter delay from the LDA filters , <breath> there was one filter with fif sixty millisecond delay and the other with ten milliseconds 
E:  and <breath> uh Hynek suggested that both could have sixty - five sixty - s 

E:  Both should have sixty - five because  

A:  You didn't gain anything , right ? 

E:  and uh it 's running . 

E:  Uh but the filter is of course closer to the reference filter . 

E:  Yeah , and then we 've started to work with this of um voiced - unvoiced stuff . 

D:  No , I w <breath> I begin to play <laugh> with Matlab and to found some parameter robust for voiced - unvoiced decision . 

D:  And we  <breath> they  we found that maybe w is a classical parameter , the <breath> sq the variance <breath> between the um FFT of the signal and the small spectrum of time <breath> we  after the um mel filter bank . 
D:  And , well , is more or less robust . 
D:  Is good for clean speech . 

E:  So , basically we wa want to look at something like the ex the ex excitation signal and  
E:  which are the variance of it and  

A:  So now I wonder  

A:  I know you want to get at something orthogonal from what you get with the smooth spectrum 
A:  Um . But if you were to really try and get a voiced - unvoiced , do you  do you want to totally ignore that ? 

A:  I mean , clearly a  a very big  very big cues <breath> for voiced - unvoiced come from uh spectral slope and so on , 

E:  Well , this would be  this would be perhaps an additional parameter , 

D:  Yeah because when did noise clear <pages turning> in these section is clear 

A:  I mean , <breath> certainly if <breath> you want to do good voiced - unvoiced detection , you need a few features . 

A:  But , you know , people look at  at slope and <breath> uh first auto - correlation coefficient , divided by power . 

A:  Each  each feature is <breath> by itself not enough . 

A:  Or maybe you could you just do it going through the P FFT 's figuring out some um probable <breath> um harmonic structure . 

E:  yeah , it 's  it 's another problem . 

E:  If you look at this um spectrum , 

E:  Is it <breath> the mel - filters ? 

E:  and what we clearly see is that in some cases , 

E:  and the  the harmonics are resolved by the f 
E:  Well , there are still appear after mel - filtering , 
E:  and it happens <breath> for high pitched voice because the width of the lower frequency mel - filters <breath> is sometimes even smaller than the pitch . 

E:  so we were thinking to modify the mel - spectrum to have something that  that 's smoother on low frequencies . 

A:  What I was talking about was just , starting with the FFT 
A:  you could  you could uh do a very rough thing to estimate  estimate uh pitch . 
A:  And uh uh , given  you know , given that , uh <breath> you could uh uh come up with some kind of estimate of how much of the low frequency energy was  was explained by  <breath> by uh uh those harmonics . 

A:  It 's uh a variant on what you 're s what you 're doing . 

A:  But as you say it 's not that smooth here . 
A:  And  and so if you  <breath> if you just you know subtracted off uh your guess of the harmonics then something like this would end up with <breath> quite a bit lower energy in the first fifteen hundred hertz or so 

A:  What 's up with you ? 

B:  Um <breath> our t I went to <breath> talk with uh Mike Jordan this  this week 
B:  um <noise> and uh <breath> shared with him the ideas about um <breath> extending the Larry Saul work 
B:  and um I asked him some questions about factorial H M 
B:  so like later down the line when <breath> we 've come up with these  these feature detectors , how do we  <breath> how do we uh <breath> you know , uh model the time series that  that happens 
B:  um <breath> <mouth> and <breath> and we talked a little bit about <breath> factorial H M Ms and how <breath> um when you 're doing inference  or w when you 're doing recognition , there 's like simple Viterbi stuff that you can do for  <breath> for these H M 
B:  and <breath> the uh  <breath> the great advantages that um a lot of times the factorial H M Ms don't <breath> um <breath> don't over - alert the problem 
B:  there they have a limited number of parameters and they focus directly on  <breath> on uh the sub - problems at hand 

B:  So he  he seemed  he seemed like really interested in  <breath> in um  in this 
B:  and said  said this is  this is something very do - able and can learn a lot 

B:  yeah , I 've just been <breath> continue reading um about certain things . 

B:  thinking of maybe using um <breath> um m modulation spectrum stuff to <breath> um  as features um also in the  in the sub - bands 
B:  because <breath> it seems like <breath> the modulation um spectrum tells you a lot about the intelligibility of  of certain um words and stuff 

C:  so I 've been looking at Avendano 's work 

C:  uh I 'll try to write up in my next stat status report a nice description of <breath> what he 's doing , 
C:  but it 's  it 's an approach to deal with <breath> reverberation or that  the aspect of his work that I 'm interested in 

C:  s so I 'm  I guess my first stab actually in continuing <breath> his work is to um <breath> re - implement this  this thing which um <breath> changes the time and frequency resolutions 
C:  cuz he doesn't have code for me . 
C:  So that that 'll take some reading about the theory . 
C:  I don't really know the theory . 

C:  so the  the way I want to extend his work is make it able to deal with a time varying reverberation response 

C:  we don't really know <breath> how fast the um  the reverberation response is varying the Meeting Recorder data 

C:  y you do  I think you read some of the  the zeros as O 's and some as zeros . 
C:  Is there a particular way we 're supposed to read them ? 

E:  Perhaps in the sheets there should be another sign for the  

A:  I mean . I think people will do what they say . 

A:  I mean in digit recognition we 've done before , you have  you have two pronunciations for that value , " O " and " zero " . 
A:  No , they just write  

E:  and  and people pronounce " O " or zero  

A:  and you just  They just want people to read the digits as you ordinarily would 

