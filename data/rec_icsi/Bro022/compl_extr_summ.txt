A:  So , should we just do the same kind of deal where we  go around and do , uh , status report  kind of things ? 

A:  Why don't you go ahead , Barry ? 

F:  Well , this past week I 've just been , uh , getting down and dirty into writing my  my proposal . 

F:  I just finished a section on , uh  on talking about these intermediate categories that I want to classify , um , as a  as a middle step . 

F:  I hope to  hope to get this , um  a full rough draft done by , uh , Monday so I can give it to Morgan . 

A:  So , uh , you want to go next , Dave ? 

E:  last week I finally got results from the SRI system about this mean subtraction approach . 
E:  And , um , we  we got an improvement , uh , in word error rate , training on the TI - digits data set and testing on Meeting Recorder digits of , um , <mouth> six percent to four point five percent , 
E:  um , on the n on the far - mike data 
E:  using PZM F , 
E:  but , um , the near - mike performance worsened , um , from one point two percent to two point four percent . 

E:  wh why would that be , um , <breath> considering that we actually got an improvement in near - mike performance using HTK ? 

E:  uh , with some input from , uh , Andreas , I have a theory in two parts . 

E:  first of all HTK  sorry , SR - the SRI system is doing channel adaptation , 
E:  and so HTK wasn't . 

E:  And also , um , the  Andreas pointed out the SRI system is using more parameters . 

E:  So those finer - grained acoustic models could be more sensitive to the artifacts  in the re - synthesized audio . 

E:  O o one thing , um , I noticed is that , um , the mean subtraction seems to make the PZM signals louder after they 've been re - synthesized . 
E:  So I was wondering , is it possible that one reason it helped with the Aurora baseline system is  just as a kind of gain control ? 
E:  Cuz some of the PZM signals sound pretty quiet if you don't amplify them . 

C:  I don't see why  why your signal is louder after processing , 

B:  I don't think just multiplying the signal by two would have any effect . 

B:  I mean , I think if you really have louder signals , what you mean is that you have  better signal - to - noise ratio . 

C:  I think , maybe  I didn't look , but one thing that makes a difference is this DC offset compensation . 
C:  Uh , eh  Do y did you have a look at  at the meet uh , meeting digits , if they have a DC component , 

G:  No . The DC component could be negligible . 

G:  I mean , any  all of the mikes have the DC removal  some capacitor sitting right in  that bias it . 

B:  Yeah . The microphone isn't gonna pass any DC . 

B:  Actually , there are  instrumentation mikes that  that do pass  go down to DC . 

B:  no , it 's the electronics . 

B:  then there 's amplification afterwards . 

B:  You can have DC offset in the data . 

E:  And I also , um , did some experiments  about normalizing the phase . 

E:  the interesting thing that I tried was , um , Adam and Morgan had this idea , 
E:  um , since my original attempts to , um , take the mean of the phase spectra over time and normalize using that , by subtracting that off , didn't work . Um , so , well , that we thought that might be due to , um , problems with , um , the arithmetic of phases . 

E:  So , <breath> what I did instead is I <breath> took the mean of the FFT spectrum without taking the log or anything , and then I took the phase of that , 

E:  But that , um , didn't work either . 

E:  and I subtracted that phase  off 

A:  Do you want to go , Stephane ? 

C:  I 'm more interested in trying to figure out what 's still the difference between the SRI system and the Aurora system . 

C:  Yeah . So , I think I will maybe train , like , gender - dependent models , 
C:  because  this is also one big difference between  the two systems . 

C:  the other differences were  the fact that maybe the acoustic models of the SRI are more  SRI system are more complex . 
C:  But , uh , Chuck , you did some experiments with this 

A:  It didn't seem to help in the HTK system . 

B:  You know , they have channel adaptation . 
B:  They have speaker adaptation . 

A:  Well , there 's also the normalization . 

A:  but , like , in the Switchboard data , there 's , um  conversation - side normalization for the  non - C - zero 

A:  I 'm not sure how they would do it when they 're working with the digits , 

C:  Their normalization works like on  on the utterance levels . 

C:  Yeah . This is another difference . 

G:  And the acoustic models are like - k triphone models or  or is it the whole word ? 

B:  I mean , so they  they have  I  I thin think they use these , uh , uh , genone things . 
B:  So there 's  there 's these kind of , uh , uh , pooled models 
B:  and  and they can go out to all sorts of dependencies . 

B:  They have tied states 

C:  Uh , the next thing is this  this VAD problem that , 

C:  So , I 'm just talking about the  the curves that I  I sent  <breath> I sent you  
C:  so , whi that shows that <mouth> when the SNR decrease , <clears throat> uh , the current  VAD approach doesn't drop much frames  for some particular noises , 
C:  uh , which might be then noises that are closer to speech , uh , acoustically . 

B:  I i Just to clarify something for me . 

B:  They were supp Supposedly , in the next evaluation , they 're going to be supplying us with boundaries . 
B:  So does any of this matter ? 

C:  First of all , the boundaries might be , uh  like we would have t two hundred milliseconds or  before and after speech . 

C:  So removing more than that might still make  a difference  in the results . 

B:  Do we  ? I mean , is there some reason that we think that 's the case ? 

C:  No . 

B:  But maybe we 'll get some insight on that when  when , uh , the gang gets back from Crete . 

C:  Well , actually if I don't  maybe don't want to work too much of  on it right now . 
C:  I just wanted to  to see if it 's  <breath-laugh> what I observed was the re was caused by this  this VAD problem . 

C:  Uh , the second thing is the  this spectral subtraction . 

C:  which I 've just started yesterday to launch a bunch of , uh , <noise> twenty - five experiments , 
C:  uh , with different , uh , values for the parameters that are used . 

C:  So the next thing , maybe I  what I will  try to  to do is just  to try to smooth mmm , <mouth> the , um  to smooth the d the result of the subtraction , 

G:  Can smooth the SNR estimate , also . 
G:  Your filter is a function of SNR . Hmm ? 

C:  Right . 

G:  th I 've been playing with this Wiener filter , like . 
G:  And there are  there were some bugs in the program , 
G:  so I was p initially trying to clear them up . 

G:  And , uh , so once it was cleared , uh , I ran a few experiments with  different ways of smoothing the estimated clean speech and how t estimated the noise and , eh , smoothing the SNR also . 
G:  And so the  the trend seems to be like , <mouth> uh , smoothing the  current estimate of the clean speech for deriving the SNR , 
G:  which is like  deriving the Wiener filter , 
G:  seems to be helping . Then updating it quite fast 

G:  But still it 's like  it 's still comparable to the baseline . 

G:  But that 's , like , not using any Wiener filter . 

G:  So far I 've been testing only with the  baseline , which is  which doesn't have any LDA filtering and on - line normalization . 
G:  I just want to separate the  the contributions out . 
G:  So it 's just VAD , plus the Wiener filter , plus the baseline system , 
G:  which is , uh , just the spectral  I mean , the mel sp mel , uh , frequency coefficients . 

G:  And the other thing is , like , putting a floor on the , uh , SNR , 

G:  some  In some cases the clean speech is , like  when it 's estimated , it goes to very low values , 
G:  so the SNR is , like , very low . 

G:  so that actually creates a lot of variance in the low - energy region of the speech . 

A:  How about you , Carmen ? 

D:  Well , I am still working with , eh , VTS . 
D:  And , one of the things that last week , 
D:  eh , say here is that maybe the problem was with the diff 
D:  because the signal have different level of energy . 
D:  And , maybe , talking with Stephane and with Sunil , we decide that maybe it was interesting to  to apply on - line normalization before applying VTS . 
D:  But then <breath-laugh> we decided that that 's  it doesn't work absolutely , because we modified also the noise . 

D:  Well , thinking about that , we  we then  we decide that maybe is a good idea . 

D:  I didn't  do the experiment yet  to apply VTS in cepstral domain . 

D:  We don't know . 

D:  but <laugh> I 'm not sure if that will be usefu useful . 

D:  Well , we s decide to m to  to obtain the new expression if we work in the cepstral domain . 

D:  It 's quite a lot  It 's a lot of work . 

D:  And I want to know if  if we have some  feeling that  the result  

D:  I don't have any feeling if this will work better than apply VTS aft in cepstral domain will work better than apply in m mel  in filter bank domain . 

D:  I don't  I don't know absolutely nothing . 

B:  Yeah . Well , you 're  I think you 're the first one here to work with VTS , 

B:  uh , maybe we could call someone else up who has , 

B:  I don't  I don't have a good feeling for it . 

