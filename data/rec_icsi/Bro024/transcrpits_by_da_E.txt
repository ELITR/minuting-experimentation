E:  It 's not four . 
E:  Hello . 
E:  Mm - hmm . 
E:  Yeah . 
E:  Yeah , if we look at the figures on the right , we see that the reference system is very bad . 
E:  Like for clean  clean training condition . 
E:  Nnn . 
E:  Yeah . 
E:  Mmm . 
E:  Yeah . 
E:  Mm - hmm . 
E:  Yeah . 
E:  I also have the feeling that um , the reason ye why it doesn't work is  yeah , that the models are much  are t um , not complex enough . 
E:  Because I  actually I als always had a good experience with spectral subtraction , 
E:  just a straight spectral subtraction algorithm when I was using neural networks , big neural networks , which maybe are more able to model strange distributions 
E:  and  
E:  But  
E:  Yeah . 
E:  Then I tried the same  exactly the same spectral subtraction algorithm on these Aurora tasks 
E:  and it simply doesn't work . 
E:  It 's even  it , uh , hurts even . 
E:  So . 
E:  Mm - hmm . 
E:  Mm - hmm . 
E:  Mm - hmm . 
E:  Mm - hmm . 
E:  If we look at the France Telecom proposal , they use some kind of noise addition . 
E:  They have a random number generator , right ? 
E:  And they add noise on the trajectory of , uh , the log energy only , right ? 
E:  Yeah . 
E:  Um , 
E:  But I don't know how much effect it  this have , 
E:  but they do that . 
E:  Yeah . 
E:  I think because they have th log energy , 
E:  yeah , 
E:  and then just generate random number . 
E:  They have some kind of mean and variance , 
E:  and they add this number to  to the log energy simply . 
E:  Um  
E:  Mm - hmm . 
E:  Only  
E:  Yeah . 
E:  Mm - hmm . 
E:  Maybe it 's just a way to decrease the importance of this particular parameter in the  in the world feature vector 
E:  cu if you add noise to one of the parameters , you widen the distributions 
E:  and  
E:  Eee - sss - uh . 
E:  Yeah . 
E:  Mm - hmm . 
E:  Mm - hmm . 
E:  Mm - hmm . 
E:  Where does the comprish compression in decoding delay comes from ? 

E:  Mm - hmm . 
E:  Mm - hmm . 
E:  I can go next . 
E:  Yeah . 
E:  Mmm . 
E:  It 's  
E:  Yeah , 
E:  we have to take  
E:  Well  
E:  OK . 
E:  So you have w w one sheet ? 
E:  This one is  you don't need it , 
E:  alright . 
E:  So you have to take the whole  the five . 
E:  There should be five sheets . 

E:  OK , maybe there 's not enough for everybody . 
E:  But  
E:  Can we look at this ? 
E:  So , 
E:  yeah , there are two figures showing actually the , mmm , um , performance of the current VAD . 
E:  So it 's a n neural network based on PLP parameters , 
E:  uh , which estimate silence probabilities , 
E:  and then I just put a median filtering on this 
E:  to smooth the probabilities , right ? 
E:  Um  
E:  I didn't use the  the scheme that 's currently in the proposal 
E:  because <breath> I don't want to  
E:  In the proposal  
E:  Well , in  in the system we want to add like speech frame before every word and a little bit of  of , uh , s a couple of frames after also . 
E:  Uh , but to estimate the performance of the VAD , we don't want to do that , 
E:  because it would artificially increase the um  the false alarm rate of speech detection . 
E:  Right ? 
E:  Um , 
E:  so , 
E:  there is u normally a figure for the Finnish and one for Italian . 
E:  And maybe someone has two for the Italian 
E:  because I 'm missing one figure here . 
E:  Well  
E:  Well , whatever . 
E:  Uh  Yeah , so one surprising thing that we can notice first is that apparently the speech miss rate is uh , higher than the false alarm rate . 
E:  So . 
E:  It means  
E:  Mm - hmm . 
E:  Yeah , there are two curves . 
E:  One curve 's for the close - talking microphone , which is the lower curve . 
E:  And the other one is for the distant microphone 
E:  which has more noise 
E:  so , 
E:  it 's logical that <laugh> it performs worse . 
E:  So as I was saying , the miss rate is quite important 
E:  uh , which means that we tend to label speech as  as a silence . 
E:  And , 
E:  uh , I didn't analyze further yet , 
E:  but <breath> I think it 's  it may be due to the fricative sounds 
E:  which may be  in noisy condition maybe label  labelled as silence . 
E:  And it may also be due to the alignment 
E:  because  
E:  well , the reference alignment . 
E:  Because right now I just use an alignment obtained from  from a system trained on channel zero . 
E:  And 
E:  I checked it a little bit 
E:  but there might be alignment errors . 
E:  Um , yeah , 
E:  e 
E:  like the fact that <breath> <clears throat> the  the models tend to align their first state on silence and their last state o on silence also . 
E:  So the reference  reference alignment would label as speech some silence frame before speech and after speech . 
E:  This is something that we already noticed before 
E:  when  
E:  mmm , 
E:  So this cus this could also explain , uh , the high miss rate maybe . 
E:  Uh  
E:  Yeah . 
E:  Right . 
E:  Um  
E:  Yeah , 
E:  and the different points of the curves are for five uh , thresholds on the probability  uh from point three to point seven . 
E:  Mm - hmm . 
E:  Yeah . 
E:  So the v 
E:  The VAD ? 
E:  Yeah . 
E:  There first , a threshold on the probability  @ @  That puts all the values to zero or one . 
E:  And then the median filtering . 
E:  Yeah . 
E:  It 's fixed , 
E:  yeah . 
E:  Mm - hmm . 
E:  So , going from channel zero to channel one , uh , almost double the error rate . 
E:  Um , 
E:  Yeah . 
E:  Well , so it 's a reference performance that we can  you know , if we want to  to work on the VAD ,  we can work on this basis 
E:  and  
E:  Yeah . 
E:  It 's a very big one . 
E:  I don't remember . 
E:  m 
E:  Mm - hmm . 
E:  Mm - hmm . 
E:  Yeah . 
E:  Uh , ppp . 
E:  I don't know , you have questions about that , or suggestions ? 
E:  It seems  the performance seems worse in Finnish , 
E:  which  
E:  uh  
E:  It 's not trained on Finnish , 
E:  yeah . 
E:  Mm - hmm . 
E:  And  
E:  And also there are like funny noises on Finnish 
E:  more than on Italian . 
E:  I mean , like music 
E:  and <breath> um  
E:  So , yeah , 
E:  we were looking at this . 
E:  But for most of the noises , noises are  
E:  um , 
E:  I don't know if we want to talk about that . 
E:  But , 
E:  well , the  the " Car " noises are below like five hundred hertz . 
E:  And we were looking at the " Music " utterances 
E:  and in this case the noise is more about two thousand hertz . 
E:  Well , the music energy 's very low apparently . 
E:  Uh , 
E:  uh , from zero to two  two thousand hertz . 
E:  So maybe just looking at this frequency range for  from five hundred to two thousand would improve somewhat the VAD 
E:  and  
E:  Mmm  
E:  Yeah , 
E:  but  
E:  Yes . 
E:  Mm - hmm . 
E:  Uh , the next , 
E:  um  
E:  Oh , it 's there . 
E:  Yeah . 
E:  No . 
E:  It 's not . 
E:  It 's  it was trained on some alignment obtained 
E:  um , 
E:  uh  For the Italian data , I think we trained the neural network on  with embedded training . 
E:  So re - estimation of the alignment using the neural network , I guess . 
E:  That 's right ? 
E:  Yeah . 
E:  So it was a f f a phonetic classification system for the Italian Aurora data . 
E:  For the Aurora data that it was trained on , it was different . 
E:  Like , for TI - digits you used a  a previous system that you had , I guess . 
E:  So the alignments from the different database that are used for training came from different system . 
E:  Then we put them tog together . 
E:  Well , you put them together and trained the VAD on them . 
E:  Mmm . 
E:  Uh , 
E:  But did you use channel  did you align channel one also ? 
E:  Or  
E:  Yeah . 
E:  So di 
E:  Yeah . 
E:  So the alignments might be wrong then on channel one , right ? 
E:  So we might , 
E:  yeah , 
E:  at least want to retrain on these alignments , 
E:  which should be better because they come from close - talking microphone . 
E:  OK . 
E:  Yeah . 
E:  Yeah . 
E:  Mm - hmm . 
E:  Mm - hmm . 
E:  Mm - hmm . 
E:  Yeah . 
E:  Right . 
E:  Yeah . 
E:  Um . 
E:  And eh , hhh 
E:  actually when we look at  at the VAD , <breath> for some utterances it 's almost perfect , 
E:  I mean , it just dropped one frame , 
E:  the first frame of speech 
E:  or  
E:  So there are some utterances where it 's almost one hundred percent VAD performance . 
E:  Uh , 
E:  but  Yeah . 
E:  Mmm  
E:  Yep . 
E:  So the next thing is um , I have the spreadsheet for three different system . 
E:  But for this you only have to look right now on the SpeechDat - Car performance 
E:  uh , because I didn't test  
E:  so  I didn't test the spectral subtraction on TI - digits yet . 
E:  Uh , so you have three she sheets . 
E:  One is the um proposal - one system . 
E:  Actually , it 's not exe exactly proposal - one . 
E:  It 's the system that Sunil just described . 
E:  Um , 
E:  but with uh , Wiener filtering from um , France Telecom included . 
E:  Um , so this gives like fifty - seven point seven percent , uh , s uh , error rate reduction on the SpeechDat - Car data . 
E:  Mmm , 
E:  and then I have two sheets where it 's for a system where  
E:  uh , 
E:  so it 's again the same system . 
E:  But in this case we have spectral subtraction 
E:  with a maximum overestimation factor of two point five . 
E:  Uh , there is smoothing of the gain trajectory with some kind of uh , low - pass filter , 
E:  which has forty milliseconds latency . 
E:  And then , after subtraction um , I add a constant to the energies 
E:  and I have two cases d where  The first case is where the constant is twenty - five DB below the mean speech energy 
E:  and the other is thirty DB below . 
E:  Um , 
E:  and for these s two system we have like fifty - five point , uh , five - percent improvement , 
E:  and fifty - eight point one . 
E:  So again , it 's around fifty - six , fifty - seven . 
E:  Uh  
E:  Yeah , because I didn't  
E:  For the France Telecom uh , spectral subtraction included in the  our system , the TI - digits number are the right one , 
E:  but not for the other system 
E:  because I didn't test it yet  this system , including  with spectral subtraction on the TI - digits data . 
E:  I just tested it on SpeechDat - Car . 
E:  This , we have to  
E:  Yeah . 
E:  Yes . 
E:  Right . 
E:  Right . 
E:  Mm - hmm . 
E:  Um , 
E:  Yeah . 
E:  Yeah . 
E:  Yeah . 
E:  The floor is lower . 
E:  Um , 
E:  mm - hmm . 
E:  To the average um , speech energy 
E:  which is estimated on the world database . 
E:  Yeah . 
E:  But it 's not  
E:  it  it 's  
E:  Yeah . 
E:  Right . 
E:  It 's  
E:  But , it 's after the thresholding . 
E:  So , 
E:  maybe  
E:  maybe we might do it before , 
E:  yeah . 
E:  Yeah . 
E:  Uh  
E:  Yeah . 
E:  But still , when you do this and you take the log after that , it  it reduce the  the variance . 
E:  But  
E:  Mmm , 
E:  Um , 
E:  We would  
E:  Mm - hmm . 
E:  Um . 
E:  Yeah . 
E:  Mm - hmm . 
E:  Yeah . 
E:  Mm - hmm . 
E:  Oh , it 's clear . 
E:  I should have gi given other results . 
E:  Also it 's clear when you don't add noise , it 's much worse . 
E:  Like , around five percent worse I guess . 
E:  And if you add too much noise it get worse also . 
E:  And it seems that <breath> right now this  this is c a constant that does not depend on   on anything that you can learn from the utterance . 
E:  It 's just a constant noise addition . 
E:  Um . 
E:  And I  I think w w 
E:  I think  
E:  Yeah , 
E:  so the way I did that ,  i I just measured the average speech energy of the  all the Italian data . 
E:  And then  I  I have  I used this as mean speech energy . 
E:  Mm - hmm . 
E:  Yeah . 
E:  And  
E:  wha what I observed is that for Italian and Spanish ,  when you go to thirty and twenty - five DB ,  uh it  it 's good . 
E:  It stays  In this range , 
E:  it 's , uh , the p u 
E:  well , the performance of the  this algorithm is quite good . 
E:  But for Finnish , <breath> you have a degradation already when you go from thirty - five to thirty 
E:  and then from thirty to twenty - five . 
E:  And  I have the feeling that maybe it 's because just Finnish has a mean energy that 's lower than  than the other databases . 
E:  And due to this the thresholds should be  
E:  the  the a the noise addition should be lower 
E:  and  
E:  Yeah . 
E:  So  
E:  It 's not . 
E:  It 's just something that 's fixed . 
E:  Yeah . 
E:  Mm - hmm . 
E:  Um  
E:  Yeah , so I g 
E:  No . 
E:  It  No . 
E:  Because I did it  I started working on Italian . 
E:  I obtained this average energy 
E:  and then I used this one . 
E:  Yeah . 
E:  Yep . 
E:  Um , 
E:  yeah , so the next thing is to use this as  as maybe initialization 
E:  and then use something on - line . 
E:  But  <breath> And I expect improvement at least in Finnish because eh  the way  
E:  Well , 
E:  um , 
E:  for Italian and Spanish it 's  th this value works good but not necessarily for Finnish . 
E:  Mmm . 
E:  But unfortunately there is , like , this forty millisecond latency 
E:  and , 
E:  um  
E:  Yeah , so I would try to somewhat reduce this @ @ . 
E:  I already know that if I completely remove this latency , so . <breath> um ,  it  um there is a three percent hit on Italian . 
E:  Mm - hmm . 
E:  It 's a smoothing over the  the gain of the subtraction algorithm . 
E:  Right . 
E:  So , to smooth this  thing . 
E:  Yeah . 
E:  Um  
E:  Um , 
E:  no , 
E:  I did not . 
E:  Mmm . 
E:  Yeah . 
E:  Mm - hmm . 
E:  Mmm  
E:  Uh , no , 
E:  it 's  it 's just the gain that 's smoothed actually 
E:  but it 's smoothed  
E:  Uh  Yeah . 
E:  Yeah . 
E:  No , in this case it 's just the gain . 
E:  And  
E:  But the way it 's done is that um , for low gain , there is this non nonlinear smoothing actually . 
E:  For low gains um , I use the smoothed sm uh , smoothed version 
E:  but  for high gain @ @  it 's  I don't smooth . 
E:  Uh - huh . 
E:  Mm - hmm . 
E:  Mm - hmm . 
E:  Uh , yeah , 
E:  I could try this . 
E:  Um . 
E:  Mm - hmm . 
E:  But  
E:  Yeah . 
E:  Then I  I would need to find a way to like smooth less also when there is high energy . 
E:  Cuz I noticed that it  it helps a little bit to s like smooth more during low energy portions and less during speech , 
E:  because if you smooth then y you kind of distort the speech . 
E:  Um . 
E:  Mm - hmm . 
E:  Mm - hmm . 
E:  Yeah . 
E:  Mm - hmm . 
E:  Mm - hmm . 
E:  Mm - hmm . 
E:  Mmm . 
E:  Um , 
E:  yeah , 
E:  but I don't trust <laugh> the current VAD . 
E:  So . 
E:  Well , maybe . 
E:  Maybe . 
E:  Uh , fff  I think that 's it . 
E:  Yeah . 
E:  Uh . 
E:  Yeah . 
E:  Yeah . 
E:  Mm - hmm . 
E:  Mm - hmm . 
E:  And , <breath> yeah , 
E:  i i i the condition where it 's better than your approach , it 's  it  just because maybe it 's better on well matched and that the weight on well matched is  is bigger , 
E:  because  
E:  if you don't weigh differently the different condition , you can see that your  well , the win the two - stage Wiener filtering is maybe better 
E:  or  
E:  It 's better for high mismatch , right ? 
E:  Mm - hmm . 
E:  But a little bit worse for well matched . 
E:  Uh - huh . 
E:  Mm - hmm . 
E:  Yeah . 
E:  Mm - hmm . 
E:  Mm - hmm . 
E:  Mm - hmm . 
E:  It 's  
E:  Um , 
E:  yeah , I did that 
E:  but it doesn't matter on SpeechDat - Car , 
E:  but , it matters , uh , a lot on TI - digits . 
E:  Yeah , 
E:  d uh , it 's much better when you  we used the clean derived LDA filter . 
E:  Uh , 
E:  but , yeah , 
E:  Sunil in  in your result it 's  
E:  It 's with the noisy one . 
E:  Yeah . 
E:  So  
E:  It 's with the clean LDA . 
E:  Yeah . 
E:  And in your case it 's all  all noisy , 
E:  yeah . 
E:  But  
E:  Yeah . 
E:  But I observe my case it 's in , uh , uh , at least on SpeechDat - Car it doesn't matter 
E:  but TI - digits it 's like two or three percent absolute , uh ,  better . 
E:  So if  
E:  Dave ? 
E:  Is it the channel , or the mike ? 
E:  I don't remember . 
E:  It 's the mike ? 
E:  It 's not four . 
