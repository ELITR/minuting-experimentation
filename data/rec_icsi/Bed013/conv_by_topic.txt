C:  <laugh> 
E:  As usual . 
B:  Yes . 
E:  <mike noise> 
B:  Whew !  
B:  <breath> 
E:  <outbreath> 
B:  <outbreath> I almost forgot  about the meeting .   
E:  <mike noise> 
C:  <yawn> 
B:  I woke up twenty minutes ago , thinking , 
E:  <laugh> 
C:  <laugh> 
E:  Oy .  
B:  what did I forget ? 
B:  <laugh> 
D:  <laugh> 
C:  <laugh> 
E:  <mike noise> 
D:  It 's great how the br brain sort of does that . 
B:  <laugh> 
E:  Something 's not right here . 
B:  Internal alarms . 
D:  <mouth> 
topic_description:	opening


D:  OK . 
D:  So the news for me is A , my 
D:  forthcoming travel plans  
B:  <mouth> 
D:  in two weeks 
B:  Yes . 
D:  from today ? 
D:  Yeah ? 
D:  More or less ? 
D:  I 'll be off to Sicily and Germany 
B:  <inbreath> 
D:  for a couple , three days . 
B:  Now what are y what are you doing there ? I forgot ? 
D:  OK , I 'm flying to Sicily basically to drop off Simon 
D:  there with his grandparents . And then I 'm flying to Germany t to go to a MOKU - Treffen which is 
D:  the meeting of all the module - responsible people in SmartKom , 
B:  Mmm . 
D:  <mouth> 
D:  and , represent ICI  
D:  and myself I guess 
D:  there . 
D:  And um . 
D:  That 's the 
D:  mmm 
D:  actual reason . 
D:  And then I 'm also going up to EML 
D:  for a day , and then I 'm going to <inbreath> 
D:  meet the very big boss , Wolfgang Walster , 
D:  in Saarbruecken and the System system integration people in Kaiserslautern 
D:  and then I 'm flying back via Sicily 
D:  pick up my son <laugh> 
B:  <laugh> 
D:  come back here on the fourth of July . 
topic_description:	mn015's visit to SmartKom


D:  And uh . 
E:  What a great time to be coming back to the U S - of - A . 
B:  <laugh> 
C:  <laugh> 
E:  <laugh> 
B:  God bless America . 
E:  You 'll see maybe  see the fireworks from your plane coming in . 
C:  <laugh> 
B:  <laugh> 
D:  <laugh> 
C:  <laugh> 
D:  And I 'm sure all the  the people at the airport will be happy to work on that day . 
E:  Yeah . <laugh> 
B:  <laugh> 
E:  You 'll get even better service than usual . 
D:  Mm - hmm . 
B:  Wait , aren't you flying on Lufthansa though ? 
D:  Alitalia . 
B:  Oh . Well then the  you know , it 's not a big deal . <laugh> 
E:  <outbreath> 
E:  <laugh> <mike noise> 
B:  Once you get to the United States it 'll be a problem , but 
D:  Yeah . 
D:  And um , 
E:  <mike noise> 
topic_description:	chitchat


D:  that 's that bit of news , and the other bit of news is we had  you know , uh , I was visited by my 
D:  German project manager  
D:  who A , did like what we did  
D:  what we 're doing here , and B , 
D:  is planning to come here either three weeks in July or three weeks in August , 
D:  to actually work . 
B:  On  ?  Oh . 
D:  With us . 
D:  And we sat around and we talked and he came up  we came up  with a 
E:  <outbreath> 
D:  pretty strange idea . 
E:  <outbreath> <laugh> 
D:  And that 's what I 'm gonna lay on you now . 
D:  And um , maybe it might be ultimately the most interesting thing for Eva 
D:  because she has 
C:  OK . 
D:  been known to complain about the fact that the stuff we do here is not weird enough . 
D:  So this is so weird it should even 
C:  Uh .  OK .  
E:  <mike noise> <laugh> 
D:  make you happy . 
E:  <mike noise> 
E:  Oh great . <outbreath> 
topic_description:	visit from German project manager


D:  Imagine 
D:  if you will , <outbreath> 
E:  <mike noise> 
D:  that we have a system that does all that understanding 
D:  that we want it to do 
B:  Mm - hmm . 
D:  based on utterances . 
D:  It should be possible 
D:  to make that system produce 
D:  questions . 
D:  So if you have the knowledge of how to interpret " where is X ? " 
E:  <outbreath> Mm - hmm . 
D:  under given conditions , 
D:  situational , user , discourse and ontological 
D:  <inbreath> conditions , 
D:  you should also be able to make that same system ask 
D:  " where is X ? " 
D:  in a sper certain way , 
D:  based on 
D:  certain intentions . 
D:  So in instead of just being able to 
E:  <outbreath> Hmm . 
D:  observe phenomenon , 
D:  um , and , 
D:  guess the intention we 
D:  might be able just to 
D:  sort of 
D:  give it an intention , and make it produce an utterance . 
B:  Well , like in 
B:  AI they generally do the 
B:  take in , and then they also do the generation phase , like Nancy 's thing . 
B:  Or uh , 
B:  you remember , in the  the hand 
B:  thing in one - eighty - two , like not only was it able to recognize but it was also to generate based upon situations . You mean that sort of thing ? 
D:  Absolutely . 
B:  OK . 
D:  And once you 've done that 
D:  what we can do is have the system ask 
D:  itself . 
E:  <laugh> <mike noise> 
D:  And answer , 
E:  <mike noise> 
D:  understand the answer , 
D:  ask something else , 
D:  and enter a dialogue with itself . So the  the ba basic  the same idea as having two chess computers play against each other . 
E:  Except this smacks a little bit more of a schizophrenic computer than AI . 
C:  <laugh> 
E:  <laugh> 
D:  Yeah you c if you want , you can have two parallel <laugh> machines 
C:  <laugh> 
D:  um , asking each other . 
D:  What would that give us ? Would A be something completely weird and strange , 
D:  and B , i 
E:  That 's good . 
D:  if you look at all the factors , 
D:  we will never observe 
D:  people 
D:  let 's say , in wheelchairs under  you know , in  under all conditions , you know , 
D:  when they say " X " , and there is a ride at the goal , and the parking is good , 
D:  we can never collect enough data . 
E:  Mm - hmm . 
D:  It 's  it 's  it 's not possible . 
E:  Right , right . 
D:  But maybe one could do some learning . 
D:  If you get the system to speak to itself , 
D:  you may find n 
D:  break downs and errors 
D:  and you may be able to 
D:  learn . 
D:  And make it 
D:  more robust , maybe learn new things . 
D:  And um , 
D:  so there 's no  
D:  no end of potential things one could get out of it , 
D:  if that works . 
D:  And he would like to actually work on that 
D:  with us . 
D:  So - 
E:  Yeah . 
D:  I think it 'd be 
D:  fun to look at it , or into that question . 
E:  Nnn , yeah . 
D:  It 's a pretty strange idea . And so that 's  that 's  But  
E:  <mike noise> 
B:  The basic idea I guess would be to give  allow the system to have intentions , basically ? 
B:  Cuz that 's basically what needs to be added to the system for it . 
D:  Well , look at th 
D:  eee , I think even  think even  
D:  What it  would be the  the prior intention . 
D:  So let 's uh  uh , let 's say we have this  
B:  Well we 'd have to seed that , I mean . 
D:  No . Let 's  we have to  we have some  some top - down processing , given certain setting . 
D:  OK , now we change nothing , and just say ask something . 
D:  Right ? 
B:  @ @  
D:  What would it ask ? 
B:  It wouldn't know what to ask . I mean .  
D:  It shur 
B:  Unless it was in a situation . We 'd have to set up a situation where , 
D:  Yeah ! 
B:  it didn't know where something was and it wanted to go there . 
C:  Mm - hmm . 
D:  Yeah . 
B:  Which means that we 'd need to set up an intention inside of the system . 
B:  Right ? 
B:  <laugh> 
D:  Eh , n  
B:  Which is basically , " I don't know where something is and I need to go there " . 
D:  <inbreath> 
E:  Yeah . 
D:  Ooh , do we really need to do that ? 
D:  Because , 
B:  <laugh> 
B:  Well , no I guess not . Excel - <laugh> 
E:  <laugh> 
D:  s 
D:  It 's  i I know it 's  it 's strange , but 
D:  look at it  
D:  Yeah . So , it be it it 's an idea that one could n 
D:  for  for example run  run past , um , 
D:  what 's that guy 's name ?  
D:  <finger-snapping>  
D:  You know ? He - he 's usually here . 
D:  Tsk .  
E:  Here in the group ? 
D:  J J Jer - Jerj -  
E:  Jerry Feldman .  
D:  Oh , yeah . That 's the guy . We  we  we  we g 
E:  <laugh> 
C:  <breath-laugh> 
B:  Wait , who ?  
D:  <laugh> 
E:  Yeah , i that would the g the bald guy . 
B:  Oh ! My advisor ! 
D:  <laugh> 
E:  <laugh> 
B:  <laugh> 
C:  <laugh> 
D:  And um . 
D:  <clear throat> so this is just an idea that 's floating around and we 'll see what happens .  
topic_description:	make system ask itself questions


B:  Well then , he probably should be coming back a year  from now . 
D:  <clear throat> 
B:  <laugh> 
D:  Yeah , I w 
D:  See the  the generation bit , making the system generate  generate something ,  
D:  is  shouldn't be too hard . 
B:  Well , once the system understands things .  
E:  Yeah . No problem . 
B:  <laugh> 
E:  <laugh> 
B:  I just don't think  
B:  I think we 're probably a year away from getting the system to understand things . 
D:  Yeah . 
D:  Well , if we can get it to understand one thing , like our " where is " 
D:  run through 
D:  we can also , maybe , e make it say , or ask 
D:  " where is 
D:  X ? " 
D:  Or not . @ @ 
E:  Mmm , I don't know . e I 'm sort of  have the impression that getting it to say the right thing in the right circumstances is much more difficult than 
E:  getting it to understand something given the circumstances and so on , you know , I mean just cuz it 's sort of harder to 
E:  learn to 
E:  speak correctly in a foreign language , rather than 
E:  learning to understand it . Right ? I mean 
D:  @ @  
E:  just the fact that we 'll get  The point is that getting it to understand one construction doesn't mean that it will n always know exactly when it 's correct to use that construction . Right ? <inbreath> 
D:  It 's  it 's uh  
D:  Well , I 've  I 've done generation and language production research for fo four  four and a half years . And so it 's  it 's  you 're right , it 's not the same as the understanding . 
E:  <mike noise> 
D:  It 's in some ways easier and some ways harder . nuh ? But , um , 
topic_description:	generation difficulty


D:  look at our Bayes - net . If we don't have  
D:  Let 's assume we don't have any input 
D:  from the language . 
D:  Right ? 
D:  So there 's also nothing we could query the ontology , but we have a certain user setting . 
D:  If you just ask , what is the likelihood of that person wanting to enter some  something , it 'll give you an answer . 
D:  Right ? That 's just how they are . 
B:  Sure .  
D:  And so , @ @ whatever that is , it 's the generic default intention . 
D:  That it would find out . Which is , 
D:  wanting to know where something is , maybe nnn  and wanting  
D:  I don't know what it 's gonna be , but there 's gonna be something that 
E:  Well you 're not gonna  are you gonna get a variety of intentions out of that then ? I mean , you 're just talking about like given this user , 
D:  <clear throat> 
E:  what 's the th what is it  what is that user most likely to want to do ? 
E:  And , have it talk about  
D:  Well you can observe some user and context stuff and ask , what 's the 
D:  posterior probabilities of all of our decision nodes . 
E:  OK . 
D:  You could even say , " let 's take all the priors , let 's observe nothing " , and query all the posterior probabilities . 
D:  It - it 's gonna tell us something . 
D:  Right ? 
D:  And  
B:  Well , it will d 
B:  r 
B:  assign values to all the nodes . Yes .  
D:  <clears throat> 
D:  Yes . And come up with 
E:  <breath-laugh> 
D:  posterior probabilities for all the values of the decision nodes .  
D:  Which , if we have an algorithm that filters out whatever the  the best or the most consistent 
D:  answer out of that , 
D:  will give us the 
D:  intention ex nihilo . 
E:  <laugh> 
D:  And that is exactly what would happen if we ask it to produce an utterance , it would be b based on that extension , ex nihilo , which we don't know what it is , but it 's there . 
D:  So we wouldn't even have to  t to kick start it by giving it a certain intention or 
D:  observing anything on the decision node . 
D:  And whatever that  
D:  maybe that would lead to " what is the castle ? " , or " what is that whatever " . 
B:  I 'm just  
B:  I guess what I 'm afraid of is if we don't , 
topic_description:	Bayes Net


B:  you know , set up a  situation ,  
D:  <sniff> 
B:  we 'll just get a bunch of garbage out , like 
B:  you know , everything 's exactly thirty percent . 
D:  No  
C:  Mmm . 
B:  <laugh> 
C:  <laugh> 
E:  <breath-laugh> 
D:  Yeah . So what we actually then need to do is  is write a little script that changes all the settings , you know , 
D:  go goes through all the permutations , which is  we did a  didn't we calculate that once ? It 's a  
B:  Well that was  that was absurdly low , in the last meeting ,  cuz I went and looked at it cuz I was thinking , that could not be right , and it would  it was on the order of 
C:  Uh , 
C:  <laugh> 
B:  twenty output nodes and something like twenty   
C:  And like thirty input nodes or some  
B:  thirty input nodes .  
B:  So to test every output node , 
B:  uh , would at least  
B:  Let 's see , so it would be two to the thirty for every output node ? <laugh> 
E:  <laugh> 
B:  Which is very th very large . 
E:  <laugh> 
C:  <laugh> 
D:  Oh ! That 's n 
E:  Oh .  
E:  <laugh> 
B:  <laugh> 
D:  that 's  that 's nothing for those neural guys . I mean , they train for millions and millions of epochs . So . 
C:  <laugh> 
B:  <mike sound>  
B:  Well , I 'm talking about  
B:  Oh , I was gonna take a drink of my water .  
E:  <laugh> 
B:  <drinking sounds> 
B:  I 'm talking about billions and billions and billions and  
B:  a number  two to the thirty is 
B:  like a 
B:  Bhaskara said , we had calculated out and Bhaskara believes that it 's larger than the number of particles in the universe .  
E:  <laugh> 
C:  <laugh> 
E:  <laugh> I don't know if that 's right or not . 
B:  And if i 
E:  <laugh> 
B:  <laugh> 
E:  Th - that 's big . 
E:  That 's just  That 's uh  It 's a billion , right ? 
B:  Two to the thirty ? 
B:  Well , two to the thirty is a billion , but if we have to do it two to the twenty times , 
E:  <inbreath> Right . <outbreath> 
E:  Argh . 
B:  then that 's a very very large number . 
E:  Oh , OK . Yeah . Yeah , that 's big . 
B:  Cuz you have to query the node , for every a 
E:  Sure . 
E:  Alright . 
B:  uh , or query the net 
B:  two to the twenty times . 
B:  Or not two to th excuse me , twenty times .  
E:  OK . So , is it t comes to twenty billion or something ? 
B:  Yes . 
E:  That 's pretty big , though . 
B:  As far as  That 's @ @  That 's big . Actually  Oh ! We calculated a different number before . How did we do that ? 
C:  <laugh> 
E:  <laugh> 
C:  Hmm . 
E:  I remember there being some other one floating around . But anyway , uh . 
C:  I don't really know . 
E:  Yeah , it 's g Anyway , the point is that given all of these different factors , it 's uh e it 's  it 's still going to be impossible to run through all of the possible 
C:  Ooo , it 's just big . <laugh> 
E:  situations or whatever . But I mean , this 'll get us a bit closer at least , right ? I mean . 
B:  If it takes us a second to do , for each one , and let 's say it 's twenty billion ,  
B:  then that 's twenty billion seconds , which is  
E:  Yeah . 
B:  Eva , do the math . 
E:  <laugh> 
D:  <laugh> 
E:  Long ! 
C:  Can't . 
B:  <laugh> 
C:  @ @  
B:  Hours and hours and hours and hours . 
B:  But we can do randomized testing . 
B:  <laugh> 
C:  <laugh> 
E:  Tah - dah !  
B:  Which probabilistically will be good enough . 
D:  Mm - hmm . 
topic_description:	too many nodes


D:  And um , hmm , 
D:  what other news do I have ? 
D:  Well we fixed some more things from the SmartKom system , but that 's not really of general interest , 
E:  <clear throat> 
E:  <breath> 
D:  Um , 
D:  Oh ! Questions , yeah . I 'll ask Eva about the E Bayes and she 's working on that . 
D:  How is the generation XML 
D:  thing ? 
B:  I 'm gonna work on that today and tomorrow . 
D:  OK . No need to do it today or tomorrow even . Do it next week or   
B:  But I did not finish 
E:  <laugh> 
B:  the uh , SmartKom. 
B:  But I 've been looking into it . 
B:  I th @ @ It 's not like it 's a blank slate . 
E:  <laugh> 
B:  I found everything that I need and stu and uh , 
B:  <outbreath> 
D:  But st 
B:  At the b uh furthermore , I told Jerry that I was gonna finish it before he got back . So . 
D:  OK . 
E:  That 's approaching . He 's coming back when ? Uh next  
B:  Well , 
B:  I think  we think we 'll see him definitely on Tuesday for the next  Or , no , wait . The meetings are on Thursday . 
D:  Maybe . 
D:  Who knows . 
B:  Maybe . 
E:  OK . 
B:  Well , we 'll see him next week . 
E:  Alright . 
D:  That 's good . 
topic_description:	Generation XML


B:  I 'm gonna finish it today , uh hopefully . 
D:  OK . 
B:  I wanna do one of those things where I stay here . Cuz uh , if I go home , I can't finish it . I 've tried 
C:  <laugh> 
B:  about five times so far , 
E:  <laugh> 
B:  where I work for a while and then I 'm like , 
B:  I 'm hungry . 
E:  <laugh> 
C:  <laugh> 
B:  So I go home , and then I think  
E:  I 'm not going back .  
E:  <laugh> 
B:  Yeah .  
C:  <laugh> 
B:  Either that or I think to myself , I can work at home . And then I try to work at home , but I fail miserably . 
E:  Yeah . 
B:  Like I ended up at Blakes last night . 
E:  <laugh> 
E:  Non - conducive . 
B:  No . 
E:  <laugh> 
B:  I almost got into a brawl . <laugh> 
topic_description:	chitchat


D:  Yeah . 
D:  The paper . 
E:  Hmm . <outbreath> 
D:  Hmm .  
B:  I was thinking about that . I think 
B:  I will try to work on the SmartKom stuff  
B:  and I 'll  if I can finish it today , I 'll help you with that tomorrow ,  
B:  if you work on it ? 
B:  I don't have a problem with us working on it though ? So . 
D:  OK . 
D:  So you would say it 's 
B:  And it  
D:  funky 
D:  cool . 
B:  I mean we just  I mean it wouldn't hurt to write up a paper , cuz then , I mean , yeah  I was talking with Nancy and Nancy said , you don't know whether you have a paper to  write up until you write it up . So . 
D:  <laugh> 
E:  Yeah . 
D:  Well 
B:  And since Jerry 's coming back , we can run it by him too . So . 
D:  Yep . 
D:  Um , what 's your input ? 
E:  <inbreath> Well , um , 
E:  I don't have much experience with uh , conference papers for compu in the computer science realm , and so when I looked at what you had , 
E:  which was apparently a complete submission , I just sort of said 
E:  what  just  
E:  I  I didn't really know what to do with it , like , this is the sort of the basic outline of the system or whatever , or  or 
E:  " here 's an idea " , right ? That 's what that paper was , " here 's  here 's one possible thing you could do " , 
D:  Mm - hmm . 
E:  short , 
E:  eight pages , and I just don't know 
E:  what you have in mind for expanding . Like I 'd  I  what I didn't do is go to the web site of the conference and look at what they 're looking for or whatever . 
D:  Mm - hmm . 
D:  Well , it seems to me that 
D:  um  
B:  Wait , is this a computer science conference or is it a   
D:  Um , well it 's more  
D:  It 's both , right ? It 's  it 's sort of 
D:  t cognitive , neural , psycho , linguistic , but all for the sake of doing computer science . 
D:  So it 's sort of cognitive , psycho , neural , plausibly motivated , architectures of natural language processing . 
B:  <laugh> 
D:  So it seems pretty interdisciplinary , and I mean , w w the keynote speaker is Tomasello and blah - blah - blah , so , 
E:  Right . Oh , yeah . 
D:  <mouth> 
D:  W the  the question is what could we actually 
D:  do and  and  and keep a straight face while doing it . 
D:  And i 
B:  Well , I really can't keep a straight face doing anything . 
E:  <laugh> 
C:  <laugh> 
C:  <laugh> 
A:  <laugh> <cough> 
E:  Hmm . 
E:  About how <laugh> all of these things  
A:  What 's the part that 's not pretend ? The writing ? 
E:  <laugh> 
B:  <laugh> 
D:  <laugh> OK , then we pretend to write about . <laugh> 
C:  <laugh> <sniff> 
E:  The submitting to a major international conference .   Yeah . 
A:  <laugh> Tha - <laugh> Which conference is it for ? 
B:  <laugh> 
E:  <laugh> 
C:  <laugh> 
D:  It 's the whatever , architectures , eh you know , where  
D:  There is this conference , it 's the seventh already international conference , on neu neurally , cognitively , motivated , architectures of natural language processing . 
A:  Oh . 
D:  <mouth> 
A:  Wow . 
D:  And 
A:  Interesting . 
B:  <laugh-breath> 
D:  the keynote speakers are Tomasello , MacWhinney ? We - MacWhinney , I think .  
A:  Whinney .  MacWhinney. Uh - huh . 
E:  MacWhinney. 
A:  So , interesting , both , like , child language people . 
D:  Yeah . 
D:  Yep . 
A:  OK . 
D:  So maybe you wanna write something too . 
A:  Yeah , maybe I wanna go . 
E:  Mmm . <outbreath> Mmm . 
A:  Um , why are they speaking at it if it  is  is it normally like  like , dialogue systems , or , you know , other NLP - ish things ? 
D:  No no no no no no no no . It 's  it 's like a  
E:  <outbreath> 
A:  Oh , it 's cognitive . OK . 
D:  Yeah . Yeah . 
D:  Even neuro . 
A:  And 
A:  uh , both learning and like , comprehension , production , that kinda stuff . 
D:  Psycho .  
D:  @ @  
D:  You could look at the web site . 
A:  OK . 
D:  I 'll  
A:  OK . 
D:  And the ad and  and the deadline is the fifteenth of June . 
A:  I don't know about it . 
A:  <clears throat> 
A:  Yeah that 's pretty soon . 
E:  Mmm . <outbreath> 
C:  <laugh> 
D:  Hey . Plenty of time . 
E:  Why , we 've got over a week !  
D:  <laugh> 
C:  <laugh> 
A:  Yeah . 
D:  I usually enjoy writing papers . It 's not  I don't re regard it as a painful thing .  
A:  Mm - hmm . It 's fun . 
A:  <cough> 
D:  And um , we should all do more for our publication lists . And . It just never hurts . 
A:  <cough> 
D:  And 
D:  Keith and - or Johno will go , probably .  
B:  Will I ? 
A:  When is it and where ? 
E:  Hmm ! 
D:  In case of  
D:  It 's on the twenty second of September , in Saarbruecken Germany .  <outbreath> 
A:  Ah , it 's in Germany . Ah , OK . I s I see . Tomasello 's already in Germany anyway , so makes sense . OK . 
E:  Just  
A:  Um . 
A:  OK . So , is the  What  Are you just talking about 
A:  you know , the details of how to do it , or whether to do it , or what it would be ? 
E:  What would one possibly put in such a paper ?  
D:  What to write about . <laugh> What is our  what 's our take home message . What  what do we actually  
A:  Or what to write about ? 
E:  <laugh> 
D:  Because I mean , it  I don't like papers where you just talk about what you plan to do . 
A:  <cough> 
D:  I mean , 
D:  it 's obvious that we can't do any kind of evaluation , and have no  you know , we can't write an ACL type paper where we say , " OK , we 've done this and now we 're 
A:  Mm - hmm . 
D:  whatever percentage better than everybody else " . You know . 
A:  Mm - hmm . 
D:  It 's far too early for that . 
D:  But uh , we  we can tell them what we think . I mean that 's  
D:  never hurts to try . 
D:  And um , 
D:  maybe even  That 's maybe the time to introduce the  the new formalism that you guys have cooked up .  
A:  Mm - hmm . 
E:  <breath-laugh> 
E:  Are in the process of   
B:  But that  
D:  Let 's  let 's  wh wh what should we  should  should we uh , um , discuss this over tea and all of us look at the web ? Oh , I can't . I 'm wizarding today . 
A:  OK , look at the web page ? 
D:  Um . 
A:  Wha - w 
D:  Look at the web page and let 's talk about it maybe tomorrow afternoon ? 
A:  More cues for us to find it are like , 
A:  neural cons 
D:  Johno will send you a link . 
A:  Oh , you have a link . OK . OK . 
B:  I got an email . 
A:  OK . 
topic_description:	conference paper


D:  My idea is , 
E:  Setting that aside . <laugh> 
D:  well , you can say we have done a little bit and that 's this , and uh sort of the rest is position paper , " we wanna also do that " . Which is not 
D:  too good . 
D:  Might be more interesting to do something like 
D:  let 's assume 
D:  um , 
D:  we 're right , 
D:  we have as Jerry calls it , a delusion of adequacy , 
E:  <laugh> 
D:  and take a " where is X " sentence , 
E:  Mm - hmm . 
D:  and say , " we will just talk about this , and how we 
D:  cognitively , neurally , 
D:  psycho - linguistically , construction grammar - ally , 
E:  Mmm . <outbreath> 
D:  motivated , 
D:  envision 
D:  uh , understanding that " . 
D:  So we can actually show how we parse it . 
D:  That should be able to  we should be able to come up with , you know , a sort of a  a parse . 
E:  Right . 
B:  <outbreath> 
D:  We 're talking about this um , alleged paper that we may , just , sort of w 
A:  Oh ! Which Johno mentioned to me . Uh - huh . 
D:  Yeah . 
A:  <mouth> 
D:  And I just sort of 
D:  brought forth the idea that 
D:  we take a sentence , " Where is the Powder - Tower " , 
A:  Mm - hmm . 
D:  and we  we p 
D:  pretend to parse it , 
D:  we pretend to understand it , 
A:  @ @  
B:  <laugh> 
D:  and we write about it . 
topic_description:	use "Where is X" sentence


A:  I 'm sorry . I 'm sorry . I 'm sorry .  
D:  It 's on , just  just put it on .  
B:  <outbreath> 
E:  <laugh> 
A:  OK . <mike noise> 
A:  Hi . <mike noise> 
B:  Did Ben harass you ? 
A:  Yes .  
B:  Good . 
A:  Was he supposed to harass me ? <mike noise>  
B:  Yes . 
A:  Well , he just told me that you came looking for me . <mike noise> 
D:  You don 
D:  @ @  
B:  Oh . 
A:  @ @ figure this out .   
D:  You will suffer in hell , you know that . 
E:  Backwards . 
C:  <sniff> 
A:  <mike noise> 
E:  There 's a s 
E:  diagram somewhere which tells you how to put that  
A:  I know , I didn't understand that either !   
E:  <laugh> 
B:  No wait . You have to put it on exactly like that , so put that  those things over your ears like that .  
D:  This is it . 
D:  Yeah . 
A:  OK . 
B:  See the p how the plastic things ar arch out like that ? There we go . 
A:  OK .  
A:  It hurts . 
B:  It hurts . It hurts real bad . 
E:  <laugh> 
A:  It does !  
E:  But that 's what you get for coming late to the meeting . <laugh> 
A:  I 'm sorry I didn't mean to  I 'm sorry . 
D:  <clear throat> 
B:  <laugh> 
E:  <laugh> 
A:  I 'm sorry , oh these are all the same . 
E:  <laugh> 
A:  OK ! th this is not very  on target . 
C:  <laugh> 
B:  Is your mike on ? 
C:  An - 
D:  Yeah , it is . 
A:  Shoot .  
C:  <sniff> 
B:  OK . 
A:  Alright , you guys can continue talking about whatever you were talking about before . 
E:  <laugh> 
E:  Um , 
topic_description:	chitchat


D:  It would be nice to go write two papers actually . Yeah . And one  one from your perspective , and one from our peve per per 
A:  Mm - hmm . 
A:  I mean , th that 's the kinda thing that maybe like , um , the general 
A:  uh con sort of like NTL - ish like , whatever , the 
A:  previous simulation based pers  maybe you 're talking about the same kind of thing . A general paper about 
A:  the approach here would probably be appropriate . 
D:  Yeah . 
A:  And good to do at some point anyway . 
D:  Yeah . 
A:  <cough> 
A:  Um . 
D:  Well , I  I also think that if we sort of 
D:  write about what we have done in the past six months , 
D:  we  we  we could 
E:  <cough> 
D:  sort of craft a nice little paper that  if it gets rejected , which could happen , 
A:  Mm - hmm . 
E:  <laugh> 
D:  doesn't hurt because it 's something we eh  
A:  Having it is still a good thing .  
D:  having it is a good  good thing .  It 's a nice exercise , it 's  
topic_description:	also a general paper


A:  How many pages ? 
B:  don't they need to finish the formalism ? <laugh> 
D:  It 's just like four pages . I mean it 's  it 's not even a h 
E:  <outbreath> Yeah . 
A:  Four pages ? 
A:  OK , so it 's a little thing . 
D:  Mm - hmm . 
A:  Oh . 
B:  Well , you said it was four thousand lines ? Is that what you s 
E:  Oh . 
A:  OK . Four pages is , like , really not very much 
D:  I don't know w Did you look at it ? 
D:  Yeah , it depends on the format . 
A:  space . 
E:  Oh my gosh . Oh , I thought you were  I thought we were talking about something which was much 
D:  No that 's  I mean that 's actually a problem . It 's difficu it 's more difficult to write on four pages than on eight . 
E:  more like ten or something . 
A:  It 's  Yeah . 
A:  <cough> 
E:  Yeah . 
A:  And it 's also difficult to  even if you had a lot of substance , it 's hard to demonstrate that in four pages , basically . Um . 
E:  Yeah . 
E:  That would be hard . 
D:  Well I uh maybe it 's just four thousand lines . I do I don't  They don't want any  
A:  I mean it 's still  it 's still  
D:  They don't have a TeX f style @ @ guide . They just want ASCII . Pure ASCII 
A:  Uh - huh , uh - huh . 
A:  OK . 
D:  lines , whatever . Why , for whatever reason , I don't know . 
A:  Not including figures and such ? 
D:  I don't know . 
D:  Very unspecific unfortunately . 
A:  OK . <sniff> 
A:  Well , 
D:  We 'll just uh  
B:  I would say that 's closer to six pages actually . Four thousand lines of ASCII ? 
D:  OK then . 
D:  It 's  
E:  Four thousand lines . I mean . 
E:  Isn't a isn't it about fifty s fifty five , sixty lines to a page ? 
D:  I d don't quote me on this . This is numbers I  I have from looking o 
A:  <laugh> 
E:  <laugh> 
B:  How many characters are on a line ? <laugh> 
E:  <laugh> 
A:  <laugh> 
D:  OK . 
A:  ASCII ? 
topic_description:	format


B:  By the way , Keith is comfortable with us calling him " cool Keith " . 
E:  <laugh> 
A:  Oh . Cool . Keith . Cool , " cool Keith " . 
E:  He  he decided <laugh> I 'm chilling in the five - one - O . 
C:  <laugh> 
B:  <laugh> 
E:  Yeah . <laugh> 
B:  <laugh> 
A:  <laugh> 
A:  <inbreath> Excellent . 
D:  OK . 
A:  <cough> 
A:  That 's a very cool T - shirt . 
D:  <clears throat> 
E:  Thank you . 
D:  And I 'm also flying  
E:  I got this from the two one two . <laugh> Yeah . <laugh> 
B:  <laugh> 
A:  New York ? 
A:  Excellent . 
A:  <laugh> 
A:  Sorry . Yes ? 
D:  I 'm flying to Sicily next  
D:  in a w two weeks from now ,  
A:  Oh , lucky you . 
E:  <laugh> 
D:  w and a week of business in Germany . I should mention that for you . 
D:  And otherwise you haven't missed much , except for a really weird idea , 
A:  <clear throat> <sniff> 
B:  <breath> 
D:  but you 'll hear about that 
A:  The idea that you and I already know about ? 
D:  soon enough . 
A:  That you already told me ? 
A:  Not that  OK . <laugh> 
D:  No , no , no . 
E:  <laugh> 
D:  Yeah , that is something for the rest of the gang to  to g 
E:  <laugh> The thing with the goats and the helicopters ? <laugh> 
A:  <laugh> 
D:  <laugh> 
B:  <laugh> 
B:  <laugh> 
A:  <laugh> 
D:  Change 
D:  the watchband . It 's time to walk the sheep . <laugh> 
E:  <laugh> 
C:  <laugh> like 
A:  OK . <clears throat> <sniff> 
D:  Um . 
D:  Did you catch that allusion ? It 's time to walk the sheep ? 
E:  No .  <laugh> 
D:  It 's a a 
D:  uh presumably one of the Watergate codes they uh  
E:  Oh . <laugh> 
topic_description:	chitchat


D:  Anyways , th um , 
B:  <breath-laugh> 
A:  <laugh> 
D:  um , 
D:  don't make any plans for spring break next year . 
A:  <laugh> 
D:  That 's  
E:  Oh , shoot .  <laugh> 
A:  <cough> <laugh> <sniff> 
D:  <laugh> 
C:  <laugh> 
B:  <laugh> 
D:  That 's the other thing . We 're gonna do an int EDU internal workshop in Sicily . 
A:  That 's what  That 's what he says . 
E:  <laugh> 
C:  <laugh> 
D:  I 've already got the funding . So , I mean . 
E:  <mike noise> 
A:  I kn That 's great ! 
A:  Does that mean  
E:  We 'll see . 
D:  No , that 's  
A:  Does that mean you 'll get  you 'll fly us there ? 
D:  Yeah , that 's what it means . 
topic_description:	EDU workshop Sicily


A:  Hhh ! OK , cool . Uh - a a 
D:  <laugh> 
E:  Huh . 
B:  And he 'll put us up , too . 
A:  I know  I know about that part . I know about the  the almond trees and stuff . 
E:  <mike noise> <laugh> 
B:  <laugh> 
C:  <laugh> 
A:  Not joking . 
D:  OK . 
B:  <laugh> 
E:  <laugh> 
A:  Name a vegetable , OK . <laugh> Oh , um , kiwi ? 
E:  <laugh> Yeah . 
C:  <laugh> 
D:  Mmm , too easy . 
A:  Coconut . 
D:  Ki - 
A:  Pineapple . See ? 
A:  Mango ? 
D:  Too easy . 
A:  OK . OK . Too easy ? 
D:  Yeah , mangos go everywhere . So do kiwi . 
A:  Really ?  
A:  Oh . OK , but I was trying to find something that he didn't grow on his farm . 
D:  But coconut anana pineapple , that 's  that 's tricky , yeah . 
C:  <laugh> 
A:  Sorry . <cough> Anyway . <coughs> 
D:  <laugh> 
E:  <mike noise> <laugh> 
C:  <laugh> 
A:  Cantaloupe . <laugh> 
E:  So , but we have to decide what , like , sort of the general idea of  
B:  Potatoes . 
B:  So . Sorry ! <laugh> 
E:  <laugh> 
C:  <laugh> 
E:  @ @ .  
A:  <clears throat> 
topic_description:	chitchat


E:  Um , 
E:  I mean , we 're gonna have an example case <laugh> um , right ? I m the  the point is to  like this " where is " case , or something . 
D:  <laugh> 
A:  <mike sound> 
A:  It 'd just be small . Like introducing the formalism might be not 
A:  really 
A:  possible in detail , but you can use an example of it . 
E:  Well , l looking at  yeah , looking at that paper that  that you had , I mean you know , like , you didn't really 
E:  explain in detail what was going on in the XML cases or whatever you just sorta said well , you know , here 's the general idea , some stuff gets put in there . 
A:  <cough> <sniff> 
E:  You know , hopefully you can  you can say something like constituents tells you what the construction is made out of , you know , without going into this intense detail . 
A:  Yeah , yeah . 
A:  So it be like using the formalism rather than 
E:  Yeah . 
A:  you know , introducing it per se . So . 
E:  Give them the one paragraph whirlwind tour of w w what this is for , and  Yeah . 
A:  Yeah . 
A:  <clear throat> <sniff> 
D:  Mm - hmm . 
A:  And people will sort of figure out 
A:  or ask about the bits that are 
D:  Yeah . 
D:  So this will be sort of documenting what we think , and documenting what we have in terms of the Bayes - net 
A:  implicit . 
A:  Mm - hmm . 
D:  stuff . 
D:  And since there 's never a bad idea to document things , no ? 
A:  That 's th that 's definitely a good idea . 
A:  <clears throat> 
D:  That would be my , uh  
D:  We  we should sketch out the details maybe tomorrow afternoon - ish , if everyone is around . 
D:  I don't know . You probably 
E:  I think so . 
D:  wouldn't be part of it . Maybe you want ? 
D:  Think about it . 
D:  Um , 
A:  <cough> 
D:  You may  may ruin your career forever , if you appear . <laugh> 
C:  <laugh> 
A:  <laugh> 
B:  Yeah , you might get blacklisted . <laugh> 
E:  <mike noise> 
topic_description:	conference paper


D:  Yeah , maybe you have  It would be kind of  The paper ha would have , in my vision , a nice flow if we could say , 
C:  <laugh> 
A:  <clears throat> 
D:  well here is th the  th here is parsing if you wanna do it c right , here is understanding if you wanna do it right , and you know  without going into technical  
A:  <cough> 
E:  Mm - hmm . 
A:  But then in the end we 're not doing like those things right yet , right ? Would that be clear in the paper or not ? 
B:  <cough> 
D:  That would be clear , we would  I  I mailed around a little paper that I have  
E:  <mike noise> 
B:  <cough> 
A:  OK . 
A:  It would be like , this is the idea . 
A:  Oh , I didn't get that , did I ? Oops .  
D:  w we could sort of say , this is  
D:  No , 
A:  Did I ? Oops .  Sorry . 
B:  No , y I don't think you got it . 
D:   See this , if you if you 're not around , and don't partake in the discussions , and you don't get any email ,  and 
A:  I 'm sorry . I 'm sorry , I 'm sorry . Sorry . 
B:  <outbreath> 
B:  <laugh> 
D:  <laugh> 
E:  <mike noise> 
A:  OK , go on . 
B:  <laugh> 
A:  So parsing done right <laugh> is like chicken done right . <laugh> 
D:  Su - 
D:  So we could  we could say this is what  what 's sort of 
C:  <laugh> 
E:  <mike noise> 
D:  state of the art today . 
A:  OK . 
D:  Nuh ? And say , this is bad . 
A:  Yeah . 
D:  Nuh ? And then we can say , uh well what we do is this . 
A:  OK . 
D:  Yeah . 
A:  Parsing done right , interpretation done right , example . 
D:  Mm - hmm . 
A:  <clears throat> 
D:  Yeah . And 
topic_description:	vision for paper


A:  And how much to get into the cognitive neural part ? 
D:  We - 
B:  That 's the only  That 's the question mark . Don't you need to reduce it if it 's a  
B:  or reduce it , if it 's a cognitive neuro  
E:  <mike noise> 
A:  Well , you don't have t I mean the conference may be cognitive neural , doesn't mean that every paper has to be both . 
D:  Yeah , and you can  you can just point to the  to the literature , you can say that construction - based @ @ 
E:  Mmm . 
A:  Like , 
A:  NLP cognitive neural . 
A:  <cough> 
D:  You know  
A:  So i so this paper wouldn't particularly deal with that side although it could reference the NTL - ish sort of , like , um , approach . Yeah . 
D:  Mm - hmm . 
D:  Yeah . 
A:  The fact that the methods here are all compatible with 
B:  <outbreath> 
A:  or designed to be compatible with whatever , neurological  neuro 
D:  Mm - hmm . 
A:  neuro - biol su stuff . 
A:  Yeah , I guess four pages you could  
A:  @ @  I mean you could definitely  
A:  it 's definitely possible to do it . It 's just  
topic_description:	cognitive neural part


D:  And um , 
D:  the uh , 
D:  other thing , 
D:  yeah we actually  
D:  Have we made any progress on what we decided , uh , last week ? 
D:  I 'm sure you read the transcript of last week 's meeting in red so sh so you 're up to dated  caught up .  
E:  <mike noise> 
A:  No . 
E:  <laugh> 
A:  Sorry . 
D:  We decided t that we 're gonna take a " where is something " question , and pretend we have parsed it , and see what we could possibly hope to observe on the discourse side . 
B:  Remember I came in and I started asking you about how we were sor going to sort out the uh , decision nodes ? 
A:  Yes ! 
A:  <clears throat> What 'd you say ? <laugh> 
D:  <laugh> 
E:  <laugh> 
B:  <laugh> I remember you talking to me , just not what you said .  
C:  <laugh> 
A:  <laugh> I do remember you talking to me . 
E:  <laugh> 
A:  Um , 
A:  a few more bits . 
E:  <mike noise> 
B:  Well , there was like we needed to  or uh , in my opinion we need to design a Bayes  another sub - Bayes - net  
B:  You know , it was whether  it was whether we would have a Bayes - net on the output and on the input , or whether the construction was gonna be in the Bayes - net , 
A:  <mouth> Oh . 
A:  Oh , yeah . OK . 
B:  a and outside of it , and  
A:  OK . 
A:  So that was  was that the question ? Was that what   
D:  <cough> 
D:  <cough> 
B:  Well that was related to what we were talking about . 
D:  <cough> 
E:  <laugh> 
A:  <cough> 
E:  <outbreath> 
D:  <mike noise> 
A:  Interesting , uh - huh . 
A:  User . 
A:  Mmm . 
D:  If  if we ask it where is something . 
D:  And , maybe it also h 
D:  enables you to think about certain things more specifically , 
D:  um , come up 
D:  with interesting questions , to which you can find interesting answers . 
D:  And , additionally it might 
D:  fit in really nicely with the paper . 
E:  Um - hmm . 
D:  Because if  if  if we want an example for the paper , 
D:  I suggest there it is . 
E:  Yeah . 
A:  <clears throat> 
D:  <mock choking noise>  
E:  <laugh> 
topic_description:	decision nodes


D:  Should I introduce it as SUDO - square ? 
D:  <mike noise> <cough> 
B:  <laugh> Yeah sure . <laugh> 
D:  We have to put this in the paper . 
B:  <laugh> 
D:  If we write it . 
E:  <laugh> 
D:  This is  this is my only constraint . The  th So . 
B:  <laugh> 
A:  <clears throat> <sniff> 
D:  The SUDO - square 
D:  <writing on whiteboard> 
D:  is , 
E:  Oh I saw the diagram in the office , yeah . <laugh> 
D:  <three-syllable laugh> " Situation " , 
D:  " User " , 
A:  <laugh> 
D:  " Discourse " , right ? " Ontology " . 
D:  OK , so we have tons of little things here , and we 've 
E:  <laugh> 
A:  I can't believe that that 's never been thought of before . <laugh> 
E:  <laugh> 
C:  <laugh> 
D:  <laugh> 
B:  Wait , what are the dots ? I don't remember what the dots were . 
E:  <laugh> Those are little bugs . <laugh> 
A:  <laugh> 
D:  <laugh> 
C:  <laugh> 
A:  Cool Keith . <laugh> 
D:  OK . 
E:  <laugh> 
D:  You know , these are our , whatever , belief - net decision nodes , and they all contribute to these 
A:  @ @  <sniff> 
E:  <laugh> 
B:  Oh , oh . 
D:   <tapping on white board> 
C:  <laugh> 
D:  things down here . 
A:  Wait , wait , what 's the middle thing ? 
D:  That 's EDU . e e Our e e e 
E:  That 's a c <laugh> 
C:  <laugh> 
A:  But wh I mean  
E:  That 's  
D:  You . We . Us . <laugh> 
A:  <laugh> But what is it ? 
C:  <laugh> 
D:  Well , in the moment it 's a Bayes - net . 
E:  <laugh> 
D:  And it has sort of fifty not - yet - specified interfaces . 
D:  OK . Eh  I have taken care that we actually can build little 
D:  interfaces , 
D:  <squeaking from writing on the white board> 
D:  to other modules that will tell us whether the user likes these things and , n the  or these things , and he  whether 
A:  OK . 
D:  he 's in a wheelchair or not , 
A:  Is that supposed to be the international sign for interface ? 
D:  I think so , yeah . 
A:  Mmm . 
A:  OK . 
B:  I 'd  I 'd never seen it before either . 
A:  OK . Just t Cool . 
C:  <laugh> 
D:  Mmm . So . 
E:  Cuz things fit onto that , see ? 
A:  Yeah . <laugh> 
D:  <laugh> 
C:  <laugh> 
A:  <cough> 
E:  <laugh> In a vaguely obscene fashion . <laugh> 
B:  <laugh> 
A:  Cool . 
D:  <laugh> 
C:  <laugh> 
A:  <laugh> 
B:  <laugh> 
D:  No , this is a RME core by agent 
D:  design , I don't know . 
C:  <laugh> 
A:  That 's so great . <laugh> 
D:  There 's maybe a different 
E:  So wait , what a what are these letters again , Situr -  Situation , User , Discourse and 
B:  <laugh> 
C:  <laugh> 
D:  Situation , user , d ontology . 
A:  User ? 
C:  <laugh> 
E:  Ontology . 
A:  What about the utterance ? 
D:  That 's here . 
E:  It 's  
C:  Discourse . 
A:  Oh , discourse . 
D:  Yeah . 
E:  Discourse is all things linguistic , yeah . 
A:  So that 's not like context , OK . 
C:  <laugh> 
D:  So this  this includes the  
D:  the current utterance plus all the previous utterances . 
topic_description:	SUDO-square


E:  <laugh> 
B:  <laugh> 
E:  <laugh> 
A:  Oh my god , that 's amazing ! 
E:  <laugh> 
D:  Mmm . 
B:  <laugh> 
D:  Yeah . Whatever . 
A:  No way . 
E:  <laugh> Way ! 
D:  Is it ? <laugh> 
A:  <laugh> 
B:  <laugh> 
C:  <laugh> 
A:  Someone 's gonna start making Phil Collins jokes . 
D:  Yeah . 
E:  <laugh> Oh , god , I hope not . 
D:  Hmm ? 
A:  Sorry . <laugh> 
D:  <laugh> 
B:  What ? <laugh> 
A:  You guys are too young . 
E:  You know like " Sussudio " , that horrible , horrible song that should never have been created . 
A:  Yeah , come on . 
B:  Oh , oh , oh , oh . 
A:  I know , that was horrible . 
A:  Sussudio .  
B:  I 've blocked every aspect of Phil Collins out of my mind . 
C:  What ? 
E:  <laugh> 
A:  I 'm sorry , I haven't .  
E:  <laugh> 
A:  Not on purpose .  
E:  @ @ in here  
A:  <laugh> 
C:  <laugh> 
E:  <laugh> 
B:  <laugh> 
D:  Oh  <laugh> Well , also he 's talking about suicide , and that 's  that 's not a notion I wanna have evoked . 
B:  <laugh> 
A:  <laugh> <cough> 
A:  No , he 's not . 
D:  He is . 
A:  Really ? 
A:  Oops .  I didn't really listen to it , I was too young . Anyway . 
D:  The  
E:  Hmm . 
E:  It sounds too rocking for that . Anyway . So , what 's going on here ? <laugh> 
A:  Yeah . <laugh> 
B:  <laugh> 
C:  <laugh> 
D:  <laugh> 
E:  So what are  what  
A:  <cough> 
E:  Was wollte der Kuenstler uns damit sagen ? 
D:  So , 
D:  <laugh> 
E:  <laugh> 
A:  Stop excluding me . 
topic_description:	chitchat


D:  And for example w i s I Irena Gurevich is going to be here eh , end of July . She 's a new linguist working for EML . 
A:  User . 
A:  <sniff> 
D:  And what she would like to do for example is great for us . She would like to 
E:  <long breath> 
D:  take the ent ontolog So , 
C:  <something dropping> Ouch .  
D:  <mouth> we have discussed in terms of the EVA  uh  <clear throat> 
A:  Grateful for us ? 
A:  Did you just say grateful for us ? 
A:  OK , sorry . Anyway .  
C:  <laugh> 
D:  Think of  back at the EVA vector , 
D:  and Johno coming up with the idea that if the person discussed the  discussed the admission fee , in  eh previously , that might be a good indication that , 
A:  Mm - hmm . 
A:  <cough> 
D:  " how do I get to the castle ? " , actually he wants to enter . 
A:  <sniff> 
D:  Or , you know , " how do I get to X ? " 
D:  discussing the admission fee in the previous utterance , is a good indication . 
E:  Mm - hmm . 
A:  @ @ 
D:  So 
D:  we don't want a hard code , 
D:  a set of lexemes , or things , that person 's 
D:  you know , sort of filter , or uh search the discourse history . 
A:  Mm - hmm . 
D:  So what would be kind of cool is 
D:  that if we encounter concepts that are castle , tower , bank , hotel , 
D:  we run it through the ontology , and the ontology tells us it has 
D:  um , admission , opening times , it has admission fees , it has this , it has that , 
A:  <clears throat> 
D:  and then we  we  we make a thesaurus lexicon , look up , and then search dynamically through the uh , discourse history 
D:  for  occurrences of these things in a given 
D:  window 
D:  of utterances . 
A:  Mm - hmm . 
D:  And that might , you know , give us additional input to belief A versus B . 
D:  Or 
A:  <cough> 
D:  E versus A . 
A:  So it 's not just a particular word 's  OK , so the  you 're looking for a few keys that you know are cues to  
A:  sorry , a few specific cues to some intention . 
B:  You can dynamically look up keys , yeah . 
D:  Yeah . 
E:  Uh , so , wait  so um , since this  since this sort of technical stuff is going over my head , the  the point is that you uh  that 
A:  OK . 
B:  And then grep , basically . 
D:  <mike noise> 
D:  <cough> 
D:  <mike noise> 
E:  when someone 's talking about a castle , you know that it 's the sort of thing that people are likely to wanna go into ? Or , is it the fact that 
D:  <mike noise> 
E:  if there 's an admission fee , then one of the things we know about admission fees is that you pay them in order to go in ? And then the idea of entering is active in the discourse or something ? And then 
D:  <mike noise> 
D:  Well 
E:  blah - blah - blah ? I mean . 
D:  the  the idea is even more general . The idea is to say , 
D:  we encounter a certain entity in a  in a in a utterance . 
D:  So le let 's look up everything we  the ontology gives us 
D:  about that entity , what 
D:  stuff it does , what roles it has , what 
D:  parts , whatever it has . 
D:  Functions .  
A:  <clears throat> 
D:  And , then we look 
D:  in the discourse , whether any of that , or any 
D:  surface structure corresponding to these 
E:  Oh , OK . 
D:  roles , functions aaa  has ever occurred . 
D:  And then , the discourse history can t tell us , " yeah " , or " no " . 
E:  OK . 
D:  And then it 's up for us 
D:  to decide what to do with it . 
E:  OK . 
D:  t 
D:  So i 
E:  So  
E:  No , go ahead . 
D:  So , we may think that if you say 
D:  um , <outbreath> 
D:  <mouth> " where is the theater " , 
D:  um , whether or not he has talked about tickets before , 
E:  Mm - hmm . 
D:  then we  he 's probably wanna go there to 
D:  see something . 
E:  OK . 
D:  Or " where is the opera in Par - Paris ? , yeah ? Lots of people go to the opera to take pictures of it and to look at it , and lots of people go to attend a performance . 
E:  Mm - hmm . OK . 
E:  Mm - hmm . 
D:  And , the discourse can maybe tell us w what 's more likely 
D:  if we know what to look for in previous statements . 
D:  And so we can hard code " for opera , look for tickets , look for this , look for that , 
E:  OK . 
E:  OK . 
D:  or look for Mozart , look for thi "   
D:  but the smarter way is to go via the ontology and dynamically , then look up 
A:  <cough> 
D:  u 
D:  stuff . 
topic_description:	dynamically use discourse history


E:  OK . But you 're still doing look up so that when the person  So the point is that when the person says , 
E:  " where is it ? " 
E:  then you sort of say , let 's go back and look at 
E:  other things and then decide , rather than the other possibility which is that  all through discourse as they talk about different things  You know like w 
E:  prior to the " where is it " question they say , you know , " how much does it cost to get in , you know , to  to see a movie around here " , um , 
E:  <mouth> " where is the closest theater "  The  the  the point is that by mentioning admission fees , that just sort of stays active now . 
D:  <mike noise> 
D:  Yeah . 
E:  You know . That becomes part of like , their sort of current ongoing 
D:  Mm - hmm . 
E:  active conceptual structure . And then , um , 
E:  over in your Bayes - net or whatever , when  when the person says " where is it " , you 've already got , you know since they were talking about admission , and that evokes the idea of entering , um , then when they go and ask " where is it " , then you 're Enter node is already active because that 's what the person is thinking about . I mean that 's the sort of cognitive linguistic - y way , and probably not practical . <inbreath> 
D:  Mm - hmm . 
D:  Yeah . 
D:  Yeah , e ultimately that 's also what we wanna get at . I think that 's  that 's the correct way . So , of course we have to keep 
D:  memory of what was the last intention , and how does it fit to this , and what does it tell us , in terms of  of the  the  what we 're examining . 
E:  Mm - hmm . 
E:  Mmm , yeah . 
D:  And furthermore , 
A:  <clears throat> 
D:  I mean we can idealize that , you know , people don't change topics , 
E:  Mm - hmm . 
D:  but they do . But , 
E:  Right . 
D:  even th for that , there is a student of ours who 's doing a dialogue act 
D:  um , recognition 
E:  Mm - hmm . 
D:  module . 
D:  So , 
D:  maybe , we 're even in a position where we can take your approach , which is of course much better , as to say how  how do these pieces  
E:  Mmm . 
E:  And much harder to r program . 
E:  <laugh> 
D:  Hmm ? 
E:  And much harder to p to program . 
D:  Yeah . How  how do these pieces fit together ? Uh - huh . 
E:  <laugh> 
topic_description:	or active conceptual structure


D:  And um . But , OK , nevertheless . So these are issues but we  what we actually decided last week , is to , 
D:  and this is , again , for your benefit  
D:  is to um , 
D:  pretend we have 
D:  observed and parsed an utterance such as " where is the Powder - Tower " , 
D:  or " where is the zoo " , 
D:  and specify 
D:  um , what  what we think the  the output 
D:  uh , observe , out  i input nodes for our Bayes - nets for the sub sub - D , for the discourse bit , should be . 
E:  <mike noise> 
D:  So that  And I will  I will then  
E:  <mike noise> 
D:  <cough> 
E:  <mike noise> 
D:  come up with the ontology side 
D:  uh , bits and pieces , so that we can say , OK we  we always just look at this utterance . 
D:  That 's the only utterance we can do , 
D:  it 's hard coded , like Srini , sort of hand parsed , 
D:  hand crafted , 
D:  but this is what we hope to be able to observe in general from utterances , and from ontologies , 
D:  and then we can sort of 
D:  fiddle with these things to see what it actually produces , in terms of output . 
D:  <mike noise> 
E:  <cough> <mike noise> 
D:  <mike noise> 
E:  Uh <mike noise> 
D:  <mike noise> 
topic_description:	decided last week


D:  So 
D:  we need to find out what the " where is X " construction will give us in terms of semantics and 
D:  <inbreath> Simspec 
D:  type things . 
A:  Just  OK . Just " where is X " ? 
D:  Mm - hmm . 
A:  Or any variants of that . 
D:  Yeah . 
D:  No !  
D:  Um , look at it this way , i 
D:  Yeah . 
D:  What did we decide . We decided sort of the  
E:  Well we were <outbreath> 
D:  the prototypical " where is X " , where 
D:  you know , we don't really know , does he wanna go there , or just wanna know where it is . 
D:  So the difference of " where is the railway station " , versus where  where  " where is Greenland " . Nuh ? 
E:  Mm - hmm . 
B:  Uh s I was just dancing , sorry . 
C:  <laugh> 
E:  <laugh> <mike noise> 
D:  We 're not videotaping any of this . So . 
E:  <laugh> 
B:  Uh  ah  
D:  <laugh> 
D:  <cough> <mike noise> 
E:  So , um , we 're supposed to  
E:  I mean we 're talking about sort of anything that has the semantics of request for location , right ? actually ? 
C:  <outbreath> 
E:  Or , 
E:  I mean , anyway , the node in the uh  the ultimate , uh , in  in the Bayes - net thing when you 're done , the  the node that we 're talking about um , is 
E:  one that says 
E:  " request for location , true " , or something like that , right ? Um , and  and exactly how that gets activated , you know , like whether we want 
D:  Yeah , but it  
E:  the sentence 
E:  " how do I get there ? " 
E:  to activate that node or not , you know , that 's  that 's sort of the issue that sort of the linguistic - y side has to deal with , right ? 
D:  Yea - Nnn -  
D:  Well actually more  m more the other way around . We wanted 
B:  <outbreath> 
D:  something that represents uncertainty uh we in terms of going there or just wanting to know where it is , for example . Some generic information . 
E:  OK . 
D:  And so 
D:  this is prototypically @ @ found in the " where is something " question , surface structure , 
E:  OK . 
B:  We - 
D:  which can be p you know , 
D:  should be maps to 
B:  <outbreath> 
D:  something that activates both . I mean 
D:  the idea is to  
B:  I don't  
E:  Alright , OK . 
B:  Hhh .  
D:  let 's have it fit nicely with the paper . The  
B:  I guess . I don't  
D:  So 
D:  we want to sort of 
B:  <outbreath> 
D:  come up with 
D:  what gets 
D:  uh , input , and how inter in case of a " where is " question . 
E:  <outbreath> 
D:  So what  what would the outcome of  of your parser look like ? 
D:  And , what other discourse information from the discourse history could we hope to get , 
D:  squeeze out of that utterance ? 
D:  So define the  the input into the Bayes - net 
E:  <mike noise> <yawn> 
D:  <mouth> 
D:  based on what the utterance , " where is X " , gives us . 
A:  <mike noise> 
D:  So definitely 
D:  have an Entity node here 
A:  s 
A:  <clear throat> 
D:  which is activated via the ontology , so 
D:  " where is X " produces something that is s stands for X , whether it 's castle , bank , restroom , toilet , whatever . And then the ontology will tell us  
A:  That it has a location or something like that ?  or th the ontology will tell us where actually it is located ? 
D:  <snaps the dry erase marker closed> 
D:  No . 
A:  OK . 
D:  Not at all . Where it is located , we have , a user proximity node here somewhere , 
A:  OK . 
A:  OK . 
D:  e which tells us how far the user  how far away the user is in respect to that uh entity . 
A:  OK . 
A:  So you 're talking about , for instance , the construction obviously involves this entity or refers  refers to this entity , 
D:  Mm - hmm . 
A:  and 
A:  from the construction also you know that it is a location  is  or a thing  
A:  thing that can be located . 
A:  Right ? Ontology says this thing has a location slot . 
A:  Sh - and that 's the thing that is being  
A:  that is the content of the question that 's being queried by 
A:  one interpretation of " where is X " . 
A:  And another one is , um , 
A:  path from current  user current location to  
E:  <mike noise> 
D:  Mm - hmm . 
A:  that location . So . 
A:  So is the question  I mean it 's just that I 'm not sure what the  
E:  <mike noise> 
A:  Is the question , for this particular construction how we specify that that 's the information it provides ? 
A:  Or  
A:  or asked for ? 
D:  <clears throat> 
A:  b 
A:  Both sides , right ? 
D:  Yeah , you don't need to 
A:  <cough> 
D:  even do that . It 's just sort of what 
D:  <clears throat> 
D:  what would be 
D:  @ @  
D:  observed 
D:  in uh  in that case . 
A:  Observed when you heard the speaker say " where is X " , or when  when that 's been parsed ? <sniff> 
D:  Mm - hmm . 
A:  So these little circles you have by the D ? 
A:  Is that  ? 
D:  That 's exactly what we 're looking for . 
A:  OK . 
A:  OK . 
B:  I change I changed my mind actually . 
D:  <clear throat> 
E:  OK . 
A:  Um , it seems like for instance , " where is X " , 
A:  the fact that it might mean 
A:  um , 
A:  " tell me how to get to X " , 
A:  like  
A:  So , would you wanna say that those two are both , like  
A:  Do y 
A:  Those are the two interpretations , right ? the  the ones that are location or path . 
A:  So , you could say that the s construction is a question asking about this location , 
E:  <outbreath> 
A:  and then you can additionally infer , if they 're asking about the location , it 's because they wanna go to that place , 
D:  Mm - hmm . 
A:  in which case , the  you 're jumping a step  step and saying , " oh , I know where it is but I also know how to get  they wanna seem  they seem to wanna get there so I 'm gonna tell them " . So there 's like structure 
E:  Yeah . 
E:  Right , th this  it 's not  it 's not that this is sort of like semantically ambiguous between these two . It 's really about this but why would you care about this ? Well , 
A:  i do you kn sort of uh , that  
D:  Mm - hmm . 
C:  <sniff> 
E:  it 's because you also want to know this , or something like that right ? 
D:  Mm - hmm . 
A:  So it 's like you infer the speaker intent , and then infer a plan , a larger plan from that , for which you have the additional information , you 're just being extra helpful . Um . <sniff> 
E:  Yeah . 
D:  Mm - hmm . 
D:  Yep . 
topic_description:	"Where is X"


B:  I don't see unde how we would be able to distinguish between the two intentions just from the g utterance , though . 
B:  I mean , uh bef or , before we don't  before we cranked it through the Bayes - net . I mean . 
D:  Yeah , we  we wouldn't . 
D:  That 's exactly what we want . 
B:  We would ?  
D:  We want to get  
D:  No . We wouldn't . 
B:  OK , but then so basically it 's just a  for every construction we have a node in the net , right ? And we turn on 
D:  Yeah . 
B:  that node . 
E:  Oy .  <laugh> 
D:  What  what is this gonna  Exactly . What is the uh  
D:  Well  
D:  <clear throat> <outbreath> 
B:  And then given that we know that  the construction  has these two things , we can set up probabilities  
A:  <cough> <sniff> 
B:  we can s basically define all the tables for ev for those  
D:  Yeah , it should be  So we have 
D:  um , 
D:  i let 's assume we  we call something like a loc - X node and a path - X node . <squeaking from writing on the white board> 
B:  <clears throat> 
D:  And what we actually get if we just look at the discourse , 
D:  " where is X " should activate 
D:  or should  
E:  Mmm . 
D:  Hmm . Should be both , 
D:  whereas maybe " where is X located " , 
D:  we find from the data , is always just asked when the person wants to know where it is , 
D:  and " how do I get to " is always asked when the person 
D:  just wants to know how to get there . 
D:  Right ? 
topic_description:	construction = node in net


B:  I d I just  I don't like having  characterizing the constructions with location and path , 
B:  or li characterizing them like that . Cuz you don't  
B:  It seems like in the general case you wouldn't know 
A:  <clears throat> 
B:  how  how to characterize them . I mean  or , for when . There could be an interpretation that we don't have a node for in the   
D:  You wouldn't . 
B:  I mean it just seems like @ @ has to have uh  a node for the construction 
B:  and then let the chips fall where they may . 
B:  Versus 
B:  uh , 
D:  <clear throat, outbreath> 
B:  saying , this construction either can mean location or path . 
B:  And , in this cas and since  since it can mean either of those things , it would light both of those up . 
D:  It 's the same . 
B:  Thoughts ? 
E:  <inbreath> 
B:  Questions ? 
E:  I 'm thinking about it . Um  
D:  It will be the same . So I think 
C:  <sniff> 
D:  r in here we have " I 'll go there " , right ? 
B:  Answers ? 
E:  <laugh-breath> 
D:  And we have our Info - on . 
D:  So in my c my case , this would 
A:  <sniff> 
D:  sort of make this  happy , and this would make the Go - there happy . 
D:  What you 're saying is we have a Where - X question , Where - X node , 
D:  that makes both happy . 
D:  Right ? That 's what you 're proposing , which is , in my mind just as fine . 
D:  So w if we have a construction  node , " where is X " , 
D:  it 's gonna 
D:  both 
D:  get the 
D:  po posterior probability that  it 's Info - on up , 
B:  Mmm , yeah . 
A:  <cough> 
D:  Info - on is True - up , and that Go - there is True - up , as well . 
A:  <sniff> 
D:  Which would be exactly analogous to what I 'm proposing is , 
D:  this makes  
D:  uh 
D:  makes something here true , and this makes something  also something here true , and this makes this True - up , and this makes this True - up as well . 
E:  I kinda like it better without that extra level of indirection too . You know with  with this points to this points to that , and so on because <inbreath> I don't know , it  
D:  Yeah , because we get  we get tons of constructions I think . Because , 
A:  Is - uh , 
E:  Yeah . 
D:  you know , mmm people have many ways of asking for the same thing , and  
B:  Yeah , sure . 
A:  Yeah . 
A:  So un 
topic_description:	characterise construction with location and path


A:  So I agree with that . I have a different kinda question , 
A:  might be related , 
A:  which is , OK so implicitly everything in EDU , we 're always inferring the speaker 
A:  intent , right ? 
A:  Like , what they want 
A:  either , the information that they want , or  
A:  It 's always information that they want probably , of some kind . 
A:  Right ? Or I  I don't know , or what 's something that they  
D:  The system doesn't massage you , no . No . 
A:  I  I  I don't  <laugh> 
E:  <laugh> 
D:  <laugh> 
A:  OK . So , um , 
E:  <mike noise> 
A:  let 's see . So I don't know if the  I mean i if th 
A:  just there 's more s here that 's not shown that you  it 's already like part of the system whatever , 
A:  but , " where is X " , 
A:  like , the fact that it is , you know , a speech - act , whatever , 
A:  it is a question . It 's a question that , 
A:  um , queries on some particular thing X , and X is that location . 
A:  There 's , like , a lot of structure in representing that . 
D:  Yep . Yeah . 
A:  So that seems different from just having the node " location - X " and that goes into EDU , right ? 
D:  Yeah . 
D:  <clear throat> Precisely . That 's  that 's  
D:  So , w 
A:  So tha is that what you 're t 
D:  Exactly . We have su we have specified two . 
A:  talking about ? wh what kinds of structure we want . 
D:  OK , the next one would be here , just for mood . 
E:  Mm - hmm . 
A:  Mm - hmm . 
D:  The next one would be what we can squeeze out of the uh 
A:  <sniff> 
D:  I don't know , maybe we wanna observe the uh , um , <clear throat> 
A:  Mmm . 
D:  <mouth> uh the length of  of the words used , and , or the prosody 
D:  and g a and t make conclusions about the user 's intelligence . I don't know , yeah . 
A:  OK . So in some ways  
A:  um , so in some ways in the other sort of parallel set of mo more linguistic meetings we 've been talking about possible semantics of some construction . 
E:  Mm - hmm . 
A:  Right ? Where it was 
A:  the simulation that 's , 
A:  according to it  you know , that  that corresponds to it , and as well the  as discourse , 
D:  Mm - hmm . 
A:  whatever , conte infor in discourse information , such as the mood , and , you know , other stuff . So , 
A:  are we looking for a sort of abbreviation of that , that 's tailored to this problem ? 
A:  Cuz that  that has , you know , basically , you know , 
A:  s it 's in progress still it 's in development still , but it definitely has various feature slots , attributes , 
D:  Mm - hmm . 
A:  um , bindings between things  
D:  Yeah . 
D:  U that 's exactly r um , why I 'm proposing  It 's too early to have  to think of them  of all of these 
A:  <sniff> 
A:  Uh - huh . 
D:  discourse things that one could possibly observe , 
A:  Mm - hmm . 
topic_description:	discourse information


D:  so let 's just assume 
A:  For the subset of  
D:  human beings are not allowed to ask anything but " where is X " . 
A:  OK . 
D:  This is the only utterance in the world . What could we observe from that ? 
A:  OK . That exactly " where is X " , not 
D:  In ter 
A:  the  the choices of " where is X " or " how do I get to X " . Just " where is X " . OK . 
E:  Yeah . 
D:  Just  just " where is X " . 
D:  And , but you know , do it  
A:  <cough> <sniff> 
D:  do it in such a way that we know that people can also say , " is the town hall in front of the bank " , 
D:  so that we need something like a w WH focus . Nuh ? Should be  
D:  should be there , that , you know , this  the  whatever we get from the  
A:  Wait , so do , or do not take other kinds of 
A:  constructions into account ? 
D:  Well , if you  if you can , oh definitely do , 
A:  OK . Where possible . OK . 
D:  where possible . Right ? 
D:  If i if  if it 's not at all triggered by our thing , then it 's irrelevant , and it doesn't hurt to leave it out for the moment . 
A:  Mm - hmm . 
D:  Um , but  
A:  OK . 
topic_description:	other constructions


D:  Think  Uh , well this is just a mental exercise . If you think about , 
A:  Yeah . 
D:  focus on this question , how would you design  that ?  
E:  Mm - hmm . 
D:  Is it  
D:  do you feel confident about saying this is part of the language already to  to detect those plans , and why would anyone care about location , if not , you know 
A:  <clears throat> 
E:  Mmm . 
D:  and so forth . 
D:  Or do you actually , 
D:  I mean this is perfectly legitimate , and I  I would not have any problems with erasing this and say , 
D:  that 's all we can activate , based on the utterance out of context . 
A:  Mm - hmm . 
A:  And just by an additional link  
A:  Oh . 
D:  What ? 
E:  Right . 
A:  Right , like , 
D:  And then the  the  the miracle that we get out the intention , Go - there , 
A:  with context and enough user information , yeah . 
E:  Yeah . 
A:  <clears throat> 
D:  happens , based on what we know about that entity , about the user , about his various beliefs , goals , desires , blah - blah - blah . 
D:  Absolutely fine . 
D:  But this is the sort of thing , I  I propose that we think about , 
A:  OK . 
topic_description:	mental exercise for design


D:  so that we actually end up with um , 
D:  um , 
D:  nodes for the discourse and ontology 
D:  so that we can put them into our Bayes - net , 
D:  never change them , 
D:  so we  all there is is " where is X " , 
D:  and , Eva can play around with the observed things , and we can run our better JavaBayes , and have it produce some output . And for the first time in th in  
D:  in the world , we look at our output , and um  and see uh whether it  
A:  <clears throat> <sniff> 
D:  it 's any good . <laugh> 
E:  <laugh> 
A:  OK . 
D:  You know ? I mean , <clear throat> 
E:  Here 's hoping . 
D:  Hmm ? 
E:  Here 's hoping . Right ? Now cross your fingers . 
E:  <mike noise> 
D:  Yeah , I  I mean , for me this is just a ba matter of curiosity , I wanna  
E:  Yeah .  Yeah . 
D:  would like to look at uh , 
D:  what this ad - hoc process of designing a belief - net would actually produce . 
topic_description:	output


D:  So th this might be a nice opening paragraph for the paper as saying , 
D:  " you know people look at kinds of  <clear throat> at ambiguities " , and 
D:  um , 
D:  in the literature there 's " bank " 
D:  and 
E:  Mm - hmm . 
D:  whatever kinds of garden path phenomenon . 
D:  And we can say , well , that 's all nonsense . 
E:  <laugh> 
D:  A , uh these things are never really ambiguous in discourse , 
A:  <clears throat> 
D:  B , don't ever occur really in discourse , but 
D:  normal statements that seem completely unambiguous , such as " where is the blah - blah " , 
E:  Mm - hmm . 
D:  actually are terribly complex , and completely ambiguous . 
E:  Mm - hmm . 
D:  And so , what every everybody else has been doing so far in  in  in  you know , has been completely nonsensical , and can all go into the wastepaper bin , 
A:  <laugh> 
E:  <laugh> That 's always a good way to begin . Yeah . Yeah . <laugh> 
D:  and the only  <laugh> 
D:  Yeah . <laugh> 
B:  <laugh> 
C:  <laugh> 
D:  And the  the  the only  
B:  I am great .  
E:  <laugh> All others are useless .  
D:  Yeah . <laugh> 
C:  <laugh> 
B:  <laugh> 
D:  Yeah . 
E:  That 's good . 
D:  Nice overture , but , you know , just not really  
C:  <sniff> 
D:  OK , I 'm eja exaggerating , but that might be , you know , 
D:  saying " hey " , you know , 
D:  some stuff is  is actually 
D:  complex , if you look at it in  in  in the vacuum 
E:  Mm - hmm . 
D:  and  and ceases to be complex in reality . And some stuff that 's as  that 's absolutely straightforward in the vacuum , 
E:  <laugh> 
D:  is actually terribly complex in reality . 
D:  Would be nice sort of , uh , also , nice , um 
D:  bottom - up linguistics , um , 
D:  type message . 
E:  Mm - hmm . 
E:  True . 
D:  Versus the old top - down school . 
topic_description:	ambiguity


D:  I 'm running out of time . OK . 
B:  When do you need to start wizarding ? <outbreath> 
D:  At four ten . 
D:  OK , this is the other bit of news . 
D:  The subjects today know Fey , so she can't be here , and do the wizarding . 
E:  Huh . 
D:  So I 'm gonna do the wizarding and Thilo 's gonna do the instructing . Also we 're getting a  a person who just got fired 
B:  <outbreath> 
B:  Mmm . 
D:  uh , from her job . 
D:  Uh a person from Oakland who is interested in maybe continuing the wizard bit once Fey leaves in August . 
E:  <mike noise> 
D:  <mike noise> 
E:  <laugh> 
D:  And um , she 's gonna look at it 
D:  today . 
D:  <inbreath> 
D:  Which is good news in the sense that if we want to continue , 
D:  after the thir 
D:  thir after July , we can . We could . 
D:  And , um  
D:  and that 's also 
D:  maybe interesting for Keith and whoever , 
D:  if you wanna get some more stuff into the data collection . 
D:  Remember this , we can completely change the set - up any time we want . 
E:  Mm - hmm . 
E:  <mike noise> OK . 
D:  Look at the results we 've gotten so far for the first , 
A:  <sniff> 
D:  whatever , fifty some 
D:  subjects ? 
A:  Fifty ? You 've had fifty so far , or  ? 
D:  No , we 're approaching twenty now . But , until Fey is 
A:  OK . 
A:  Yeah . 
D:  leaving , we surely will hit the  
A:  <clears throat> <sniff> 
D:  some of the higher numbers . 
A:  Hmm . 
D:  And um , 
D:  so that 's cool . 
topic_description:	data collection


D:  Can 
D:  a 
D:  do more funky stuff . 
E:  Sure . 
E:  Yeah , I 'll have to look more into that data . Is that around ? Like , cuz that 's pretty much getting posted or something right away when you get it ? Or  ? I guess it has to be transcribed , huh ? 
D:  Um . 
D:  We have uh , eh found someone here who 's hand st hand transcribing the first twelve . 
E:  OK . 
D:  First dozen subjects  
E:  Uh - huh . 
D:  just so we can build a  a language model for the recognizer . 
E:  OK . 
D:  But , um  So those should be available soon . 
E:  OK . 
D:  The first twelve . And 
D:  I can ch ch st e 
E:  You know  
E:  I mean you know that I  that I looked at the first  the first one and got enough data to keep me going for , you know , probably most of July . So . 
A:  <laugh> 
D:  <laugh> 
E:  <inbreath> But , um . 
C:  <laugh> 
B:  <laugh> 
E:  Yeah , a probably not the right way to do it actually . 
D:  But you can listen to  
D:  a y y y You can listen to all of them from your Solaris box . 
E:  OK . 
D:  If you want . 
E:  Right . 
D:  It 's always fun . 
topic_description:	data available


E:  <mike noise>  
A:  <mike sound>  
topic_description:	closing


