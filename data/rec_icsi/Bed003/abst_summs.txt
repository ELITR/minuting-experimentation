B:  Um right now it 's still kind of  in a toy  version of it , 
abst_sum - abstract: The group discussed the first version of the Bayes-net used to work out a user's intentions when asking for directions from a navigation device.

B:  The probability  whether the probability of a Vista , Tango , or Enter . 
abst_sum - abstract: Three intentions were identified: Vista (to view), Enter (to visit) and Tango (to approach).

B:  So then the features we decided  or we decided we were  talked about , 
B:  You know . We had a list of things like " to go " and " to visit " and what not . 
B:  Uh the  the prosody , the discourse ,  verb choice . 
D:  So there are certain cues that are very strong  either lexical or topic - based um , concept cues 
D:  and some of them are sort of <breath> either world knowledge or situational  things . 
A:  is that maybe we ob we could observe a couple of um discourse phenomena such as the admission fee , 
abst_sum - abstract: The structure of the belief-net comprises, firstly, a feature layer, which includes linguistic, discourse and world knowledge information that can be gleaned from the data.

A:  So maybe this could be sort of a separate region of the net ,  which has two   has it 's own middle layer . 
A:  They ra may have there own hidden layer  that points to some of  the  the real hidden layer , um or the general hidden layer . 
abst_sum - abstract: It is possible for these variables to form thematic clusters( eg "entrance", "type of object", "verb"), each one with a separate middle layer.

B:  but the middle thing , we were thinking along the lines of maybe trying to figure out , like , the concept of whether they 're a tourist  or  whether they 're running an errand or something like that 
B:  So then the hidden variables  hair variables we came up with were whether someone was on a tour , running an errand , or whether they were in a hurry , 
C:  but the other ones , the final destination , the whether they 're doing business , whether they 're in a hurry , and whether they 're tourists , 
A:  They ra may have there own hidden layer  that points to some of  the  the real hidden layer , um or the general hidden layer . 
A:  And then these should then connect somehow to the more plan - based deep space 
abst_sum - abstract: These feed, in turn, into the main middle layer, that defines more general hidden variables, such as the tourist/business status of the user.

D:  So there are certain cues that are very strong  either lexical or topic - based um , concept cues 
A:  so <breath> maybe what  what  what happened  what might happen is that we do get this sort of task - based middle layer , 
D:  entering or som you know like they might be more task - based . 
abst_sum - abstract: The feature layer can end up being cue-based, while the middle layers task-based.

B:  So . The mode  basically has three different  outputs . 
abst_sum - abstract: The latter determine the final probability of each intention in the output layer.

C:  it 's cra has a GUI and it 's uh  
C:  But uh  it 's free . 
B:  But actually it had an interface . 
B:  and he 's updated it for an XML version of I guess Bayes - nets . 
abst_sum - abstract: This first model of the belief-net was built in JavaBayes, since it is a free package, has a graphical interface, and it can take XML files as input.

C:  Like ,  we totally hand - tuned the probabilities , 
C:  The probabilities and all are completely ad - hoc . 
abst_sum - abstract: At this stage, all the actual probabilities are ad-hoc and hand-coded.

A:  But um  in terms of specifying the scenario , <breath> um  uh  uh  we 've gotten a little further 
A:  So we wanted just to collect data , to get  that  that  that  elicits more , uh , that elicits richer language . 
abst_sum - abstract: However, there has been progress in the design and organisation of experiments, that will eventually provide data more useful and appropriate for this task.

B:  So then our next idea was to add a middle layer , 
B:  Uh  we kept um  things from directly affecting the mode  beyond the concept , 
B:  But we just decided to keep all the things we extracted  to point at the middle and then  down . 
B:  I guess , the fact that the  there 's a complete separation between the  observed features and in the output . 
abst_sum - decisions: It is necessary for the belief-net to have at least one layer of nodes between the features and the final output.

None
abst_sum - decisions: This makes the structure more flexible in terms of coding feature-layer probabilities.

A:  is that maybe we ob we could observe a couple of um discourse phenomena such as the admission fee , 
A:  So maybe this could be sort of a separate region of the net ,  which has two   has it 's own middle layer . 
B:  That would all f funnel into one node that would  constitute entrance requirements or something like that . 
A:  They ra may have there own hidden layer  that points to some of  the  the real hidden layer , um or the general hidden layer . 
abst_sum - decisions: Another technique to systematise the work is the thematic clustering of the features, each cluster forming a Bayes-net of each own: for example features like "admission fee" and "opening hours" can feed into an intermediate "entrance" node connecting to the main middle layer.

A:  So , um I suggest w to  for  to proceed with this in  in the sense that  maybe throughout this week the three of us will  will talk some more about maybe segmenting off different regions , 
A:  Identify  four regions , 
A:  maybe make up some features for each region 
abst_sum - decisions: The next stage is to refine the set of feature nodes and identify possible clusters.

D:  So one thing that might be helpful which is implicit in the  use of " admission fee discussion " as a cue for entry , <breath>  is thinking about the plans that various people might have . 
D:  They 're  in  in non in sort of more traditional AI kinds of plan recognition things you sort of have <breath>  you know , some idea at each turn of agent doing something , 
A:  I mean there are some  some of them are extremely elaborate , 
abst_sum - decisions: Although, in theory, traditional AI plan recognition techniques could also be helpful for inferring intentions, the schemas involved are too elaborate for this task.

C:  Yeah , another thing to do , um , is also to , um  I guess to ask around people about other Bayes - net packages . 
abst_sum - decisions: Further work also includes discussing the possible advantages of Bayes-net packages, other than JavaBayes, with experts at ICSI.

C:  we can maybe write an interface th for uh entering probability distributions easily , 
C:  something like  like a little script . 
C:  I think it might  it might be simpler to just  have a script that , you know  
abst_sum - decisions: If they continue using JavaBayes, a script to help with the inputting of probabilities in the nodes is needed, as the in-built method is cumbersome.

D:  Like we wanna  we wanna be able to collect <breath> as much of the variables that are needed for that , 
A:  So now I think we should maybe have at least one navigational task with  with sort of explicit  uh 
abst_sum - decisions: Finally, it was decided that at least some of the experiments designed for the new data collection initiative will factor in the intentions studied in the current task.

None
abst_sum - problems: The set of cues that form the feature nodes is not well-defined yet.

C:  That 's  that  that needs a lot of work . 
abst_sum - problems: Especially with lexical cues (verbs, modifiers etc), no one offered specific intuitions as to how they might contribute to the inference of intentions.

B:  because we didn't know the probabilities of   or  
C:  So that 's like a huge uh clue that they 're trying to Enter the place rather than uh to Tango or Vista , 
C:  Like ,  we totally hand - tuned the probabilities , 
C:  The probabilities and all are completely ad - hoc . 
abst_sum - problems: Other features, like "admission fee", may be intuitively linked with one of the outputs (Enter), however, any probabilities are coded in an ad-hoc fashion and are by no means realistic.

B:  but you could see perhaps discus the " admission fee " going directly to the mode pointing at " Enter " , 
B:  well for instance , the " discourse admission fee "  node seems like it should point directly to the  
B:  or increase the probability of " enter  directly " versus " going there via tourist " . 
abst_sum - problems: Cases like this, where feature and output seem to be linked directly, bring the necessity of a middle layer in the belief-net to question.

B:  Reasons being , you know , it 'd be a pain to set up all the probabilities for that . 
B:  If we moved onto the next step and did learning of some sort , uh according Bhaskara we 'd be handicapped . 
abst_sum - problems: Nevertheless, not having a middle layer would not allow for shifts in the discourse and would make the setting of probabilities and manipulation of the belief-net clumsy.

C:  It might be that if you add a new thing pointing to a variable , you just like  it just overwrites everything . 
C:  But  they 're not very friendly . 
abst_sum - problems: Some issues with the use of JavaBayes also arose: the addition of new variables in an existing node overwrites all previous settings, and the native text file where the probability tables are set is not easy to read; this makes adding and changing variables and nodes problematic.

B:  I didn't think it did learning . 
abst_sum - problems: Finally, it is unclear how much learning can be done on the created nets.

