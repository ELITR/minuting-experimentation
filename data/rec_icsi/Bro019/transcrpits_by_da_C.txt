C:  Sure . 
C:  Uh , is it the twenty - fourth ? 
C:  Yeah . 
C:  Yeah . 
C:  Yeah . 
C:  We uh  we abandoned the lapel 
C:  because they sort of were not too  not too hot , not too cold , 
C:  they were  you know , they were <inbreath> uh , far enough away that you got more background noise , uh , and uh  and so forth 
C:  but they weren't so close that they got quite the  you know , the really good  No , th 
C:  they  I mean they didn't  
C:  Wait a minute . 
C:  I 'm saying that wrong . 
C:  They were not so far away that they were really good representative distant mikes , 
C:  but on the other hand they were not so close that they got rid of all the interference . 
C:  So it was no  didn't seem to be a good point to them . 
C:  On the other hand if you only had to have one mike in some ways you could argue the lapel was a good choice , 
C:  precisely because it 's in the middle . 
C:  There 's uh , some kinds of junk that you get with these things that you don't get with the lapel 
C:  uh , little mouth clicks and breaths and so forth are worse with these than with the lapel , 
C:  but 
C:  given the choice we  there seemed to be very strong opinions for uh , getting rid of lapels . 
C:  So , 
C:  And you should do a lot of talking so we get a lot more of your pronunciations . 
C:  no , they don't  don't have a  have any Indian pronunciations . 
C:  Yeah . 
C:  Session R 
C:  R - nineteen . 
C:  If you say so . 
C:  O K . 
C:  Do we have anything like an agenda ? 
C:  What 's going on ? 
C:  Um . 
C:  I guess 
C:  um . 
C:  So . 
C:  One thing  
C:  Sunil 's here for the summer , 
C:  right . 
C:  Um , 
C:  so , one thing is to talk about a kick off meeting 
C:  maybe 
C:  uh , 
C:  and then just uh , I guess uh , progress reports individually , and then uh , plans for where we go between now and then , pretty much . 
C:  Um . 
C:  Mm - hmm . 
C:  OK . 
C:  Why don't you start with that ? 
C:  That 's sort of  
C:  Yeah ? 
C:  How about an email that points to the FAQ , 
C:  you know what I 'm saying ? 
C:  so that you can  
C:  Yeah . 
C:  So as I understand , you know , he 's using all the machines and you 're using all the machines , 
C:  is the rough division of  
C:  I remember I  I forget whether it was when the Rutgers or  or Hopkins workshop , 
C:  I remember one of the workshops I was at there were  everybody was real excited cuz they got twenty - five machines 
C:  and there was some kind of P - make like thing that sit sent things out . 
C:  So all twenty - five people were sending things to all twenty - five machines 
C:  and <laugh> and things were a lot less efficient than if you 'd just use your own machine . 
C:  as I recall , 
C:  but . 
C:  Yeah . 
C:  So " run command " doesn't use P - make , or  ? 
C:  So why would one use that rather than P - make ? 
C:  Now , does it have the same sort of behavior as P - make , 
C:  which is that , you know , if you run something on somebody 's machine and they come in and hit a key then it  
C:  Mm - hmm . 
C:  Mm - hmm . 
C:  Um , what  what about  
C:  I remember always used to be an issue , maybe it 's not anymore , that if you  if something required  if your machine required somebody hitting a key in order to evict things that are on it so you could work , 
C:  but if you were logged into it from home ? 
C:  and you weren't hitting any keys ? cuz you were , home ? 
C:  Yeah . 
C:  Hmm . 
C:  OK . 
C:  We can ask him sometime . 
C:  You probably wouldn't ordinarily , though . 
C:  Yeah . Right ? 
C:  You probably wouldn't ordinarily . 
C:  I mean you sort of  
C:  you 're at home and you 're trying to log in , 
C:  and it takes forever to even log you in , 
C:  and you probably go , " screw this " , 
C:  and  <laugh> You know . 
C:  Yeah . 
C:  yeah . 
C:  OK . 
C:  OK . 
C:  Well , why don't we uh , 
C:  uh , 
C:  Sunil since you 're <inbreath> haven't  haven't been at one of these yet , why don't yo you tell us what 's  what 's up with you ? 
C:  Wh - what you 've been up to , hopefully . 
C:  Yeah . 
C:  Uh , can you back up a second , 
C:  I  I  I missed something , 
C:  uh , 
C:  I guess my mind wandered . 
C:  Ad - ad When you added the on - line normalization and so forth , uh , uh things got better again ? 
C:  or is it ? 
C:  Did it not ? 
C:  No , no . 
C:  With a different time constant . 
C:  Oh . 
C:  No you didn't , 
C:  OK . 
C:  Yeah . 
C:  OK . 
C:  OK . 
C:  OK . 
C:  Hmm . 
C:  G I guess the issue is that people do that anyway , 
C:  everybody does that , 
C:  and they wanted to see , given that you 're doing that , what  what are the best features that you should use . 
C:  I mean clearly they 're interact . 
C:  So I don't know that I entirely agree with it . 
C:  But  but it might be uh  In some ways it might be better t to  rather than giving the endpoints , to have a standard that everybody uses and then interacts with . 
C:  But , you know . It 's  it 's still someth reasonable . 
C:  So it should make the spectral subtraction style things work even better , 
C:  because you don't have the mistakes in it . 
C:  Yeah ? 
C:  OK . 
C:  Yeah . 
C:  So it 's g it 's gonna be harder to <breath-laugh> beat that actually . 
C:  But  but  
C:  OK . 
C:  No , that 's  that 's  that 's a good  good update . 
C:  Yeah . 
C:  Mm - hmm . 
C:  Yeah . 
C:  S 
C:  So you s you So you said one thing I want to jump on for a second . 
C:  So  so now you 're  you 're getting tuned into the repository thing that he has here 
C:  and  so we we 'll have a <inbreath> single place where the stuff is . 
C:  Cool . 
C:  Um , 
C:  so maybe uh , just briefly , you could remind us about the related experiments . 
C:  Cuz you did some stuff that you talked about last week , 
C:  I guess ? 
C:  Um , where you were also combining something  
C:  both of you I guess were both combining something from the uh , French Telecom system with <inbreath> the u uh  
C:  I  I don't know whether it was system one or system two , 
C:  or  ? 
C:  OK . 
C:  So I let me  let me just stop you there . 
C:  So then , one distinction is that uh , you were taking the actual France Telecom features and then applying something to  
C:  Yeah . 
C:  Yeah . 
C:  But that 's what I mean . 
C:  But u u 
C:  Sorry , 
C:  yeah , I 'm not being  I 'm not being clear . 
C:  What I meant was you had something like cepstra or something , right ? 
C:  And so one difference is that , I guess you were taking spectra . 
C:  But you got some sort of different result . 
C:  So I 'm trying to understand it . 
C:  But uh , 
C:  I th 
C:  So it sounds like you should look at some tables of results or something 
C:  and see where i where the  <inbreath> where they were different and what we can learn from it . 
C:  Mm - hmm . 
C:  Right . 
C:  But are they changing the weighting ? 
C:  I don't understand that . 
C:  I guess I  I haven't been part of the discussion , 
C:  so , um , 
C:  it seems to me that the well - matched condition is gonna be unusual , 
C:  in this case . 
C:  Unusual . 
C:  Because , um , you don't actually have good matches ordinarily for what any @ @  particular person 's car is like , 
C:  or 
C:  uh , 
C:  It seems like something like the middle one is  is more natural . 
C:  So I don't know why the  well - matched is 
C:  uh  
C:  The well wa matched has mismatch ? 
C:  Yeah . 
C:  Yeah . 
C:  So remind me of what well - matched meant ? 
C:  You 've told me many times . 
C:  Yeah . 
C:  Right . 
C:  So , I mean , 
C:  yeah , unless they deliberately chose it to be different , which they didn't because they want it to be well - matched , 
C:  it is pretty much  
C:  You know , so it 's  so it 's sort of saying if you  
C:  Uh , it 's not guaranteed . 
C:  Right . 
C:  Right . 
C:  Again , if you have enough  if you have enough  
C:  So it 's sort of i i it 's sort of saying OK , 
C:  so you  much as you train your dictation machine for talking into your computer , um , you  you have a car , 
C:  and so you drive it around a bunch and  and record noise conditions , or something , 
C:  and then  I don't think that 's very realistic , 
C:  I mean I th 
C:  I  I you know , 
C:  so I  
C:  I  I  you know , 
C:  I guess they 're saying that if you were a company that was selling the stuff commercially , that you would have a bunch of people driving around in a bunch of cars , 
C:  and  and you would have something that was roughly similar 
C:  and maybe that 's the argument , 
C:  but I 'm not sure I buy it , 
C:  so . 
C:  Uh , 
C:  So 
C:  What else is going on ? 
C:  Hmm . 
C:  OK . 
C:  Mm - hmm . 
C:  Well , the other thing would be to combine what you 're doing . 
C:  I mean maybe one or  one or the other of the things that you 're doing would benefit from the other happening first . 
C:  Right , 
C:  so he 's doing a signal subspace thing , 
C:  maybe it would work better if you 'd already done some simple spectral subtraction , 
C:  or maybe vi maybe the other way around , 
C:  you know ? 
C:  How is it  
C:  I  I guess I 'm ignorant about this , 
C:  how does  
C:  I mean , since Wiener filter also assumes that you 're  that you 're adding together the two signals , how is  how is that differ from signal subspace ? 
C:  Yeah . 
C:  Oh , OK . 
C:  Oh , oh , OK 
C:  so the difference is the KL . 
C:  I see . 
C:  So essentially you could do simple spectral subtraction , followed by a KL transform , followed by a 
C:  Wiener filter . 
C:  Yeah , in general , you don't  
C:  that 's right 
C:  you don't wanna othorg orthogonalize if the things are noisy . 
C:  Actually . 
C:  Um , that was something that uh , Herve and I were talking about with um , the multi - band stuff , 
C:  that if you 're converting things to from uh , bands , groups of bands into cepstral coef you know , local sort of local cepstral coefficients that it 's not that great to do it if it 's noisy . 
C:  Uh , 
C:  so . 
C:  Yeah . 
C:  So you should do spectral subtraction and then add noise . 
C:  Yeah . 
C:  Yeah . 
C:  I was only half kidding . 
C:  I mean if you  sort of <laugh> you do the s spectral subtraction , that also gets rid  
C:  and then you  then  then add a little bit l noise  noise addition  
C:  I mean , that sort of what J  JRASTA does , in a way . 
C:  If you look at what JRASTA doing essentially i i it 's equivalent to sort of adding a little  adding a little noise , 
C:  in order to get rid of the effects of noise . 
C:  OK . 
C:  Mm - hmm . 
C:  Yes . 
C:  Who is doing this ? 
C:  Who 's the guy in Grenada ? 
C:  I don't know him . 
C:  Uh - huh . 
C:  Uh - huh . 
C:  Yeah , so at any rate , you 're looking general , uh , standing back from it , looking at ways to combine one form or another of uh , noise removal , uh , with  with these other things we have , 
C:  uh , looks like a worthy thing to  to do here . 
C:  Oh yeah . 
C:  Well one of the  seems like one of the things to go through next week when Hari 's here , 
C:  cuz Hari 'll have his own ideas too  
C:  or  I guess not next week , 
C:  week and a half , 
C:  uh , will be sort of go through these alternatives , 
C:  what we 've seen so far , 
C:  and come up with some game plans . 
C:  Um . 
C:  You know . 
C:  So , I mean one way would  
C:  he Here are some alternate visions . 
C:  I mean one would be , you look at a few things very quickly , 
C:  you pick on something that looks like it 's promising 
C:  and then everybody works really hard on the same  different aspects of the same thing . 
C:  Another thing would be to have t to  to pick two pol two plausible things , 
C:  and  and you know , have t sort of two working things for a while until we figure out what 's better , 
C:  and then , 
C:  you know , 
C:  uh , 
C:  but , w um , 
C:  uh , he 'll have some ideas on that too . 
C:  So they 're making  
C:  there  Somebody 's generating Wall Street Journal with additive  artificially added noise or something ? 
C:  Sort of a  sort of like what they did with TI - digits , and ? 
C:  Yeah , OK . 
C:  OK . 
C:  And then they 're  they 're uh , uh , generating HTK scripts to  
C:  Mis - Mississippi State maybe , 
C:  yeah . 
C:  Yeah , so that 'll be a little  little task in itself . 
C:  Um , 
C:  well we 've  
C:  Yeah , it 's true for the additive noise , y artificially added noise we 've always used small vocabulary too . 
C:  But for n there 's been noisy speech this larv large vocabulary that we 've worked with in Broadcast News . 
C:  So we we did the Broadcast News evaluation 
C:  and some of the focus conditions were noisy 
C:  and  and  
C:  But we  but we didn't do spectral subtraction . 
C:  We were doing our funny stuff , right ? 
C:  We were doing multi multi uh , multi - stream and  and so forth . 
C:  But it , you know , we di stuff we did helped . 
C:  I mean it , did something . 
C:  So . 
C:  Um , 
C:  now we have this um , meeting data . 
C:  You know , like the stuff we 're  recording right now , 
C:  and  
C:  and uh , 
C:  that we have uh , for the  uh , the quote - unquote noisy data there is just  noisy and reverberant actually . 
C:  It 's the far field mike . 
C:  And uh , we have uh , the digits that we do at the end of these things . 
C:  And that 's what most o 
C:  again , most of our work has been done with that , 
C:  with  with uh , connected digits . 
C:  Um , 
C:  but uh , we have recognition now with some of the continuous speech , 
C:  large vocabulary continuous speech , using Switchboard  uh , Switchboard recognizer , 
C:  uh , 
C:  no training , <laugh> from this , 
C:  just  just plain using the Switchboard . 
C:  That 's  that 's what we 're doing , 
C:  yeah . 
C:  Now there are some adaptation though , 
C:  that  that uh , Andreas has been playing with , 
C:  but we 're hop 
C:  uh , actually uh , Dave and I were just talking earlier today about maybe at some point not that distant future , trying some of the techniques that we 've talked about on , uh , some of the large vocabulary data . 
C:  Um , 
C:  I mean , I guess no one had done  yet done test one on the distant mike using uh , the SRI recognizer 
C:  and , uh , 
C:  Yeah , 
C:  cuz everybody 's scared . 
C:  You 'll see a little smoke coming up from the  the CPU or something <laugh> trying to  trying to do it , 
C:  but 
C:  uh , yeah . 
C:  But , you 're right 
C:  that  that  that 's a real good point , that uh , we  we don't know yeah , uh , I mean , what if any of these ta 
C:  I guess that 's why they 're pushing that in the uh  in the evaluation . 
C:  Uh , 
C:  But um , 
C:  Good . 
C:  OK . 
C:  Anything else going on ? 
C:  at you guys ' end , 
C:  or  ? 
C:  Yeah . 
C:  So maybe  You probably need to back up a bit 
C:  seeing as how Sunil , 
C:  yeah . 
C:  I  I  I really wonder though . 
C:  I mean we 've had these discussions before , 
C:  and  and one of the things that struck me was that  uh , about this line of thought that was particularly interesting to me was that we um  whenever you condense things , uh , in an irreversible way , um , you throw away some information . 
C:  And , that 's mostly viewed on as a good thing , in the way we use it , 
C:  because we wanna suppress things that will cause variability for uh particular , uh , phonetic units . 
C:  Um , 
C:  but , you 'll do throw something away . 
C:  And so the question is , uh , can we figure out if there 's something we 've thrown away that we shouldn't have . 
C:  And um . 
C:  So , 
C:  when they were looking at the difference between the filter bank and the FFT that was going into the filter bank , I was thinking " oh , OK , 
C:  so they 're picking on something 
C:  they 're looking on it to figure out noise , or voice  voiced property whatever . " 
C:  So that  that 's interesting . 
C:  Maybe that helps to drive the  the thought process of coming up with the features . 
C:  But for me sort of the interesting thing was , " well , but is there just something in that difference which is useful ? " 
C:  So another way of doing it , maybe , would be just to take the FFT uh , power spectrum , and feed it into a neural network , 
C:  and then use it , you know , in combination , or alone , or  or whatever 
C:  Uh , no . 
C:  No 
C:  the  just the same  same way we 're using  I mean , the same way that we 're using the filter bank . 
C:  Exact way  the same way we 're using the filter bank . 
C:  I mean , the filter bank is good for all the reasons that we say it 's good . 
C:  But it 's different . 
C:  And , you know , maybe if it 's used in combination , it will get at something that we 're missing . 
C:  And maybe , you know , using , orth you know , KLT , or uh , um , adding probabilities , I mean , all th all the different ways that we 've been playing with , that we would let the  essentially let the neural network determine what is it that 's useful , that we 're missing here . 
C:  Well , that 's probably why y i it would be unlikely to work as well by itself , 
C:  but it might help in combination . 
C:  But I  I  I have to tell you , 
C:  I can't remember the conference , 
C:  but , uh , I think it 's about ten years ago , I remember going to one of the speech conferences 
C:  and  and uh , 
C:  I saw within very short distance of one another a couple different posters that showed about the wonders of some auditory inspired front - end or something , 
C:  and a couple posters away it was somebody who compared one to uh , just putting in the FFT 
C:  and the FFT did slightly better . 
C:  So I mean the  i i It 's true there 's lots of variability , 
C:  but again we have these wonderful statistical mechanisms for quantifying that a that variability , and you know , doing something reasonable with it . 
C:  So , 
C:  um , 
C:  uh , 
C:  It - it 's same , you know , argument that 's gone both ways about uh , you know , we have these data driven filters , in LDA , 
C:  and on the other hand , if it 's data driven it means it 's driven by things that have lots of variability , and that are necessarily  not necessarily gonna be the same in training and test , 
C:  so , in some ways it 's good to have data driven things , 
C:  and in some ways it 's bad to have data driven things . 
C:  So , 
C:  part of what we 're discovering , is ways to combine things that are data driven than are not . 
C:  Uh , so anyway , it 's just a thought , that  that if we  if we had that  maybe it 's just a baseline 
C:  uh , which would show us " well , what are we really getting out of the filters " , 
C:  or maybe i i 
C:  probably not by itself , 
C:  but in combination , 
C:  uh , 
C:  you know , maybe there 's something to be gained from it , 
C:  and let the  
C:  But , you know , y you 've only worked with us for a short time , 
C:  maybe in a year or two you w you will actually come up with the right set of things to extract from this information . 
C:  But , maybe the neural net and the H M Ms could figure it out quicker than you . 
C:  So . 
C:  It 's just a thought . 
C:  Yeah . 
C:  Mm - hmm . 
C:  And it 's particularly more relevant now since we 're gonna be given the endpoints . 
C:  So . 
C:  Uh . 
C:  So . 
C:  Um . 
C:  Talking cumulants or something ? 
C:  Cumulants or something . 
C:  But  No . 
C:  Yeah , 
C:  cumulants , 
C:  yeah . 
C:  Oh . 
C:  Or m e 
C:  Yeah . 
C:  Uh . 
C:  Yeah , but again  You could argue that th that 's exactly what the neural network does . 
C:  So n neural network uh , is in some sense equivalent to computing , you know , higher - order moments of what you  
C:  yeah . 
C:  So . 
C:  I mean , it doesn't do it very specifically , 
C:  and 
C:  pretty  you know . 
C:  But . 
C:  Uh , 
C:  anything on your end you want to talk about ? 
C:  Uh . 
C:  Yeah . 
C:  By  by the way , uh , the voiced - unvoiced version of that for instance could tie right in to what Carmen was looking at . 
C:  So , 
C:  you know , um , if you  if a multi - band approach was helpful as  as I think it is , 
C:  it seems to be helpful for determining voiced - unvoiced , 
C:  that one might be another thing . 
C:  Oh no . 
C:  So you live in a cardboard box in the street now 
C:  or , no ? 
C:  Yeah . 
C:  Suni - i d ' you v did uh  did you find a place ? 
C:  Is that out of the way ? 
C:  OK . 
C:  OK . 
C:  And then , you 're coming back uh  
C:  Thirty - first , 
C:  OK . 
C:  Well , I mean i i if  if  
C:  They 're available , 
C:  and they 'll be able to get you something , 
C:  so worst comes to worst we 'll put you up in a hotel for  for  for a while 
C:  until you  
C:  OK . 
C:  So a two bedroom cardboard box . 
C:  Th - that 's great . 
C:  Thanks Dave . 
C:  Um , 
C:  Do y wanna say anything about  
C:  You  you actually been  
C:  Uh , last week you were doing this stuff with Pierre , you were  you were mentioning . 
C:  Is that  that something worth talking about , 
C:  or  ? 
C:  It 's a r root LPC , uh , of some sort . 
C:  Yeah . 
C:  No , no . 
C:  It 's  it 's  it 's taking the  finding the roots of the LPC polynomial . 
C:  So it 's like line spectral pairs . 
C:  Except I think what they call line spectral pairs they push it towards the unit circle , 
C:  don't they , 
C:  to sort of ? 
C:  But it  
C:  But uh , you know . 
C:  But what we 'd used to do w when I did synthesis at National Semiconductor twenty years ago , the technique we were playing with initially was  was taking the LPC polynomial and  and uh , finding the roots . 
C:  It wasn't PLP cuz Hynek hadn't invented it yet , 
C:  but it was just LPC , 
C:  and uh , we found the roots of the polynomial , 
C:  And th When you do that , sometimes they 're f they 're what most people call formants , 
C:  sometimes they 're not . 
C:  So it 's  it 's  it 's a little , 
C:  uh  Formant tracking with it can be a little tricky 
C:  cuz you get these funny <inbreath> values in  in real speech , 
C:  but . 
C:  Well you get these complex pairs . 
C:  And it depends on the order that you 're doing , 
C:  but . 
C:  Yeah . 
C:  This is from synthetic speech , 
C:  or  ? 
C:  Yeah . 
C:  So if it 's from synthetic speech then maybe it 'll be cleaner . 
C:  I mean for real speech in real  then what you end up having is , like I say , funny little things that are  don't exactly fit your notion of formants all that well . 
C:  But  but mostly they are . 
C:  Mostly they do . 
C:  And  and what  I mean in  in what we were doing , which was not so much looking at things , it was OK 
C:  because it was just a question of quantization . 
C:  Uh , we were just you know , storing  
C:  It was  We were doing , uh , stored speech , uh , quantization . 
C:  But  but uh , in your case 
C:  um , you know  
C:  I bet it  it might have  may have been 
C:  but maybe he didn't have control over it or something ? 
C:  Yeah . 
C:  Yeah , 
C:  so the actual  
C:  So you 're not getting the actual formants per se . 
C:  You 're getting the  Again , you 're getting sort of the , 
C:  uh  
C:  You 're getting something that is  is uh , af strongly affected by the PLP model . 
C:  And so it 's more psycho - acoustic . 
C:  So it 's a little  It 's  It 's  It 's sort of  sort of a different thing . 
C:  But  Yeah . 
C:  i Ordinarily , in a formant synthesizer , the bandwidths as well as the ban uh , formant centers are  
C:  I mean , that 's  Somewhere in the synthesizer that was put in , 
C:  as  as what you  
C:  But  but yeah , 
C:  you view each complex pair as essentially a second - order section , 
C:  which has , uh , band center and band width , 
C:  and um , 
C:  um  
C:  But . 
C:  Yeah . 
C:  O K . 
C:  So , uh , 
C:  yeah , you 're going back today 
C:  and then back in a week I guess , 
C:  and . 
C:  Yeah . 
C:  Great ! 
C:  Well , welcome . 
C:  Oh yeah , digits . 
C:  I almost forgot that . 
C:  I almost forgot our daily digits . 
C:  Sure . 
