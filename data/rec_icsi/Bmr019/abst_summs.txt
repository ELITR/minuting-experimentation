B:  And the interesting thing is that even though , <inbreath> yes , it 's a digits task and that 's a relatively small number of words and there 's a bunch of digits that you train on , <inbreath> it 's just not as good as having a  a l very large amount of data and training up a  a  a nice good big <inbreath> HMM . 
abst_sum - abstract: The Berkeley Meeting Recorder group discussed efforts to train and test the Aurora group's HTK-based recognition system on ICSI's digits corpus.

E:  Two items , which was , uh , digits and possibly stuff on  on , uh , forced alignment , 
A:  So we  we only r hav I only looked at actually alignments from one meeting that we chose , 
abst_sum - abstract: Members also discussed efforts to produce forced alignments from a selection of Meeting Recorder data.

B:  Uh , but the other is that , um , the digits <inbreath> recorded here in this room with these close mikes , i uh , are actually a lot harder than the  studio - recording TI - digits . 
F:  If you have only one utterance per speaker you might actually screw up on estimating the  the warping , uh , factor . 
G:  Well , I know there were some speaker labelling problems , um , after interruptions . 
G:  But you 're actually saying that certain , uh , speakers were mis mis - identified . 
abst_sum - abstract: Performance in both tasks was adversely affected by the manner of recording conditions implemented and difficulties attributing utterances to the appropriate speakers.

A:  and  and  W we  we were able to get some definite improvement on the forced alignments by looking at them first and then realizing the kinds of errors  that were occurring 
A:  So just sort of working through a bunch of debugging kinds of issues . 
abst_sum - abstract: While debugging efforts resulted in improved forced alignments, dealing with mixed channel speech and speaker overlap remains a key objective for future work.

F:  So  so the key  thing that 's missing here is basically the ability to feed , you know , other features <outbreath> i into the recognizer 
F:  and also then to train the system . 
B:  we want to <inbreath> have the ability to feed it different features . 
abst_sum - abstract: The group is additionally focused on a continued ability to feed different features into the recognizer and then train the system accordingly.

B:  Yeah , bu although I 'd be  I think it 'd be interesting to just take this exact actual system 
B:  and try it out on TI - digits . 
abst_sum - decisions: For comparing Meeting Recorder digits results, it was decided that the Aurora HTK-based system should be tested on data from the TI digits corpus.

F:  So , we might have to modify that script to recognize the , um , speakers , <inbreath> um , in the  in the , uh , um , <mouth> TI - digits  database . 
E:  because we may have to do an extract to get the  amount of data per speaker about right . 
abst_sum - decisions: The script for extracting speaker ID information will require modifications to obtain a more accurate estimation of the amount of data recorded per speaker.

B:  Yeah . I  I know what I was thinking was that maybe , uh , i i we could actually t t try at least looking at , uh , some of the  the large vocabulary speech from a far microphone , 
B:  But I 'm saying if you do the same kind of limited thing <inbreath> as people have done in Switchboard evaluations or as  a 
E:  Could we do exactly the same thing that we 're doing now , but do it with a far - field mike ? 
E:  but you use the acoustics from the far - field mike . 
abst_sum - decisions: Subsequent recognition experiments will look at large vocabulary speech from a far-field microphone (as performed in Switchboard evaluations).

F:  So , <inbreath> we would need a hand - marked , um , <mouth> word - level alignments 
F:  or at least sort of the boundaries of the speech betw you know , between the speakers . 
F:  and tune the parameters of the  of the model , uh , to op to get the best  performance . 
abst_sum - decisions: Hand-marked, word-level alignments are needed to reveal speaker boundaries and tune the parameters of the model.

A:  You know , interface - wise if you 're looking at speech , you wanna be able to know really where the words are . 
A:  um , and see if you can in maybe incorporate it into the Transcriber tool some way , 
A:  Yeah , it wou the advantage would just be that when you brought up a bin you would be able  if you were zoomed in enough in Transcriber to see all the words , 
A:  you would be able to , like , have the words sort of located in time , 
abst_sum - decisions: Modifications to the Transcriber tool are required for allowing transcribers to simultaneously view the signal in XWaves and see where words are located in time.

None
abst_sum - problems: Digits training needs to be performed on a larger data set.

B:  Um , also you had the adaptation in the SRI system , which we didn't have in this . 
F:  So there was a significant loss from not doing the adaptation . 
abst_sum - problems: A significant loss in recognition resulted from not having included the type of phone-loop adaptation found in the SRI system.

B:  Uh , but the other is that , um , the digits <inbreath> recorded here in this room with these close mikes , i uh , are actually a lot harder than the  studio - recording TI - digits . 
abst_sum - problems: Recognition performance was worse for digits recorded in closed microphone conditions versus those recorded in a studio (e.g. TI-digits).

B:  Uh , but the other is that , um , the digits <inbreath> recorded here in this room with these close mikes , i uh , are actually a lot harder than the  studio - recording TI - digits . 
F:  I suspect that to get sort of the last bit out of these higher - quality recordings you would have to in fact , uh , use models that , uh , were trained on wider - band data . 
F:  That 's where the most m acoustic mismatch is between the currently used models and the  the r the set up here . 
B:  the near versus far . 
abst_sum - problems: A mismatch between the manner in which data were collected and the models used for doing recognition---e.g. bandwidth parameterization and the use of near- versus far-field microphones---was identified.

F:  If you have only one utterance per speaker you might actually screw up on estimating the  the warping , uh , factor . 
abst_sum - problems: Too little data per speaker can have a negative effect on VTL estimation.

E:  Because it 's further away from most of the people reading digits . 
abst_sum - problems: The PZM channel selected for obtaining digits data was too far away from most of the speakers.

F:  you know , as Liz said the  we f enforce the fact that , uh , the foreground speech has to be continuous . 
A:  things like words that do occur just by themselves  a alone , like backchannels or something that we did allow to have background speech around it  
A:  those would be able to do that , 
A:  but the rest would be constrained . 
abst_sum - problems: Current speech alignment techniques assume that foreground speech must be continuous and, barring some isolated words and backchannels, can not cope with overlapping background speech.

A:  We probably want to adapt at least the foreground speaker . 
A:  But , I guess Andreas tried adapting both the foreground and a background generic speaker , 
A:  and that 's actually a little bit of a f funky model . 
A:  Like , it gives you some weird alignments , 
A:  just because often the background speakers match better to the foreground than the foreground speaker . 
abst_sum - problems: Performing adaptations on both the foreground and background speaker produced a new variety of misalignments, a problem resulting, in part, from the fact that background speakers often match better to foreground conditionss.

A:  Tha - There are some cases like where the  the wrong speaker  uh , these ca Not a lot , but where the  the wrong person  the  the speech is addre attached to the wrong speaker 
abst_sum - problems: Transcribers occasionally misidentified speakers and omitted backchannels that were more hidden in the mixed signal.

