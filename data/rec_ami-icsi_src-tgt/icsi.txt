{"dialogue": "and <breath> the main thing that i was gon na ask people to help with today isto give input on what kinds of database format we shoulduse in starting to link up things like word transcripts and annotations of word transcripts , th - there are sort of two choices .", "summary": "abstract: two main options were discussed as to the organisation of the collected data ."}
{"dialogue": "i mean , wei sort of already have developed an xml format for this sort of stuff . so tha it has a single time - line , i think for word - level , this would be ok .", "summary": "abstract: on the one hand , a bespoke xml structure that connects transcriptions and annotations ( down to the word-level ) to a common timeline ."}
{"dialogue": "and i thought it was better if you 're looking at a raw file to bet for the tags to say `` it 's an utterance `` , as opposed to the tag to say `` it 's a link `` . one of them is that it 's easy to parse . can youbut you can add to those structures if you the other thingthe other way that i sort of established this was as easy translation to and from the transcriber format .", "summary": "abstract: its advantages are that it is easier to read , parse , map onto the transcriber format and to expand with extra features ."}
{"dialogue": "so i think itit 's debatable whether you want to do phone - level in the same thing .", "summary": "abstract: phone-level analysis can be included in the same structure , or in a separate , linked file ."}
{"dialogue": "oror any frame - level stuff i would use p - file . it 's ics uh , icsi has a format for frame - level representation of features . and we have a lot of tools already to deal with it . i mean , it 's something that we developed at icsi . but , i mean , it is just something we developed at icsi .", "summary": "abstract: the respective frame-level representation can be handled by p-files , a technology developed at icsi , which also comes with a library of tools ."}
{"dialogue": "more compact ,", "summary": "abstract: separation of levels of analysis makes files more compact and manageable ."}
{"dialogue": "there 's astandard again in xml , specifically for searching xml documentsstructured x - xml documents , where you can specify both the content and the structural position . it 'sit 'syou would use that to build your tool to do that sort of search . what you would do is , someone would build a tool that used that as a library .", "summary": "abstract: xml standards offer libraries that can be used for the development of search tools ."}
{"dialogue": "which was their file format is just nodes and links ,", "summary": "abstract: on the other hand , the atlas ( nist ) technology offers a very similar , but more generic organisational scheme based on nodes and links ."}
{"dialogue": "and then `` type `` would be `` utterance `` .", "summary": "abstract: these are labeled with domain specific types , like `` utterance '' or `` speaker '' ."}
{"dialogue": "they 're developing a big infrastructure . um , and apparently they 've also developed a lot of tools , one of the things that atlas is doing is they 're trying to define an api which is independent of the back store , so that , uh , you could define a single api and thethe storage could be flat xml files or a database .", "summary": "abstract: this option offer well-developed infrastructure and flexibility as to the type of data storage ( flat xml files or relational database ) ."}
{"dialogue": "but i thought it would be good to get something that we canthat other people can use or adopt for their own kinds of encoding . and so i wanted something whereall of this can be done in a elegant way and that if somebody wants to try something or compute something else , that it can be done flexibly .", "summary": "abstract: in either case , it is important for the chosen format to allow for fast searches , flexible updates and , if possible , be reusable in future work ."}
{"dialogue": "we should look at atlas , maybe i should . so i 'lli 'll take a closer look at it .", "summary": "decisions: in order to confirm the suitability of the data format provided by the atlas project , its current state of development will be investigated ."}
{"dialogue": "do they already have something that 'sthat would be useful for us in place ? well , i think i 'mi think w i had better look at it again but i 'm forgetting the exact level of nesting . i mean , i have to look at it again to see whether it can really do what we want ,", "summary": "decisions: more specifically , the issues that have to be ascertained are , firstly , whether the external file representation offers a format that would be appropriate for speech data , and , secondly , how the linking between the different annotations ( eg , between word-level representations and prosodic-feature structures ) can be achieved ."}
{"dialogue": "it seems to me you want to keep the frame - level stuff separate .", "summary": "decisions: regardless of the actual format , however , there was consensus that keeping levels of analysis ( words , phones , frames , etc ) on separate , inter-linked files can make their management easier ."}
{"dialogue": "ii think if it 's conceptually close , and they already have or will have tools that everybody else will be using , i mean , <breath> it would be crazy to do something s you know , separate that", "summary": "problems: choosing a project-specific format for the representation of the data might not be optimal for future work ."}
{"dialogue": "do they already have something that 'sthat would be useful for us in place ? um , th what wouldwouldwouldwhat would worry me is that maybe we might miss a little detail i mean , i have to look at it again to see whether it can really do what we want ,", "summary": "problems: on the other hand , it is not yet clear whether a more standardised , but generic technology , like that of the atlas project , can accommodate all the requirements of speech analysis ."}
{"dialogue": "for lower than word - level , you 're talking about so much data that i justi do n't know . these are big files .", "summary": "problems: regardless of the particular format , including all annotations ( sentences , words , phones , frames , etc ) in one file could result in unmanageable file sizes ."}
{"dialogue": "none", "summary": "problems: searching , updating or simply parsing a file for a simple task can become an unwieldy process ."}
{"dialogue": "i mean these are long meetings but i think , a anything at frame - level , even p - file , is too verbose .", "summary": "problems: even p-files , which are only for frame-level annotation , may be too verbose for the amount of data resulting from hour-long recordings ."}
{"dialogue": "no matter what format you choose , you 're gon na have the trou you 're gon na have the difficulty of relating thethe frame - level features", "summary": "problems: the actual mapping of word-level transcriptions to frame-level representations is expected to be problematic anyway ."}
{"dialogue": "and sometimes the word sequences even differ slightly because they were edited s at one place but not the other . but , see , if you 'd annotate dialogue acts , you do n't necessarily want toor topicsyou do n't really want to be dealing with time - marks .", "summary": "problems: likewise , problems will arise if , in the future , slightly different transcripts of the same data are annotated in formats that do not include time-marks ."}
{"dialogue": "the hard part is specifying what you mean by `` merge `` .", "summary": "problems: trying to merge such annotations later will not be easy , because of the combination of transcription discrepancies with the loss of the underlying connection offered by the time-marks ."}
{"dialogue": "oh , this was aboutum , inferring intentions from features in context , and the words ,", "summary": "abstract: the initial task of the edu group is to work on inferring intentions through context ."}
{"dialogue": "so , < clears throat > what we found interesting is , first of all , intentions differ . maybe you want to enter a building . maybe you want to see it , or maybe you actually want to come as close as possible to the building . if you do n't have the intention of entering your building , but you know that something is really close to it , and you just want to approach it , or get to that building .", "summary": "abstract: in the navigational paradigm used for the task , these intentions are to `` see '' to `` enter '' or to `` get to the closest point of '' a building ."}
{"dialogue": "but , um , since we are designing aaaan , compared to this , even bigger data collection effort , um , we will definitely take care to put it in there ,", "summary": "abstract: there will be purpose-designed experiments carried out ."}
{"dialogue": "um , we can look at some factors that may make a difference . um . sometimes i found in theuh , looking at the data , in a superficial way , i found some s sort of modifiers thatthat m may also give us a hint , and this leads us straight to the context which also should be considered . and i will try toto sort of come up with a list of factors that we need to get out of there , there 's gon na be contextual things , there 're gon na be linguistic things , there 're gon na be discourse things , the issue is , can we find a way to , basically , featurize it", "summary": "abstract: however , the starting point is , through the use of existing data , to determine possible linguistic , discourse or situation features that define intentionality ."}
{"dialogue": "like `` s go to see `` , or `` visit `` , or some this is of course a crucial factor , `` what type of object is it ? `` then of course thethe actual phrases may give us some idea of what the person wants . oh , another thing you want is some information abou i think , about the time of day . so if it turns out that , whatever it is , you want to know whether the person 's uh , a tourist or not , ok ? that becomes a feature .", "summary": "abstract: these may include the type of building , time of day , particular phrases used or whether the user is a tourist or a native ."}
{"dialogue": "and we 're able to , by hand , extract the features to put in the belief - net . if that goes well , then we can start worrying about how we would extract them . so we 'll be like , hand , uh , doing all the probabilities .", "summary": "abstract: initially , these features will be hand-coded , but the goal is to find ways of extracting them automatically from the xml data ."}
{"dialogue": "if we feed it through a belief - net oror something along those lines . we 'd get an inferred intention , wewe produce a structure that differentiates between the vista , the enter , and the , um , tango mode . and , my idea on how to combine them is with a belief - net , which is going to have as output , the conditional pr probability of one of three things , but the idea is to take as a first goal , see if we could actually build a belief - net that would make this three way distinction uh , in a plausible way , here 're the things which , if you get them out ofout of the language and discourse , and put them into the belief - net , it would tell you which of these three uh , intentions is most likely . `` i think that , uh , if we can get the information , a belief - net is a perfectly good way of doing the inferential combination of it . javabayes or something ?", "summary": "abstract: consequently , they will be fed into a belief-net -implemented on a software package like javabayes- and the conditional probability of each intention calculated ."}
{"dialogue": "so one thing you could do is build a little system that , said , `` whenever you got a question like that i 've got one of three answers . u u sort of i 'm , at the moment , curious and i 'mi 'ms w want to approach it from the end where we can s sort of start with this toy system that we can play around with , and then in the longer run , you would figure out how you could derive them . from previous discourse or w any anything else you knew . and , then as soon as we have it , i think we should start trying to populate it for this problem .", "summary": "abstract: a prototype system will be put together to test hypotheses regarding both the exact nature of the features and how intentions are derived from them ."}
{"dialogue": "maybe for a deep understanding task , that 's a nice sort of playground or first little thing . `` so we think it 's a well - formed , uh , starter task for this , uh , deeper understanding in the tourist domain .", "summary": "decisions: inferring intentions in a navigational context is an appropriate task both in project and real-world terms ."}
{"dialogue": "ok ? wewe have awe know what the outcomes are gon na be , it allall of a sudden it does much better .", "summary": "decisions: its goals are clearly defined and contributre to a smarter system ."}
{"dialogue": "thesewe have all these transcripts but , um , since we are designing aaaan , compared to this , even bigger data collection effort , um , we will definitely take care to put it in there , and start recording subjects probably within a month or something .", "summary": "decisions: although there are some preliminary data to work on , task-specific experiments and recordings will take place ."}
{"dialogue": "so , th they 're gon na give us some cr uhorwe can assume that y you get this crude information . so , yeah , we 're sort of < mike noise > committed to xml as the kind of , uh , interchange .", "summary": "decisions: the xml format is going to be used has not been defined , although the smartkom data can be used as a foundation ."}
{"dialogue": "ok ? soy so one of th one of the things we wan na do is actually , uh , pick a package , yeah bu w i 'd like that thisy yeah , this week , to ha to n to <inbreath> have y guys , uh , you know , pick <mouth> they you know , belief - net package", "summary": "decisions: in the first instance , the group will have to decide on the software package to be used for the creation and manipulation of the belief-nets ."}
{"dialogue": "you know , we do n't need the one that 'll solve massive , uh , belief - nets quickly . but we do want one in which it 's easy to interact with and , uh , modify . you want it stable , you want it and probably one in which it 's easy to have , um , what amounts to transcript files .", "summary": "decisions: stability and ease-of-use -in addition to ability to handle xml- of the package are the focus at this stage , instead of the ability to handle large amounts of data ."}
{"dialogue": "an and there 're plenty of people around , students in the department who , you know , live and breathe bayes - nets .", "summary": "decisions: experts in bayes nets within icsi can be consulted on the matter ."}
{"dialogue": "well , i 'd like to also , though , uh , ha have a first cut at what the belief - net looks like . is show the state and show the system and show that .", "summary": "decisions: the decision will be presented in the next meeting along with a first schema of the belief-nets themselves ."}
{"dialogue": "and you probably need intermediate nodes . and then in the longer run , you would figure out how you could derive them . from previous discourse or w any anything else you knew .", "summary": "decisions: possible intermediate nodes can be added to the nets after this ."}
{"dialogue": "is , uh , one , where do you get this iinformation from , if that goes well , then we can start worrying about how we would extract them . and then we can start worrying about where to get this input , the issue is , can we find a way to , basically , featurize it and , as soon as we have one , we can start trying to , uh , make a first cut at what 's going on .", "summary": "decisions: the hypothesis that a set of features from which intentions can be derived exists has to be assessed , before moving on to how to extract these features from the data automatically ."}
{"dialogue": "the street network of our geographic information system . a lot of parsers , um , that 's way beyond their scope , isof interpreting that . because i we can not differentiate , at the moment , between , you know , the intention of wanting to go there or the intention of just know wanting to know wherewhere it is .", "summary": "problems: curent navigation systems do not provide for the user 's particular intentions when asking for directions ."}
{"dialogue": "it would always use the closest point to the object ,", "summary": "problems: they always compute the shortest path between source and destination ."}
{"dialogue": "what we do know , is that the parser we use in the smartkom system will never differentiate between any of these . so it 'sit 'sit 's way too crude to d capture those differences in intentions . what he was saying is , the m - three - l does not have any of that . that 's way beyond their scope , isof interpreting that .", "summary": "problems: the smartkom parser , for example , does not mark up data with features adequate for the inference of these intentions ."}
{"dialogue": "there 's gon na be contextual things , there 're gon na be linguistic things , there 're gon na be discourse things , is , uh , one , where do you get this iinformation from , but if we ca n't do that , then we 're in trouble . the real issue is , do what are the factors involved in determining this ? the issue is , can we find a way to , basically , featurize it", "summary": "problems: although it is understandable that language , discourse and situation features will play a role in how they are weighed , the exact nature of those features is unclear ."}
{"dialogue": "and two , what 's the structure of the belief - net ? so that we get some discrete number of features so that , uh , when we know the values to all those features , or as many as possible , we can w come up with the best estimate of which of the , in this case three little intentions , are most likely .", "summary": "problems: also hard to evaluate at this stage , is how the assumed features will combine in a belief-net , in order to provide the conditional probabilities of the users ' intentions ."}
{"dialogue": "if that goes well , then we can start worrying about how we would extract them . and then in the longer run , you would figure out how you could derive them . from previous discourse or w any anything else you knew .", "summary": "problems: even if these problems are solved , extracting the features from the data may prove to be a bottleneck ."}
{"dialogue": "not from that data . butit was never th th the goal of that data collection toto serve for sat for such a purpose . so that 's why for example the tasks were not differentiated by intentionality , uh , what one hopes is that when we understand how the analyzer works , we can both worry about converting it to english and worry about how it could ex extract the parameters we need for the belief - net .", "summary": "problems: the existing data are appropriate only for preliminary work , as they do n't include intention-related information ."}
{"dialogue": "so . uh , wewe have to have this discussion of th the experiment , and the data collection , and all that sorta stuff so , we that 's part of what we 'll have to figure out .", "summary": "problems: on the other hand , the details of the experiments that will have to be designed to get more appropriate data are not clearcut and are yet to be settled ."}
{"dialogue": "um right now it 's still kind ofin a toyversion of it ,", "summary": "abstract: the group discussed the first version of the bayes-net used to work out a user 's intentions when asking for directions from a navigation device ."}
{"dialogue": "the probabilitywhether the probability of a vista , tango , or enter .", "summary": "abstract: three intentions were identified: vista ( to view ) , enter ( to visit ) and tango ( to approach ) ."}
{"dialogue": "so then the features we decidedor we decided we weretalked about , you know . we had a list of things like `` to go `` and `` to visit `` and what not . uh thethe prosody , the discourse , verb choice . so there are certain cues that are very strongeither lexical or topic - based um , concept cues and some of them are sort of <breath> either world knowledge or situationalthings . is that maybe we ob we could observe a couple of um discourse phenomena such as the admission fee ,", "summary": "abstract: the structure of the belief-net comprises , firstly , a feature layer , which includes linguistic , discourse and world knowledge information that can be gleaned from the data ."}
{"dialogue": "so maybe this could be sort of a separate region of the net , which has twohas it 's own middle layer . they ra may have there own hidden layerthat points to some ofthethe real hidden layer , um or the general hidden layer .", "summary": "abstract: it is possible for these variables to form thematic clusters ( eg `` entrance '' , `` type of object '' , `` verb '' ) , each one with a separate middle layer ."}
{"dialogue": "but the middle thing , we were thinking along the lines of maybe trying to figure out , like , the concept of whether they 're a touristorwhether they 're running an errand or something like that so then the hidden variableshair variables we came up with were whether someone was on a tour , running an errand , or whether they were in a hurry , but the other ones , the final destination , the whether they 're doing business , whether they 're in a hurry , and whether they 're tourists , they ra may have there own hidden layerthat points to some ofthethe real hidden layer , um or the general hidden layer . and then these should then connect somehow to the more plan - based deep space", "summary": "abstract: these feed , in turn , into the main middle layer , that defines more general hidden variables , such as the tourist / business status of the user ."}
{"dialogue": "so there are certain cues that are very strongeither lexical or topic - based um , concept cues so <breath> maybe whatwhatwhat happenedwhat might happen is that we do get this sort of task - based middle layer , entering or som you know like they might be more task - based .", "summary": "abstract: the feature layer can end up being cue-based , while the middle layers task-based ."}
{"dialogue": "so . the modebasically has three differentoutputs .", "summary": "abstract: the latter determine the final probability of each intention in the output layer ."}
{"dialogue": "it 's cra has a gui and it 's uh but uhit 's free . but actually it had an interface . and he 's updated it for an xml version of i guess bayes - nets .", "summary": "abstract: this first model of the belief-net was built in javabayes , since it is a free package , has a graphical interface , and it can take xml files as input ."}
{"dialogue": "like , we totally hand - tuned the probabilities , the probabilities and all are completely ad - hoc .", "summary": "abstract: at this stage , all the actual probabilities are ad-hoc and hand-coded ."}
{"dialogue": "but umin terms of specifying the scenario , <breath> umuhuhwe 've gotten a little further so we wanted just to collect data , to getthatthatthatelicits more , uh , that elicits richer language .", "summary": "abstract: however , there has been progress in the design and organisation of experiments , that will eventually provide data more useful and appropriate for this task ."}
{"dialogue": "so then our next idea was to add a middle layer , uhwe kept umthings from directly affecting the modebeyond the concept , but we just decided to keep all the things we extractedto point at the middle and thendown . i guess , the fact that thethere 's a complete separation between theobserved features and in the output .", "summary": "decisions: it is necessary for the belief-net to have at least one layer of nodes between the features and the final output ."}
{"dialogue": "none", "summary": "decisions: this makes the structure more flexible in terms of coding feature-layer probabilities ."}
{"dialogue": "is that maybe we ob we could observe a couple of um discourse phenomena such as the admission fee , so maybe this could be sort of a separate region of the net , which has twohas it 's own middle layer . that would all f funnel into one node that wouldconstitute entrance requirements or something like that . they ra may have there own hidden layerthat points to some ofthethe real hidden layer , um or the general hidden layer .", "summary": "decisions: another technique to systematise the work is the thematic clustering of the features , each cluster forming a bayes-net of each own: for example features like `` admission fee '' and `` opening hours '' can feed into an intermediate `` entrance '' node connecting to the main middle layer ."}
{"dialogue": "so , um i suggest w toforto proceed with this inin the sense thatmaybe throughout this week the three of us willwill talk some more about maybe segmenting off different regions , identifyfour regions , maybe make up some features for each region", "summary": "decisions: the next stage is to refine the set of feature nodes and identify possible clusters ."}
{"dialogue": "so one thing that might be helpful which is implicit in theuse of `` admission fee discussion `` as a cue for entry , <breath> is thinking about the plans that various people might have . they 'reinin non in sort of more traditional ai kinds of plan recognition things you sort of have <breath> you know , some idea at each turn of agent doing something , i mean there are somesome of them are extremely elaborate ,", "summary": "decisions: although , in theory , traditional ai plan recognition techniques could also be helpful for inferring intentions , the schemas involved are too elaborate for this task ."}
{"dialogue": "yeah , another thing to do , um , is also to , umi guess to ask around people about other bayes - net packages .", "summary": "decisions: further work also includes discussing the possible advantages of bayes-net packages , other than javabayes , with experts at icsi ."}
{"dialogue": "we can maybe write an interface th for uh entering probability distributions easily , something likelike a little script . i think it mightit might be simpler to justhave a script that , you know", "summary": "decisions: if they continue using javabayes , a script to help with the inputting of probabilities in the nodes is needed , as the in-built method is cumbersome ."}
{"dialogue": "like we wannawe wan na be able to collect <breath> as much of the variables that are needed for that , so now i think we should maybe have at least one navigational task withwith sort of explicituh", "summary": "decisions: finally , it was decided that at least some of the experiments designed for the new data collection initiative will factor in the intentions studied in the current task ."}
{"dialogue": "none", "summary": "problems: the set of cues that form the feature nodes is not well-defined yet ."}
{"dialogue": "that 'sthatthat needs a lot of work .", "summary": "problems: especially with lexical cues ( verbs , modifiers etc ) , no one offered specific intuitions as to how they might contribute to the inference of intentions ."}
{"dialogue": "because we did n't know the probabilities ofor so that 's like a huge uh clue that they 're trying to enter the place rather than uh to tango or vista , like , we totally hand - tuned the probabilities , the probabilities and all are completely ad - hoc .", "summary": "problems: other features , like `` admission fee '' , may be intuitively linked with one of the outputs ( enter ) , however , any probabilities are coded in an ad-hoc fashion and are by no means realistic ."}
{"dialogue": "but you could see perhaps discus the `` admission fee `` going directly to the mode pointing at `` enter `` , well for instance , the `` discourse admission fee `` node seems like it should point directly to the or increase the probability of `` enterdirectly `` versus `` going there via tourist `` .", "summary": "problems: cases like this , where feature and output seem to be linked directly , bring the necessity of a middle layer in the belief-net to question ."}
{"dialogue": "reasons being , you know , it 'd be a pain to set up all the probabilities for that . if we moved onto the next step and did learning of some sort , uh according bhaskara we 'd be handicapped .", "summary": "problems: nevertheless , not having a middle layer would not allow for shifts in the discourse and would make the setting of probabilities and manipulation of the belief-net clumsy ."}
{"dialogue": "it might be that if you add a new thing pointing to a variable , you just likeit just overwrites everything . butthey 're not very friendly .", "summary": "problems: some issues with the use of javabayes also arose: the addition of new variables in an existing node overwrites all previous settings , and the native text file where the probability tables are set is not easy to read ; this makes adding and changing variables and nodes problematic ."}
{"dialogue": "i did n't think it did learning .", "summary": "problems: finally , it is unclear how much learning can be done on the created nets ."}
{"dialogue": "so . on friday we had our wizard test data test and um <outbreath> these are some of the results .", "summary": "abstract: a test run of the data collection design was very successful ."}
{"dialogue": "um , we have to refine the tasks more and more , which of course we have n't done at all , so far , in order to avoid this rephrasing , and uh my suggestion is of course wewe keep the wizard , because i think she did a wonderful job , umand also if she 's willing to take on the job of organizing all those subjects and stuff that would be wonderful .", "summary": "abstract: the group decided to hire the `` wizard '' and continue with the refinement of the design and recruitment of subjects ."}
{"dialogue": "none", "summary": "abstract: on the other hand , there was a presentation of a new version of the belief-net for the vista / enter / tango mode task ."}
{"dialogue": "so , what i did for thisthis isuh , a pedagogical belief - net and i grouped things according to whathow i thought they would fit in to uh image schemas that would be related . well , this is not a working bayes - net . but the uhthethe nice thing is that you know , it just is ais a visual aid for thinking about these things which has comple clearly have to be specified m more carefully", "summary": "abstract: it is not a working net yet , but identifying clusters of features that define the output mode provides a visual aid for further work ."}
{"dialogue": "is , if we just do this , we could wind up with a huge uh , combinatoric input to the mode thing . uh , we have a d a technical problem with the belief - nets that wewe do n't want all the com too many factors if weif we allow them to just go combinatorially .", "summary": "abstract: there are potential problems from a combinatorics perspective ."}
{"dialogue": "which is there are technical ways of doing it , and the other trick , which is not a technical trick , it 's kind of a knowledge engineering trick , is to make the neach node sufficiently narrow that you do n't get this combinatorics .", "summary": "abstract: these can be tackled either with technical adjustments or through careful knowledge engineering ."}
{"dialogue": "we have to add , you know , not too much about um object types and stuff , that 's another sort of thing `` ok , here 's aanother kind of minimal uh way of tackling this `` . add extra properties , a deterministic rule for every property", "summary": "abstract: a base solution for the task would be to simply add some extra action-mode rules in the smartkom system ."}
{"dialogue": "and umand here is exactly where what 's gon na be replaced with our bayes - net ,", "summary": "abstract: action modes , however , can be inferred more efficiently by feeding a collection of features -from the ontology , discourse history , parsing , etc . - into bayes-nets that would replace those rules ."}
{"dialogue": "none", "summary": "abstract: ideally , the results of this small task will give insights into the function of linguistic deep understanding ."}
{"dialogue": "so . what you 're trying to get out of this deep co cognitive linguistics is the fact that w if you know about sourcesource , paths and goals , and nnnall this sort of stuff , that a lot of this is the same , for different tasks . and thatuh there 'sthere 's somesome important generalities that you 're getting , so that if you have sources , you have trajectors and stuff like that , but what i 'd like to be able to do is to have the way that you extract properties , that will go into different bayes - nets , be theuh general . what you 'd really like of course is the same thing you 'd always like which is that you have um a kind of intermediate representation which looks the same o over a bunch of inputs and a bunch of outputs .", "summary": "abstract: for instance , the final combination of features used in the current study may form a representation of the ontology , general enough to employ in any task that includes trajectors and paths ."}
{"dialogue": "s so if you just number them `` one `` , `` two `` , `` three `` it 's and uh my suggestion is of course wewe keep the wizard , because i think she did a wonderful job ,", "summary": "decisions: although the data collection test went well and it was decided to hire the `` wizard '' , there are minor amendments in the procedure to be carried out ( shortenting the preparatory reading , numbering tasks etc ) ."}
{"dialogue": "my idea on that wasuh , partly we 'll talk about system stuff for the computer scientists , but partly i did want it to get the linguists involved in some of this issue about what the task is and allum you know , what the dialogue is , and what 's going on linguistically , you just uh do `` this is what we did , and here 's thething , and here 's s some of the dialogue andand so forth . ``", "summary": "decisions: a presentation of the data collection design should be included in the forthcoming meeting with other research groups , along with some account of the system design and the use of belief-nets ."}
{"dialogue": "none", "summary": "decisions: the structure of the latter was a major issue during the meeting ."}
{"dialogue": "so the belief - net takes as input , a vector , and then we want to look up some more stuff in the ontology but also we definitely want to look up in the dialogue history um some s some stuff . there will be rules , but they are n't rules that come to final decisions , they 're rules that gather information for a decision process . my guess is it 'll be the same basic agent that um can go off and get information , run it through aa c this belief - net that", "summary": "decisions: their input vector is to be provided by information extracted from the various modules of the system , such as the ontology and discourse history , using standard rule-based methods ."}
{"dialogue": "and you wanted to specialize it to these three ones , then you would have to supply the parameters . and that may actually involve getting more information .", "summary": "decisions: the output action essentially provides additional semantic parameters for the x-schema , and , in turn , may trigger the collection of more features from the data ."}
{"dialogue": "i think weii can come up with aa code for a module that we call the `` cognitive dispatcher `` , which does nothing , but it looks of complect object trees and decides howare there parts missing that need to be filled out , and then collect uh sub - objects and then recombine them and put them together .", "summary": "decisions: the feature extraction could be carried out by a software tool checking object ( feature ) trees and filling them with appropriate values ."}
{"dialogue": "none", "summary": "decisions: for this concept to be put to work , further refinement of the belief-net variables is necessary , with particular attention on the combinatorics involved ."}
{"dialogue": "five minutes is just too long . s so if you just number them `` one `` , `` two `` , `` three `` it 's", "summary": "problems: after the trial run of the experiment , some minor issues , like the length of the preliminary reading and the need to order the tasks given to the subjects , were highlighted ."}
{"dialogue": "she also agrees that you know if it 's all just gon na be students the data is gon na be less valuable because of that", "summary": "problems: it is also possible that the pool of subjects ends up comprising almost entirely of students ; more variation in the sample is needed ."}
{"dialogue": "is , if we just do this , we could wind up with a huge uh , combinatoric input to the mode thing . uh , we have a d a technical problem with the belief - nets that wewe do n't want all the com too many factors if weif we allow them to just go combinatorially .", "summary": "problems: from a system design perspective , the progress so far has shown that the combinatorics of the bayes-net even for a simple task , like the choice of vista / enter / tango mode , could render it unmanageable ."}
{"dialogue": "so , what i did for thisthis isuh , a pedagogical belief - net well , this is not a working bayes - net .", "summary": "problems: the belief-net presented in the meeting is not a working bayes-net ."}
{"dialogue": "i mean , not necessarily in th in this meeting , but to try to informally think about what the decision variables are . so the immediate problem is just deciding w which aspects of the x - schema to add .", "summary": "problems: consequently , it is as yet unclear what the decision nodes in the net are , and what values these can take ."}
{"dialogue": "the harder problem is we decide what we want to use , how are we gon na get it ?", "summary": "problems: even if those were decided , how to extract the necessary information from the data , would still be an open issue ."}
{"dialogue": "and i do n't yet see how that goes .", "summary": "problems: looking at the bigger picture , the current task is yet to provide insights into more general ways to achieve linguistic deep understanding ."}
{"dialogue": "and uh see if we can find a way to present this to this linguists group thatthat is helpful to them .", "summary": "problems: with these intricacies in mind , it is not easy to put together a presentation of the project cohesive and attractive enough for the other research groups in the institute ."}
{"dialogue": "what we think is gon na happen is that , uh , in parallel starting about now <breath> we 're gon na get fey <mouth> to , where you 're working with me and robert , draft a note that we 're gon na send out to various cogsci c and other classes saying , `` here 's an opportunity to be a subject . but what i 'd like to do , if it 's o k , <breath> is to s to , as i say , start the recruiting in parallel and possibly start running subjects next week .", "summary": "abstract: the data collection running in parallel with the project can start shortly with recruiting subjects ."}
{"dialogue": "and , umand now it 'swe have a complete english parser that does everything the german parser does . and it still is , now in english . that , these guys did in ain a day .", "summary": "abstract: meanwhile , the german parser now works with english sentences ."}
{"dialogue": "one thing i was wondering , was , those functions there , are those things that modify the m - three - l basically ? i think each of those functions act on the current xml structure , and change it in some way , for example , by adding aa l a field to it , or something . there were other actions uh , thatthat s seemed to stepstate variables somewhere , which , in german , uh , takes these t sentence templates and produces xml structures .", "summary": "abstract: the parser 's output modifies the xml used by the system to initiate actions and generate responses ."}
{"dialogue": "uhyouyou have a route , and everyevery element of that e r r f of thatevery segment we call a `` route element `` . where y whereyou sort of end , and some points of interest along the way .", "summary": "abstract: the xml for map requests also comprise a route , route elements and points of interest along the way ."}
{"dialogue": "is one , um , <breath> <mouth> also allocating , uh , some tags for our action schema enter - vista - approach ,", "summary": "abstract: it is at this level that enter / vista / approach tags will be added as action modes ."}
{"dialogue": "uh , at some point we 're going to have to worry about the language end .", "summary": "abstract: as the project evolves , further enrichment of the ontology ( actions , linguistic features ) will be necessary ."}
{"dialogue": "ehso , youyouyou may orso , then you 'd have this little vector of , um , you know , approach mode or eva mode . it 's part of what you know aboutaan object , <breath> is its eva vector .", "summary": "abstract: similarly , object representations will include an eva vector ."}
{"dialogue": "if you know it for a specific landmark you put it there . if you do n't , you just go up the hierarchy to the first place you find one . if it 's that type of thing , and we want its eva vector , pppt - pppt ! it 's that . ``", "summary": "abstract: this can be incorporated in the database entry for a particular building or inherited from the ontology of the building type ."}
{"dialogue": "the typical example is that , um , these are all a bunch of cues for something , and this is a certain effect that we 'd like to conclude .", "summary": "abstract: these elements will constitute only a small part of the inputs of the bayes-net that determines the action mode ."}
{"dialogue": "and , that 's a lot of probabilities to put here , which is kind of a pain .", "summary": "abstract: the actual number of the inputs can create a combinatorial explosion when setting the probabilities ."}
{"dialogue": "sonoisy - ors are a way to , uh , <breath> sort of deal with this . so we come up with these l little tables for each of those and the final thing is that , um <breath> <mouth> this is a deterministic function of these , th - c the full conditional probability tablewith some function .", "summary": "abstract: noisy-or 's can help avoid this by simplifying the probability tables and applying a deterministic function to produce their complete version ."}
{"dialogue": "none", "summary": "abstract: in any case , further to fulfilling the basic requirements ( translating the parser and the generator into english ) , the project is entirely open-ended in terms of focus of research ."}
{"dialogue": "in parallel with that , we 're gon na need to actually do the script . thisthe permission form .", "summary": "decisions: as the data collection is about to begin , there are some minor changes to be done in the design of the experiment , the script and the permission forms ."}
{"dialogue": "what we think is gon na happen is that , uh , in parallel starting about now <breath> we 're gon na get fey <mouth> to , where you 're working with me and robert , draft a note that we 're gon na send out to various cogsci c and other classes saying , `` here 's an opportunity to be a subject . not necessarily by any means all students but what i 'd like to do , if it 's o k , <breath> is to s to , as i say , start the recruiting in parallel and possibly start running subjects next week . which is we gon na check out our social infrastructures for possible subjects .", "summary": "decisions: subjects can be recruited either from within the university or through other social circles ."}
{"dialogue": "that , these guys did in ain a day . eh , but again , there 's one module in which there 's one piece <mouth> that we have to convert to english .", "summary": "decisions: as to the system design , the next step is the translation of the generator into english ."}
{"dialogue": "and the next thing i would like to be able to do , and it seems like this would not be too difficult either , is <breath> to say , `` ok let 's now pretend we actually wanted to not only change the <breath> the mapping ofof , uh , words to the m - three - l but we also wanted to changeadd a new sentence type so , yeah . i definitely think it 's <breath> it 's worth the exercise of trying to actually add something that is n't there .", "summary": "decisions: moreover , it is important to test the system and its internal workings by adding new sentence types and modifying the parser ."}
{"dialogue": "it seems to me we can get <breath> all the complexity we want in actions and in language without going outside of tourists in heidelberg . so , at leastunless somebody else wants t to suggest otherwise i think <breath> the general domain we do n't have t to uh , broaden . that is , tourists in heidelberg .", "summary": "decisions: all further research will use the existing domain ( `` tourists in heidelberg '' ) , as this provides enough diversity for the purposes of the project ."}
{"dialogue": "none", "summary": "decisions: the german partners for the project will realise all the necessary changes in the ontology ."}
{"dialogue": "so it seemed to me , what we ought to do is get our story together . and think about it some , internally , before asking them to make changes . ok . what are the thl class of things we think we might try to do in a year or two ? this isthis is everything thatthat , um , <breath> you know , umwe might want to do in the next couple years .", "summary": "decisions: it is therefore preferable for the group to exercise foresight and agree on the set of new tags they will need in the long run , so that they limit the number of change requests ."}
{"dialogue": "sonoisy - ors are a way to , uh , <breath> sort of deal with this . i think we definitelyi think it 's a great idea tha toto pursue that .", "summary": "decisions: finally , on a more technical note , noisy-or 's were discussed and considered a sensible approach to deal with the potential problems with the setting the conditional probabilities of the bayes-nets ."}
{"dialogue": "and , umand now it 'swe have a complete english parser that does everything the german parser does . i think each of those functions act on the current xml structure , and change it in some way , for example , by adding aa l a field to it , or something . there were other actions uh , thatthat s seemed to stepstate variables somewhere , it 's mystery functions . that , these guys did in ain a day .", "summary": "problems: although the parser has been modified to work with english , the details of its internal workings ( calling functions , setting discourse variables , generating actions ) are not yet clear ."}
{"dialogue": "although th the <breath> to get at them from a language may not be trivial . so , it 's a relational database with persons , events , <breath> and , um , objects .", "summary": "problems: understanding the parsed data is helped by the database of objects , people and events accompanying the system , but the mapping of referring expressions to database objects can still be a hurdle ."}
{"dialogue": "and , that 's a lot of probabilities to put here , which is kind of a pain .", "summary": "problems: on a different level , the bayes-net used to generate the different action modes can easily become unmanageable as the number of features to be taken into account increases ."}
{"dialogue": "sonoisy - ors are a way to , uh , <breath> sort of deal with this .", "summary": "problems: this can be tackled with the use of the noisy-or technique ."}
{"dialogue": "so , if ba - javabayes wo n't do it for you , and thenbut , the combination functions , and whether we can put those in java bayes , and all that sort of stuff , is , uhis the bigger deal .", "summary": "problems: the deterministic functions this requires can not be introduced directly into javabayes , although some runaround ways can be implemented ."}
{"dialogue": "there 's this whole framework problem that i 'm feeling really uncomfortable about .", "summary": "problems: a final , high-level issue , that has not been dealt with yet , is the definition of the constructions and the construction grammar framework analysis behind the whole enterprise ."}
{"dialogue": "so they 'll have a little bit more natural interaction ?", "summary": "abstract: the data collection script has been slightly modified , so that it encourages more natural dialogue between the subjects and the `` wizard '' ."}
{"dialogue": "and um we have a little description of asking peop subjects to contact fey for you know recruiting them for our thing however there is always more people in ain a facul uh in a department than are just taking his class or anybody else 's class at the moment and then we 're going to have anotherwe 're gon na have w another trial run", "summary": "abstract: another trial run will take place , while a call to recruit subjects is being emailed to students ."}
{"dialogue": "um , the basic requirement is fulfilled almost . you can speak into it and ask for tv and movie information", "summary": "abstract: meanwhile , the translation of the tv and cinema information system to english is almost complete ."}
{"dialogue": "none", "summary": "abstract: this was the basic requirement of the project ."}
{"dialogue": "then uh on to the modeling . in the future though , the content of a hypothesis will not only be an object and anan action and a domain object but an action , a domain object , and a rich action description ,", "summary": "abstract: on the other hand , there was a presentation of the model that offers more elaborate action planning for smartkom , of which enter / view / approach ( eva ) modes are a part ."}
{"dialogue": "inside of enter there will be roles that can be filled basically .", "summary": "abstract: these modes will form categories of complete xml schemas with information filled in from the language understanding in a more elaborate way than the current object- '' go action '' -object model ."}
{"dialogue": "the idea is , so , imagine we have a library of schema such as the source - path - goal well one of the types of action schemas is source - path - goal action .", "summary": "abstract: these categories will , in turn , be linked with action schemas , one of which is source-path-goal ( spg ) ."}
{"dialogue": "the idea is , so , imagine we have a library of schema so if you wanted to have a new type of action you 'd create a new type of category .", "summary": "abstract: categories and action schemas can have -in theory- any number of blocks depending on the expansion of the domain ."}
{"dialogue": "meaning we can reference . and link it to another one , and this not only within a document but also via documents ,", "summary": "abstract: the notation provides for linking and referencing between different schemas ."}
{"dialogue": "and then those actions can be in multiple categories at the same time if necessary . it 'sit 's crucially necessary , is that we can have multiple schemas and multiple action schemas in parallel .", "summary": "abstract: the model also allows for multiple action schemas to be triggered in parallel ."}
{"dialogue": "um and i agree that you know this is something we need to discuss ,", "summary": "abstract: however , the structure of the model is open for discussion , since its use was to elicit discussion and highlight issues ."}
{"dialogue": "um , so we 're about to collect data and um we have a little description of asking peop subjects to contact fey for you know recruiting them for our thing", "summary": "decisions: as the data collection is about to start , a call for the recruitment of subjects is going to be sent out ."}
{"dialogue": "however there is always more people in ain a facul uh in a department than are just taking his class or anybody else 's class at the moment", "summary": "decisions: the main pool of subjects is going to be the student community in the institute ."}
{"dialogue": "there the idea is now that next actually wewe need to hire one more person to actually do that job", "summary": "decisions: along with the `` wizard '' , who is going to be an integral part of the experiments , another person needs to be hired as the instructor for the tasks involved in them ."}
{"dialogue": "meeting time rescheduling . i n did n't you say something about friday ,", "summary": "decisions: meetings were rescheduled and are now going to take place on fridays ."}
{"dialogue": "so i mean clearly there 'si can talk about the um the parser changes on friday at least ,", "summary": "decisions: for the next meeting , there is going to be a presentation of the modifications in the parser module of the basic system ."}
{"dialogue": "andand this is onon aonon my list of things until nextnext week . yeah , wei will promise for the next time to have fleshed out nxml examples for aa run through andand see how thisthis then translates ,", "summary": "decisions: additionally , the proposed xml model will be put to the test with concrete data ."}
{"dialogue": "and um if you can get that binding point also maybe with a nice example that would be helpful for johno and me .", "summary": "decisions: similarly , such examples will clarify issues relating to the binding and redundancy of features with common characteristics amongst the shcemas ( eg `` container '' for enter and `` goal '' for spg ) ."}
{"dialogue": "um and then , secondly , we had , you may remember , um the problem with the re - phrasing , that subject always re - phrase sort of the task that uh we gave them ,", "summary": "problems: subjects in the trial runs of the experiment were given detailed descriptions of the tasks , which led to the subsequent dialogue being a re-iteration or re-phrasing of the instructions ."}
{"dialogue": "however , not only wasthe common census wereamong all participants of friday 's meeting was it 's gon na be very laborious toto make these drawings for each different things , so all of a sudden we 'll get descriptions of pictures in there .", "summary": "problems: using pictures instead would be one way to deal with the problem , however , it was deemed too laborious and it would divert the focus of the experiment ."}
{"dialogue": "and the problem is , is that the current system does not distinguish between goes of type `` going into `` , goes of type `` want to go to a place where i can take a picture of `` , et cetera . in the future though , the content of a hypothesis will not only be an object and anan action and a domain object but an action , a domain object , and a rich action description ,", "summary": "problems: as the original action planner of the smartkom system only included a generic spg schema , a new module was presented that allows for variety in the user intentions to be included ."}
{"dialogue": "well , i think we 're gon na hit a lot of interesting problems um and i agree that you know this is something we need to discuss ,", "summary": "problems: this being only a model , there are several issues that will need to be clarified in the future ."}
{"dialogue": "it 's also a question of the recursiveness andand a hier hierarchy um in there .", "summary": "problems: how the model deals with redundancy of information among categories and action schemas , and whether a flat or a hierarchical model would be preferable are two of them ."}
{"dialogue": "and it 's gon na get more and more complex thethe l complexer and larger our domains get .", "summary": "problems: what is also clear is that as the domain of research broadens beyond the study of eva modes , the complexity of the model will also increase ."}
{"dialogue": "none", "summary": "abstract: a detailed diagram of the belief-net had already been disseminated ."}
{"dialogue": "one of which is just lay out the influence structure of what we think influences what", "summary": "abstract: its structure was discussed during the meeting ."}
{"dialogue": "the way we had been designing this , there were three intermediate nodes uh which were the endpoint decision as seen from the uh user model as seen from the ontology and as seen from the discourse . these are all like saying ev or a ,", "summary": "abstract: there are several endpoints ( user , ontology , discourse etc ) with separate eva ( enter / view / approach ) values ."}
{"dialogue": "one of which is just lay out the influence structure of what we think influences what", "summary": "abstract: details of how different inputs feed into them were discussed at length ."}
{"dialogue": "if it 's fixing things selling things , or servicing things so the idea would be that you might wan na merge those three you could have a node that 'sthat was a measure of the match between the object 's feature , you know , the match between the object the entity , i 'm sorry and the user .", "summary": "abstract: ideas mentioned included grouping features of buildings like `` selling '' , `` fixing '' and `` exhibiting '' , as well as creating a user-compatibility node that would take different values depending on the situation and the user status ."}
{"dialogue": "so here is thethewe had that the user 's budget may influence the outcome of decisions . well the fir see the first thing is , getting back to thing we left out of the other is the actual discourse .", "summary": "abstract: similarly , a go-there ( towards a building ) node can be influenced by things like the user 's budget and discourse parameters amongst other things ."}
{"dialogue": "and we do n't know what they are yet .", "summary": "abstract: the latter are still ill-defined at this stage ."}
{"dialogue": "because uh we 're gon na want to know you know , which constructions indicate various of these properties", "summary": "abstract: the study of the linguistic constructions that people use in this kind of navigational domain is expected to be prove useful in that respect ."}
{"dialogue": "so um recall the basic problem which is that um you have a belief - net and you have like a lot of different nodes all contributing to one node . so the problem is to specify the uh so the conditional property of this given all those ,", "summary": "abstract: as each node in the tree is the decision point of the combination of its parent nodes , which rules govern this combination is an important issue ."}
{"dialogue": "and we just take the uh we essentially take um averages , this is a hidden variable . w i was just , if you wanted to pay attention to more than one you could pass a w a weighting s system though too ,", "summary": "abstract: there are several approaches ranging from simply averaging the inputs to using a hidden variable in order to weight them differently depending on context ."}
{"dialogue": "ok , so theythey could either be hand coded or learned or", "summary": "abstract: if the latter architecture is used , the net could -to an extent- be trained with the data that is currently being collected ."}
{"dialogue": "none", "summary": "decisions: although this was mainly a brainstorming meeting , some minor tasks were allocated for the near future ."}
{"dialogue": "yeah , ii mean , it might soon , if this is gon na be used in a serious way like java base then it might soon be necessary to uh start modifying it for our purposes .", "summary": "decisions: since the net architecture and possible decision algorithms were discussed , it is necessary to examine how much of this javabayes can accommodate and , if not , what modifications would be necessary ."}
{"dialogue": "none", "summary": "decisions: additionally , the german partners visiting the institute will need to see some results of the new system design ."}
{"dialogue": "so , i mean i know we 're going for sort of a rough and ready .", "summary": "decisions: finally , the analysis of the linguistic constructions for the current research domain can begin even with limited data , as , at this stage , they need not be very detailed ."}
{"dialogue": "none", "summary": "problems: the is only a diagrammatic view of how the decision tree for the eva task looks like ."}
{"dialogue": "we have the user interest is ais a vector of five hundred values , that you 'd have to do see in order to do reference and stuff like that um you 've got ta have both the current discourse and the context to say i wan na go back there ,", "summary": "problems: a lot of the details have been glossed over: the user model can potentially comprise a huge number of factors ; a planning `` go-there '' node needs input from several other areas of the net ; there are intricate interactions between discourse and the situation model ."}
{"dialogue": "and we do n't know what they are yet .", "summary": "problems: similarly , what discourse properties are of importance and how they influence eva probabilities is still a mystery ."}
{"dialogue": "but then the question is do youdo we wan na propagate beliefs every single time it 's updated or only when we need to ?", "summary": "problems: on a more general note , there is also the question of whether the net should be updated continuously or only when it is needed ."}
{"dialogue": "none", "summary": "problems: no final decision was taken as to the rules of computation applying in the belief-net ."}
{"dialogue": "ok , so theythey could either be hand coded or learned or based on training data , like , are we able to get these nodes from the data ?", "summary": "problems: the more interesting solutions would ideally require training data , and it is still debatable whether the current collection would be appropriate for this particular task ."}
{"dialogue": "yeah , ii mean , it might soon , if this is gon na be used in a serious way like java base then it might soon be necessary to uh start modifying it for our purposes .", "summary": "problems: in any case , how different architectures can be implemented in javabayes and what modifications would be necessary for the purposes of this project also need to be investigated ."}
{"dialogue": "umso far i 've thought of it as sort of adding it onto the modeler knowledge module . we talked about this several times thatthatthethe input end is gon na need a fair amount of feedback from the planning end . so we talked about the fact that there 're going to be a certain number of decisions that you want the knowledge modeler to make , that will be then fed to the function module , that does uh , route planning .", "summary": "abstract: the berkeley even deeper understanding group discussed plans and concerns regarding the architecture of smartkom , its proposed modules , and the types of interactions expected to take place between modules ."}
{"dialogue": "and then that can be sort of developed uh as needed when we getenter the tourism domain . we probably wo n't do this early on , because the current focus is more on the decision making and stuff like that .", "summary": "abstract: the meeting was largely focused on smartkom 's decision making capacity and how to adapt this functionality to the tourist information domain ."}
{"dialogue": "so anyt we 'll find a time later in the week to uh get together and talk aboutyour understanding of what smartkom plans are .", "summary": "decisions: the group set a date for assessing smartkom plans ."}
{"dialogue": "and they 're currently um agreeing oror in the process of agreeing on an x m l - ification of um something like a state - transition network of how dialogues would proceed .", "summary": "decisions: it was decided that smartkom 's action plans should be represented in xml as a state transition network ."}
{"dialogue": "it oughta be called aa dialogue manager .", "summary": "decisions: it was proposed that the term 'dialogue planner ' should replace 'dialogue manager ' ."}
{"dialogue": "no he 's completely gon na rewrite everything . in java . no , that 's gon na be phased out .", "summary": "decisions: prolog will be phased out completely and replaced by java code ."}
{"dialogue": "and thisone of these planning modules comes along and says `` hey , right now we need to ask a question `` . so that forces the dialogue manager to change state .", "summary": "decisions: the dialogue manager must be capable of changing states , i.e . go from being event driven to answering a question from a planning module ."}
{"dialogue": "andand thethe underlying idea of course is that there is something like kernel modules with kernel functionality that you can plug uh certain applications like tourist information or um the home scenario with uh controlling a vcr and so on . and keep these things like uh tourist information external . that 's an additional reason to have this well - defined interface so if you can do this , then the notion would be that across a very large range of domains , you could use this deep conceptual basis as the interface .", "summary": "decisions: smartkom should feature a well defined core interface , with domain-specific information kept external ."}
{"dialogue": "um it 's toto integrate and syntactic analysis . butbut uh given th the constraints , that you want it to be small and fast and so forth , my guess is you 're probably into some kind of chunk parsing .", "summary": "decisions: a syntactic analysis component that performs chunk parsing will be added to the system ."}
{"dialogue": "you know th the functional module thatthat interacts withwith where the tourism g stuff is goingprobably is too restrictive . um is based on slots that have to be filled and i 'm not sure ifif complex slots of that type are really um being taken into consideration .", "summary": "problems: as a functional module , the action planner is too restrictive for the tourist domain and requires complex slots from the dialogue manager ."}
{"dialogue": "i think thethe true key issues is how does the whatever comes out of the language input pipeline look like and then what the action planner does with it", "summary": "problems: what form will the language input have , and what will the action planner do with it ?"}
{"dialogue": "we talked about this several times thatthatthethe input end is gon na need a fair amount of feedback from the planning end .", "summary": "problems: links must be in place between the input end , action planner , parser , and language feedback components for communicating the current state of plan ."}
{"dialogue": "yeah i think just thethe spatial planner and the route planner soa printout of the communication between those two fills up i do n't know how many pages", "summary": "problems: interactions in a deep map system between the spatial planner and the route planner are too convoluted ."}
{"dialogue": "yeah , uh the problem is th that it has to be very fast and they also have to be very robust . cuz of um speech recognition errors butbut uh given th the constraints , that you want it to be small and fast and so forth , my guess is you 're probably into some kind of chunk parsing . some extensions uh have to be made . forfor a english version", "summary": "problems: smartkom requires a fast and robust parser that includes language-specific extensions ."}
{"dialogue": "but the other half of the problem is how would you get that kind of information from the parsed input ?", "summary": "problems: which form of semantic construction grammar should be used , and how would such information be derived from the parsed input ?"}
{"dialogue": "none", "summary": "abstract: the translation of smartkom to english is in its final stages ."}
{"dialogue": "none", "summary": "abstract: the synthesis module will be the last one to do , after the english syntax trees are completed ."}
{"dialogue": "right now it 's brittle and you need to ch start it up and then make ts twenty changes onononon seventeen modules before they actually can stomach it , anything . we can even make asort of an internal demo , um . <outbreath> well it was just amazing toto see uh howhow instable the whole thing is ,", "summary": "abstract: the system is still buggy and unstable , but it will soon be ready for a demonstration ."}
{"dialogue": "n no , to just get the dem get the demos they need . so th the demo the demo requirements for this fall are sort of taken care of as of later this week or something .", "summary": "abstract: this is the first of two working demos required for the project ."}
{"dialogue": "but , more focused on uh an idealized version than just getting the demo out .", "summary": "abstract: further than that , there are no restrictions on the focus of the research or its possible applications ."}
{"dialogue": "and so these issues about uh , reference , andspatialreference , discourse reference , uh - uh - uh - uhall this sort of stuff , uh , deixis which is part of what you were talking about , so we got ta do all this .", "summary": "abstract: for example , issues like spatial descriptions could be investigated ."}
{"dialogue": "on this scale , you have it either be ego or allocentric . so in addition to e ego and allocentric uh which appear all over the place , you also apparently have this proximal - distal thing which is very deeply uh embedded .", "summary": "abstract: the variety of linguistic conventions seem to develop around an ego / allo-centric and a proximal / distal paradigm ."}
{"dialogue": "by the way , theresomething that i did n't know until about a week ago or so , is apparently , there are separate brain areas for things within reach , and things that are out of reach .", "summary": "abstract: the latter is also reflected in neuro-physiological data ."}
{"dialogue": "so , i think as far as this group goes , um , it 's certainly worth continuing for the next few weeks to get closure on the uh belief - net and the ideas that are involved in that , and what are th what are the concepts .", "summary": "abstract: from an engineering perspective , the belief-net for the ave task should be completed within a few weeks ."}
{"dialogue": "and we went through this , and , i think , more or less convinced ourselves that at least the vast majority of the nodes that we needed for the demo level we were thinking of , were in there .", "summary": "abstract: the majority of the nodes are already there ."}
{"dialogue": "ok ? what allyou know , what are the considerations and how and what are the ways in which they relate .", "summary": "abstract: this leaves the dependencies between them and the rules of computation to be set ."}
{"dialogue": "so `` ok , we 're not using their system . that means we need our system . `` but to do that we 're gon na need to make some decisions like ontology , i does uh either the uh smartkom project or one of the projects at eml have something that we can just p pull out , for that .", "summary": "abstract: since the whole system is going to be re-designed , there are major decisions to be taken regarding the parser and the ontology , as well as what can be re-used from past eml projects ."}
{"dialogue": "so the idea is there 's this uh , other subgroup that 's worrying about formalizing the nota getting a notation .", "summary": "abstract: in parallel , another team is working on formalisation and notation ."}
{"dialogue": "oh there 's yet another one of the incoming firstincoming first - year graduate students who 's expressed interest , and actually i talked today to a uh undergraduate who wants to do an honors thesis on this . and , while we 're at this level , uh , there 's at least one new doctoral student in computer science who will be joining the project , either next week or the first of august , depending on the blandishments of microsoft .", "summary": "abstract: finally , more ideas are expected to come from students and their research ."}
{"dialogue": "so , c sh we could set that up as actually an institute wide thing ? well d wewe do wan na have all the bugs out b where you have to sort of pipe in extra xml messages from left and right before you 're", "summary": "decisions: the final english smartkom demo will be presented to the whole institute once the system is de-bugged and stabilised ."}
{"dialogue": "so i 'd like to , for the summer turn into science mode . but , more focused on uh an idealized version than just getting the demo out . uh . i mean there are a lot of issues , what 's the ontology look like , you know what do the constructions look like , what 's the execution engine look like ,", "summary": "decisions: after the demo , the focus of research can switch towards purely scientific goals , including issues on ontology , deep semantic constructions , execution engines etc ."}
{"dialogue": "so `` ok , we 're not using their system . that means we need our system . `` and so , uh , in addition to the business about just getting the linguistics right , and the formalism and stuff , we 're actually gon na build something", "summary": "decisions: moreover , a new system will be designed for the project and at least some parts of it should be built ."}
{"dialogue": "cuz we 'rewe 're not only goingthe plan is not only to lay out this thing , but to actually uh build some of it . it looks like we 're now in a position that the construction analyzer that we want for this applied project can be the same as the construction analyzer that nancy needs for the child language modeling .", "summary": "decisions: similarly , the construction analyser should be a single , general tool working for both the tourist domain and child language modelling ."}
{"dialogue": "and one of the things we need to do is the um , and this i think is relatively tighttightly constrained , is to finish up this belief - net stuff . so , i think as far as this group goes , um , it 's certainly worth continuing for the next few weeks to get closure on the uh belief - net and the ideas that are involved in that , and what are th what are the concepts .", "summary": "decisions: the focus for the next meeting will be on the belief-net , of which a working demo should be complete in the next few weeks ."}
{"dialogue": "so uh what we 're gon na do initially isis do design , and , i if you will , guess . but for the limited amount of stuff we have for this particular exercise i think we 'll just design it .", "summary": "decisions: since there are not enough data , its connections and weights will have to be designed ."}
{"dialogue": "none", "summary": "decisions: although javabayes has been the tool of choice until now , the possibility that hugin could be a better option should be investigated ."}
{"dialogue": "and um , part of my responsibility is uh to use our internal `` group - ware `` server at eml , so that whatever we discuss in terms of parsing andand generating and constructions w wewe sort of uh put it in there and they put what they do in there and maybe we can even um , get some overlap , get some synergy out of that .", "summary": "decisions: in order to promote the collaboration with eml , the group-ware server there will be updated with all progress being made in the two sites ."}
{"dialogue": "and so anyway we c uhwe can m undoubtedly get ami uh to give a talk at uh eml or something like that . while he 's inin uh a lot of interest . actually , either place , dfki or uh", "summary": "decisions: a talk on some of the issues will also be organised to take place at dfki ."}
{"dialogue": "e the versionthat is , the full version that 's on the server d does not work .", "summary": "problems: the german smartkom version available on the server does not work ."}
{"dialogue": "right now it 's brittle and you need to ch start it up and then make ts twenty changes onononon seventeen modules before they actually can stomach it , anything . because it 's designed for this seevit thing , where you have the gestural recognition running with this s siemens virtual touch screen , which we do n't have here . but it 's working now , and i g i got the feeling that we arethe only ones right now who have a running system . um . <outbreath> well it was just amazing toto see uh howhow instable the whole thing is ,", "summary": "problems: the english version , although still under development , does work , however , the system is still unstable as -apart from other reasons- it was initially built to work with a touch screen ."}
{"dialogue": "well d wewe do wan na have all the bugs out b where you have to sort of pipe in extra xml messages from left and right before you 're", "summary": "problems: de-bugging and cleaning up has to take place before any new modules are added on it ."}
{"dialogue": "none", "summary": "problems: as regards the belief-net , no connections and dependencies have been built into it ."}
{"dialogue": "so uh what we 're gon na do initially isis do design , and , i if you will , guess . but for the limited amount of stuff we have for this particular exercise i think we 'll just design it .", "summary": "problems: these will have to be guessed instead of learnt through data , as not enough data is available for such a task ."}
{"dialogue": "javabayes does not support that . ii also s would suggest not to d spend two weeks ininin changing thethe javabayes code .", "summary": "problems: finally , it has been noted that the javabayes gui does not satisfy all the presentation requirements for this belief-net and modifying the underlying code would be too time-consuming ."}
{"dialogue": "uh one of them is to work on the semantics of the belief - net which is going to be the main inference engine for thi the system uh making decisions . and we 're also , sort of uh in the same process , going to work with fey on what there should be in the dialogues .", "summary": "abstract: the main focus of the meeting was firstly on the structure of the belief-net , its decision nodes and the parameters that influence them , and secondly , on the design of the data collection tasks ."}
{"dialogue": "and umand fey has some thirty subjects lined up ? so weyeah we do n't know how many we can get next door at theuh shelter for example .", "summary": "abstract: for the latter , there are already 30 subjects lined up and more are expected to be recruited off campus ."}
{"dialogue": "and umand then they gon na have to f um um choose from one of these tasks , which are listed here . so ifif it 's one service , one luxury item , you know , one big - ish place , and so forth and so on , umthen my guess is thatthat the data is going to be easier to handle . that w maybe one thing we should do is go through this list and sort of select things that are categories and then o offer only one member of that category ?", "summary": "abstract: it was agreed that making subjects select from categories of tasks , such as `` big place '' , `` service '' , etc . could provide a better range of data ."}
{"dialogue": "i b my guess is it 's gon na be ten .", "summary": "abstract: the duration of each dialogue will probably be no more than 10 minutes ."}
{"dialogue": "none", "summary": "abstract: on the other hand , the organisation of the intermediate nodes of the belief-net and their properties is almost complete , although no conditional probabilities have been inserted yet ."}
{"dialogue": "and decisions are going to turn out to be parameter choices for calls on other modules .", "summary": "abstract: these nodes represent decisions that will function as parameters to action calls in the system ."}
{"dialogue": "and that we can actually infer them to a significant de degree , or we ask . oreh so , y but there 's th but definitely a back - off position to asking .", "summary": "abstract: their values will either be inferred from the user-system interaction , or -as a last resort- requested directly from the user ."}
{"dialogue": "ok , because uhwe do wan na get them r u perfectlybut i think we 're gon na have to do a first cut at a lot of them to see how they interact .", "summary": "abstract: finally , as to the semantic and syntactic constructions , work will start with more general and brief descriptions , before moving to exhaustive analysis of at least a subset ."}
{"dialogue": "we are expecting johno to build a parser , uhhe 's g he 's hoping to do this for his masters ' thesis s by a year from now . uhlimited . well , the hope is that the parser itself is , uh , pretty robust .", "summary": "abstract: similarly , the construction parser that is to be built within a year is expected to be relatively basic , yet robust ."}
{"dialogue": "maybei suggest we make some fine tuning of these , getsort ofrun through ten or so subjects um but anywayyeah , so i thinkit 's a good idea to start with the sort of relatively straight forward res just response system .", "summary": "decisions: as the data collection is ready to start , it was agreed that for the first ten subjects the interaction with the system / instructor will be along the lines of a basic response system ."}
{"dialogue": "and umand then they gon na have to f um um choose from one of these tasks , which are listed here . that w maybe one thing we should do is go through this list and sort of select things that are categories and then o offer only one member of that category ? like at you know , `` attend a theater , symphony or opera `` isis a group , and `` tour the university , castle or zoo `` ,", "summary": "decisions: tasks will be divided in categories ( `` tour '' , `` attend '' etc ) and subjects are going to be asked to choose no more than one task out of each category ."}
{"dialogue": "sotrying to im umimplant the intention of going to a place now , going to a place later on the same tour , and see whether we wan na make it more complex or not , depending on whatwhat sort of results we 're getting . umii would say maybe two weeks . let 's plan next monday , ok , to have a review of what we have so far . this means audio , but but it would be great if you could , um , not transcribe it all , but pick out uh , some stuff . and then if we want to uhget them to start doinguhmultiple step planning with a whole bunch of things and then organize them tell them which things are near each other and we 're gon na start thinking a aboutuhwhat constructions we want to elicit .", "summary": "decisions: this first run will probably take a couple of weeks , but the first results ( audio files and selected highlights ) will be discussed shortly , in order to decide whether more detail ( complex spatial relationships , temporal planning etc ) should be included in the design or particular constructions be elicited ."}
{"dialogue": "see thisthisthisuhontology node is probably something that i will try to expand . and hopefully you can sort of also try to find out , you know , sooner or later in the course of the summer what we can expect to get from the discourse that might , you knowor the", "summary": "decisions: regarding the completion of the belief-net , the remaining details , mainly the properties of the ontology and discourse nodes , should be added ."}
{"dialogue": "uh robert and eva and bhaskara are gon na actuallybuild a belief - net thatthat , um , has cpt 's and , you know , tries to infer this from various kinds of information .", "summary": "decisions: after building in the conditional probability tables , a working prototype of the net will be ready ."}
{"dialogue": "ok , because uhwe do wan na get them r u perfectlybut i think we 're gon na have to do a first cut at a lot of them to see how they interact .", "summary": "decisions: finally , the initial work on constructions should focus on a general overview of the dialogues with brief descriptions ."}
{"dialogue": "whatever you need in order to uh , be able to then , uh , by hand , you know , explain , some fraction of the utterances .", "summary": "decisions: further analysis will follow from there in a top-down fashion ."}
{"dialogue": "so there 's a lot of things where we have no analogous tasks , andthat may or may not be a problem .", "summary": "problems: although there is an effort to include some of the key features of the belief-net in the design of the data gathering , not all of them can be built in ."}
{"dialogue": "and these are the data tasks where w we can assume the person would like to enter , view or just approach the thing . now of course you have this i guess possible danger that somehow there 're certain constructions that people use uh when talking about a museum that they would n't talk about with a university and stuff ,", "summary": "problems: the tasks that the subjects will have to carry out will be categorised in ways that will indicate eva intentions , however , this approach may limit the variety of possible constructions used within a single category of entities ."}
{"dialogue": "none", "summary": "problems: on the other hand , generating more diverse dialogues may have an adverse effect from a speech recognition perspective ."}
{"dialogue": "and um we 're still l looking for a room on the sixth floor because they stole away that conference room . umbehind our backs . david andand jane andand lila are working on that as we speak .", "summary": "problems: a minor problem has arisen with the laboratory where recordings are supposed to take place , but this is currently being sorted out ."}
{"dialogue": "none", "summary": "problems: as regards the completion of the belief-net , no work has been done on the cpt 's yet ."}
{"dialogue": "and ii me it would it would be completely out of the question to really do more than , say , like , oh i do n't know , ten , over the summer ,", "summary": "problems: finally , it was noted that although a general overview of the pertinent constructions is attainable , no more than ten of them can be analysed in detail with the summer months ."}
{"dialogue": "none", "summary": "abstract: the focus of the meeting was on a presentation of the work done already on the building of the bayes-net ."}
{"dialogue": "that 's basicallyjust specifying thethe input for thew what 's it 's based on things like , uh , there 's gon na be a node for go - there or not , and there 's gon na be a node for enter , view , approach .", "summary": "abstract: the input layer deriving information from things like the user and situation models , feeds into a set of decision nodes , such as the enter / view / approach ( eva ) endpoint ."}
{"dialogue": "and somesome things will always be sort of toonot significant enough .", "summary": "abstract: in any particular situation , most of the outputs will not be relevant to the given context ."}
{"dialogue": "cuz , that 's whati mean , in the bayes - net you always ask for the posterior probability of a specific node .", "summary": "abstract: therefore , they will either have to be pruned a posteriori , or only a subset of the possible decision nodes will be computed in each occasion ."}
{"dialogue": "i mean , maybe it does make a difference in terms of performance , computational time . so basically , you 'd have a decision treequery , go - there . and just basically do a binary search through the ?", "summary": "abstract: the latter option could could follow a binary search-tree approach and it could also be better in computational terms ."}
{"dialogue": "you won'tit 'll be hard to decide .", "summary": "abstract: in any case , on what basis the `` winner '' output is chosen is not clear ."}
{"dialogue": "and for the where - is construction , we know we need to l look at this node , that merges these three things together so my i so , if we were to it with a bayes - net , we 'd have to have a nodefor every question that we knew how to deal with , every construction .", "summary": "abstract: one suggestion was discussed: the particular constructions used can determine the pertinent decision ( output ) nodes ."}
{"dialogue": "and , um , finish up this bayes - net . and we present our results ,", "summary": "abstract: the complete prototype of the bayes-net will be presented in the next meeting ."}
{"dialogue": "ok . because then , once we have it sort of up and running , then we can start you know , defining the interfaces and then hook it up to some fake construction parser", "summary": "abstract: after that , it will be possible to define interfaces and a dummy construction parser , in order to test and link modules together ."}
{"dialogue": "every construction .", "summary": "decisions: the suggestion that the most appropriate decision node of the belief-net in each situation could be chosen as a function of what construction was used , was deemed unsuitable at this stage ."}
{"dialogue": "because there are interdependencies ,", "summary": "decisions: there are many interdependencies between the output nodes that this approach could not take into account ."}
{"dialogue": "sometimethis weekagain and finish up the , uh , values of this .", "summary": "decisions: the rest of the values for the bayes-net nodes will be built in within the week ."}
{"dialogue": "and , um , finish up this bayes - net . and we present our results ,", "summary": "decisions: the finished prototype will be presented during the next meeting ."}
{"dialogue": "as , if i understand it correctly , it always gives you all the posterior probabilities for all the values of all decision nodes . so , itn i meana all i 'm saying is , whatever our input is , we 're always gon na get the full output . whatwhatwhat i am thinking , or what we 're about to propose here is we 're always gon na get the whole list of values and their posterior probabilities . cuz , that 's whati mean , in the bayes - net you always ask for the posterior probability of a specific node .", "summary": "problems: any set of inputs will provide either the whole range of output values of the bayes-net or an a priori selection of those outputs ."}
{"dialogue": "and the question is what to do with it , and now we need an expert system or belief - net or something that interprets that , well , eventually , you still have to pick out which ones you look at .", "summary": "problems: in both cases , what is needed is a way to single out the appropriate outputs for any given context ."}
{"dialogue": "so the person said , um , `` where is x ? `` we want to know , um , isdoes he want info ? or does he want to go there ?", "summary": "problems: for example , in the case of a `` where is '' question , whether the prevalent output should be `` go-there '' or `` info-on '' or even a third option has to be computed somehow ."}
{"dialogue": "none", "summary": "problems: in any case , there are many input values that have not been entered in the bayes-net at this stage ."}
{"dialogue": "yeah , i can worry about the ontology interface and you cankeith can worry about the discourse .", "summary": "problems: furthermore , no inputs for the ontology and discourse can be built in yet , as they involve research that will be carried out in the future ."}
{"dialogue": "also , i 'm somewhat boggled by that hugin software . i ca n't figure out how to get the probabilities into it .", "summary": "problems: finally , there has been a problem with adding probabilities in a net created with the hugin software , but this should be overcome very shortly ."}
{"dialogue": "and the other bit of news is we hadyou know , uh , i was visited by my german project manager and he came upwe came upwith a pretty strange idea . it should be possible to make that system produce questions .", "summary": "abstract: an idea for future work was suggested during the visit of the german project manager: the possibility to use the same system for language generation ."}
{"dialogue": "but maybe one could do some learning .", "summary": "abstract: having a system able to ask questions could contribute significantly to training the belief-net ."}
{"dialogue": "the basic idea i guess would be to giveallow the system to have intentions , basically ? well you can observe some user and context stuff and ask , what 's the posterior probabilities of all of our decision nodes .", "summary": "abstract: setting up certain inputs in the bayes-net would imply certain intentions , which would trigger dialogues ."}
{"dialogue": "i mean we justi mean it would n't hurt to write up a paper , well , ii also think that if we sort of write about what we have done in the past six months , wewewe could sort of craft a nice little paper thatif it gets rejected , which could happen , does n't hurt and then we can say , uh well what we do is this .", "summary": "abstract: there is potential to make a conference paper out of presenting the current work and the project aspirations within a parsing paradigm ."}
{"dialogue": "so this will be sort of documenting what we think , and documenting what we have in terms of the bayes - net stuff . well , in the moment it 's a bayes - net . and it has sort of fifty not - yet - specified interfaces .", "summary": "abstract: the focus should be the bayes-net , to which all other modules interface ."}
{"dialogue": "the sudo - square < writing on whiteboard > is , < three-syllable laugh > `` situation `` , `` user `` , `` discourse `` , right ? `` ontology `` .", "summary": "abstract: situation , user , discourse and ontology feed into the net to infer user intentions ."}
{"dialogue": "and johno coming up with the idea that if the person discussed thediscussed the admission fee , ineh previously , that might be a good indication that , `` how do i get to the castle ? `` , actually he wants to enter .", "summary": "abstract: someone asking where the castle is after having asked about the admission fee , indicates that -given that the castle is open to tourists- they want to go there , as opposed to knowing its whereabouts ."}
{"dialogue": "and specify um , whatwhat we think thethe output uh , observe , outi input nodes for our bayes - nets for the sub sub - d , for the discourse bit , should be . so we want to sort of come up with what gets uh , input , and how inter in case of a `` where is `` question . so that we actually end up with um , um , nodes for the discourse and ontology so that we can put them into our bayes - net ,", "summary": "abstract: it was suggested that they start analysing what the discourse and ontology would give as inputs to the bayes-net by working on simple utterances like `` where is x ? `` ."}
{"dialogue": "and we can run our better javabayes , and have it produce some output .", "summary": "abstract: with this addition , all input layers of the net would be functioning ."}
{"dialogue": "none", "summary": "abstract: although this function would be limited , it would allow for the bayes-net to be tested in its entirety and , henceforth , extended ."}
{"dialogue": "none", "summary": "decisions: the possibility of incorporating language generation into the system will have to be discussed further ."}
{"dialogue": "look at the web page and let 's talk about it maybe tomorrow afternoon ?", "summary": "decisions: similarly , as no one could recall some of the points of the conference call , the group will have to meet again and define the exact structure and content of the paper they are going to submit ."}
{"dialogue": "so this will be sort of documenting what we think , and documenting what we have in terms of the bayes - net stuff .", "summary": "decisions: the bayes-net is going to be the focus of the presentation ."}
{"dialogue": "and specify um , whatwhat we think thethe output uh , observe , outi input nodes for our bayes - nets for the sub sub - d , for the discourse bit , should be . so we want to sort of come up with what gets uh , input , and how inter in case of a `` where is `` question . so that we actually end up with um , um , nodes for the discourse and ontology", "summary": "decisions: in order to complete a functioning prototype of the belief-net , it was decided to start expanding the ontology and discourse nodes by working with a simple construction , like `` where is x ? `` ."}
{"dialogue": "wait , so do , or do not take other kinds of constructions into account ? well , if youif you can , oh definitely do ,", "summary": "decisions: a robust analysis of such a basic utterance will indicate what the limits of the information derived from the construction are , as well as ways to design the whole module and fit other constructions in ."}
{"dialogue": "e i 'm sort ofhave the impression that getting it to say the right thing in the right circumstances is much more difficult than getting it to understand something given the circumstances and so on , it 's not the same as the understanding .", "summary": "problems: the idea to create a language generation module for the system , along with the language understanding , was met with interest , although it was made clear that generation is not just the inverse of understanding ."}
{"dialogue": "just the fact that we 'll getthe point is that getting it to understand one construction does n't mean that it will n always know exactly when it 's correct to use that construction . right ?", "summary": "problems: understanding what a construction entails does not mean the system can use the construction in all appropriate circumstances ."}
{"dialogue": "but maybe one could do some learning . yeah , it 's g anyway , the point is that given all of these different factors , it 's uh e it 'sit 's still going to be impossible to run through all of the possible situations or whatever .", "summary": "problems: a dialogue producing system would be useful for training the system further , even though the number of input permutations could render the process computationally unwieldy ."}
{"dialogue": "i mean , it 's obvious that we ca n't do any kind of evaluation ,", "summary": "problems: regarding the conference paper , it was noted that at this stage they have not completed any big parts of the system and there is no evaluation ."}
{"dialogue": "like introducing the formalism might be not really possible in detail ,", "summary": "problems: similarly , the length of the paper would not allow for presentation of the formalism in detail ."}
{"dialogue": "none", "summary": "problems: the focus would have to be on cognitive motivations of the research , and not on system design , anyway ."}
{"dialogue": "none", "summary": "problems: such motivations also apply to the belief-net: there are various direct or indirect ways to link features of the ontology or discourse with specific intentions ."}
{"dialogue": "but normal statements that seem completely unambiguous , such as `` where is the blah - blah `` , actually are terribly complex , and completely ambiguous .", "summary": "problems: the originating observation behind the whole project is that utterances like `` where is x ? '' are seemingly unambiguous , but , in context , they can acquire much more complex interpretations ."}
{"dialogue": "and eva is using the xalan style sheet processor to convert the xml that 's output by the java bayes for theinto the , uh , e bayes input .", "summary": "abstract: minor technical issues , such as format conversions for xml and javabayes and the full translation of the smartkom generation module in english , are currently being resolved ."}
{"dialogue": "yep . we ha we have to change the voice .", "summary": "abstract: the voice synthesiser will also be replaced by better technology ."}
{"dialogue": "uh , w which ismental spaces and uhand - or but the other part of it is the way they connect to these , uh , probabilistic relational models .", "summary": "abstract: an important research issue to be investigated is how the concept of mental spaces and probabilistic relational models can be integrated into the belief-net ."}
{"dialogue": "so there probably are some , uh , relatively clean rules , is that people do manage to do this", "summary": "abstract: mental space interdependencies are based on relatively clean rules , since people seem to manage them easily ."}
{"dialogue": "no , i know , i th i i think that is gon na be sort of the key to this wh to th the big project of the summer ofof getting the constructions right", "summary": "abstract: a step towards this goal is the construction formalism being put together ."}
{"dialogue": "which is the issue of , um , how do you simulate questions ? we didn'twe never did figure out how we were gon na do emphasis inin uh , the semspec . incl including the questions uh , no , all the focus stuff . and we 'll figure out exactly how to write that up and so on ,", "summary": "abstract: this module will eventually have to include ways to simulate questions , do emphasis and focus ."}
{"dialogue": "the question of whether the polysemy is sort of like in the construction or pragmatic . well the question is basically , is this conventional or conversational implicature ?", "summary": "abstract: the constructions could be built assuming either conventional or conversational implicature ."}
{"dialogue": "w we know for sure that we have to be able to do both . i mean itth <inbreath> i can thi i can think of arguments in either direction on that .", "summary": "abstract: at this stage both routes need to be examined ."}
{"dialogue": "right . so . <laugh> right . so thingthat 's part of why we want the formalism ,", "summary": "abstract: the formalism will also serve as a starting point for the definition of construal mechanisms ."}
{"dialogue": "none", "summary": "abstract: similarly , issues like time plans and discourse stacks are dependent on how the ontology and discourse history are going to be structured and linked ."}
{"dialogue": "priming a spreading activation", "summary": "abstract: one suggestion was to use the spreading activation as a paradigm for activating nodes in the belief-net ."}
{"dialogue": "whichuh , so far , in terms of like putting up all the constraints as , you know , pushing them into type constraints , thewhen i 've , you know , propo then proposed it to linguists who have n't yet given meyou know , we have n't yet thought of a reason that that would n't work . right ? as long as we allow our type constraints to be reasonablycomplex .", "summary": "abstract: finally , using type constraints in the construction analysis should work , as long as they are complex enough not to generate too many parses ."}
{"dialogue": "actually , maybe i could try , like , emailing the guy and see if he has any something already .", "summary": "decisions: it is necessary to ask the javabayes programmer whether he already has xml conversion programs ."}
{"dialogue": "so i just need todo the , uhwrite a new set oftree combining rules . and fey has foolheartedly agreed to rewrite uh , the german concept uh syntax - to - prosody rules", "summary": "decisions: for the smartkom generation module , all the syntax-to-prosody rules are going to be re-written for english ."}
{"dialogue": "ogi has , uh , crafted a couple of diphone type voices that are really nice", "summary": "decisions: additionally , ogi can offer a range of synthesiser voices to choose from ."}
{"dialogue": "anyway , uh , that we werethat we 're gon na try to get a uh , first cut at the revised formalism by the end of next week . so the idea is on monday at two we 'llwe 'll see an intermediate version of the formalism for the constructions ,", "summary": "decisions: the focus of the next meeting , whose time was rescheduled , will be the discussion of the revised construction formalism ."}
{"dialogue": "uh , just trying to write up essentially whatwhat you guys have worked out so that everybody has something to look at . yeah . well , ififi mean , i part ofof what the exercise is , t by the end of next week , is to say what are the things that we just do n't have answers for yet .", "summary": "decisions: the presentation will unify the existing ideas and help identify the areas in need of further work , such as how it can deal with time and tense use and how they affect inferences in belief-nets ."}
{"dialogue": "the question of whether the polysemy is sort of like in the construction or pragmatic . well the question is basically , is this conventional or conversational implicature ? w we know for sure that we have to be able to do both . i mean itth <inbreath> i can thi i can think of arguments in either direction on that .", "summary": "decisions: the ambiguity in a `` where is x ? '' construction can be coded in the formalism as a semantic feature or pushed forward to the belief-net where pragmatic features will disambiguate it: in terms of system design , both options need to be investigated at this stage ."}
{"dialogue": "that 's the lisp - type scheme . well , i guess if you 're not used to functional programming , scheme can be completely incomprehensible .", "summary": "problems: as the translation of the german smartkom into english moves on , the generation rules may prove difficult to tackle for someone without experience in functional programming , as they are written in lisp ."}
{"dialogue": "one of the things i w would like to do over the next , uh , month , it may take more , is to st understand to what extent we can not only figure out the constructions for them for multiple worlds uh sort of what the formalism will look like and where the slots and fillers will be , but also what that would translate into in terms of belief - net and the inferences . one is the linguistic part of what are the couplings andand when you have a certain , uh , construction , that implies certain couplings and other couplings , and then we have this inference problem of exactly technically how does the belief - net work", "summary": "problems: as far as the construction analysis is concerned , the two problems that will need to be solved are to identify the couplings between constructions in different mental spaces and to define how inferences will work in the belief-net from a technical point of view ."}
{"dialogue": "the question of whether the polysemy is sort of like in the construction or pragmatic . the question is whether the construction is semantic or like ambiguous between asking for location and asking for path . well the question is basically , is this conventional or conversational implicature ? i mean itth <inbreath> i can thi i can think of arguments in either direction on that .", "summary": "problems: additionally , in the example `` where is x ? '' construction , the ambiguity ( location or path ) could be coded either in the semantics of the construction or as if determined by context ."}
{"dialogue": "so i a i i th i agree with you that , um , it 's a disaster to try to make separate constructions for every uh , pragmatic reading ,", "summary": "problems: the former could mean creating a different construction for every slight pragmatic variation ."}
{"dialogue": "although there are some that will need to be there . so you could just as well tag the lexical construction with the fact that it 's a uh , you know , thirty percent increase in probability of entering .", "summary": "problems: on the other hand , some of the belief-net probabilities could be instantiated in the lexicon ."}
{"dialogue": "none", "summary": "problems: specifying which approach to take when linking the ontology and the discourse history has also proven not to be straightforward ."}
{"dialogue": "uh , this isthis is , speaking of hard problems , this is a very good time um , to start trying to make explicit where construal comes in andyou know , where c where the construction per - se endsand where construal comes in ,", "summary": "problems: finally , it is still undecided where construal comes in , which would help delimit the constructions as well ."}
{"dialogue": "and so one on one side ison one side is a sort of the revised sort of updated semantic specification . and the other side is , um , sort of a revised construction formalism .", "summary": "abstract: the discussion concerned the revised semantic specification and the construction formalism ."}
{"dialogue": "so they could all have a type at the beginning . ok , and then again semantic constraints here are justare just bindings .", "summary": "abstract: the different levels of the latter focus on what construction types are encountered and what bindings there are between them ."}
{"dialogue": "but , you know , we have theproperties of dependency grammars and some properties of constituentsconstituent - based grammar .", "summary": "abstract: the notation maintains properties of both dependency and constituent-based grammars ."}
{"dialogue": "i think that 's still in progress . other things we did n't <breath> totally deal with , um , well , we 've had a lot of other stuff that keith and i have them working on in terms of like how you deal with like an adjective . you know , aa nominal expression .", "summary": "abstract: the encoding of features is still incomplete: frame profiles , focus , adjectives , nominal expressions are phenomena in the process of being integrated ."}
{"dialogue": "so there 's going to be some extrayou know , definitely other notation we 'll need for that which we skip for now .", "summary": "abstract: similarly , ways to handle mental spaces will have to be added on top ."}
{"dialogue": "so you see it 's `` scenario `` , `` referent `` and `` discourse segment `` . the `` scenario `` box ,", "summary": "abstract: on the other hand , the semantic specification structures information in terms of `` scenario '' , `` referent '' and `` discourse segment '' ."}
{"dialogue": "and actually it 's just a list of various slots from which you would drawdraw in order to paint your picture , a bunch of frames , bi and bindings , right ?", "summary": "abstract: each category comprises a number of slots filled in by information derived from the utterance ."}
{"dialogue": "which is made up entirely of these things and , uh , bindings among them . and bindings to ontology items . so thatthat the who that this is the tool kit under whi out of which you can make a semantic specification . so this is an that anything you have , in the party line , anything you have as the semantic side of constructions comes , from pieces of thisignoring li but it 's got to be pieces of this along with constraints among them .", "summary": "abstract: it is , essentially , a toolkit with which to create semantic constructions , as well as the bindings between them and with the ontology ."}
{"dialogue": "yeah , but youdo n't we ultimately want to handle that analogously to the way we handle time and place , um , we might be able to handle context in the same way that we handle mental spaces so that pulling something out of a discourse context is i think similar to other kinds of , uh , mental space phenomena .", "summary": "abstract: among the issues still being defined , mental spaces and context ( eg pronoun references ) present similarities that can be echoed in the specification ."}
{"dialogue": "um , and we 're going to have to s sort of bound the complexity . but just try to describe which ones you think we ought to have . justjust sort of , you know , define your space .", "summary": "abstract: work on both of these formalisms will continue with circumscription of the construction space that will be studied in more detail ."}
{"dialogue": "um , imagine youyou write a bayes - net , um , completely from scratch every time you do construal . and that fills in your cpt 's with which you can then query , um , thethe net that you just wrote and find out how thing x is construed as an utterance u . you may have some general rules as to how things can becan be construed as what , so that will allow you to craft thethethe initial notes .", "summary": "abstract: work on construal will use bayes-nets , which will be fed information from other modules and implement general rules to infer how utterances are construed ."}
{"dialogue": "none", "summary": "decisions: the semantic specification requires some adjustments ."}
{"dialogue": "except for `` cause `` , that i forgot . causal stuff we absolutely need .", "summary": "decisions: amongst other things `` cause '' has to be added as another x-schema ."}
{"dialogue": "well we were just talking about this sort of evidentiality and stuff like that , right ? confidence or something like that .", "summary": "decisions: linguistic hedging will also be encoded as a demarcation of evidentiality or speaker confidence ."}
{"dialogue": "um , it 's often thought of asit is also considered a mental space , same thing . yeah , but youdo n't we ultimately want to handle that analogously to the way we handle time and place , um , we might be able to handle context in the same way that we handle mental spaces it 's likeit 's like what 's happeningthat , yeah , what what 's happening , uh , there is that you 're moving the base space or something like that , right ?", "summary": "decisions: mental spaces can be tackled with mechanisms that can also deal with context issues ( time , space etc . ) : creating a base space and rules of interaction with other interconnected spaces ."}
{"dialogue": "um , and we 're going to have to s sort of bound the complexity . but just try to describe which ones you think we ought to have . justjust sort of , you know , define your space .", "summary": "decisions: however , the complexity of these mechanisms has to be bound as well: it is necessary to define the range of constructions to be studied ."}
{"dialogue": "wewe do n't have to care too much about the speaker attitude , right ? soso we 're gon na get the w we 're basically dealing with two domains , the tourist domain and theand the child language learning .", "summary": "decisions: given the domains currently used ( tourist , child language learning ) , some features , like speaker attitude , are not of equal importance at this stage ."}
{"dialogue": "is this , uhwas it intentional to leave off things like `` inherits `` i did n't want to think too much about that forfor now . can we make it more elegant ? ``", "summary": "decisions: on the other hand , it was decided for the inheritance between constructions to be left out for now , as the notation can be rendered more elegant later on ."}
{"dialogue": "um , imagine youyou write a bayes - net , um , completely from scratch every time you do construal . but the question is do you want to , for example , send the little group , uh , a draft of your thesis proposal we can do it th - thursday again .", "summary": "decisions: finally , a preliminary presentation on the idea of how to use bayes-nets for construal will take place in the next meeting ."}
{"dialogue": "and so it was an issue whether constraintsum , there were some linguists who reacted against `` constraints `` , saying , `` oh , if it 's not used for matching , then it should n't be called a constraint `` . the wholethe mental space thing is clearly not here .", "summary": "problems: the construction formalism is not yet complete as to the semantic constraints -the terminology has also been met with objections- and does not deal with mental spaces ."}
{"dialogue": "you know , um , basically all of these so - called space builders that are in the sentence are going to sort of assuming that at any point in discourse there 's the possibility that we could be sort of talking about a bunch of different world scenarios , whatever , and the speaker 's supposed to be keeping track of those . the , umthe construction that you actually get is just gon na sort of give you a cue as to which one of those that you 've already got going , um , you 're supposed to add structure to . but it does n't tell you like exactly what itwhat the point of doing so is .", "summary": "problems: on their own , constructions can only give limited information regarding mental spaces: forms can provide cues to create a different mental space , but the semantic nuances are defined by context ."}
{"dialogue": "none", "summary": "problems: it is not decided at this stage whether the necessary values should be coded within the construction or as part of construal ."}
{"dialogue": "ok , it 's likeuh , it 's notit might be that there 's a syntactic , uh , device that you use to indicate focus uh , soso i think that 's kind of nice to keep `` focus `` being an information structure term . i think that 's still in progress . but it didoneone implication it does f have for the other side , which we 'll get to in a minute is that i could n't think of a good way to say `` here are the possible things that you could focus on `` , but ii ca n't think of like the limited set of possible meanings that you wouldthat you would focu maybe you want to forget stress . canonically speaking you canif you look at aa curve over sentence , you can find out where a certain stress is and say , `` hey , that 's my focus exponent . `` it does n't tell you anything what the focus is .", "summary": "problems: other issues concern focus and stress: focus is seen as an information structure device , but there has been no suggestion as to how to predict its effects or break it down in possible focused elements ; as to stress , it may not be useful as a form value , as it shows the focus exponent , but not what the focus is on ."}
{"dialogue": "except for `` cause `` , that i forgot . causal stuff we absolutely need . mental space we need . andand so we 're , uh gon na have to , um , chain those as well . it 'sas far as i can tell there 's this one major thing we have to do which is the mentalthe whole s mental space thing .", "summary": "problems: moving to the semantic specification , the analysis still needs mechanisms to deal with causality , as well as mental spaces and bindings between them ."}
{"dialogue": "none", "summary": "problems: additionally , how referring expressions are linked to referents or even how mental spaces affect this linking are still to lay down in detail ."}
{"dialogue": "then i 'm also going to present a little talk at eml , about what we have done here let 's talk about your thesis proposal .", "summary": "abstract: the meeting was taken up by discussion about a thesis proposal and a talk about to take place at eml ."}
{"dialogue": "then i 'm also going to present a little talk at eml , about what we have done here then i 'm going to talk about the data ,", "summary": "abstract: the latter will present the work that is currently being done at icsi including examples of inference of user intentions and of the recordings of the on-going data collection ."}
{"dialogue": "e tell a little bitas much as ican about the ntl story . and then maybe talk about the big picture here , so x - schemas , then , i would like to do and then at the end about our bayes - net .", "summary": "abstract: the talk will also outline the theoretical ( x-schemas , image schemas , bayes-nets ) and neural background ."}
{"dialogue": "it basically says , well `` this is construal `` , and then it continues to say that one could potentially build a probabilistic relational model that has some general , domain - general rules and then the idea is to use ontology , situation , user , and discourse model to instantiate elements in the classes of the probabilistic relational modelto do some inferences in terms of what is being construed as what", "summary": "abstract: the thesis proposal , on the other hand , presents the idea of `` construal '' and makes claims as to how inferences are drawn in a probabilistic relational model by using information from the ontology , situation , user and discourse models ."}
{"dialogue": "none", "summary": "abstract: it was advised that more emphasis should be put on the role of construal in the understanding of metaphor and metonymy ."}
{"dialogue": "and to make them apply to metaphorical cases and metonymic cases and all those things , requires this additional mechanism , of construal . but cover only base cases . but there are basic cases . w well we have , for example , a canonical use of something and y it 's , you know , we have some constructions and then it 's construed as something , and then wewe may get the same constructions with a metaphorical use that 's also relevant to theto the domain .", "summary": "abstract: base constructions deal with the norm , while further general domain mechanisms determine how the constructions are invoked depending on the context ."}
{"dialogue": "but `` walked into the cafe and ordered a drink , `` and `` walked into the cafe and broke his nose , `` but `` run into `` does . so `` in the bus `` and `` on the bus , `` we hadwe hadinitially we 'dstarted discussing the `` out of film . `` where is the castle ? i mean maybe the `` where is something `` question as a whole , you know , can be construed as , u i locational versus instructional request .", "summary": "abstract: several potential examples of polysemy were discussed in detail: `` walk / run into '' , `` on the bus '' , `` out of film '' , `` where is x ? `` ."}
{"dialogue": "but i think the argument should beuh , can be made that , you know , despite the fact that this is not the most met metaphorical domain ,", "summary": "abstract: however , none of them was an example of lexical polysemy resolved by construal straightforward enough to include in the proposal ; the tourist domain is not metaphor rich ."}
{"dialogue": "e tell a little bitas much as ican about the ntl story . and then maybe talk about the big picture here , oh , maybe the fmri stuff . well , the time to mention it , if you mention it , is when you talk about mirror neurons ,", "summary": "decisions: as the talk at eml will also refer to a theoretical framework , it was suggested that along with presenting ntl and the piece on mirror neurons , it also alludes to relevant fmri work ."}
{"dialogue": "the b the combination of the biology and the leipzig connection might be interesting to these guys ,", "summary": "decisions: the neural side of the research could be of interest to various groups ."}
{"dialogue": "therethetherewe 've got various i generations of slides that show language analysis , and matching to the underlying image schemas ,", "summary": "decisions: the language analysis itself will be introduced in terms of image schemas ."}
{"dialogue": "ok . so why do n't we plan to give you feedback electronically .", "summary": "decisions: on the other hand , it was arranged for more feedback on the thesis proposal to be sent by email ."}
{"dialogue": "current formalism thing that you presented .", "summary": "decisions: the latest version of the construction formalism will also be needed to complete the presentation ."}
{"dialogue": "i i it looks like the , uh , metaphor did n't get in yet . but cover only base cases . and to make them apply to metaphorical cases and metonymic cases and all those things , requires this additional mechanism , of construal . w well we have , for example , a canonical use of something and y it 's , you know , we have some constructions and then it 's construed as something , and then wewe may get the same constructions with a metaphorical use that 's also relevant to theto the domain .", "summary": "problems: it was noted that the thesis proposal did not put any emphasis on metaphor or on the scalability achieved by combining constructions with general construal mechanisms: constructions cover base cases , while metaphoric and metonymic cases are resolved with the extra help provided by construal ."}
{"dialogue": "none", "summary": "problems: during this discussion , however , the suggested examples of polysemy , which is tackled by the proposed framework , were not straightforward enough ."}
{"dialogue": "but i think the argument should beuh , can be made that , you know , despite the fact that this is not the most met metaphorical domain ,", "summary": "problems: it was agreed that metaphors are not abundant in the spatial domain ."}
{"dialogue": "so `` in the bus `` and `` on the bus , `` we hadwe hadinitially we 'dstarted discussing the `` out of film . `` ok . can we think of a nice metaphorical use of `` where `` in the tourist 's domain ? a fixed expression , yeah .", "summary": "problems: some of the candidates discussed were phrases like `` on the bus '' , `` out of film '' , non-spatial uses of `` where '' or other fixed expressions ."}
{"dialogue": "none", "summary": "abstract: the first phase of the data collection has finished ."}
{"dialogue": "um , and we found another uh , cogsci student who 's interested in playing wizard for us . here we 're gon na make it a little bit more complicated for the subjects , uh this round .", "summary": "abstract: there is a new wizard for phase two , during which subjects will be given more complex scenarios ."}
{"dialogue": "as for smartkom , i 'mthe last smartkom meeting i mentioned that we have some problems with the synthesis , which as of this morning should be resolved . so maybe uh uh , when tomorrow is over , we 're done .", "summary": "abstract: also finished are the modifications on smartkom: the remaining glitches will take no more than a day to iron out ."}
{"dialogue": "something happened , inon eva 's side with the prm that we 're gon na look at today ,", "summary": "abstract: a big part of the meeting was covered by the presentation of the prm of the proposed system ."}
{"dialogue": "i sorta constructed a couple of classes . the red lines on the , um , graph are the um , relations between the different um , classes . this is more or less similar to the flat bayes - net that i have , you know , with the input nodes and all that .", "summary": "abstract: an alternative representation of the bayes-net , it depicts context features as classes , and dependencies as relations between them ."}
{"dialogue": "ok . so it only makes two decisions , in this model . and one is basically how desirable a site is and the other is the mode of the visit , whether th it 's the eva decision .", "summary": "abstract: the current outputs show the desirability of a site , as well as its eva mode ."}
{"dialogue": "i mean , the notion of instantiating your el elements from the ontology and stuff fits this very nicely and does n't fit very well into the extended belief - net .", "summary": "abstract: the fact that this model allows for instantiations of classes fits the research purposes much better than the extended belief-net ."}
{"dialogue": "we have a visitor from bruchsal from the international university . good . then , we can move on and see what andreas has got out his sleeve .", "summary": "abstract: following this , a visiting researcher presented an overview of a parallel project at the international university ."}
{"dialogue": "and so , what i want to build is basically aa smart f a q system . so , i want to be able to model information like , um , so in thein the context ofin the context of developing distributed systems , of a at a computer science school , uh , i want to build a smart librarian , basically", "summary": "abstract: it attempts to build a smart tutoring system for a computer science course ."}
{"dialogue": "now , what you uh need to do here is you need to provide some context information now , what i plan to do is i want to uh sort of do a uhuhtry to improve the quality of the search results ,", "summary": "abstract: the assumption is that document searches can give more personalised results , if they take into account contextual parameters ( user , situation ) ."}
{"dialogue": "and i 'm guessing that youyou wo n't be doing that ? no . on the other hand , uh , framenet could well be useful .", "summary": "abstract: although no detailed linguistic analysis takes place , it was suggested that the use of framenet could be a useful approach ."}
{"dialogue": "the other person i thought of is dan gildea ?", "summary": "abstract: there were also further suggestions for meetings with icsi researchers ."}
{"dialogue": "uh in ain a smaller group we had uh , talked and decided about continuation of the data collection . here we 're gon na make it a little bit more complicated for the subjects , uh this round .", "summary": "decisions: as the data collection is going into its second phase , more complex scenarios will be used to generate more intricate dialogues ."}
{"dialogue": "she 's actually suggested to look um , at the psychology department students , because they have to partake in two experiments in order to fulfill some requirements .", "summary": "decisions: subjects can be recruited from within the psychology department students , since such participation in experiments is compulsory in their syllabus ."}
{"dialogue": "uh , so one of the things that eva 's gon na do over the next few weeks is see if we can track that down .", "summary": "decisions: as the work on creating a prm for the system has progressed , it is now necessary to find an implementation that can work as a prm interpreter ."}
{"dialogue": "uh , we are n't gon na build our own interpreter , the people at stanford write papers as if they had one ,", "summary": "decisions: there are no plans to build one from scratch , but it seems that other research groups at stanford may already have one ."}
{"dialogue": "and supposedly , um , we 'll actually get s deepseriously connected toto their work somebody 'lluh , you knowif it 's a group meeting once a week probably someone 'll go down and , whatever .", "summary": "decisions: moreover , closer collaboration with the local prm group will be pursued with additional participation in their meetings ."}
{"dialogue": "and it turns out , you know , the cpt 's are really big , if i do that ,", "summary": "problems: an early version of the prm of the system presented the same problem as a flat bayes-net: the cpt 's become too large ."}
{"dialogue": "but i do n't remember reading how you specify i remember them learning when , you know , you do n't know the structure for sure ,", "summary": "problems: another prm issue that arose and remained unclear was how the probabilities are specified ( instead of learnt ) on the actual relations between the classes ."}
{"dialogue": "theyouyou did n't look at all yet to see if there 's anybody has a implementation . so w anyway . so that 's aa major open issue .", "summary": "problems: furthermore , the lack of a prm interpreter is an open issue ."}
{"dialogue": "uh , we are n't gon na build our own interpreter , uh , so one of the things that eva 's gon na do over the next few weeks is see if we can track that down .", "summary": "problems: it is not within the remit of the project to build one from scratch , therefore , an existing implementation has to be found ."}
{"dialogue": "now , what i plan to do is i want to uh sort of do a uhuhtry to improve the quality of the search results ,", "summary": "problems: on the other hand , the discussion about the smart tutoring system being built at the international university showed the importance of finding outwhich context parameters are influential in a given domain ."}
{"dialogue": "now , the big problem that i 'm facing right now is um , it 's fairly easy to hack up a system uh quickly , thatthat works in the small domain , but the problem is obviously the scalability . cuz it 'sit 's very easy to whip up something quickly ,", "summary": "problems: it is easy to hack up a system for a small domain , but making it scalable is much more difficult ."}
{"dialogue": "as for smartkom , i 'mthe last smartkom meeting i mentioned that we have some problems with the synthesis ,", "summary": "problems: finally , there was a passing mention of problems encountered with the speech synthesis module of smartkom ."}
{"dialogue": "topic of this meeting is i wan na talk a little bit about transcription . so , well w shall we move on and talk a little bit about transcription then ? isand so one of the things was to get an estimate of how long it would take , and then also what tools we would use . and so the next decision which has to be made actually pretty soon is how are we gon na do it ? i mean , i looked at cyber transcriber", "summary": "abstract: the berkeley meeting recorder group discussed the aims , methods , timing , and outsourcing issues concerning transcription of the meeting recorder corpus ."}
{"dialogue": "what we 're using right now is a tool , um , from this french group , called `` transcriber `` so as far as i 'm concerned those transcription conventions are fixed right now . andbut so in terms of the con the conventions , then , <breath> uh , basically , <breath> uh , it 's strictly orthographic so i havei have a convention of putting like a dash <breath> arrow just to indicate that this person 's utterance continues .", "summary": "abstract: the transcriber software tool was introduced , along with a set of transcription conventions for coding different speech events ."}
{"dialogue": "these are linguistics grad students . but we can pay a graduate student seven dollars an hour .", "summary": "abstract: the prospect of sending the data to an external transcription service was weighed against that of hiring a graduate student transcriber pool ."}
{"dialogue": "so that means that even if it takes them thirty times real time it 's cheaper toto do graduate students . i mean , that 's why i said originally , that i could n't imagine sending it out 's gon na be cheaper .", "summary": "abstract: it was tentatively decided that the latter option would be less costly and allow bmr to maintain greater control over the transcription process ."}
{"dialogue": "maybe we should s consider also , um , starting to build up a web site around all of these things .", "summary": "abstract: methods for distributing the data were briefly discussed , along with an initiative for creating a bmr project website ."}
{"dialogue": "and then get an update on the electronics , um , let 's move on to electronics .", "summary": "abstract: the group received an update on the meeting room recording setup and electronics ."}
{"dialogue": "cuz they 're distributing it through the ldc . maybe we shouldmaybe we should get a copy of it just to see what they did soso that we canwe can compare . csae . corpus of spoken american english .", "summary": "decisions: the group will obtain a copy of the corpus of spoken american english ( csae ) from the ldc to compare the methods and conventions used by uc santa barbara with those being considered for the meeting recorder project ."}
{"dialogue": "so i mean , i 've been sort of playing with , uh , different ways of mar cuz i 'm thinking , you know , i mean , if you could get optimal instructions you could cut back on the number of hours it would take . so i think though it 's a good proposal to be used on a newa new batch of text that i have n't yet done yet in the same meeting . could use it on the next segment of the text . i could generate the segmentation andand you could do the words , and time yourself on it .", "summary": "decisions: speakers fe008 and me011 will experiment with pre-segmentation procedures in hopes of facilitating the transcription process ."}
{"dialogue": "so what we wanted to do was have jane do basically one meeting 's worth , you know , forty minutes to an hour ,", "summary": "decisions: speaker fe008 will perform the transcription for one meeting ( 40-60 minutes of data ) as a pilot project ."}
{"dialogue": "i hope it 's jane . yeah , no , thatii would be interested in thatin becoming involved in the project in some aspect like that", "summary": "decisions: a tentative decision was made to put speaker fe008 in charge of the in-house transcription effort ."}
{"dialogue": "we could program that pretty easily , areare those d delays adjustable ? could you get it so that withso it wouldit would detect volume on a channel and insert a marker ? sure . so if we wantif we didif we did something like programmed in a delay , which actually i think is a great idea , um , i 'm sure they would want that incorporated back in . and i said , well , maybe . and they havethey 've actually asked if we are willing to do any development well , so anyway , are we interested then in writing tools to try to generate any of this stuff automatically ?", "summary": "decisions: modifications to the transcriber source code , e.g . adjusting the delay between the audio play function and the inputting of time boundaries , may be undertaken by the bmr group ."}
{"dialogue": "maybe we should s consider also , um , starting to build up a web site around all of these things . i think mostly internal . we could do an ht access which would accommodate those things .", "summary": "decisions: an initiative for creating an internal bmr project website was discussed , along with ideas for providing web access to external organizations , such as the university of washington ."}
{"dialogue": "well i can build a cabinet .", "summary": "decisions: a cabinet will be built to house wires and other electronic equipment used in the recording setup ."}
{"dialogue": "which is to say just laptop with a wireless . so we certainly could use that asas a constant reminder of what the vu meters are doing .", "summary": "decisions: a laptop and wireless modem will be avaiable to participants for monitoring the recording progress ."}
{"dialogue": "andand so how we do we distribute the transcripts , how do we distribute the audio files , butbut so should we do it in the same format as ldc", "summary": "problems: how should transcripts and corresponding audio files be formatted and distributed ?"}
{"dialogue": "they 're never gon na be able to do a meeting like this . and soso what i 'm saying is that if we hire an external service i think we can expect three hundred dollars an hour . who knows if they 're gon na be able to m manage multal multiple channel data ? they wo n't . i mean , that 's why i said originally , that i could n't imagine sending it out 's gon na be cheaper .", "summary": "problems: external transcription services are expensive , difficult to monitor , and are unlikely to be able to handle multi-channel data ."}
{"dialogue": "none", "summary": "problems: it is unclear which levels of transcription should be encoded ."}
{"dialogue": "there 's some interesting human factors problems like , <breath> yeah , what span ofof time is it useful to segment the thing into in order to uh , transcribe it the most quickly .", "summary": "problems: what size of segment is most useful for doing transcriptions ?"}
{"dialogue": "none", "summary": "problems: which level of segmentation is most suitable for the aims of the project ?"}
{"dialogue": "um , the user interface only allows two . and so ifif you 're using their interface to specify overlapping speakers you can only do two . it 's just there 's no user interface for specifying multipleany more than two .", "summary": "problems: transcriber 's interface only allows the user to view two overlapping speakers ."}
{"dialogue": "no , but w certainly one of the issues isis the , uhis security .", "summary": "problems: decisions must be made regarding the security of electronic recording equipment ."}
{"dialogue": "um , so um the one th one thing i know that we have on that is uh we had talked aa couple weeks before um uh about the uhthe stuff you were doing withwith uh um uh l l attempting to locate events , but anyway somesome potential collaboration there aboutabout theabout theworking with these data . um , so , uh , he was interested in the question ofyou know , relating to histo the research he presented recently , um of inference structures , so um we were trying to think of ways that his interests could interact with ours he 's interested in thesethese knowledge structures , inferences that you drawi from toto find aa good solution to detect eh , the overlapping zone in eh speech recorded . but you haveyou have time uh , uh markedtwelve minutethethethe um overlaps in twelve minutes of it . like very straightforward question is where we are on the amount of data and the amount of transcribed data ,", "summary": "abstract: topics discussed by the berkeley meeting recorder group included a potential collaboration with another icsi member regarding the analysis of inference structures , efforts by speaker mn005 to detect speaker overlap , the current status on recordings and transcriptions , and future efforts to collect meeting data ."}
{"dialogue": "but there 's at least one meeting recorded of uh the uh uh natural language guys . uh , we 've started having a morning meeting , today uh i starting a w a week or two ago , on the uh front - end issues , and we 're recording those , uh there 's a network services and applications group here who 's agreed to have their meetings recorded , if anyone knows of one more m or two more wee meetings per week that happen at icsi , um that we could record , i think it would be worth it .", "summary": "abstract: in addition to weekly meetings by the bmr group , efforts are in progress to record meetings by other icsi research groups , as well as routine discussions by non-icsi members ."}
{"dialogue": "so , we need to talk about this later .", "summary": "decisions: the group will resume its discussion of speaker anonymization in a subsequent meeting ."}
{"dialogue": "on - only to markonly to mark overlapping zone , but then i think it 's a good idea . but i mean weif uhif he could speed up what he was doing by just getting the speaker overlaps so that we had it , say , for forty - five minutes , then at least we 'd have three hundred examples of it .", "summary": "decisions: to save time , speaker mn005 will only mark the sample of transcribed data for regions of overlapping speech , as opposed to marking all acoustic events ."}
{"dialogue": "yeah , whoever we have working on the acoustics for the meeting recorder are gon na start with that .", "summary": "decisions: the digits extraction task will be delegated to whomever is working on acoustics for the meeting recorder project ."}
{"dialogue": "if anyone knows of one more m or two more wee meetings per week that happen at icsi , um that we could record , i think it would be worth it .", "summary": "decisions: the group will inquire with other icsi researchers and colleagues at the university of washington about collecting additional meeting data ."}
{"dialogue": "i mean , one of the things i wanted to do , uh , that i i talked toto don about , is one of the possible things he could do or m also , we could have someone else do it , is to do block echo cancellation , so that 's something i 'd like somebody to do at some point , just take these digits , take the far - field mike signal , and the close uh mike signal , and apply really good echo cancellation . somebody lookandand the digits would be a reasonable thing to do that with .", "summary": "decisions: echo cancellation experiments will be performed on meeting recorder digits data ."}
{"dialogue": "so this isthis isthis isgonna be a big , big problem if you want to later do uh , you know , indexing , or speech understanding of any sort .", "summary": "problems: use of pronouns ( e.g . he , she , you ) during meetings is potentially problematic for indexing referents and analysing speech understanding ."}
{"dialogue": "and in fact , it isit isit is sensitive . you know , i asked her very specifically about this clause of how , um , you know , it says `` no individuals will be identified", "summary": "problems: sensitivity issues involved in mentioning individuals by name were also discussed ."}
{"dialogue": "i mean , if i 'm tapping on the table , you it 's not gon na show up on any of the mikes , but it 's gon na show up rather loudly in the pzm . thethethe far - field , because ii found a difference .", "summary": "problems: data obtained via the close-talking microphone channels do n't match meeting content yielded via the far-field microphones ."}
{"dialogue": "one of the things that i think is a littlea little bit of a limitation , there is a think when the people are not involved uh in our work , we probably ca n't do it every week . so , i think it 's gon na be a problem to get people regularly .", "summary": "problems: the collection of meeting data from non-meeting recorder participants is likely to be more infrequent ."}
{"dialogue": "um , but i 'd rather try to get more regular meetings of types that we know about , and hear , then sort of a mish - mosh of a bunch of oneone - time", "summary": "abstract: the berkeley meeting recorder group discussed research aims and corresponding concerns for future data collection ."}
{"dialogue": "and in that uh , regard , i thought we definitely w will needit 'd b it 'd be nice for us to have a bunch of data from a few different domains , or a few different kinds of meetings . um , but i 'd rather try to get more regular meetings of types that we know about , and hear , then sort of a mish - mosh of a bunch of oneone - time but also data where we hold some parameters constant or fairly similar , uh , for other kinds of research , particularly the acoustic oriented research , i actually feel the opposite need . i 'd like to have many different speakers . so , um i think i would also very much like us to have a fair amount of really random scattered meetings , of somebody coming down from campus , andand uh , i 'd love to get people that are not linguists or engineers , cuz these are both weird", "summary": "abstract: it was agreed that a substantial amount of meeting data is required from different domains , and comprising several speakers , to perform the types of discourse and acoustic analyses desired ."}
{"dialogue": "i have , eh , < clears throat > the result of my work during the last days . it 's a real problem , a frequently problemuh , because you have overlapping zones eh , eh , eh , all the time . but , eh , my idea is , eh , is very interesting toto workinin the line of , eh , automatic segmenter . no , iiplan to do that . now , <mouth> eh , i need ehm , <mouth> to detect eh all the overlapping zones exactly . so the first thing is for you toto build up something that will detect the overlaps .", "summary": "abstract: ongoing efforts by speaker mn005 to automaticallydetect regions of speaker overlap were considered ."}
{"dialogue": "i would take just a few features . instead of taking all the mfcc 's , or all the plp 's or whatever , i would just take a couple . uh , and uh on the other hand , the lpc residual , the energy in the lpc residual , <breath> will say how well , uh <breath> the low - order lpc <breath> model 's fitting it , which should be <breath> pretty poorly for two two or more <breath> people speaking at the same time , and it should be pretty well , for w forfor one . well , thatthatthat 's another reason why very simple features , things like energy , and thingsthings like harmonicity , and <breath> residual energy are uh , yeah areare better to use than very complex ones because they 'll be more reliable .", "summary": "abstract: it was suggested that speaker mn005 focus on a small set of acoustic parameters , e.g . energy and harmonics-related features , to distinguish regions of overlap from those containing the speech of just one speaker ."}
{"dialogue": "and <breath> then um , i guess another topic would be <breath> where are we in the whole disk resourcesquestion", "summary": "abstract: disk space issues were discussed ."}
{"dialogue": "um and then also anonymity , how we want to anonymize the data . the question becomes what symbol are you gon na put in there for everybody 's name , and whether you 're gon na put it in the text where he says `` hey roger `` or are we gon na put that person 's anonymized name in instead ? because if we made thethe transcript be the tag that we 're using for roger , someone who had the transcript and the audio would then have a mapping between the anonymized name and the real name , and we wan na avoid that . um , how important is it for a person to be identified by first name versus full name ? however , taking one step further back , they 'd be identifiable anyway , even if we changed all the names . on the other hand , this is a smallthis is a small pool , and people who say things about topic x e who are researchers and well - known in the field , they 'll be identifiable and simply from thefrom the first name . now , it would be very possible for me to take those data put them in ain a study , and just change everybody 's name for the purpose of the publication . and within that , it may be that it 's sufficient to not uh change theto not incorporate anonymization yet , but always , always in the publications we have to .", "summary": "abstract: and , finally , the problem of speaker anonymization was explored ."}
{"dialogue": "well , i think that , umi think that the only thing we should say in the advertisement is that the meeting should be held in english .", "summary": "decisions: recordings must be of existing meetings that are conducted in english ."}
{"dialogue": "so i wasi was thinking more in terms of talking to professors uh , andandand uh , senior uh , uh , d and uh , doctoral students who are leading projects and offering to them that they have theirhold their meeting down here . i mean , ititi think that if we 're aiming atat uh , groups of graduate students and professors and so forth who are talking about things together , and it 's from the berkeley campus , probably most of it will be ok , and my point in m in my note to liz was i think that undergrads are an iff iffy population .", "summary": "decisions: participants should ideally consist of professors and doctoral students , but no undergraduate students , who are willing to record their meetings at icsi ."}
{"dialogue": "and in that uh , regard , i thought we definitely w will needit 'd b it 'd be nice for us to have a bunch of data from a few different domains , or a few different kinds of meetings . i 'd like to have many different speakers . so , um i think i would also very much like us to have a fair amount of really random scattered meetings , of somebody coming down from campus , andand uh , i 'd love to get people that are not linguists or engineers , cuz these are both weird", "summary": "decisions: the meeting recorder corpus should comprise data from a large number of speakers representing different domains ."}
{"dialogue": "none", "summary": "decisions: attempts should also be made to optimize the speaker population for generating good language models ."}
{"dialogue": "um , i had ai spoke with some people up at haas business school who volunteered . should i pursue that ? oh , definitely , yeah .", "summary": "decisions: speaker me011 will pursue volunteers from the haas business school to record their weekly meetings at icsi ."}
{"dialogue": "the o the o the otherthe other thing is , uh , that wewe talked about is give to themuh , burn an extra cd - rom . we could burn it after it 's been cleared with the transcript stage . so , after the transcript screening phase .", "summary": "decisions: a tentative decision was made to offer participants a recorded version of their meeting on a cd rom once the transcript screening phase is complete for that meeting ."}
{"dialogue": "if you have people who are using english as aas an interlanguage because theythey don'tuh , they ca n't speak in their native languages andbut their interlanguage is n't really a match to any existing , uh , language model ,", "summary": "problems: non-native speakers with a low proficiency in english are problematic for language modelling ."}
{"dialogue": "uh , i we realized in discussion that the other thing is , what about this business of distant and close microphones ? if you 're talking about something simple , where you throw away a lot of these dimensions , then you can do that right away .", "summary": "problems: the prospect of creating another recording setup requires the elimination certain more complicated dimensions of the existing setup , e.g . the use of close-talking and far-field microphones ."}
{"dialogue": "then , uh , it seems to me thatwell , maybe iuh it seems to me that if you change the name , the transcript 's gon na disagree with the audio , and you wo n't be able to use that . ok , well , but then there 's this issue of if we 're gon na use this for a discourse type of thing , thenand , you know , liz was mentioning stuff in a previous meeting about gaze direction and who 'swho 's the addressee and all , then to have `` roger `` be the thing in the utterance and then actually have the speaker identifier who was `` roger `` be `` frank `` , that 's going to be really confusing and make it pretty much useless for discourse analysis .", "summary": "problems: speaker anonymization poses problems for the transcription proccess , and also discourse analysis , as it makes it more difficult to track who is speaking and to whom a particular utterance is being addressed ."}
{"dialogue": "well , the current one they do n't do speaker identity . and so in their current conventions there are no multiple speaker conventions .", "summary": "problems: as the current version of transcriptions does not include speaker identification labels , no multiple speaker transcription conventions are in use ."}
{"dialogue": "and what we 're doing now is , aside from the many other differences in the task , we are considering overlap", "summary": "abstract: the berkeley meeting recorder group focussed its discussion on overlapping speech segments ."}
{"dialogue": "raw counts . so . of the times a person spoke and furthermore was involved in a two two - person overlap , <laugh> <inbreath> what percentage of the time were they the overlapper and what percent of the time were they th the overlappee ? but , of course , uh i e <laugh> this is just one meeting , uhthere 's no statistical testing involved , and that would berequired for afor a findingofanykind ofscientificreliability . well , of course th the biggest , umresult here , which is one we 'vewe 've talked about many times and is n't new to us , but which i think would be interesting to show someone who is n't familiar with this <inbreath> is just the sheer number of overlaps . it 's a fortyforty plus minute <inbreath> meeting , what we 've learned about is overlaps in this situation , is thatthe firstthe first - order thing i would say is that there 's a lot of them . in fact <inbreath> and it 's not just an overlapbunch of overlapssecond - order thing is <inbreath> it 's not just a bunch of overlaps in one particular point , <inbreath> but that there 's overlaps , uh throughout the thing . um <mouth> preliminary analysis of overlaps in the pilot data we have transcribed ,", "summary": "abstract: speaker fe008 presented raw counts and percentages for one transcribed meeting , revealing a large number of overlaps throughout the 40-plus-minute transcript ."}
{"dialogue": "um , that some people tend to be overlappedwith more often than they 're overlapped , andit would be , you knowof course , there 's also the question of what type of overlap was this , and w what were they , so , um then it becothoughsojustjust superficially to giveuma couple ideas of the types of overlaps involved , i have at the bottom several that i noticed . so , uh , the point is that , um <inbreath> overlap 's not necessarily a bad thing and that it would be imi useful to subdivide these further and see if there are individual differences in styles with respect to the types involved . so , the question is , you know , how many more overlaps <inbreath> do you haveof , say the two - person type , by adding more people . to a meeting , so it may be that having three people <inbreath> is very different from having two people or it may not be . but we should still be able to somehow say whatwhat is the added contra contribution to sort of overlap time of each additional person , or something like that . these werethese werebenevolent types , as peoplefinishing each other 's sentences , andstuff . and that it would be interesting to look atwhether there are these kinds of constraints that jane mentioned , that <inbreath> what maybe the additional people add to this competition that happens right after a turn ,", "summary": "abstract: efforts by speakers fe008 and fe016 are in progress to categorize and subcategorize types of overlapping speech and evaluate the contribution of multiple speakers in an interaction to the amount and types of overlap observed ."}
{"dialogue": "yeah , i 've been playing with , um uh , using the close - talking mike to doto try to figure out who 's speaking . so my first attempt was just using thresholding and filtering , that we talked aboutabout two weeks ago , ok and then the other thing i did , was i took <inbreath> javier 's speaker - change detectoracoustic - change detector , and i implemented that with the close - talking mikes , umso , at any rate , my next attempt , which i 'm in the midst of and have n't quite finished yet was actually using the <inbreath> uh , thresholding as the way of generating the candidates . but all of this is close - talking mike , what i 'm doing <inbreath> is trying to use the close - talking mike <inbreath> and just usecan - and just generate candidate and justtry to get a first pass at something that sort of works .", "summary": "abstract: speaker me011 described his attempts to automatically identify speakers via the close-talking microphone channels using thresholding and filtering methods and an existing speaker-change detection algorithm ."}
{"dialogue": "or , this is getting a little extravagant , we could put up some kind of blinds or something toto remove , uhvisual contact . so this is the things that i think we did <laugh> in the last three months", "summary": "abstract: the group also tentatively discussed the erection of visual barriers during meeting recordings , and speaker me013 presented a list of work performed by bmr over the previous three months to be included in a forthcoming report to ibm ."}
{"dialogue": "i 'll do that on the next set of forms . so i 'm gon na put little labels on all the chairs with the seat number .", "summary": "decisions: for future meetings , speaker me011 will generate a system for mapping speakers and their positions in the recording room ."}
{"dialogue": "i thinkwhat iwhat this has , uh , caused meso this discussion caused me to wan na subdivide these further . i 'm gon na take a look at the , uhbackchannels , how much we have anal i hope to have that for next time .", "summary": "decisions: speaker fe008 will analyze backchannels for a subset of meeting data and givee a report in the next meeting ."}
{"dialogue": "so , from the point of view of studying dialogue , i mean , whichdan jurafsky and andreas and i had some projects on , you want to know the sequence of turns . so , for things like language modeling or dialogue modeling <inbreath> it 'swe know that that 's wrong in real time .", "summary": "problems: for language and dialogue modelling , current methods of marking and segmenting overlap are abstracted from real time , as individual speaker turns are indicated sequentially ."}
{"dialogue": "but , of course , uh i e <laugh> this is just one meeting , uhthere 's no statistical testing involved , and that would berequired for afor a findingofanykind ofscientificreliability . you know , the other thing i was thinking was that , umtheseall these interesting questions are , of course , pretty hard to answer with , uh uyou know , a small amount of data .", "summary": "problems: a large amount of data must be collected to address research questions concerning overlapping speech ."}
{"dialogue": "and that works o k , if you fil if you tune the filter parameters , if you tune <inbreath> how long your median filter is and how high you 're looking for your thresholds .", "summary": "problems: for automatic speaker identification , thresholding and filtering methods are sensitive regarding the particular filter width and threshold selected ."}
{"dialogue": "so if you fiddle around with it a little bit and you get good numbers you can actually do a pretty good job of segmenting when someone 's talking and when they 're not . but if you try to use the same paramenters on another speaker , it does n't work anymore , it does work for the one speaker throughout the whole meeting .", "summary": "problems: while such parameters can be finely tuned for one speaker to achieve good results , extending the same parameters to another speaker is problematic ."}
{"dialogue": "andunfortunately that 's not working real well , and it looks like it 's and what looks like it 's happening is that theeven on the close - talking mike the broad phone class classifier 's doing a really bad job .", "summary": "problems: the broad phone classifier of the speaker-change detector is peforming poorly ."}
{"dialogue": "none", "summary": "problems: the prospect of erecting visual barriers during meetings would require partitioning off each of the participants ."}
{"dialogue": "so we need a barrier that does n't disturbthe sound ,", "summary": "problems: also , barriers that do not affect the overall room acoustics would be required ."}
{"dialogue": "but um uh jose and i were just talking about <inbreath> the uh < page turn > uh , speech e energy thing , he washehe was taking everything over two hundred milliseconds and so i i hishishe 's making the constraint it has to be at least two hundred milliseconds .", "summary": "abstract: the berkely meeting recorder group discussed efforts by speaker mn005 to measure energy levels in cases of speaker overlap in which the time window analyzed was 200 milliseconds or greater ."}
{"dialogue": "right now , that he 's not really showing any kind of uh distinction , but uh um . and uh one is that uh this is all in log energy um andbut one thing he was pointing out is when hehe looked at a bunch of examples in log domain , it is actually pretty hard to see <inbreath> the change . and when he 's looking in the log domain he 's not really seeing it .", "summary": "abstract: preliminary results were presented showing that log domain analyses did not reveal a significant difference in mean energy levels for windows of overlapping versus non-overlapping speech ."}
{"dialogue": "and when he 's looking in straight energy he is , umbutsince <inbreath> uh your intuition from looking at some of the data , is that when you looked at the regular energy , that it did in fact usually go up , <laugh> when two people were talking , <inbreath> that 'seh you know , you should be able to come up with a measure which willmatch your intuition .", "summary": "abstract: in contrast , raw energy analyses were successful in showing the two groups to be distinct ."}
{"dialogue": "and i had plan to go through with it , ofof co coding the types of overlaps that people were involved in s just with reference to speaker style so , you know , with reference so i was planning to do a taxonomy of types overlaps with reference to that .", "summary": "abstract: participants discussed alternate strategies for examining energy and the importance of categorizing types of speaker overlap ."}
{"dialogue": "yeah this was the problem with these categories ,", "summary": "abstract: participants also reviewed the latest iteration of speaker forms , and discussed recent changes to the transcriber tool ."}
{"dialogue": "umanother is that he needs to play with thethe different uhuh temporal sizes . uh , and uh he 's going to vary that number and also look at moving windows , as we discussed before . um and uhand the other thing is that theyeah doing the <inbreath> subtracting off the mean and the variance in theuh and dividing it by thestandard deviation in the log domain , <inbreath> may not bethe right thing to do . so yeah theretheretherethere 's a good chance then given that different people do talk different amountsthat there istherethere is still a lot more to be gained from gain norm normalization with some sort uh . but we were agreed that in addition to thatuh there should bes stuff related to pitch and harmonics and so forth . um and then we w i think we 're agreed that pitch - related things areareare going to be aa really likely candidate to help . and then you can move on to the uhuh more < mike loud pop > pitch related stuff . and then that should give us some indicationbetween those , should give us some indication of whether there 's anything to be achieved f from energy at all . not consider the log energy . i think i would just sort of look at the energyand then get into the harmonicity asas a suggestion .", "summary": "decisions: continuing efforts by speaker mn005 to measure energy levels in cases of speaker overlap will not include additional log energy analyses , but rather an analysis of raw energy for normalized speaker dataacross windows of varying duration , followed by an examination of pitch- and harmonicity-related features ."}
{"dialogue": "and i had plan to go through with it , ofof co coding the types of overlaps that people were involved in s just with reference to speaker style so , you know , with reference so i was planning to do a taxonomy of types overlaps with reference to that .", "summary": "decisions: speakers fe008 and fe016 discussed plans to categorize and produce a taxonomy of types of speaker overlap ."}
{"dialogue": "but it is definitely true that we need to have the time marks , and i was assuming that will be inherited because , if you have the words and they 're roughly aligned in time via forced alignment or whatever we end up using , then you know , thisstudent and i would be looking at the time marks well , wewe would n't be able to do any work without a forced alignment anyway ,", "summary": "problems: time marks for transcribed or force-aligned data are needed to analyze types of speaker overlap ."}
{"dialogue": "so i 'm not sure what to do about the region field for english variety . but i do n't know how toi do n't know how toi do n't know how to categorize them . yeah this was the problem with these categories ,", "summary": "problems: with respect to speaker forms , the group discussed problems associated with categorizing regional dialects of american english ."}
{"dialogue": "but the problem with it is the drawing of those waveforms is so slow that every time you do anything it just crawls . just about anything , and itit was so slow it was not usable .", "summary": "problems: the new version of transcriber does not feature the waveform , as re-drawing of this window is too slow using snack ."}
{"dialogue": "well , um , i cangive you an update on thetranscription effort . because at present , < spike on / p / > <inbreath> um , because < spike on / b / > of the limitations of <inbreath> th the interface we 're using , overlaps are , uh , not being < spike on / b / > encoded by < spike on / b / > the transcribers in as complete < spike on / p / > and , uh , detailed a way as it might be , what our decision was is thatwe 'll go ahead with what we have with a not very fine time scale on the overlaps .", "summary": "abstract: the berkeley meeting recorder group talked about the ongoing transcription effort and issues related to the transcriber tool , which despite its limitations for capturing tight time markings for overlapping speech , will continue to remain in use ."}
{"dialogue": "thewe have greatgreat , uh , p steps forward in terms of the nonspeech - speech pre - segmenting of the signal . um , so , uh , what we basically did so far was using the mixed file toto detect s speech or nonspeechportions in that . but < spike on `` but '' > itit saves so much timethethe <spike> transcribers", "summary": "abstract: speaker mn014 explained his efforts to pre-segment the signal into speech and non-speech portions for facilitating transcriptions ."}
{"dialogue": "uh , maybe < mike spike > raise the issue of microphone , uh , um procedures well , let 'swhy do n't we talk about microphone issues ? but ii think that itit does n't hurt , uh , the naturalness of the situation to try to have peoplewear the microphones properly , if possible , so , anything to reduce breathing isisis a good thing . so you want it enough to the side so that when you exhale through your nose , it doesn'tthe wind does n't hit the mike .", "summary": "abstract: recording equipment and procedures were discussed , with a focus on audible breathing and the need for standards in microphone wear and use ."}
{"dialogue": "but , i mean , the other things that we talked about is , uh , <inbreath> pitch - related things and harmonicity - related things , you know , have ahave a couple markov models which is to say , do n't worry so much about the , uh , features . and , uh , try to indi try to determine , you know , w when is th when are you in an overlap , when are you not in an overlap . and let the , uh , uh , statistical systemdetermine what 's the right way to look at the data . and i hope thethe next week i will have , eh , some results and wewe will showwe will see , eh , thethe parameterthe pitch , <inbreath> eh , tracking inwith the program . uh , thehashas , uh , been exploring , uh , e largely the energy issue so far , um , uh , jose hashas been but it may begiven that you have a limited time here , itit just may not be the best thing to <inbreath> toto focus on for the remaining of it . th - they were suggesting going to markov models ,", "summary": "abstract: and , finally , it was determined that speaker mn005 's efforts to detect speaker overlap using energy should instead be focussed on pitch- and harmonicity-related features or be guided by a non-featural , statistical approach , i.e . via the use of markov models ."}
{"dialogue": "what our decision was is thatwe 'll go ahead with what we have with a not very fine time scale on the overlaps . then < spike on / th / > when they 're encoding the overlaps < spike on / p / > it would be nice for them to be able to specify whenyou know , the start points and end points of overlaps . and i hope that if we do a forced alignment with the close - talking mike , that will be enough to recover at least some of the time the time information of when the overlap occurred .", "summary": "decisions: in the interest of time , it was decided that the group should continue using the existing transcriber tool and perform a forced alignment on the close-talking microphones that will , it is hoped , help to recover some of the time information indicating where different speaker overlaps occurred in the signal ."}
{"dialogue": "oh , we should definitely get with them then , agree upon a format .", "summary": "decisions: a meeting will be arranged with nist to decide on a common standard and format for doing transcriptions ."}
{"dialogue": "i think it would also be interesting to have , uh , a couple of the meetings have more than one transcriber do , cuz i 'm curious about inter - annotator agreement .", "summary": "decisions: one or two meetings will be assigned to multiple transcribers to check for inter-annotator agreement ."}
{"dialogue": "but ii think that itit does n't hurt , uh , the naturalness of the situation to try to have peoplewear the microphones properly , if possible , so , anything to reduce breathing isisis a good thing . so you want it enough to the side so that when you exhale through your nose , it doesn'tthe wind does n't hit the mike .", "summary": "decisions: to cut down on audible breaths during recordings , the group will institute some level of standards for microphone wear and use ."}
{"dialogue": "but , i mean , the other things that we talked about is , uh , <inbreath> pitch - related things and harmonicity - related things , and i hope thethe next week i will have , eh , some results and wewe will showwe will see , eh , thethe parameterthe pitch , <inbreath> eh , tracking inwith the program . but , eh , what did you think about the possibility of using the javier software ? right . so if weif we fed the hand - segmentation to javier 's and it does n't work , then we know something 's wrong . yeah . i think that 's probably worthwhile doing .", "summary": "decisions: speaker mn005 will feed his hand-segmented data into the speech segmenter developed by javier to train it to identify different types of speech ( i.e . that of single versus multiple speakers ) , as well as focussing on pitch- and harmonicity-related features for identifying overlapping speech ."}
{"dialogue": "cuz there is one thing that we do n't have right now and that is the automatic , um , channel identifier . thatthat , you know , that would g help in terms of encoding of overlaps .", "summary": "problems: there is no channel identifier to help in encoding speaker overlaps ."}
{"dialogue": "well , the thing that youis hard to deal with is whe <inbreath> when they speak while laughing .", "summary": "problems: speech uttered while laughing is problematic for asr ."}
{"dialogue": "but the bottom line is it 's still not , uh , separating out very well . so far , um , uh , jose hashas been andand so far at least has not come up with <inbreath> any combination that really gave you an indicator .", "summary": "problems: so far , speaker mn005 's attempts to detect speaker overlap have been unsuccessful , as it has not been possible to normalize energy as a reliable indicator of overlap ."}
{"dialogue": "and the other one is , um , uh , is there some good use that we can make of the transcribers to do other things ? oneone was uh , we had s had some discussion in the past about some very high level labelings , um , the other thing is thatthere was a number of things at the transcription side that , um , transcribers can do , like dialogue act tagging ,", "summary": "abstract: the berkeley meeting recorder group discussed recording equipment and setup issues , recent developments in the transcription effort , other potential types of tagging to be assigned to transcribers , and the post-processing of waveforms ."}
{"dialogue": "and actually in addition to that , that thethe close talking mikes are worn in such a way as to best capture the signal . so it 's towards the corner of your mouth so that breath sounds do n't get on it . but if we could actually standardize , you know , thethe microphones , uh , as much as possible that would be really helpful . but have them all be the same mike . it 's the equipment and also how it 's worn . it 's really < mike noise > it makes a big difference from the transcribers ' point of view so we might as well get it as uniform as we can . and , uh , also dan ellis 's innovation of the , uhthe multi - channel to here really helped a r a lot in terms of clearingclearing up h hearings that involve overlaps .", "summary": "abstract: the discussion was largely focused on efforts to facilitate transcriptions , including the improvement of strategies for transcribing overlapping speech , and achieving greater uniformity in the type of equipment used during recordings and the manner in which recording devices are worn by speakers ."}
{"dialogue": "uh , well one thing i was gon na say was that , um , i we could get more , uh , of the head mounted microphones so why do n't we just go out andand get an order ofof but have them all be the same mike . so we might as well get it as uniform as we can .", "summary": "decisions: to achieve greater uniformity in across-speaker recording conditions , the group decided to purchase three additional head-mounted microphones ."}
{"dialogue": "i guess i wanted to , um , sort of make a pitch for trying to collect more meetings . because i think it 'd be good ifif we can get a few different sort of non - internal types of meetings", "summary": "decisions: future work will include recording more varied meeting data from non-icsi discussion groups ."}
{"dialogue": "but that , um , it would be helpful if i can stay in the loop somehow with , um , people who are doing any kind of post - processing ,", "summary": "decisions: it was proposed by speaker fe016 that better communication be established between researchers involved in post-processing of the waveform and asr ."}
{"dialogue": "it adds this extra , you know , vari variable for each speaker toto deal with when the microphones are n't similar .", "summary": "problems: use of dissimilar microphones adds an extra , unwanted variable to individual speaker recordings ."}
{"dialogue": "but if we could actually standardize , you know , thethe microphones , uh , as much as possible that would be really helpful . it 's the equipment and also how it 's worn . it 's really < mike noise > it makes a big difference from the transcribers ' point of view", "summary": "problems: similarly , differences in the type of recording equipment used and the manner in which microphones are worn by speakers causes problems for the transcription effort ."}
{"dialogue": "but if you 're d i the kind of person who 's doing array processing you actually care about funny little times . andand so you actually wou would want to have a completely different set up than we have , is there an interest in getting video recordings for these meetings ? yes , absolutely . but it 's exactly the same problem , that you have an infrastructure problem , they were interested in ours . and , uh , it is related to ours .", "summary": "problems: setting up a microphone array and performing video recordings ( in a possible collaboration with nist ) are problematic due to the types of changes in infrastructure they require ."}
{"dialogue": "but there could be problems , right ? with that . then for forced alignment we actually do n't know whereyou know , in the signal the transcriber heard that word . th - but there 's going to be a real problem , uh , even if we chop up based on speech silence these , uh , the transcripts from i b m , we do n't actually know where the words were , which segment they belonged to .", "summary": "problems: ibm 's single-channel approach to transcriptions may pose problems for the post-processing of waveforms and forced alignments , as the group foresees difficulties in referencing chopped segments back to the original times / locations from which they were extracted ."}
{"dialogue": "so the problem is like , uh , on the microphone of somebody who 's not talking they 're picking up signals from other peopleand that 's <breath> causing problems ?", "summary": "problems: another post-processing problem involves cross-talk , and , in particular , situations in which a speaker whose contributions to the discussion are relatively sparse but whose microphone picks up signals from the other speakers ."}
{"dialogue": "ok well , the , w uh as you can see from the numbers on the digits we 're almost done . and so , once we 'reit 's done it would be very nice to train up a recognizer and actually start working with this data .", "summary": "abstract: the berkeley meeting recorder group discussed the collection status for a set of connected digits recordings that are nearly complete and ready to be trained on a recognizer ."}
{"dialogue": "yeah just by way of uh , uh , a uh , order of magnitude , uh , um , we 've been working with this aurora , uh data set . and , uh , the best score , on the , nicest part of the data , that is , where you 've got training and test set that are basically the same kinds of noise and so forth , uh , is about , i think the best score was something like five percent , uh , error , per digit .", "summary": "abstract: anticipated results were discussed in reference to results obtained for other digits corpora , i.e . aurora and ti-digits ."}
{"dialogue": "one question i have thatthat i mean , we would n't know the answer to now but might , do some guessing , but i was talking before about doing some model modeling of arti uh , uh , marking of articulatory , features , with overlap and so on . one thought might be to do this uh , onon the digits , or some piece of the digits . so , i mean another way to look at this is to , is to , uh , do some stuff on switchboard which has all this other , stuff to it . and then , um , as we get , further down the road and we can do more things ahead of time , we can , do some of the same things to the meeting data .", "summary": "abstract: the group also considered the prospect of performing fine-grained acoustic-phonetic analyses on a subset of meeting recorder digits or switchboard data ."}
{"dialogue": "uh , oh yeah , um , <breath> i worked a little bit on theon the presegmentation toto get another version which does channel - specific , uh , speech - nonspeech detection .", "summary": "abstract: pre-segmentation manipulations that allow for the segmentation of channel-specific speech / non-speech portions of the signal and the distinction of foreground versus background speech were discussed ."}
{"dialogue": "also we discussed some adaptational things , uhyou know i had n't , uh , incorporated , a convention explicitly to handle acronyms , for example , and then , a similar conv uh , convention for numbers . so if they hear a breath and they do n't know who breath it is it 's better to put it in that channel than to put it in the speaker 's channel", "summary": "abstract: finally , speaker fe008 and fe016 reported on new efforts to adapt transcriptions to the needs of the sri recognizer , including conventions for encoding acronyms , numbers , ambient noise , and unidentified inbreaths ."}
{"dialogue": "and so thethe question is , should we have the transcribers do that or should we just do it ? and i think it 's ait 's a fine idea partly because , um , it 's not un unrelated to their present skill set , and then , hand off to jane , and the transcribers to do the actual extraction of the digits .", "summary": "decisions: the group decided to delegate the extraction of digits to the transcriber pool ."}
{"dialogue": "well , you know , umi mean if we 're talking about , having the , annotators annotate these kinds of features , it seems like , so i mean i we 'll see wha how much we can , uh , get the people to do , and how much money we 'll have and all this sort of thing , so , i mean another way to look at this is to , is to , uh , do some stuff on switchboard which has all this other , stuff to it .", "summary": "decisions: a tentative decision was also made to delegate transcribers with the task of labelling a subset of digits or switchboard data for fine-grained acoustic-phonetic features ."}
{"dialogue": "it seems to me that it would be good to have , a few minutes fromfrom different meetings , so , as a first pass through , a first chance without having to do a lot of hand - editing , what we 're gon na do , is , i 'll run it through channelize , give them those data after i 've done the editing process and be sure it 's clean . and then we 'll see if the units that we 're getting , uh , with theat that level , are sufficient .", "summary": "decisions: speaker fe008 will run selected meeting recorder data through channelize and determine whether the resulting units are of a sufficient length ."}
{"dialogue": "none", "summary": "problems: with respect to encoding more fine-grained acoustic information in transcriptions , the question was posed: which features should be marked ?"}
{"dialogue": "there are some problems with the lapel mike . but , there are somesomeas i said some problems with the lapel mike ,", "summary": "problems: speaker mn014 reported problems pre-segmenting speech recorded via the lapel microphones ."}
{"dialogue": "then , the , yeah , there arethere are some problems withwithwith n with normalization , and , then , uh , there the system does n't work at all .", "summary": "problems: normalization of the energy measured across and within channels is problematic when performed for speakers who say little or nothing during meetings ."}
{"dialogue": "and , the thing is ii , then the evaluation ofof the system is a little bit hard , as i do n't have any references .", "summary": "problems: the evaluation of pre-segmented data is difficult without tightly transcribed time references to the individual channels from which the speech was derived ."}
{"dialogue": "it drifted into the afternoon , <inbreath> uh , concerning this issue of , um , the , well there 's basically the issue of the interplay between the transcript format and the processing that , they need to do for , the sri recognizer . and , um , < mike noise > their recognizer would prefer that the units not be overly long .", "summary": "problems: the sri recognizer requires that multi-channel format units not be too large , indicating that some additional pre-processing of unit lengths may be necessary ."}
{"dialogue": "the other topic i was thinking of was the sta status on microphones and channels , and all that . um , the new microphones , the two new ones are in . so what we would do is replace the wired mikes with wireless . and so we could replace our wired mikes with wireless if we bought another base station and more wireless mikes . no , we 're just replacing the wiredthe two wired that are still working , along with a couple of the wired that are n't working , one of the wired that 's not working , with a wireless .", "summary": "abstract: the berkeley meeting recorder group discussed recording equipment issues , including the purchase of two additional headsets and the prospect of getting a new base station and a set of wireless microphones to replace those wired microphones currently in use ."}
{"dialogue": "but ithink it would come to about eleven hours that are finished uh , transcribing from them right now . the next step is tothat i 'm working on is to insure that the data are clean first , and then channelized . and also that we now incorporate these additional conventions that uh , liz requested in terms of um , umin terms of having a s a systematic handling of numbers , and acronyms which i had n't been specific about . that the mark - up is consistent all the way throughout ,", "summary": "abstract: speaker fe008 presented the current status on transcriptions , and explained procedures for cleaning up transcripts and ensuring they conform with set conventions ."}
{"dialogue": "yeah , and iand i tried t to normalize uhuh the features , there 's loudness and modified loudness , um , within one channel , because they 're , <outbreath> yeah toto be able to distinguish between foreground and background speech .", "summary": "abstract: speaker mn014 briefly described his efforts to normalize loudness levels across speech channels to distinguish between foreground and background speech ."}
{"dialogue": "i wan na talk a little bit about gettinghow we 're gon na to get people to edit bleeps , parts of the meeting that they do n't want to include . the transcription part ? so i guess the next thing is this uhbleep editing . we need to provide the transcripts to every participant of every meeting to give them an opportunity to bleep out sections they do n't want . '' if you agree to participate you 'll have the opportunity to have anything ex anything excised , which you would prefer not to have included in the data set . `` there again you will be allowed to indicate any sections that you 'd prefer to have excised from the database , and they will m be removed both from the transcript and the recording . ``", "summary": "abstract: finally , the group discussed legal and procedural issues concerning the provision of transcripts to meeting participants for 'bleeping out ' any sections of speech they want excluded from the meeting recorder database ."}
{"dialogue": "`` if you agree to participate you 'll have the opportunity to have anything ex anything excised , which you would prefer not to have included in the data set . `` and they will m be removed both from the transcript and the recording . `` there again you will be allowed to indicate any sections that you 'd prefer to have excised from the database , again let 's you know , sort of circulate thethe wording on each of these things and get it right ,", "summary": "decisions: the consent form issued to subjects prior to meetings will be revised to make more explicit details concerning access to transcripts and the ability of subjects to mark sections of meetings for exclusion from the database ."}
{"dialogue": "so what we would do is replace the wired mikes with wireless . and so we could replace our wired mikes with wireless if we bought another base station and more wireless mikes . no , we 're just replacing the wiredthe two wired that are still working , along with a couple of the wired that are n't working , one of the wired that 's not working , with a wireless .", "summary": "decisions: the group decided to replace wired microphones with a wireless setup , i.e . a new base station and set of wireless microphones ."}
{"dialogue": "well we should talk to them about it because i know that sri is also in the process of looking at stuff , and so , you know , what we should try to keep everyoneon the same page with that .", "summary": "decisions: efforts will be made to ensure that recording conventions are consistent across icsi , the university of washington , and sri ."}
{"dialogue": "in listening tosome of these meetings that have already been recorded there are sometimes big spikes on particular things ,", "summary": "problems: some of the meeting recordings contain spikes ."}
{"dialogue": "none", "summary": "problems: it was surmised that such disturbances are probably due to the connectors attached to a set of wired microphones in use ."}
{"dialogue": "areare people going to be allowed to bleep out sections of a meeting where they were n't speaking ? so that means other people are editing what you say ?", "summary": "problems: with respect to editing bleeps , should participants be allowed to edit out others ' speech ?"}
{"dialogue": "but i really think we wan na make it the rare incidence . andand uh , i am just a little worried about making it so easy for people to do ,", "summary": "problems: it was suggested that making transcripts available to all of the subjects involved might make it too easy for them to edit out sections of meetings , whereas the bias should be to ensure that editing bleeps occur only rarely in the database ."}
{"dialogue": "i have a short thing about digits and then uh i wan na talk a little bit about naming conventions , so the only thing i wan na say about digits is , we are pretty much done with the first test set . uh , the last one wasthat you had there , was about naming ? we want some way of specifying , more than looking in the `` key `` file , what channel and what mike . what channel , what mike , and what broadcaster .", "summary": "abstract: topics discussed by the berkeley meeting recorder group included the status of the first test set of digits data , naming conventions for files , speaker identification tags , and encoding files with details about the recording ."}
{"dialogue": "uh , right , soso ii was just gon na talk briefly about the nsf itr . ok , so uh e l i guess , let me , uh , get mymy short thing out about the nsf . so this was , uh , a , uh , proposal that we put in so is i forit was a <mouth> proposal for the itr program , um , < clears throat > since we have such a short agenda list i guess i wi i will ask howhow are the transcriptions going ? andand i 'm tried toto , uh , adjust thetoto improve , eh , an harmonicity , eh , detector that , eh , ii implement . eh , and now i 'mi 'mi 'm trying toto find , eh , some kind of a , um <breath> of h of help , eh , using the energy toto distinguish between possible harmonics , andand other fre frequency peaks , that , eh , corres not harmonics . you 're trying distinguish between the case where there is , uhwherewhere there are more thanuh , where there 's more than one speaker and the case where there 's only one speaker .", "summary": "abstract: the group also discussed a proposal for a grant from the nsf 's itr ( information technology research ) program , transcriptions , and efforts by speaker mn005 to detect speaker overlap using harmonicity-related features ."}
{"dialogue": "that there 's one third thing i wanted toto ex raise as a to as an issue which is , um , how to handle breaths .", "summary": "abstract: particular focus was paid to questions about transcription procedures , i.e . how to deal with overlooked backchannels , and audible breaths ."}
{"dialogue": "seems like we should just change the transcripts", "summary": "decisions: a small percentage of transcripts will be changed to reflect mis-read , uncorrected digits ."}
{"dialogue": "that also brings up the point that we have to start assembling a speaker database so that we get those links back and forth and keep it consistent .", "summary": "decisions: a speaker database will be compiled to establish consistent links between speakers and their corresponding identification tags ."}
{"dialogue": "well so thenthen , maybe the answer is to , uh , listen especially densely in places of overlap ,", "summary": "decisions: sections of densely overlapping speech will require hand-checking so that overlooked backchannels may be manually segmented and labelled ."}
{"dialogue": "so i would say do n't tell them to transcribe anything that 's outside of a grouping of words .", "summary": "decisions: the transcribers should only code audible breaths within a grouping of words , and not outside regions of continuous speech ."}
{"dialogue": "i do n't knowthink it 'd be ideal . and breaths are part of real speech .", "summary": "decisions: it was further determined that audible breaths are an important facet of recorded speech , and that removing them from the corpus would be contrary to the aims of the project ."}
{"dialogue": "i will prepare for the next week eh , all my results about the harmonicity", "summary": "decisions: speaker mn005 will prepare his results for detecting speaker overlap and present them in the next meeting ."}
{"dialogue": "but , um , the other problem we were thinking about is if you just put the numerals , they might say forty - three instead of four three .", "summary": "problems: during digits readings , subjects tend to chunk numbers together rather than reading each number separately ."}
{"dialogue": "but , um , with the mixed , when you have an overlap , you only have aa choice of one start and end time for that entire overlap ,", "summary": "problems: when working from the mixed channel , transcribers may select only one start and end time for overlapping speech , resulting in points of overlap that are less tightly tuned ."}
{"dialogue": "once in a while a backchannel will be overlooked by the transcriber .", "summary": "problems: transcribers are likely to overlook backchannels in densely populated sections of speaker overlap ."}
{"dialogue": "yeah , but those backchannels will always be a problem i think . uh especially if they 're really short and they 're not very loud and so itit canitit will always happen that also the automatic s detection system will miss some of them ,", "summary": "problems: speaker mn014 reported that this is also problematic for the automatic detection of speech and non-speech , as backchannels that are very short and not loud enough will inevitably be overlooked ."}
{"dialogue": "none", "summary": "problems: speaker mn005 reported problems distinguishing between possible harmonics and other frequency peaks , and creating an algorithm for obtaining the instantaneous frequency ."}
{"dialogue": "um , aside from the fact that they 're obviously very time - consuming to encode ,", "summary": "problems: the encoding of all audible breaths is too time-consuming ."}
{"dialogue": "so the other topic with digits is uh , we have asr results from liz , transcript status from jane , and disk space and storage formats from don . don , you had disk space and storage formats .", "summary": "abstract: the berkeley meeting recorder group discussed digits data , recent asr results , the status of transcriptions , and disk space and storage format issues ."}
{"dialogue": "we have about two hours worth . so what that means is we have about an hour of transcribed digits that we can play with . and you 're saying two hours , uh , is digits ,", "summary": "abstract: approximately two hours of digits have been recorded , half of which have been extracted ."}
{"dialogue": "um , leads us to believe that doing a better segmentation , like your channel - based segmentation , or some kind of uh , echo cancellation to get basically back down to the individual speaker utterances would be probably all that we would need to be able to do good recognition on theon the close - talking mikes .", "summary": "abstract: researchers doing asr are looking into methods for generating a better channel-based segmentation to improve recognition results for close-talking microphone data ."}
{"dialogue": "alright so , first of all , um , there was aan interest in the transcribe transcription , uh , checking procedures", "summary": "abstract: transcription checking procedures were reviewed , and efforts to coordinate the channelization and presegmention of data with the tightening of time bins were discussed ."}
{"dialogue": "none", "summary": "abstract: the group also talked about downsampling and strategies for coping with low disk space ."}
{"dialogue": "ok soso i can just add to the instructions to read it as digits", "summary": "decisions: digits forms will instruct speakers to read digits separately and not as connected numbers ."}
{"dialogue": "none", "summary": "decisions: a tentative decision was made to collect overlapping digits from speakers ."}
{"dialogue": "give itgive one tr transcriber thethe channelized version ofof my speech - nonspeech detection and look ifif that 's helpful for them ,", "summary": "decisions: transcribers will be given channelized data that has been segmented for speech / non-speech boundaries to determine whether such pre-processing facilitates the transcription process ."}
{"dialogue": "and they 're slowly s trickling in . and so we tried last week with them written out in english . and it just did n't work at all because no one grouped them together .", "summary": "problems: participants have been slow in returning the relevant forms necessary for matching digits data with speaker ids . forms containing digits that were written out in english were unsuccessful for obtaining desired prosodic groupings ."}
{"dialogue": "especially for speakers that do n't talk a lot . so we have a problem with acoustic adaptation ,", "summary": "problems: acoustic adaptation is problematic for speakers who seldom talk during meetings ."}
{"dialogue": "it 's the fact that there 's overlap that causes recognition errors . so with a one - word utterance and ten insertions you know you got huge error rate .", "summary": "problems: speaker overlap causes recognition errors ."}
{"dialogue": "i guess the other neat thing is it shows for sure w that the lapel , you know within speaker is bad . and it 's bad because it picks up the overlapping speech .", "summary": "problems: the lapel microphone is problematic as it picks up overlapping background speech ."}
{"dialogue": "thatthat 's why we need more disk space", "summary": "problems: more disk space is needed ."}
{"dialogue": "you ca n't load an hour of speech into x waves .", "summary": "problems: loading long waveforms in x waves is very time consuming ."}
{"dialogue": "but if there 's things that um , we change later , then we always have to keep ourthe dictionary up to date .", "summary": "problems: the dictionary must be updated with forms introduced as part of speaker fe008 's set of transcription conventions ."}
{"dialogue": "well , you know the problemthe problem is that somesome of the adjustments that they 're making are to bringare to combine bins that weretime bins which were previously separate . but thei guess the ef the effect for you guys , because you 're pulling out the little wave forms into separate ones , that would mean these boundaries are constantly changing but if you split inside something , you do n't where the wordwhich words moved .", "summary": "problems: the ongoing tightening of boundaries on time bins causes segment boundaries to change , indicating potential problems for other ongoing processing tasks ."}
{"dialogue": "and then we go in and adjust the boundaries . how quickly can the transcribers scan over and fix the boundaries , and then it 'sthen it 'sthen it 's the transcribers tightening stuff up , so you 're talking about tightening up time boundaries ? well , soso that 's something that the transcribers will have tohave to do . so , if i excluded the pathological ones , <laugh> by definition , those that had like over ninety - five percent error rate , <inbreath> and the non - natives , then the average error rate was like one point four or something ,", "summary": "abstract: the berkeley meeting recorder group discussed the preparation of a data sample for ibm , the manual adjustment of time bins by transcribers , recognition results for a test set of digits data , and forced alignments ."}
{"dialogue": "none", "summary": "abstract: participants also talked about eurospeech 2001 submissions , and exchanged comments on the proceedings of the recently attended human language technologies conference ( hlt'01 ) ."}
{"dialogue": "so , if i excluded the pathological ones , <laugh> by definition , those that had like over ninety - five percent error rate , <inbreath> and the non - natives , then the average error rate was like one point four or something ,", "summary": "abstract: preliminary recognition results were presented for a subset of digits data ."}
{"dialogue": "so we need some way to push these first chunk of meetings into a state where we get good alignments .", "summary": "abstract: efforts to deal with cross-talk and improve forced alignments for non-digits data were also discussed ."}
{"dialogue": "and then we go in and adjust the boundaries . and then it 'sthen it 'sthen it 's the transcribers tightening stuff up , well , soso that 's something that the transcribers will have tohave to do .", "summary": "decisions: subsequent manual adjustment of speech and non-speech boundaries will be delegated to the transcriber pool ."}
{"dialogue": "he generated , um , a channel - wise presegmented version of a meeting , and then it 's ibm .", "summary": "decisions: a subset of meeting recorder data will be prepared ( i.e . pre-segmented and manually adjusted ) for delivery to ibm ."}
{"dialogue": "i think that if we decide that we needthat they need to see the visuals , we need to change the interface so that they can do that .", "summary": "decisions: the transcriber interface may require modifications if it becomes necessary for transcribers to quickly switch among waveform displays ."}
{"dialogue": "and there really was , then , if it did n't show up in a mixed signal to verify , then it might be overlooked , yeah , but presumably , most of those they should be able to hear from the mixed signal unless they 're embedded in the heavil heavy overlap section i do n't know that you can locate them very well from the mixed signal ,", "summary": "problems: transcribers risk overlooking speech that is deeply embedded in the mixed signal ."}
{"dialogue": "so , i mean , the question is `` shouldshould a transcriber listen to the entire thing or can it g can it be based on the mixed signal ? ``", "summary": "problems: should transcriptions be derived from each of the close-talking channels or from the mixed signal alone ?"}
{"dialogue": "except for < clears throat > it does n't do well on short things , remember .", "summary": "problems: the pre-segmentation tool does not perform well on short utterances , e.g . backchannels ."}
{"dialogue": "the problem is thatthatthe tcl - tk interface with the visuals , it 's very slow to load waveforms . but you just ca n't get the visual display to show quickly .", "summary": "problems: the transcriber interface does not allow the user to quickly switch among visual displays , i.e . multi-channel waveforms ."}
{"dialogue": "oh , well , yeah , so i 've been struggling with the forced alignments . but it might well be that we ca n't get clean alignments out of thisout of those , uh , <inbreath> channels , so he thought well if we can do something quick and dirty because dan said the cross - cancellation , it 's not straight - forward .", "summary": "problems: forced alignments were problematic for non-digits data due to cross-talk ."}
{"dialogue": "none", "summary": "problems: this problem was reported to be particularly bad for cross-talk featuring more than one word ."}
{"dialogue": "unless maybe we do this , uh , um , cancellation business . but it 's clear from dan that this is not something you can do in a short amount of time . um , but then if you add the dynamic aspect of adapting distances , then it was n't", "summary": "problems: echo cancellation was considered as a means of improving forced alignments , but was ultimately deemed to be too time-consuming given the dynamic aspect of adapting distances between speakers ."}
{"dialogue": "it 's very tedious to check these .", "summary": "problems: comparing error rates in terms of the recording device used , i.e . lapel versus wireless microphones , is tedious ."}
{"dialogue": "and i really find it a pain in the neck to delete things", "summary": "problems: deleting segments of the recordings is expected to be very time-consuming for transcribers ."}
{"dialogue": "yeah , for eurospeech we want some results", "summary": "problems: more results are needed for generating adequate submissions for eurospeech'01 ."}
{"dialogue": "but if they 're not comfortable , we have the same problems we have with these stupid things .", "summary": "problems: participants have complained that the head-mounted microphone is uncomfortable ."}
{"dialogue": "and the interesting thing is that even though , <inbreath> yes , it 's a digits task and that 's a relatively small number of words and there 's a bunch of digits that you train on , <inbreath> it 's just not as good as having aa l very large amount of data and training up aaa nice good big <inbreath> hmm .", "summary": "abstract: the berkeley meeting recorder group discussed efforts to train and test the aurora group 's htk-based recognition system on icsi 's digits corpus ."}
{"dialogue": "two items , which was , uh , digits and possibly stuff onon , uh , forced alignment , so wewe only r hav i only looked at actually alignments from one meeting that we chose ,", "summary": "abstract: members also discussed efforts to produce forced alignments from a selection of meeting recorder data ."}
{"dialogue": "uh , but the other is that , um , the digits <inbreath> recorded here in this room with these close mikes , i uh , are actually a lot harder than thestudio - recording ti - digits . if you have only one utterance per speaker you might actually screw up on estimating thethe warping , uh , factor . well , i know there were some speaker labelling problems , um , after interruptions . but you 're actually saying that certain , uh , speakers were mis mis - identified .", "summary": "abstract: performance in both tasks was adversely affected by the manner of recording conditions implemented and difficulties attributing utterances to the appropriate speakers ."}
{"dialogue": "andandw wewe were able to get some definite improvement on the forced alignments by looking at them first and then realizing the kinds of errorsthat were occurring so just sort of working through a bunch of debugging kinds of issues .", "summary": "abstract: while debugging efforts resulted in improved forced alignments , dealing with mixed channel speech and speaker overlap remains a key objective for future work ."}
{"dialogue": "soso the keything that 's missing here is basically the ability to feed , you know , other features <outbreath> i into the recognizer and also then to train the system . we want to <inbreath> have the ability to feed it different features .", "summary": "abstract: the group is additionally focused on a continued ability to feed different features into the recognizer and then train the system accordingly ."}
{"dialogue": "yeah , bu although i 'd bei think it 'd be interesting to just take this exact actual system and try it out on ti - digits .", "summary": "decisions: for comparing meeting recorder digits results , it was decided that the aurora htk-based system should be tested on data from the ti digits corpus ."}
{"dialogue": "so , we might have to modify that script to recognize the , um , speakers , <inbreath> um , in thein the , uh , um , <mouth> ti - digitsdatabase . because we may have to do an extract to get theamount of data per speaker about right .", "summary": "decisions: the script for extracting speaker id information will require modifications to obtain a more accurate estimation of the amount of data recorded per speaker ."}
{"dialogue": "yeah . ii know what i was thinking was that maybe , uh , i i we could actually t t try at least looking at , uh , some of thethe large vocabulary speech from a far microphone , but i 'm saying if you do the same kind of limited thing <inbreath> as people have done in switchboard evaluations or asa could we do exactly the same thing that we 're doing now , but do it with a far - field mike ? but you use the acoustics from the far - field mike .", "summary": "decisions: subsequent recognition experiments will look at large vocabulary speech from a far-field microphone ( as performed in switchboard evaluations ) ."}
{"dialogue": "so , <inbreath> we would need a hand - marked , um , <mouth> word - level alignments or at least sort of the boundaries of the speech betw you know , between the speakers . and tune the parameters of theof the model , uh , to op to get the bestperformance .", "summary": "decisions: hand-marked , word-level alignments are needed to reveal speaker boundaries and tune the parameters of the model ."}
{"dialogue": "you know , interface - wise if you 're looking at speech , you wan na be able to know really where the words are . um , and see if you can in maybe incorporate it into the transcriber tool some way , yeah , it wou the advantage would just be that when you brought up a bin you would be ableif you were zoomed in enough in transcriber to see all the words , you would be able to , like , have the words sort of located in time ,", "summary": "decisions: modifications to the transcriber tool are required for allowing transcribers to simultaneously view the signal in xwaves and see where words are located in time ."}
{"dialogue": "none", "summary": "problems: digits training needs to be performed on a larger data set ."}
{"dialogue": "um , also you had the adaptation in the sri system , which we did n't have in this . so there was a significant loss from not doing the adaptation .", "summary": "problems: a significant loss in recognition resulted from not having included the type of phone-loop adaptation found in the sri system ."}
{"dialogue": "uh , but the other is that , um , the digits <inbreath> recorded here in this room with these close mikes , i uh , are actually a lot harder than thestudio - recording ti - digits .", "summary": "problems: recognition performance was worse for digits recorded in closed microphone conditions versus those recorded in a studio ( e.g . ti-digits ) ."}
{"dialogue": "uh , but the other is that , um , the digits <inbreath> recorded here in this room with these close mikes , i uh , are actually a lot harder than thestudio - recording ti - digits . i suspect that to get sort of the last bit out of these higher - quality recordings you would have to in fact , uh , use models that , uh , were trained on wider - band data . that 's where the most m acoustic mismatch is between the currently used models and thethe r the set up here . the near versus far .", "summary": "problems: a mismatch between the manner in which data were collected and the models used for doing recognition -- -e . g . bandwidth parameterization and the use of near- versus far-field microphones -- -was identified ."}
{"dialogue": "if you have only one utterance per speaker you might actually screw up on estimating thethe warping , uh , factor .", "summary": "problems: too little data per speaker can have a negative effect on vtl estimation ."}
{"dialogue": "because it 's further away from most of the people reading digits .", "summary": "problems: the pzm channel selected for obtaining digits data was too far away from most of the speakers ."}
{"dialogue": "you know , as liz said thewe f enforce the fact that , uh , the foreground speech has to be continuous . things like words that do occur just by themselvesa alone , like backchannels or something that we did allow to have background speech around it those would be able to do that , but the rest would be constrained .", "summary": "problems: current speech alignment techniques assume that foreground speech must be continuous and , barring some isolated words and backchannels , can not cope with overlapping background speech ."}
{"dialogue": "we probably want to adapt at least the foreground speaker . but , i guess andreas tried adapting both the foreground and a background generic speaker , and that 's actually a little bit of a f funky model . like , it gives you some weird alignments , just because often the background speakers match better to the foreground than the foreground speaker .", "summary": "problems: performing adaptations on both the foreground and background speaker produced a new variety of misalignments , a problem resulting , in part , from the fact that background speakers often match better to foreground conditionss ."}
{"dialogue": "tha - there are some cases like where thethe wrong speakeruh , these ca not a lot , but where thethe wrong personthethe speech is addre attached to the wrong speaker", "summary": "problems: transcribers occasionally misidentified speakers and omitted backchannels that were more hidden in the mixed signal ."}
{"dialogue": "so the only agenda items were janewas jane wanted to talk about some of the ibm transcription process . uh , and you just sent off a eurospeech paper , so , we should probably talk about the ibm transcription process stuff that", "summary": "abstract: the main topics of the agenda were a paper submitted to eurospeech and the organising of the recording transcriptions to be done by ibm ."}
{"dialogue": "uh , the one was that thejust thethe amount of overlap but , even if you take out all the backchannels you still have significant overlap .", "summary": "abstract: the results presented in the former show a significant percentage of overlapping speech even without counting in backchanneling ."}
{"dialogue": "and we rescored things um , a little bit more carefully . and then the second one was just basically the <breath> the stuff we had in thein the hlt paper on how overlaps effect therecognition performance . but basically what we found is after we take out these regionsso we only score the regions that were certified as foreground speech , <breath> the recognition error went down to almost <breath> uh , thelevel of the non - overlappedspeech .", "summary": "abstract: additionally , the high error rate in the recognition of such overlapping speech by the sri recogniser was minimised simply by changing the scoring method used ."}
{"dialogue": "so at the end after a discourse marker or after backchannel or after filled pause , you 're much more likely to be interrupted <breath> than before .", "summary": "abstract: finally , a strong correlation between pauses and interruptions was confirmed ."}
{"dialogue": "no . well , according to the transcripts .", "summary": "abstract: all these measurements were based on the sample of available transcripts ."}
{"dialogue": "although that 'sii take it that 's something that uh don willwill look at", "summary": "abstract: other features , like prosody , will be studied in the near future ."}
{"dialogue": "and also , um , the other person that wants itthere is one person at sri who wants to look at the <breath> um , you know , the uhthe data we have so far , and so i figured that ftp is the bestapproach . so what i did is i um <mouth> <breath> @ @ i made a n new directory", "summary": "abstract: an ftp directory containing such experimental data is being set up for the benefit of other researchers ."}
{"dialogue": "so the only agenda items were janewas jane wanted to talk about some of the ibm transcription process . so , we should probably talk about the ibm transcription process stuff that", "summary": "abstract: regarding the transcriptions to be carried out by ibm , the discussion mainly concerned the format of the recordings that should be sent to them ."}
{"dialogue": "and , if the chunked files focused on the dominant speakers , <breath> then , whenwhen it got s patched together when it comes back from ibm , we can add the backchannels . and you just use the s the segments of the dominant speaker then ? forfor sending toto ibm but then we could just use thethe output of the detector , and do the beeping on it , and send it to i b without having her check anything . butbut iii haveanother suggestion on that , which is , <breath> since , really what this is , isisis trying to in the large , send the right thing to them and there is gon na be thisthis post - processing step , and we 'llwe 'll fix things up", "summary": "abstract: suggestions included sending only the channels with the dominant speakers for transcription , but it was finally agreed on sending the original files with minimal modifications , as there will be extensive in-house post-processing ."}
{"dialogue": "so that if youif you playback that bin and have it in the mode where it stops at the boundary , <breath> it sounds like a normal word . but my general goal <breath> when there wassufficient space , room , pauseafter itto have it bekind of a natural feelinggap .", "summary": "abstract: within this discussion , the rationale behind the coding of the time bins according to the flow of discourse was also explained ."}
{"dialogue": "we should probablyuhgive them the non - downsampled versions . but , umthey probably w want the originals .", "summary": "decisions: the files made available in the ftp directory will be the original ones ( before down-sampling ) , as these seem to be wanted by other parties ."}
{"dialogue": "yeah , in fact after our meeting uh , this morning thilo came in and said that <breath> um , there could beother differences between <breath> the uhalready transcribed meeting with the beeps in it and one that hasjust r been run through his process . so tomorrow , <breath> when we go to make the umuh , chunked file <breath> for ibm , we 're going to actually compare the two . and then we 're gon na do the beep - ify on both , and listen to them and see if we notice any real differences .", "summary": "decisions: moreover , as files may have been modified through different processing , tests will be carried out in order to ensure the generation of beep files in a consistent way ."}
{"dialogue": "so whatwhat we 're probably gon na do is just write a script , that if two , chunks are very close to each other on the same channel we 'll just merge them . but i like this idea ofuh , for our purposes for thefor the ibm preparation , <breath> uh , n having thesejoined together ,", "summary": "decisions: also towards this goal , some of the time bins will need to be merged ."}
{"dialogue": "uh , because we could use that to fine tune our alignment process i mean w i mean what i wouldi was interested in is having <breath> a se having time marks for the beginnings and ends of speech ii hand - adjusted two of them soso at some point we will try to fine - tune our forced alignment", "summary": "decisions: on the other hand , the two meetings where time bins have been hand-coded in detail will be used to fine-tune the forced alignments ."}
{"dialogue": "we need to give brian the beeps file , and we send it to ibm . the other one is <breath> we just run his thing and send it to ibm . send it off to ibm .", "summary": "decisions: recordings will be sent to ibm for transcription ."}
{"dialogue": "but then we could just use thethe output of the detector , and do the beeping on it , and send it to i b so thethe one suggestion is you know we <breath> we run thilo 's thing the other one is <breath> we just run his thing and send it to ibm . and that is <breath> if we go ahead and we <breath> just run his , and we generate the beeps file , then we have somebody listen beeps file . put the beeps file ,", "summary": "decisions: before that , the files will be automatically pre-segmented into speech / non-speech bins and the beeps will be inserted ."}
{"dialogue": "the other problem is , that when itwhen it uh d i on the breathy ones , where you get <breath> <breath> breathing , uh , inti indicated as speech . so , i could run this on those breathy channels , and what that 'll do is just cut the time a little further .", "summary": "decisions: in order to make things easier for the transcribers , breathy channels , which are erroneously marked as speech , will be re-classified correctly with other methods ."}
{"dialogue": "why do n't we check through a bunch of things by sampling it ?", "summary": "decisions: all this pre-processing will have to be evaluated first by checking a sample of the output files ."}
{"dialogue": "what can you do ? and we 'll correct it when it comes back .", "summary": "decisions: other issues , like whether and how synthesised speech off a laptop needs be transcribed , will be resolved during the in-house post-processing of the transcriptions ."}
{"dialogue": "we actually exceeded the delayed deadline by o another day , i hope they accept it .", "summary": "problems: there is a slight worry about the acceptance of the paper submitted to eurospeech as the deadline was exceeded ."}
{"dialogue": "well , we did n't get to look at that , yeah , i just wonder if you have to normalize by the numbers of speakers or something . i bet there 's a weak dependence .", "summary": "problems: as to the content of the paper , the overlap statistics have not been normalised against the number of participants in the conversation , although the dependency is probably going to be a weak one ."}
{"dialogue": "there 's no statement about cause and effect .", "summary": "problems: additionally , the correlation between pauses in speech and interruptions does not provide a cause-and-effect link for these phenomena ."}
{"dialogue": "yeah , in fact after our meeting uh , this morning thilo came in and said that <breath> um , there could beother differences between <breath> the uhalready transcribed meeting with the beeps in it and one that hasjust r been run through his process . that 's because of channel overlap .", "summary": "problems: the preparation of files for transcription by ibm is facing some minor difficulties , as some features ( hand-coded time boundaries , multiplicity of channels etc ) may complicate the generation of beep files ."}
{"dialogue": "but you know , i wanted to say , his segmentation is so good , that <breath> um , the part that i listened to with her yesterday <breath> did n't need any adjustments of the bins . i can'treallyhhh , tsk . ido n't have really representative numbers , i think .", "summary": "problems: besides this , the automatic pre-segmentation has been deemed to be good , but there are still no specific measurements to verify this ."}
{"dialogue": "and i <laugh> the speech - nonspeech detector just assigns randomly the speech toto one of the channels ,", "summary": "problems: the pre-segmentation tool also classifies synthesised speech used in a recording as `` normal speech '' and assigns a random channel to it ."}
{"dialogue": "a hand - transcriber would have trouble with that .", "summary": "problems: the transcribers at ibm may not be able to differentiate between the two ."}
{"dialogue": "none", "summary": "abstract: the berkley meeting recorder project is well underway , and this meeting discusses the progress and ongoing issues ."}
{"dialogue": "because <inbreath> it occurred to me that this is late may and the darpa meeting is inmid july . i mean in particular i wouldi would really hope that when we do this darpa meeting in july that we sort of havewe 'rewe 're into production mode , somehow um , we are gon na have this darpameeting in the middle of july , given that we 've beenwe 've given a couple public talks about it already , spaced by months and months , i think it 'd be pretty bad if we continued to say none of this is available .", "summary": "abstract: a pressing concern for the group is the darpa meeting in july , which is only a short time away , and for which they would like to have some progress ."}
{"dialogue": "and so he talked it over with the transcriber and the transcriber thought that the easiest thing for them would be if there was a beep and then the nu a number , a digit , and then a beep , uh , at the beginning of each one e e u uthe reason i 'm asking is because , uh , jane and i have just been talking , and she 's just been doing . <laugh> uh , e a , you know , further hiring of transcribers . and so we do n't sort of really know exactly what they 'll be doing , how long they 'll be doing it , and so forth , because right now she has no choice but to operate in the mode that we already have working . i hired two transcribers today . i 'm thinking of hiring another one , which willbecause we 've had a lot of attrition . yeah . so , um , uh , jane and adam and i had a meeting where we talked about the reorganization of thedirectory structure for all of the meeting for all the meeting recorder data .", "summary": "abstract: specifically , the group would like to have transcripts available , which would mean resolving legal issues for data use and on the basis of feedback from ibm get more transcription underway ."}
{"dialogue": "i know that we were gon na do something with the transcriber interface is one thing , well , we were gon na do a mock - up , like , question answering or something , i thought , i was gon na ask adam to , uh , say if he thought anymore about the demo stuff", "summary": "abstract: additionally they would also like to have the question answering mock-up and transcriber interface ready for then ."}
{"dialogue": "is there stuff that 's happened about , um , uh , thesri recognizer et cetera , y y you guys were doing a bunch of experiments with different front - ends and then with now thetheyou saw the note that the plp now is getting basically the same as the mfcc . um , it looks like the vocal tract length normalization is working beautifully , actually , because in all our previous experiments , we had theuh , you know , we were essentially cheating by having the , um , you know , the h the hand - segmentations as the basis of the recognition . and so now with thilo 's segmenter working so well , i think we shouldconsider doing a and eventhe good thing is that since you , um , have high recall , even if you have low precision cuz you 're over - generating , that 's good hashas , uh ? we justi think , just talked about this the other day , but h hashas anybody had a chance to try changing , uh , insertion penalty sort of things with thewith the , uh <breath> uh , using the tandem system input for the ? but the plp features workum , uh , you know , continue to improve the ,", "summary": "abstract: plp results for the front-end look good , with the group also reporting progress in segmentation: thilo 's segmenter will now be used and ways of improving performance investigated ;"}
{"dialogue": "but we did find that some of the features that , i gue jane would know about , that are expressing sort of the <breath> distance of , um , <mouth> boundaries from peaks in the utterance and <breath> somelocal , um , rangepitch range effects , like how close people are to their floor , are showing up in these classifiers , um , so we 're starting to see some patterns because the <breath> prosodic features arevery noisy and so youyou need a lot of data in order to model them .", "summary": "abstract: the classifier segmentation is progressing well , especially in the use of prosody for identifying interruption ."}
{"dialogue": "hashas , uh ? we justi think , just talked about this the other day , but h hashas anybody had a chance to try changing , uh , insertion penalty sort of things with thewith the , uh <breath> uh , using the tandem system input for the ? as i said before , theuh using dan 's , uh , uh , vocal tract normalization option works very well . but the plp features workum , uh , you know , continue to improve the , well , but if you add them all up you have , uh , almost five percent difference now . and i think i agree with you that if we fixed lots of different things and they would all add up , we would probably have aaa competitive system . but i think not that much of it is due to the front - end per se . i think maybe a couple percent of it is , as far as i can see from this . eh at this point i 'm as i mean , you knowe i 'm wondering is itcan we expect , uh , a tandem system to do better than a properly trainedyou know , a gaussian system trained directly on the features with , you know , the right ch choice ofparameters ?", "summary": "abstract: work on the front end continues , with improvements of 3-5 % being made ."}
{"dialogue": "i mean , are we trying to do them < mike noise > in synchrony ? that might be fun . well , it 's < breath-laugh > it 'sit 's notyou know , it 's not gon na work out but we couldwe could just , uh , uh , see if we find a rhythm ,", "summary": "decisions: the group discussed how the digits should be recorded in the meeting ."}
{"dialogue": "i mean , are we trying to do them < mike noise > in synchrony ? that might be fun . but we couldwe could just , uh , uh , see if we find a rhythm , well , it 's < breath-laugh > it 'sit 's notyou know , it 's not gon na work out", "summary": "decisions: in the end they decided to record these in unison for all of the meeting participants as a whole ."}
{"dialogue": "and so now with thilo 's segmenter working so well , i think we shouldconsider doing a so we do need some kind of pre - segmentation . we shouldwe should consider doing some extra things , like , um , you know , retraining or adapting the <breath> the models for background noise to theto this environment , for instance . and , yeah , using thilo 's , you know , posteriors or some kind ofor", "summary": "decisions: to improve the performance of thilo 's automatic segmenter , this is going to be retrained and adapted to run with thilo 's posteriors and speaker background models ."}
{"dialogue": "and so he talked it over with the transcriber e e u uthe reason i 'm asking is because , uh , jane and i have just been talking , and she 's just been doing . <laugh> uh , e a , you know , further hiring of transcribers . and so we do n't sort of really know exactly what they 'll be doing , how long they 'll be doing it , and so forth , because right now she has no choice but to operate in the mode that we already have working . you know , that wewe actually <breath> have a stream going and we know howhow well it does and howand how it operates . i hired two transcribers today . i 'm thinking of hiring another one , which willbecause we 've had a lot of attrition . but if we hire f you know , f we have five on stafffive or six on staff at any given time , then <inbreath> it 's a small enough number so we can be flexible either way .", "summary": "decisions: regarding transcription , no new transcribers will be employed until situation regarding ibm is clarified ."}
{"dialogue": "i mean in particular i wouldi would really hope that when we do this darpa meeting in july that we sort of havewe 'rewe 're into production mode , somehow you know , that wewe actually <breath> have a stream going and we know howhow well it does and howand how it operates . right . so we can s wewe wan na be able to say `` here is a subset that is available right now `` and that 's has been through the legal issues and so forth . and they do n't have to approve , you know , th an edited version , they can just give their approval to whatever version well , in principle , yes . but , i mean , i ififif somebody actually did get into some legal issue with it then we yeah . but th i mean , the editing will continue . presumably ifif s errors are found , they will be fixed , i ityou know , there there is a point at which i agree it becomes ridiculous unfortunately , uh , inin the sign thing that they signed , it says `` transcripts `` . '' you 'll beyou 'll be provided the transcripts when they 're available . `` so letlet me just suggest that <inbreath> uh , off - line that , uh , the people involved figure it out and take care of it before it 's july .", "summary": "decisions: legal issues surrounding the approval and signing off of transcripts by participants has proved to be very complicated , and so will be sorted out off line by those involved by july ."}
{"dialogue": "and , <breath> for instance , uh , dan @ @ dan just sent me a message saying that cmu used , um , <mouth> something like ten gaussians per cluster you know , eacheach mixture has tengaussians hmm . we 're using sixty - four , so that 's <breath> obviously a big difference and give very poorly trained , uh , you know , gaussians that way , the turn - around time on the training when we train only thea male system with , uh , you know , our small training set , is <breath> less than twenty - four hours ,", "summary": "decisions: after finding discrepancies with the cmu researchers , the icsi group have decided to tune the size of their gaussian system ."}
{"dialogue": "yeah . <inbreath> ii would actually double check with stephane at this point , yeah . it 's hard with features , cuz you do n't know what they should look like . i mean , you ca n't just , like , print thethe values out in ascii and , you know , look at them , see if they 're not unless you had a lot of time", "summary": "decisions: after raising the difficulty of checking for bugs in their generation of tandem features , they decide to check with stephane who has more experience of these procedures ."}
{"dialogue": "i was gon na ask adam to , uh , say if he thought anymore about the demo stuff because <inbreath> it occurred to me that this is late may and the darpa meeting is inmid july . i know that we were gon na do something with the transcriber interface is one thing , well , we were gon na do a mock - up , like , question answering or something , i thought , i mean in particular i wouldi would really hope that when we do this darpa meeting in july that we sort of havewe 'rewe 're into production mode , somehow yeah . so , um , uh , jane and adam and i had a meeting where we talked about the reorganization of thedirectory structure for all of the meeting for all the meeting recorder data . um , we are gon na have this darpameeting in the middle of july , given that we 've beenwe 've given a couple public talks about it already , spaced by months and months , i think it 'd be pretty bad if we continued to say none of this is available . right . so we can s wewe wan na be able to say `` here is a subset that is available right now ``", "summary": "problems: for the darpa meeting in july , the group propose that they should have the question answering mock-up and transcriber interface ready for then , and also have data available ."}
{"dialogue": "so letlet me just suggest that <inbreath> uh , off - line that , uh , the people involved figure it out and take care of it before it 's july . '' you 'll beyou 'll be provided the transcripts when they 're available . `` unfortunately , uh , inin the sign thing that they signed , it says `` transcripts `` . i ityou know , there there is a point at which i agree it becomes ridiculous yeah . but th i mean , the editing will continue . presumably ifif s errors are found , they will be fixed , well , in principle , yes . but , i mean , i ififif somebody actually did get into some legal issue with it then we and they do n't have to approve , you know , th an edited version , they can just give their approval to whatever version and that 's has been through the legal issues and so forth .", "summary": "problems: unfortunately , there are legal issues regarding the approval of transcripts ."}
{"dialogue": "because right now she has no choice but to operate in the mode that we already have working . you know , that wewe actually <breath> have a stream going and we know howhow well it does and howand how it operates . i hired two transcribers today . i 'm thinking of hiring another one , which willbecause we 've had a lot of attrition . butbut actually i it 's so correct for so much of the time , that it 's an enormous time saver and it just gets tweaked a little around the boundaries . thethethe pre - segmentations are so muchare s so extremely helpful . wha - what you 'd really like is that they started with pre - segmented and were pre - segmented all the way through . yeah . as long as we have a record , i guess , of the originalautomatic one , we can always find out how wellwe would do fr from the recognition side by using those boundaries . well , le let me put in another sort of a milestone kind ofasas i did with the , uh , uhthethe pipeline .", "summary": "problems: additionally , the group would like to have their data transcriptions in `` production mode '' by then ."}
{"dialogue": "e e u uthe reason i 'm asking is because , uh , jane and i have just been talking , and she 's just been doing . <laugh> uh , e a , you know , further hiring of transcribers . and so we do n't sort of really know exactly what they 'll be doing , how long they 'll be doing it , and so forth , because right now she has no choice but to operate in the mode that we already have working .", "summary": "problems: however the group do not want to hire more transcribers until ibm confirms in the next 2-3 weeks the acceptability of the data ."}
{"dialogue": "because in all our previous experiments , we had theuh , you know , we were essentially cheating by having the , um , you know , the h the hand - segmentations as the basis of the recognition . and so now with thilo 's segmenter working so well , i think we shouldconsider doing a", "summary": "problems: segmentation for the recogniser has been done by hand which the group consider `` cheating '' , instead now they want to use thilo 's automatic segmenter ."}
{"dialogue": "because we could n't use the non - nativeall non - native meetings and <breath> it 's , well , probably below threshold on enough data for us for the things we 're looking at because the <breath> prosodic features arevery noisy and so youyou need a lot of data in order to model them .", "summary": "problems: the classifier segmentation work is going well , but needs more data to improve results since non-native speaker data can not be used ."}
{"dialogue": "you know , chuck and i talked and the @ @ next thing to do is probably to tune theum , the size of the gaussian system , um , @ @ toto thisto this feature vector , which we have n't done at all . we just used the same <breath> configuration as we used for the <breath> for the standard system . and , <breath> for instance , uh , dan @ @ dan just sent me a message saying that cmu used , um , <mouth> something like ten gaussians per cluster you know , eacheach mixture has tengaussians hmm . we 're using sixty - four , so that 's <breath> obviously a big difference and give very poorly trained , uh , you know , gaussians that way , the turn - around time on the training when we train only thea male system with , uh , you know , our small training set , is <breath> less than twenty - four hours , but the plp features workum , uh , you know , continue to improve the , as i said before , theuh using dan 's , uh , uh , vocal tract normalization option works very well .", "summary": "problems: for the front-end , so far the group have been using a high number of gaussians per cluster ( 64 ) rather than the ten per cluster used by researchers at cmu , therefore they need to tune their gaussian system to the feature vector ."}
{"dialogue": "but there the main point is that , um , you know , it took us a while but we have the procedure for coupling the two systems <inbreath> debugged now andi mean , there 's still conceivably some bug somewhere in the way we 're feeding the tandem features uh , either generating them or feeding them to thisto the <breath> sri system , thatthati think that 'sthisthat 's essentially the same as we use with the ce with the p l p fe features . yeah . there could be a bug inin thesomewhere before that . yeah . <inbreath> ii would actually double check with stephane at this point , yeah . it 's hard with features , cuz you do n't know what they should look like . i mean , you ca n't just , like , print thethe values out in ascii and , you know , look at them , see if they 're not unless you had a lot of time", "summary": "problems: the groupobserved that it would be difficult to check for bugs in the generation of tandem features for the sri system ."}
{"dialogue": "none", "summary": "abstract: this meeting mainly outlines the progress of the meeting recorder project ."}
{"dialogue": "well , maybe uh , since thatthat was a pretty short one , maybe we should talk about the ibm transcription status . so , we , uhwe did another version of the beeps , where we separated each beeps with a spoken digit . ii hirei 've hired two extra people already , expect to hire two more . which are now being edited by my head transcriber , <breath> in terms of spelling errors and all that . she 's also checking through and mar and <breath> and monitoring , um , the transcription of another transcriber . andand you indicated to me that we have a g a goal now , <breath> for thefor the , um , <click> <breath> the , uh , darpa demo , of twenty hours . so , i 'm gon na go up to twenty hours , be sure that everything gets processed , and released , andand that 'sthat 's what my goal is . but i guess the other thing is that , um , thatthat 's kinda twenty hours asap because the longer before the demo we actually have the twenty hours , the more time it 'll be for people to actually do cool things with it . yeah , i mean , i guess theso the difference ifif , um , if the ibm stuff works out , the difference in the job would be that they p primarily would be checking through things that were already done by someone else ?", "summary": "abstract: in particular , the group discuss their preparation of materials for the transcriptions of digits by ibm , and also the human transcribers who are working towards preparing the set of 20 for the darpa meeting ."}
{"dialogue": "n i 'm successfully , uh , increasing the error rate . we 've always viewed it , anyway , as the major difference between the two , is actually in the smoothing , that thethat the , um , <inbreath> plp , andand the reason plp has been advantageous in , uh , slightly noisy situations is because , <inbreath> plp does the smoothing at the end by an auto - regressive model ,", "summary": "abstract: other discussion focuses on the re-evaluation of recognition without cheating on segmentation , and also how sri recognition can be improved , especially for the female group ."}
{"dialogue": "and the , uhporzeland the , uh , smartkom group are collecting some dialogues . i mean , i do n't care what directory tree you have it under . well , butbut , <mouth> i put it under the same directory tree . and just simply in the file you mark somewhere that this is this type of interaction , rather than another type of interaction . we 're aboutwe 're about halfhalfway through our disk right now . well , but you can have it nw archive toyou can have , <inbreath> uh , a non - backed - up disk nw archived ,", "summary": "abstract: a number of issues regarding the management of data are addressed by the group:"}
{"dialogue": "and the , uhporzeland the , uh , smartkom group are collecting some dialogues . it 's just that it 's , you know , different directory , it 's called something different , it 's and just simply in the file you mark somewhere that this is this type of interaction , rather than another type of interaction . i mean , i do n't care what directory tree you have it under . well , butbut , <mouth> i put it under the same directory tree . we 're aboutwe 're about halfhalfway through our disk right now . well , but you can have it nw archive toyou can have , <inbreath> uh , a non - backed - up disk nw archived ,", "summary": "abstract: the inclusion of different data types in the corpus , and the storage and back-up of the group 's data ."}
{"dialogue": "butbut , uh , probably , if we had to pick somethingthat we would talk on for ten minutes or so while they 're coming here . or i guess it would be , you think , reorganization status , i mean , i think , chuck was the one who added out the agenda item . i do n't really have anything to say other than that we still have n't done it . so , naming conventions and things like that , that i 've been trying to keep actually up to date . and i 've been sharing them with u - d uw folks also .", "summary": "abstract: progress has been made in naming conventions , with file reorganisation to be done at a later date , however this was not discussed fully due to chuck 's absence ."}
{"dialogue": "so , is there something quick about absinthethat you ? and got <mouth> <inbreath> a speedup roughly proportional to the number of processors times the clock cycle . but thewhat it means is that it 's likely that for net training and forward passes , we 'llabsinthe will be a good machine . especially if we get a few more processors and upgrade the processors .", "summary": "abstract: finally , absinthe is now up and running with improved performance ."}
{"dialogue": "so i guess the other thing that we were gon na talk about isis , uh , demo . and , um , so , these are the demos for theuh , july , uh , meetingand , umdarpa mee but maybe , uhmaybe we 'll just put that off for now , given that but i think maybe we should have aa sub - meeting , i think , uh , probably , uh , adam andand , uh , chuck and me should talk aboutshould get together and talk about that sometime soon .", "summary": "abstract: discussion of demos for the july darpa meeting were left to the individuals concerned ."}
{"dialogue": "and the , uhporzeland the , uh , smartkom group are collecting some dialogues . i mean , i do n't care what directory tree you have it under . well , butbut , <mouth> i put it under the same directory tree . and just simply in the file you mark somewhere that this is this type of interaction , rather than another type of interaction .", "summary": "decisions: a number of data issues were resolved:"}
{"dialogue": "and the , uhporzeland the , uh , smartkom group are collecting some dialogues . basically they have one person sitting in here , looking at a picture , and a wizard sitting in another room somewhere . and , uh , they 're doing a travel task . but it starts where the wizard is pretending to be a computer and it goes through a , uh , <breath> speech generation system . should this be part of the corpus or not ? and my attitude was yes , because there might be people who are using this corpus foracoustics , as opposed to just for language . we simulate a computer breakdown halfway through the session , and so then after that , the person 's told that they 're now talking to a , uhto a human . but of course they do n't know that it 's the same person both times . and i said , `` well that 's silly , ifif we 're gon na try to do it for a corpus , there might be people who are interested in acoustics . `` ii would not say it was part of the meetings corpus . so it 'sititi guess itthebegs the question of what is the meeting corpus . i think it 'sii thinki th think the idea of two or more people conversing with one another is key . well , this has two or more people conversing with each other . we give everyone who 's involved as their own user id , give it session i ds , <inbreath> let all the tools that handle meeting recorder handle it , or do we wan na special case it ? well , itit makes sense to handle it with the same infrastructure , since we do n't want to duplicate things unnecessarily . but as far as distributing it , we should n't label it as part of this meeting corpus . because we have , like , meetings that have a reason . andand thoseand this sounds like it 's more of an experimental setup . it 's scenario - based , it 'sit 's human - computer interface <inbreath> it 's really pretty different . it 's just that it 's , you know , different directory , it 's called something different , it 's and just simply in the file you mark somewhere that this is this type of interaction , rather than another type of interaction . well , i don i would n't call reading digits `` meetings `` . well , butbut , <mouth> i put it under the same directory tree . i mean , i do n't care what directory tree you have it under .", "summary": "decisions: after discussing the human-computer interaction smartkom data , the group decide that different types of data can be included in the meeting corpus , but that it should be structured into different directories according to data type ."}
{"dialogue": "well , but you can have it nw archive toyou can have , <inbreath> uh , a non - backed - up disk nw archived ,", "summary": "decisions: some of the data storage problems can be overcome by backing up using the nw archive ."}
{"dialogue": "and iand i think a crucial part of that is the idea ofof not wanting to do it until right before the next level zero back - up so that there wo n't be huge number ofof added ,", "summary": "decisions: however , file reorganisation will be left until just before zero-level back up ."}
{"dialogue": "um , or we could try some automated methods . and mymy tendency right now is , well , if ibm comes back with this meeting and the transcript is good , just let them do it . yeah , i mean , i guess theso the difference ifif , um , if the ibm stuff works out , the difference in the job would be that they p primarily would be checking through things that were already done by someone else ? we could let ibm transcribe it .", "summary": "decisions: the group decide to use ibm transcription of the digits , in addition to automatic methods ."}
{"dialogue": "yeah , i mean , i guess theso the difference ifif , um , if the ibm stuff works out , the difference in the job would be that they p primarily would be checking through things that were already done by someone else ?", "summary": "decisions: if ibm methods work , transcribers will check and comment these ."}
{"dialogue": "but maybe , uhmaybe we 'll just put that off for now , given that", "summary": "decisions: discussion of demos for the july meeting has been postponed: the individuals concerned will meet independently ."}
{"dialogue": "we 're aboutwe 're about halfhalfway through our disk right now . so , once everything gets converted over to the disks we 're supposed to be using we 'll be probably , uh , seventy - five percent . i 'm much more concerned about the backed - up . what about putting the stuff on , like , c - cd - rom or dvd or something ? i mean , when i say two or three years what i 'm saying is that i have had disks which are gone in a year . but , uhiiyou do n't want to per p have your only copy on a media that fails . soso how about putting them on that plus , like on aonon dat or some other medium that is n't risky ? icsi already has a perfectly good tape system and it 's more reliable . so for archiving , we 'll just use tape . but even without that , the back - up system is becoming saturated . butbut this back - up system is smart enough to figure out that something has n't changed and does n't need to bebacked - up again . well , but you can have it nw archive toyou can have , <inbreath> uh , a non - backed - up disk nw archived ,", "summary": "problems: disk space is an issue for the group , especially in terms of back-up , which is 75 % full: dvds or cds are unreliable and can not be used , and although tape is reliable , this creates access issues ."}
{"dialogue": "n i 'm successfully , uh , increasing the error rate . so , i mean i 'm just playing with , um , the number of gaussians that we use in thethe recognizer , and well , you have to sa you have totell people that you 'reyou 're doingyou 're trying the tandem features . a and i 'm still tinkering with the plp features . that wasthat was before i tried it on the females . we had reached the point where , um , on the male portion of thedevelopment set , the , umor one of the development sets , i should say <inbreath> the , umthe male error rate with , uh , icsi plp features was pretty much identical with , uh , sri features . um , and the test data is callhome and switchboard . oh , and plus thethe vocal tractlength normalization didn'tactually made things worse . so something 's really seriously wrong . sobut you see , now , betweenbetween the males and the females , there 's certainly a much bigger difference in the scaling range , than there is , say , just within the males . d so the one thing that i then tried was to put in the low - pass filter , which we have in the so , mostmost hub - five systems actually band - limit theuh , at about , uh , thirty - seven hundred , um , hertz . although , you know , normally , i mean , the channel goes to fourfour thousand . umand it did n't hurt on the males either . oh , and suddenly , also the v the vocal tract length normalization only in the test se on the test data . maybe between one and two percent , um , for the females . we 're looking at the discrepancy between the sri system and the sri system when trained with icsi features . or maybeor maybe you 're doing one too many . no , but with baum - welch , there should n't be an over - fitting issue , really .", "summary": "problems: experimentation with the sri recognition have shown greater error when using tandem features , with vocal tract normalisation also making results worse ."}
{"dialogue": "that wasthat was before i tried it on the females . we had reached the point where , um , on the male portion of thedevelopment set , the , umor one of the development sets , i should say <inbreath> the , umthe male error rate with , uh , icsi plp features was pretty much identical with , uh , sri features . sobut you see , now , betweenbetween the males and the females , there 's certainly a much bigger difference in the scaling range , than there is , say , just within the males . d so the one thing that i then tried was to put in the low - pass filter , which we have in the umand it did n't hurt on the males either . oh , and suddenly , also the v the vocal tract length normalization only in the test se on the test data . maybe between one and two percent , um , for the females . we 're looking at the discrepancy between the sri system and the sri system when trained with icsi features . or maybeor maybe you 're doing one too many . no , but with baum - welch , there should n't be an over - fitting issue , really .", "summary": "problems: in particular more error is found with the female group which is 1-2 % worse than the males ."}
{"dialogue": "none", "summary": "abstract: this meeting of the berkley meeting recorder group charts the progress of their project and covers ongoing issues as well as some new ones ."}
{"dialogue": "darpa demos ,", "summary": "abstract: the most pressing issue concerns the demos which the group are preparing for the darpa meeting next month ."}
{"dialogue": "but it does mean you need to be running a web server . and so itit 's pretty big and complex . uh and it would be difficult to port to windows uh the other option is dan did the tcl - tk thisl gui front - end for broadcast news and so i 've written some tools to convert everything into the right for file formats . and the command line version of the indexing and the querying is now working . so another idea i w t had just now actually for the demo was whether it might be of interest to sh to show some of the prosody uh <mouth> work that don 's been doing .", "summary": "abstract: here they discuss the querying and indexing tool which is progressing well albeit with a few front-end issues , and also the transcriber tool ."}
{"dialogue": "um i hired several more transcribers , they 're making great progress . uh i 've been uh finishing up the uh double checking .", "summary": "abstract: transcription is progressing well , with new people hired , and double checking almost complete ."}
{"dialogue": "we 're sort of doing things in parallel , especially for the information retrieval stuff .", "summary": "abstract: work is also going on in parallel with ibm ."}
{"dialogue": "um i spoke with dave johnson about putting all the meeting recorder stuff on non - backed - up disk to save the overhead of backup and uh , so the only issue here is the timing between getting more disks and uh recording meetings . so i guess the idea is that we would be reserving the non - backed - up space for things that took less than twenty - four hours to recreate or something like that , things that are recreatable easily and alsoyeah , basically things that are recreatable .", "summary": "abstract: additionally , the group have progressed further with data storage issues , with backing-up their data now regarded as a priority , and more disk space required ."}
{"dialogue": "so i 've been doing a bunch of xml tools yeah and then the other thing also that thilo noticed is , on the microphone , i mean this is why i wan na use a g a tool to do it rather than the plain text thethe one that shows up here , that will flash yellow if the mike is n't connected .", "summary": "abstract: tools for accessing key file information have been developed which should ensure all meeting information is present ."}
{"dialogue": "good . crosspads ? who basically said `` if you 're not using them , could you return them ? `` wewe used them a couple times , wewe get somebody to buy into the idea of doing this as part of the task . uh part of the reasoni think part of the reason that adam was so interested in uh the speechcorder sort of f idea from the beginning is he said from the beginning he hated taking notes well if you wanted to do that maybe the right architecture for it is to get a pda with a wireless card . andand that way you can synchronize very easily with thethethe meeting i mean for whatwhat you 've been describing buttons would be even more convenient than anything else , maybe we could do like a student project , you know , maybe someone who wants to do this as their main like s project for something would be cool . i mean if we had them out and sitting on the table people might use them a little more", "summary": "abstract: the collection of crosspad note-taking data will be pursued in future meetings ."}
{"dialogue": "i know that uh that thilo you were , um , bringing the channeltrans interface onto the windows machine ? yeah it 'sitbasically it 's done , and then at the same time i 'll probably rewire the room as per jane 's suggestion w uhwe ordered uh more wireless , so that uh the first n channels are wireless , eh are the m the close - talking and the next n are far - field . i mean there 'sthere 's all this stuff going on uh between uh andreas andandand dave and chuck and others with various kinds of runs uh umrecognition runs , trying to figure things out about the features but it 'sit 's all sort of in process ,", "summary": "abstract: finally , other progress made includes getting the channeltrans interface working , ordering more wireless microphones , and analysing recognition runs ."}
{"dialogue": "s so when we here were having this demo meeting , what we 're sort of coming up with is that we wan na have all these pieces together , to first order , by the end of the month next month . uhthat 'llthat 'll give usthat 'll give us a week or so to uhto port things over to my laptop and make sure that works ,", "summary": "decisions: darpa demo illustrating prosody of meeting events will be completed by the end of the ( next ) month , so as to allow a week or so for transferring data across to laptops ."}
{"dialogue": "um i spoke with dave johnson about putting all the meeting recorder stuff on non - backed - up disk to save the overhead of backup but he thought it was a bad idea . in fact what he said is doing the manual one , doing uh nw archive to copy itis a good idea and we should do that and have it backed up . he w he 's a firm believer inin lots of different modalities of backup . this data can not be recovered . and if then a mistake is made and we lose the archive we should have the backup . if it 's stationary it 's not going to go through the increment it 's not gon na burden things in the incremental backups . justjust the monthly full . and we 're far enough away from saturation on full backups that it 's w probably ok . and uh , so the only issue here is the timing between getting more disks and uh recording meetings . so i guess the idea is that we would be reserving the non - backed - up space for things that took less than twenty - four hours to recreate or something like that , things that are recreatable easily and alsoyeah , basically things that are recreatable .", "summary": "decisions: after consulting others , the group decide that not backing up their meeting data is a bad idea , since this can not be recovered ."}
{"dialogue": "in fact what he said is doing the manual one , doing uh nw archive to copy itis a good idea and we should do that and have it backed up . he w he 's a firm believer inin lots of different modalities of backup . this data can not be recovered . and if then a mistake is made and we lose the archive we should have the backup . if it 's stationary it 's not going to go through the increment it 's not gon na burden things in the incremental backups . justjust the monthly full . and we 're far enough away from saturation on full backups that it 's w probably ok . and uh , so the only issue here is the timing between getting more disks and uh recording meetings . so i guess the idea is that we would be reserving the non - backed - up space for things that took less than twenty - four hours to recreate or something like that , things that are recreatable easily and alsoyeah , basically things that are recreatable .", "summary": "decisions: therefore , meeting recorder data will be backed up , and also stored manually using the nw archive ."}
{"dialogue": "so i guess the idea is that we would be reserving the non - backed - up space for things that took less than twenty - four hours to recreate or something like that , things that are recreatable easily and alsoyeah , basically things that are recreatable . and uh , so the only issue here is the timing between getting more disks and uh recording meetings .", "summary": "decisions: more disk space will be purchased , however for now , data which is easily re-creatable will not be backed up ."}
{"dialogue": "uh part of the reasoni think part of the reason that adam was so interested in uh the speechcorder sort of f idea from the beginning is he said from the beginning he hated taking notes butuh by ii would suggest you return one . because wewe you know , wewe have n't used it at all . one would probably be fine . maybe we could do like a student project , you know , maybe someone who wants to do this as their main like s project for something would be cool . i mean if we had them out and sitting on the table people might use them a little more", "summary": "decisions: after evaluating the use of the crosspads , the group decide to return one , and also keep one which will be left out in meetings to encourage its use ."}
{"dialogue": "wewe get somebody to buy into the idea of doing this as part of the task . well if you wanted to do that maybe the right architecture for it is to get a pda with a wireless card . andand that way you can synchronize very easily with thethethe meeting i mean for whatwhat you 've been describing buttons would be even more convenient than anything else , maybe we could do like a student project , you know , maybe someone who wants to do this as their main like s project for something would be cool . i mean if we had them out and sitting on the table people might use them a little more", "summary": "decisions: use of pdas and buttons for note-taking will be investigated , along with using the data for a student research project ."}
{"dialogue": "i mean you hav sorta have to . yeah , so we might wan na do it simultaneous .", "summary": "decisions: because of time constraints , the group decide to do simultaneous digits ."}
{"dialogue": "but my intention is to do a prettier user interface based either but it does mean you need to be running a web server . and so itit 's pretty big and complex . uh and it would be difficult to port to windows uh the other option is dan did the tcl - tk thisl gui front - end for broadcast news", "summary": "problems: improving the thisl front-end user interface may be difficult if it is to run on windows as a web server tcl-tk may need to be used instead ."}
{"dialogue": "so yet again we should probably meet to talk about transcription formats in xml", "summary": "problems: more information on xml transcription formats is required for the creation of the tools ."}
{"dialogue": "oh , quick question on that . isdo we have the < clears throat > the seat information ? the seat information is on the key files for the ones which but i just had n't ever been putting it in the key files . i never knew we were supposed to put it in the key file . i mean this is why i wan na use a g a tool to do it rather than the plain text because with the plain text it 's very easy to skip those things . yeah and then the other thing also that thilo noticed is , on the microphone , on channel zero it says hand - held mike or crown mike , you actually have to say which one . and then uh also in a couple of places instead of filling the participants under `` participants `` they were filled in under `` description `` . thethe one that shows up here , that will flash yellow if the mike is n't connected .", "summary": "problems: information for key files , such as microphone type , seating , and participant information , is not being properly recorded , and in some cases the microphones are n't working properly ."}
{"dialogue": "i mean this is why i wan na use a g a tool to do it rather than the plain text because with the plain text it 's very easy to skip those things . yeah and then the other thing also that thilo noticed is , on the microphone , thethe one that shows up here , that will flash yellow if the mike is n't connected .", "summary": "problems: however this should be rectified by the use of appropriate xml tools ."}
{"dialogue": "wewe used them a couple times , and i haveuh so mymy feeling on it is that i think in principle it 's a really nice idea , and you have the time tags which makes it better tha than just taking ra raw notes . on the other hand , ithe down side for me was that i think the pen is really noisy . so that you canyou have a record of whatever it is you 've written . so i if you take notes it 's a great little device . and one of the reasons that it was brought up originally was because uh we were interested inin higher - level things , not just the , you know , microphone stuff but also summarization and so forth so that it 's synchronized with the time on that and then you have to download to an application , and then you have to figure out what the data formats are and convert it over if you wan na do anything with this information . and you do n't wan na take notes well , what if you 're sitting there and you just wan na make an x", "summary": "problems: the crosspads have not been used to their full potential , which is because of a number of problems regarding their use:"}
{"dialogue": "so that it 's synchronized with the time on that and then you have to download to an application , and then you have to figure out what the data formats are and convert it over if you wan na do anything with this information .", "summary": "problems: first , they need to be synchronised with the time of the meeting recording , and secondly , they use a non standard data format which needs converting ."}
{"dialogue": "and you do n't wan na take notes well , what if you 're sitting there and you just wan na make an x", "summary": "problems: additionally , some people tend not to make notes in meetings ."}
{"dialogue": "so , i think this is gon na be a pretty short meeting because i have four agenda items ,", "summary": "abstract: this is a relatively short meeting of the meeting recorder group , with only a few agenda items ."}
{"dialogue": "three of them were requested by jane who is not gon na be at the meeting today . umwell first of all with ibm i got a note from brian yesterday saying that they finally made the tape for the thing that we sent them aweek or week and a half ago and hopefully next week we 'll have the transcription back from that . so we 're doing some in parallel .", "summary": "abstract: transcription was discussed briefly because jane was not present , however this appears to be progressing well in parallel with ibm ."}
{"dialogue": "so i 've been trying to keep a web page uh up to date f showing what the current status is of the trans of all the things we 've collected that 's the thing that i sent out just to foo people saying can you update these pages so jane also wanted to talk about participant approval , but i do n't really think there 's much to talk about . i 'm gon na send out to the participants , uh , with links to web pages which contain the transcripts and allow them tosuggest edits . so but it 's just transcripts , not thenot the audio ? nope , they 'll have access to the audio also . because the transcripts might not be right . so , um the audio that they 're gon na have access to , will that be the uncompressed version ? or will you have scripts that like uncompress the various pieces and yeah , it 'sit 's probably going to have to be the uncompressed versions because , uh , uh , it takes too long to do random access decompression .", "summary": "abstract: web pages have been set up to show transcription status and to allow participants to approve transcripts ."}
{"dialogue": "um , darpa demo status , not much to say . the back - end stuff is working out fine . and , also um , i was just showing andreas , i got um an x waves kind of display , and i do n't know how much more we can do with it with like the prosodic stuff where we have like stylized pitches and signals and the transcripts on the bottom", "summary": "abstract: darpa demos are progressing well with the back-end indexed to allow front-end filtering , and a potential demo ideas investigated which would use x waves ."}
{"dialogue": "i 've been putting together uh transcriber things for windows butbut it would be cool if the transcriber interface had like another window for theyou know , maybe above the waveform where it would show some arbitrary valued function that isthat is you know time synchron ti ti time synchronous with the wavform . and see the pitch contours also . just record the audio clip and show an image and i think that 's and , < clear throat > the more live , the better , but uh , given the crunch of time , we may have to retreat from it to some extent . so i thinkfor a lot of reasons , i think it would be very nice to have this transcriber interface be able to show some other interesting signal along with it", "summary": "abstract: transcriber is now working for windows , however live pitch contours may not work in the time available ."}
{"dialogue": "and the last i item on the agenda is disk issues yet again . we 'rewe 're only about thirty percent on the second disk . but we are like ninety five percent , ninety eight percent on the scratch disks for the expanded meetings .", "summary": "abstract: backed-up disk space is now fine , however temporary space is running out fast ."}
{"dialogue": "uh , you know dave johnson is gone for , like , ten days , i mean it 's just a question of figuring out where they should be and hanging them , so this is a question that 's pretty hard to solve without talking to dave , but at any rate i think that there 's athere 's a longer term thing and there 's immediate need", "summary": "abstract: interim measures are discussed while sysadmin are away ."}
{"dialogue": "um yot i tested the uhthe sort of final version of the plp configuration um on development test data forfor this year 's hub - five test set . and the recognition performance was exactly , and i mean exactly up to theyou know , the first decimal , same as with the uh mel cepstra front - end . theythey werethe males i think were slightly better and the females were slightly worse but nothing really . and then the really nice thing was that ifif we combine the two systems we get a one and a half percent improvement .", "summary": "abstract: improvement has been made in the final version of the plp , which shows better female performance , and combined with mel ceptra offers 1.5 % improvement ."}
{"dialogue": "and then we had some results ondigits , uh , with um and the reason is basically there 's a whole bunch of read speech data in the hub - five training set .", "summary": "abstract: digit performance also improved thanks to training using scripted speech data ."}
{"dialogue": "and then i th guess chuck and i had some discussions about how to proceed with the tandem uh system", "summary": "abstract: progress has also been made in sri alignment for tandem system ."}
{"dialogue": "so something that we wan na do next meeting isis uh to put together um , a kind of reasonable list for ourselves of what is it , um , that we 've done . i mean just sort of bulletize i mean o e do do i cani can dream up text butthis is basically gon na lead to the annual report . so just a week from tomorrow ? umuhone thingi meanwe <inbreath> < clear throat > in past meetings we had um also a you know variousvariously talked about the um work that w uh was happening sort of on theon the recognition side well , it 's thatit 's just gon na be ver very boring for people who are not you know , sort of really interested in the details of the recognition system . well , ok , so how manyhow many people here would not be interested in uhin a meeting about recognition ? liz and jane probably . why do n't we alternate this meeting every other week ? but i do i don'ti mean a lot of times lately it seems like we do n't really have enough for a full meeting on meeting recorder . and then if we find , you know we 're just not getting enough done , there 's all these topics not coming up , then we can expand into another meeting . uh . so uh . um . let 's chat about it with liz and janewhen we get a chance , see what they think and", "summary": "abstract: the group note that the annual report needs to be worked on for next week , and it is also suggested to hold recognition meetings separately , however these issues will be discussed in more detail at the next meeting ."}
{"dialogue": "because ii need to ask jane whether it 'sit would be ok for herum , s some of her people to transcribe uh some of the initial data we got from the smartkom data collection , which is these short like five or seven minute sessions . but to get going we would like some of the data transcribed right away so we can get started . and so um i wanted to ask jane ifif uh , you know , maybe one of their transcribers couldcould do i mean since these are very short , that should really be uh ,", "summary": "decisions: jane will be contacted to see whether transcribers could work on a small amount of smartkom data , in order to get the project moving ."}
{"dialogue": "i 'll send it out to the list telling people to look at it .", "summary": "decisions: details of the transcription status web page will be sent to the group ."}
{"dialogue": "so jane also wanted to talk about participant approval , but i do n't really think there 's much to talk about . i 'm gon na send out to the participants , uh , with links to web pages which contain the transcripts and allow them tosuggest edits . so but it 's just transcripts , not thenot the audio ? nope , they 'll have access to the audio also . because the transcripts might not be right . so , um the audio that they 're gon na have access to , will that be the uncompressed version ? or will you have scripts that like uncompress the various pieces and yeah , it 'sit 's probably going to have to be the uncompressed versions because , uh , uh , it takes too long to do random access decompression . yeah , i was just wondering because we 're uh running out of the un - backed - up disk space on", "summary": "decisions: participants will be contacted to approve transcripts or suggest edits , however this depends upon decisions regarding disk space and ( un ) compression of audio files ."}
{"dialogue": "uh , you know dave johnson is gone for , like , ten days , i mean it 's just a question of figuring out where they should be and hanging them , so this is a question that 's pretty hard to solve without talking to dave , but at any rate i think that there 's athere 's a longer term thing and there 's immediate need", "summary": "decisions: there are disk space problems regarding scratch space , although the group decide that a solution about adding extra drives can not be resolved without talking to sysadmin ."}
{"dialogue": "i have umi have an eighteen gig drive hanging off of my computer . i mean it 's just a question of figuring out where they should be and hanging them , so this is a question that 's pretty hard to solve without talking to dave , but at any rate i think that there 's athere 's a longer term thing and there 's immediate need", "summary": "decisions: until they can be contacted , the group will use the hard drives on each other 's machines ."}
{"dialogue": "butbut it would be cool if the transcriber interface had like another window for theyou know , maybe above the waveform where it would show some arbitrary valued function that isthat is you know time synchron ti ti time synchronous with the wavform . and see the pitch contours also . just record the audio clip and show an image and i think that 's and , < clear throat > the more live , the better , but uh , given the crunch of time , we may have to retreat from it to some extent . so i thinkfor a lot of reasons , i think it would be very nice to have this transcriber interface be able to show some other interesting signal along with it", "summary": "decisions: displaying pitch contours live in transcriber would be desirable for the demo , however , if the group run out of time , the group note that they could generate this statically using powerpoint ."}
{"dialogue": "umuhone thingi meanwe <inbreath> < clear throat > in past meetings we had um also a you know variousvariously talked about the um work that w uh was happening sort of on theon the recognition side well , it 's thatit 's just gon na be ver very boring for people who are not you know , sort of really interested in the details of the recognition system . well , ok , so how manyhow many people here would not be interested in uhin a meeting about recognition ? liz and jane probably . why do n't we alternate this meeting every other week ? but i do i don'ti mean a lot of times lately it seems like we do n't really have enough for a full meeting on meeting recorder . and then if we find , you know we 're just not getting enough done , there 's all these topics not coming up , then we can expand into another meeting . uh . so uh . um . let 's chat about it with liz and janewhen we get a chance , see what they think and", "summary": "decisions: the group decide that it may be more beneficial to have separate meetings to discuss recognition , since jane and liz are less likely to be interested in this ."}
{"dialogue": "uh . so uh . um . let 's chat about it with liz and janewhen we get a chance , see what they think and", "summary": "decisions: they will discuss this with them before going ahead ."}
{"dialogue": "but we are like ninety five percent , ninety eight percent on the scratch disks for the expanded meetings . and , my original intention was like we would just delete them as we needed more space , but unfortunately we 're in the position where we have to deal with all the meeting dataall at once , in a lot of different ways . youwe need about a gig per meeting . i have umi have an eighteen gig drive hanging off of my computer . but at any rate i think that there 's athere 's a longer term thing and there 's immediate need", "summary": "problems: scratch disk space used to store the uncompressed meetings when they are being processed is getting short - the group are using 98 % ."}
{"dialogue": "well , maybe it should get another rack . uh , you know dave johnson is gone for , like , ten days , i have umi have an eighteen gig drive hanging off of my computer . i mean it 's just a question of figuring out where they should be and hanging them , well i sent that message out to , i guess , you and dave asking forif we could get some disk . the sysadmins would prefer to have one external drive per machine . so they do n't want to stack up external drives . so this is a question that 's pretty hard to solve without talking to dave , i think part of the reason why dave ca n't get thethe new machines up is because he does n't have room in the machine room right now . but at any rate i think that there 's athere 's a longer term thing and there 's immediate need", "summary": "problems: various options are suggested about adding extra drives , externally to their machines , or to the server , but these can not be resolved until after the relevant sysadmin person returns from a break in 10 days time ."}
{"dialogue": "uhthe back - end is uh , going more slowly as i s i think i said before just cuz i 'm not much of a tcl - tk programmer .", "summary": "problems: time is getting tight for some of the demo development , especially a lack of tcl-tk skills slowing up back-end progress ."}
{"dialogue": "butbut it would be cool if the transcriber interface had like another window for theyou know , maybe above the waveform where it would show some arbitrary valued function that isthat is you know time synchron ti ti time synchronous with the wavform . and see the pitch contours also . just record the audio clip and show an image and i think that 's and , < clear throat > the more live , the better , but uh , given the crunch of time , we may have to retreat from it to some extent . so i thinkfor a lot of reasons , i think it would be very nice to have this transcriber interface be able to show some other interesting signal along with it", "summary": "problems: additionally , time constraints may impinge upon the `` live-ness '' of the transcriber pitch contour demo ."}
{"dialogue": "so something that we wan na do next meeting isis uh to put together um , a kind of reasonable list for ourselves of what is it , um , that we 've done . i mean just sort of bulletize i mean o e do do i cani can dream up text butthis is basically gon na lead to the annual report . so just a week from tomorrow ?", "summary": "problems: annual report is due next week , so this will need to be discussed at the next meeting ."}
{"dialogue": "so i did n't send out agenda items because until five minutes ago we only had one agenda item and now we have two . and if you disagree with it , why do n't you read it and give me comments on it ?", "summary": "abstract: although the meeting recorder group only list two agenda items , this meeting explores transcription , and in particular , consent forms in depth , and at times results in heated debate ."}
{"dialogue": "so , uh , as most of you should know , i did send out the consent form thingies and we had decided that they havethey only needed to sign once . no . at some point y you go around and get people to sign something ? this is in the summer period and presumably people may be out of town . but we can make the assumption , ca n't we ? that , um , they will be receiving email , uh , most of the month . itwell , itwell , you 're right . sometimes somebody will beaway that 'sit 's , you know , just a certain risk to take . cuz i because if we wan na be able to give it to people july fifteenth , if somebody 's gon na come back and say `` ok , i do n't want this and this and this used `` , uh , clearly we need some time to respond to that .", "summary": "abstract: with regard to obtaining consent , the group discuss the extent to which they need to attempt to contact people , which methods are most appropriate , and how much responsibility rests on participants being available and checking their e-mail regularly ."}
{"dialogue": "but i thought it might be good to remind people two weeks prior to that cuz i because if we wan na be able to give it to people july fifteenth , if somebody 's gon na come back and say `` ok , i do n't want this and this and this used `` , uh , clearly we need some time to respond to that . maybeuh , do we have mailing addresses for these people ? al - altogether we 've got twenty people . these people are people who read their email almost all the time . ii really do n't see that it 's a problem . ii think that it 's a common courtesy to ask themuh , to expect for them to , uh , be able to have @ @ us try to contact them , u just in case they had n't gotten their email . i think they 'd appreciate it . and if there 's half the people , say , who do n't respondat all by , you know , some period of time , <breath> we can just make a list of these people and i 'll hand it to administrative staff or whatever , and they 'll just call them up and say , you know , `` have you isis this ok ? and would you please mailyou know , mail adam that it is , if i if it , you know , is or not . `` the other thing that there 's a psychological effect thatat least for most people , that if they 've responded to your email saying `` yes , i will do it `` or `` yes , i got your email `` , they 're more likely to actually do itlaterthan to just ignore it . so what are we gon na do when we run into someone that we ca n't get in touch with ? i do n't think , uhthey 're so recent , these visitors . ii mean , ii w i 'll be able toif you have any trouble finding them , i really think i could find them . well , the way icsi goes , people , uh , who , uh , were here ten years ago still have acc <laugh> have forwards to other accounts and so on . that if they give us contact information and that contact information is n't accurate thatwe fulfilled our burden . and itithis discussion has made me think it might be nice to have a follow - up email within the next couple of days saying `` by the way , you know , we wan na hear back from you by x date", "summary": "abstract: the group suggest sending reminder e-mails , although since many participants are local they can be contacted by other means if necessary ."}
{"dialogue": "we heard anything from ibm ? so we got the transcript back from that one meeting . everything seemed fine . adamhad a script that willput everything back together and there waswell , there was one small problem but it was a simple thing to fix . yeah . now we have n't actually had anyone go through that meeting , to see whether the transcript is correct yeah . it 's gon na have to go through our regular process . i mean , the one thing i noticed is it did miss a lot of backchannels . do you suppose that was because they were n't caught by the pre - segmenter ? yeah . they 'rethey 're not in the segmented . it 's not that theibm people did n't do it .", "summary": "abstract: transcriptions are back from ibm , and the group discuss the checking of these , particularly since the pre-segmenter has interfered with back-channel data ."}
{"dialogue": "the german ones will be ready for next week . nsa . um @ @ so , this is from one of the nsa meetings no , no . these arethese are our local transcriptions of the nsa meetings . sometimes some speakers will insert foreign language terms . and i 'm hoping that when the checked versions are run through the recognizer that you 'll see s substantial improvements in performance yeah , but i beti bet they 're acoustically challenging parts anyway , though . no , actually no . oh , so it 's just jargon . i mean this iscuz , you know you do n't realize in daily life how much you have top - down influences in what you 're hearing . and it 's jar it 's jargon coupled with a foreign accent . but we don'ti mean , our language model right now does n't know about these words anyhow .", "summary": "abstract: checking of the nsa meetings has revealed that this non-native english meeting data contains transcription inaccuracies due to the use of foreign language terms and technical vocabulary ."}
{"dialogue": "disk space , that for every meeting any meeting which has any bleeps in it we need yet another copy of . well <inbreath> iyou know , i think at a certain point , that copy that has the deletions will become the master copy . so ii do n't wanti really would rather make a copy of it , rather than bleep it out are you del are you bleeping it by adding ? we 've been , uh , contacted by university of washington now , of course , to , um we sent them the transcripts that correspond to thosesix meetings and they 're downloading the audio files . uh , the only one was don wanted to , uh , talk about disk space yet again . we 've just ordered a hundred gigabytes . uh , and there 's also an annual report . now , so theyso darpa just said do an annual report . i mean , thethe next thing on our agenda is to go back and look at the , um <mouth> the automatic alignments iii learned from thilo what data we can use as a benchmark to see how well we 're doing on automatic alignments of the background speech or , of the foreground speech with background speech . and then , uh , i guess , the new data that don will start to process you know , before we were working with these segments that were all synchronous we got our abstract accepted for this conference , isca workshop , in , um , uh , new jersey . but we 're hoping to have a paper for that as well , which should be an interesting but , i mean , the good news is that that will have sort of the european experts in prosody sort of a different crowd , and i think we 're the only people working on prosody in meetings so far , uh , it 's isca workshop on prosody in speech recognition and understanding , or something like that y you going to , uh , eurospeech ? i do n't have a paper but i 'd kinda like to go ,", "summary": "abstract: additional topics covered more briefly in this meeting are disk space , the darpa annual report , progress with the demo , conference submissions and attendance , and requests from the university of washington for data ."}
{"dialogue": "so , just to repeat the thing bef that we said last week , it was there 's this suggestion of alternating weeks on <inbreath> more , uh , automatic speech recognition related or not ? wellwe have n't really started ,", "summary": "decisions: the group discuss whether this meeting will relate to either meeting recorder or speech recognition issues ."}
{"dialogue": "so , just to repeat the thing bef that we said last week , it was there 's this suggestion of alternating weeks on <inbreath> more , uh , automatic speech recognition related or not ? wellwe have n't really started , but i figure also if they 're short agenda items , we could also do a little bit of each . so next week we 'll do automatic transcription status , plus anything that 's real timely .", "summary": "decisions: they decide that covering such topics over alternate weeks will commence at the next meeting , although other topics will be discussed if time allows ."}
{"dialogue": "and then maybe it 'd be good to set an explicit deadline , something likea weekbefore that , uh , j july fifteenth date , or two weeks before .", "summary": "decisions: the group decide that it would be good to set a date for having the non-native network services group data , and one or two weeks before the 15th of july is suggested ."}
{"dialogue": "and we had decided that they havethey only needed to sign once . no . at some point y you go around and get people to sign something ? so . <inbreath> a and , then , you know , say very clearly that if they don'tif we do n't hear from them , you know , as morgan suggested , by a certain time or after a certain <inbreath> period after we contact them <inbreath> that is implicitly giving their agreement . well , they 've already signed a form . and the s and the form was approved by human subjects , i i i em email is enough . i mean , i 'm not a lawyer , but i 've been through these things a f things f like this a few times with lawyers now so ii <inbreath> i i 'm pretty comfortable with that .", "summary": "decisions: with regard to contacting participants to request consent , the group decide that no signature is required , and an e-mail would be enough ."}
{"dialogue": "so if we get to a boundary case like that then maybe i will call the attorney about it .", "summary": "decisions: however for `` boundary cases '' legal advice would be sought ."}
{"dialogue": "so i guess if you 're in both these types of meetings , you 'd have a lot . i mean , it also depends on how many like , if we releasethis time it 's a fairly small number of meetings , well , what my s expectation is , is that we 'll send out one of these emailsevery time a meeting has been checked and is ready .", "summary": "decisions: as soon as the next set of data is ready for checking , participants should be contacted , so that this process is on-going ."}
{"dialogue": "but i thought it might be good to remind people two weeks prior to that cuz i because if we wan na be able to give it to people july fifteenth , if somebody 's gon na come back and say `` ok , i do n't want this and this and this used `` , uh , clearly we need some time to respond to that . the other thing that there 's a psychological effect thatat least for most people , that if they 've responded to your email saying `` yes , i will do it `` or `` yes , i got your email `` , they 're more likely to actually do itlaterthan to just ignore it . you know , an official ok from somebodyis better than no answer , even if they responded that they got your email . and itithis discussion has made me think it might be nice to have a follow - up email within the next couple of days saying `` by the way , you know , we wan na hear back from you by x date", "summary": "decisions: when the deadline for giving consent is approaching , a reminder e-mail should be sent out ."}
{"dialogue": "al - altogether we 've got twenty people . these people are people who read their email almost all the time . ii really do n't see that it 's a problem . ii think that it 's a common courtesy to ask themuh , to expect for them to , uh , be able to have @ @ us try to contact them , u just in case they had n't gotten their email . i think they 'd appreciate it . and if there 's half the people , say , who do n't respondat all by , you know , some period of time , <breath> we can just make a list of these people and i 'll hand it to administrative staff or whatever , and they 'll just call them up and say , you know , `` have you isis this ok ? and would you please mailyou know , mail adam that it is , if i if it , you know , is or not . `` the other thing that there 's a psychological effect thatat least for most people , that if they 've responded to your email saying `` yes , i will do it `` or `` yes , i got your email `` , they 're more likely to actually do itlaterthan to just ignore it . you know , an official ok from somebodyis better than no answer , even if they responded that they got your email . so what are we gon na do when we run into someone that we ca n't get in touch with ? i do n't think , uhthey 're so recent , these visitors . ii mean , ii w i 'll be able toif you have any trouble finding them , i really think i could find them . well , the way icsi goes , people , uh , who , uh , were here ten years ago still have acc <laugh> have forwards to other accounts and so on . that if they give us contact information and that contact information is n't accurate thatwe fulfilled our burden .", "summary": "decisions: in cases where no consent response is given , participants could be chased up since many are local ."}
{"dialogue": "disk space , that for every meeting any meeting which has any bleeps in it we need yet another copy of . well <inbreath> iyou know , i think at a certain point , that copy that has the deletions will become the master copy . so ii do n't wanti really would rather make a copy of it , rather than bleep it out are you del are you bleeping it by adding ? and then overlapping . so , it 'sit 's exactly a censor bleep . so what i really think is `` bleep ``", "summary": "decisions: original uncensored copies of meetings will be kept , with all of the old signal deleted and replaced with new when censoring ."}
{"dialogue": "that 'sit 's , you know , just a certain risk to take . you know , specify exactly uh , what , you know , howhow they will be contacted w you know , when the whole thing starts , when they sign the <mouth> the agreement <inbreath> that so . <inbreath> a and , then , you know , say very clearly that if they don'tif we do n't hear from them , you know , as morgan suggested , by a certain time or after a certain <inbreath> period after we contact them <inbreath> that is implicitly giving their agreement . because if youif you , uh , do this <inbreath> and youthen there 's a dispute later and , uh , some <inbreath> you know , someone who understands these matters concludes that they did n't have , uh , you know , enough opportunity to actually <inbreath> exercise theirtheir right because although they signed this , they do n't know by which date to expect your email . and sosomeone whose machine is down or whatever because people do n't read their email , or they 'll read and say `` i do n't care about that , i 'm not gon na delete anything `` and they don just wo n't reply to it . maybeuh , do we have mailing addresses for these people ? so if we get to a boundary case like that then maybe i will call the attorney about it .", "summary": "problems: gaining consent from participants for the use of the meeting data is raising a number of issues for the group , some of which may have legal implications ."}
{"dialogue": "this is in the summer period and presumably people may be out of town . but we can make the assumption , ca n't we ? that , um , they will be receiving email , uh , most of the month . itwell , itwell , you 're right . sometimes somebody will beaway that 'sit 's , you know , just a certain risk to take . you know , specify exactly uh , what , you know , howhow they will be contacted w you know , when the whole thing starts , when they sign the <mouth> the agreement <inbreath> that so . <inbreath> a and , then , you know , say very clearly that if they don'tif we do n't hear from them , you know , as morgan suggested , by a certain time or after a certain <inbreath> period after we contact them <inbreath> that is implicitly giving their agreement . because although they signed this , they do n't know by which date to expect your email . and sosomeone whose machine is down or whatever because people do n't read their email , or they 'll read and say `` i do n't care about that , i 'm not gon na delete anything `` and they don just wo n't reply to it . maybeuh , do we have mailing addresses for these people ?", "summary": "problems: firstly a relatively arbitrary deadline of 15 july has been set , and since this is during the summer break , the group debate whether enough action has been made to contact participants ."}
{"dialogue": "you know , specify exactly uh , what , you know , howhow they will be contacted w you know , when the whole thing starts , when they sign the <mouth> the agreement <inbreath> that so . <inbreath> a and , then , you know , say very clearly that if they don'tif we do n't hear from them , you know , as morgan suggested , by a certain time or after a certain <inbreath> period after we contact them <inbreath> that is implicitly giving their agreement . well , they 've already signed a form . and the s and the form was approved by human subjects , because people do n't read their email , or they 'll read and say `` i do n't care about that , i 'm not gon na delete anything `` and they don just wo n't reply to it . maybeuh , do we have mailing addresses for these people ? i do n't think , uhthey 're so recent , these visitors . so what are we gon na do when we run into someone that we ca n't get in touch with ? ii mean , ii w i 'll be able toif you have any trouble finding them , i really think i could find them . that if they give us contact information and that contact information is n't accurate thatwe fulfilled our burden . so if we get to a boundary case like that then maybe i will call the attorney about it .", "summary": "problems: if people do n't respond in time , the group discuss what facility should there be for later amendments , and whether a meeting can be used if they do n't respond at all ."}
{"dialogue": "the german ones will be ready for next week . nsa . um @ @ so , this is from one of the nsa meetings no , no . these arethese are our local transcriptions of the nsa meetings . sometimes some speakers will insert foreign language terms . and i 'm hoping that when the checked versions are run through the recognizer that you 'll see s substantial improvements in performance yeah , but i beti bet they 're acoustically challenging parts anyway , though . no , actually no . oh , so it 's just jargon . i mean this iscuz , you know you do n't realize in daily life how much you have top - down influences in what you 're hearing . and it 's jar it 's jargon coupled with a foreign accent . but we don'ti mean , our language model right now does n't know about these words anyhow .", "summary": "problems: checking of the nsa meeting transcripts has shown that although acoustically fine , some errors have shown up , especially relating to foreign language terms and jargon or technical terminology ."}
{"dialogue": "disk space , that for every meeting any meeting which has any bleeps in it we need yet another copy of . you have spare headsets ? because i , uh , i could use one on my workstation , yeah , i stilli still need to get a pair , too . no . justjustjustjust buy them . uh , the only one was don wanted to , uh , talk about disk space yet again . the disk space was short . we 've just ordered a hundred gigabytes . yeah . i mean , i guess the thing is is , all i need is to hang it off , like , <inbreath> the person who 's coming in , sonali 's , computer . if you 'reif you 're desperate , i have some space on my drive . yeah . i think i can find something if i 'm desperate", "summary": "problems: additionally , the discussions reveal that there is a shortage of headphones amongst group members , and also that disk space is in short supply , especially if original copies of edited transcripts are retained ."}
{"dialogue": "um , we should talk a little bit about the plans for the uhthe field trip next week . and uhmostly uh first though about the logistics for it . then maybe later on in the meeting we should talk about what we actually you know , might accomplish . uh , in andkind of go aroundsee what people have been doingtalk about that , a r progress report . um , essentially . umand then uhanother topic i had was that uhuhuhdave here had uh said uh `` give me something to do . `` and so maybe we can discuss that a little bit . uh , and uh , then uh , talk a little bit aboutabout disks and resourceresource issues thatthat 's starting to get worked out . did youhappen to find out anything about the ogi multilingual database ? one they call the multi - language database , and another one is a twenty - two language , something like that . but it 's also telephone speech . well , actually , for the moment if we w do not want to use these phone databases , wewe already have uhenglish , spanish and french uh , with microphone speech . uh , actually , these three databases are um generic databases . so w f forfor uh italian , which is close to spanish , french and , i i uh , ti - digits we have both uh , digitstraining data and alsomore general training data . well , we also have this broadcast news that we were talking about taking off the disk , which is <laugh> is microphone data forfor english . yeah , perhapsyeah , there is also timit .", "summary": "abstract: the main topics discussed were arrangements and objectives of an upcoming field trip to visit research partners ogi ; a number of members reported their progress to date ; if there are any tasks that one member can help others with ; an overall description of the cube project , a multi-lingual speech recognition system for use by the cellular phone industry , along with consideration of some of the issues therein , specifically disk and resource issues ."}
{"dialogue": "well , the inputs are one dimension of the cube , so , a a actuallymaybenow you 've got me sort of intrigued . can you describe whatwhat 's on the cube ? basically , thethe cube will have three dimensions . the first dimension is thethe features that we 're going to use . and the second dimension , um , is the training corpus . and that 's the training on the discriminant neural net . and then , there 's the testing corpus .", "summary": "abstract: essentially the cube consists of three dimension: input features ; training corpus ; and test corpus ."}
{"dialogue": "well , the inputs are one dimension of the cube , which , um , we 've talked about it being , uh , plp , um , m f c cs , um , j - jrasta , jrasta - lda um , for the training corpuscorpus , um , we have , um , thethe ddigits < tapping sounds , writing on whiteboard > from the various languages . so that 's , uh , three hundred and forty - three , uh , <laugh> different systems that are going to be developed . something like seven things in each , uheach column . so it seems like there 'sthere 's some peculiarities of the , uhof each of these dimensions that are getting sorted out . and then , um , ifif you work on getting the , uh , assembly lines together , and then thethe pieces sort of get ready to go into the assembly line what 'swhat 's great about this is it sets it up in a very systematic way , so that , uh , once theseall of these , you know , mundane but real problems get sorted out , we can just start turning the crank and , uh , the thing is that once you get a better handle on how much you can realistically do , uh , um , <mouth> concurrently on different machines , different sperts , and so forth , uh , and you see how long it takes on what machine and so forth , you can stand back from it and say , `` ok , if we look at all these combinations we 're talking about , and combinations of combinations , and so forth , `` you 'll probably find you ca n't do it all . so then at that point , uh , we should sort out which ones do we throw away . which of the combinations acrossyou know , what are the most likely ones ,", "summary": "abstract: most important concerns are which combinations of features to use , and what combinations of languages and broad / specific corpora to use for the training"}
{"dialogue": "um , we should talk a little bit about the plans for the uhthe field trip next week . and uhmostly uh first though about the logistics for it . those of you who are not , you know , used to this area , it can be very tricky to get to the airport atat uh , you know , six thirty . ok , so ifif everybody can get here at six .", "summary": "decisions: the group will meet at the building at 6am to go to the airport for their field trip together ."}
{"dialogue": "dandavid , um , put a new , um , drive onto abbott , that 's an x disk , um , i 've been going through and copying data that is , you know , some kind of corpus stuff usually , thatthat we 've got on a cd - rom or something , onto that new disk to free up spaceon other disks . we have n't deleted them off of the slash - dc disk that they 're on right now in abbott , uh , but wei would like to go throughsit down with you about some of these other ones and see if we can move them onto , um , this new disk also . yeah , ok .", "summary": "decisions: speaker me018 needs to discuss files that can be moved with speaker mn007 ."}
{"dialogue": "imaybe we 're already there , or almost there , is goals for thefor next week 's meeting . uh . i i i it seems to me that we wan na do is flush out what you put on the board here . so w we can say what we 're doing , and , um , also , if you havesorted out , um , this information about how long i roughly how long it takes to do on what and , you know , what we canhow many of these trainings , uh , uh , and testings and so forth that we can realistically do , uh , then one of the big goals of going there next week would be toto actually settle on which of them we 're gon na do . and , uh , when we come back we can charge in and do it .", "summary": "decisions: for the ogi meeting they need to take a clear description of the cube project , and an estimate of how long the entire process should take ."}
{"dialogue": "and , um , also , if you havesorted out , um , this information about how long i roughly how long it takes to do on what and , you know , what we canhow many of these trainings , uh , uh , and testings and so forth that we can realistically do , uh , then one of the big goals of going there next week would be toto actually settle on which of them we 're gon na do . and , uh , when we come back we can charge in and do it .", "summary": "decisions: at the meeting they should discuss what they will ultimately put through the system ."}
{"dialogue": "and uhand the otherthethe last topic i had here was , um , uh d dave 's fine offer toto , uh , do something <laugh> on this . i mean he 's doing <laugh> he 's working on other things , but toto do something on this project . so the question is , `` wherewhere could we , uh , uh , most use dave 's help ? `` and , um , <mouth> trying to have a closer look at theperhaps the , um , <mouth> speech , uh , noise detection or , uh , voiced - sound - unvoiced - sound detection let 's fall back to that . but i think the first responsibility is sort of to figure out if there 's somethingthat , uh , anan additional what an additional clever person could help with when we 're really in a crunch for time . but if we could think of somesome piece that 'sthat 's well defined , that he could help with , he 's expressing a will willingness to do that . sowh thatso thethe other suggestion that just came up was , well what about having himwork on the , uh , multilingual super f supersetkind of thing . uh , coming up with that and then , you know , training ittraining a net on that , say , um , fromfrom , uhfrom timit or something .", "summary": "decisions: people are to consider what me034 could do on the project to speed things up , though creating the phoneme superset is a possibility ."}
{"dialogue": "stephane , where you 're doing your computations . it 's nutmeg and mustard , i think , well , you 're theyou 're the disk czar now . well , i 'll check on that .", "summary": "decisions: speaker me018 is to look into the machines that mn007 has been running data on to find out what they are ."}
{"dialogue": "an another question occurred to me isis what were you folks planning to do about normalization ? well , we were thinking about using this systematically for all the experiments . but we think perhaps we can use thethe best , uh , um , uh , normalization scheme as ogi is using , so , with parameters that they use there , i mean it 's i i wewe seem to have enough dimensions as it is .", "summary": "decisions: rather than consider level of normalization as a further dimension to the project , whatever ogi finds the best will be used systematically ."}
{"dialogue": "clearly , therethere 's no way we can even begin to do an any significant amount here unless we use multiple machines . i mean there 's plenty of machines here and they 're n they 're often not inin a greatgreat deal of use . y you did ayou did it on a spert board . yes . again , we do have a bunch of spert boards . you could set up , uh , you know , ten different jobs , or something , to run on spertdifferent spert boards oror we 're not going to get through any significant number of these . so , with very limited time , we actually have really quite aquite a bit of computational resource available if you , you know , get a look across the institute and how little things are being used . and , uh , the thing is that once you get a better handle on how much you can realistically do , uh , um , <mouth> concurrently on different machines , different sperts , and so forth , uh , and you see how long it takes on what machine and so forth , you can stand back from it and say , `` ok , if we look at all these combinations we 're talking about , and combinations of combinations , and so forth , `` you 'll probably find you ca n't do it all .", "summary": "decisions: need to use multiple machines and spert boards to run processes on because they take so long ."}
{"dialogue": "soso , maybe we could look at articulatory type stuff , because that 'sthat 's the other route to go . to really mark articulatory features , you really wan na look at the acoustics andand see where everything is , and we 're not gon na do that . uh , the second class way of doing it isto look at the , uh , phones that are labeled and translate them into acousticuh , uharticulatory , uh , uh , features . so it wo n't really be right . is that we couldwe could , uh , just translateinstead of translating to a superset , just translate to articulatory features , some set of articulatory features and train with that . we could do an interesting cheating experiment with that too . so i was thinking , you knowit made me think about this , that ifit 'd be an interesting experiment just to see , you know , if you did get all of those right .", "summary": "decisions: they will consider looking at articulatory features rather than straight phonemes , though it would n't be perfect ."}
{"dialogue": "so it seems like there 'sthere 's some peculiarities of the , uhof each of these dimensions that are getting sorted out . and then , um , ifif you work on getting the , uh , assembly lines together , and then thethe pieces sort of get ready to go into the assembly line what 'swhat 's great about this is it sets it up in a very systematic way , so that , uh , once theseall of these , you know , mundane but real problems get sorted out , we can just start turning the crank and , uh , the thing is that once you get a better handle on how much you can realistically do , uh , um , <mouth> concurrently on different machines , different sperts , and so forth , uh , and you see how long it takes on what machine and so forth , you can stand back from it and say , `` ok , if we look at all these combinations we 're talking about , and combinations of combinations , and so forth , `` you 'll probably find you ca n't do it all . so then at that point , uh , we should sort out which ones do we throw away . which of the combinations acrossyou know , what are the most likely ones ,", "summary": "problems: it is not clear what combinations of dimensions , which features , should be run in the cube project ."}
{"dialogue": "cuz you do n't know who 's gon na call , clearly , therethere 's no way we can even begin to do an any significant amount here unless we use multiple machines . and then , um , ifif you work on getting the , uh , assembly lines together , and then thethe pieces sort of get ready to go into the assembly line what 'swhat 's great about this is it sets it up in a very systematic way , so that , uh , once theseall of these , you know , mundane but real problems get sorted out , we can just start turning the crank and , uh , the thing is that once you get a better handle on how much you can realistically do , uh , um , <mouth> concurrently on different machines , different sperts , and so forth , uh , and you see how long it takes on what machine and so forth , you can stand back from it and say , `` ok , if we look at all these combinations we 're talking about , and combinations of combinations , and so forth , `` you 'll probably find you ca n't do it all .", "summary": "problems: it is important to know because the processes are going to be large and processor and memory hungry ."}
{"dialogue": "uhhow do you know what language it is ? somebody picks up the phone . so thi this is their image . so the phone does n't know what awhatwhat your language is . but the particular image that the cellular industry has right now is that it 's distributed speech recognition , where the , uh , uh , probabilistic part , andand s semantics and so forth are all on the servers , and you compute features of theuh , on the phone . we mightmight or might not agree that that 's the way it will be in ten years , but that 'sthat 'sthat 's what they 're asking for . soso i think thatth th it is an important issue whether it works cross - language .", "summary": "problems: to bear in mind is the fact that the cellular industry has an image of speech recognition in that 's what they are after ."}
{"dialogue": "were the digits , um , hand - labeled for phones ? those werethose were automatically derived byby dan using , um , embeddedembedded training and alignment . ii think you 're doing this test because you want to determine whether or not , uh , having s general speech performs as well as having specificspeech . so i was just wondering if the fact that timityou 're using the hand - labeled stuff from timit might beconfuse the results that you get . it would be another interesting scientific question to ask , `` is it because it 's a broad source or because it was , you know , carefully ? ``", "summary": "problems: must be careful if using a broad training source that is carefully hand marked , because it would be unclear which is the reason for improvement ."}
{"dialogue": "is n't there like a limiton the computation load , or d latency , or something like that for aurora task ? so , there 's not really a limit . what it is is that there 'sthere 's , uhit 's just penalty , thatthat if you 're using , uh , a megabyte , then they 'll say that 's very nice , but , of course , it will never go on a cheap cell phone .", "summary": "problems: memory is of concern , because final product needs to run potentially one cheaper cell phones , which have limited memory capacity ."}
{"dialogue": "has ogi done anything about this issue ? do they havedo they have any kind of superset that they already have ? well , theytheythey 're going actually thethe other way , defining uh , phoneme clusters , apparently . so they just throw the speech from all different languages together , then cluster it into sixty or fifty or whatever clusters ? and e i perhaps u using broad phoneme classes , it 'sit 's ok for um , uh classifying the digits , but as soon as you will have more words , well , words can differ with only a single phoneme , andwhich could be the same , uh , class . so you 're saying that there may not be enough information coming out of the net to help you discriminate the words ? yeah , fact , most confusions are within the phonephone classes , right ?", "summary": "problems: ogi does n't have a phoneme superset ready prepared , for they are working with clusters , which may be good enough for digits , but not for discriminating words ."}
{"dialogue": "so where are we onon uh <laugh> our runs ? uh so . uhwesoas i was already said , wewe mainly focused on uh four kind of features . the plp , the plp with jrasta , the msg , and the mfcc from the baseline aurora . uh , and we focused for thethe test part on the english and the italian . um . we 've trained uh several neural networks on soon the ti - digits englishand on the italian data and also on the broad uhenglish uh french and uh spanish databases . and um , actually what wewe @ @ observed is that if the network is trained on the task data it works pretty well .", "summary": "abstract: the meeting was dominated by a discussion of the first results coming in ."}
{"dialogue": "the first testing iswith task data the second test is trained on a single language um with broad database , but the same language as the t task data . but for italian we choose spanish whichwe assume is close to italian . the third test is by using , um the three language database that 's including the w thethe the one that it 's yeah . it 's the broaddata . and the fourth test is uhexcluding from these three languages the languagethat isthe task language .", "summary": "abstract: there have been four types of test , in which the training data varies , and a variety of input features have been tried ."}
{"dialogue": "but actually we did n't train network onuh both types of data we only did either tasktask data oruh broaddata . and then when we jump to the multilingual data it 's uh it become worse uh . the error rate increase u ofofof ten percent , relative . exampleuh when we go from ti - digits training totimit traininguh we loseuh around ten percent , twenty toto thirty percent further . ok , but i think thatgiven the pressure of time we probably want to drawbecause of thatespecially , we wan na draw some conclusions from this , and make some strong decisions for what we 're gon na do testing on before next week .", "summary": "abstract: the process and results were explained to the group , the implications of the results discussed , and plans for moving forward were made ."}
{"dialogue": "so they 'rethey 're doingthethe vad i guess they mean voice activity detection so again , it 's the silence so um their uhthe results look pretty good . so um i think that it 'sit 's nice to do that in this because in fact , it 's gon na give a better word error result and therefore will help within an evaluation . um . uh , as you know , part of the problem with evaluation right now is that theword models are pretty bad and nobody wantshashas approached improving them . so um the question we 're gon na wan na gothrough next week when hynek shows up i guess is given that we 've been we 're uh looking atuh , by then i guess , combinations of features and multi - band uh , and we 've been looking atcross - language , crosstaskissues . but they 've been looking at uhat these issues . at the on - line normalization and the uhvoice activity detection . and i guess when he comes here we 're gon na have to start deciding aboutum what do we choosefrom what we 've looked atto um blend withsome group of things in what they 've looked at and once we choose that , how do we split up theeffort ?", "summary": "abstract: there was also discussion of some of the work being conducted by research partners ogi , including how the two groups should best work together ."}
{"dialogue": "we have thelittle tiny ibm machine <laugh> that might someday grow up to be a bigibm machine . it 's got s slots for eight , i think we only got two so far , yeah , i mean you can check with uhdave johnson . andsomebody could doyou know , uh , check outuh the multi - threadinglibraries . i mean , i guess the prudent thing to do would be for somebody to do the work onon getting our code runningon that machine with two processorseven though there are n't five or eight .", "summary": "abstract: the group also briefly touched upon resource issues ."}
{"dialogue": "uh so , act actually we have discussed uh @ @ um , these andandwe were thinking perhaps thatuhthe way we use the tandem is not if we trained the networks on theona language and a t or a specifictask , um , what we ask isto the networkis to put the bound the decision boundaries somewhere in the space . and uhmmm and ask the network to put one , at one side of theforfor a particular phoneme at one side of the boundarydecision boundary andso there is kind of reduction of the information there that 's not correct because if we change taskand if the phonemes are not in the same context in the new task , obviously thedecision boundaries are notshould not be at the sameplace . but the way the feature givesthethe way the network gives the features is that it reduce completely theit removes completely the informationa lot of information from thethe featuresby uhuhplacing the decision boundaries atoptimal places forone kind ofdata the way wewe do it now is that we have a neural network andbasicallythe net network is trained almost to give binary decisions .", "summary": "decisions: speaker mn007 would like to investigate increasing the context of the phonemes ."}
{"dialogue": "and once youthe other thing is that once you representstart representing more and more contextit isuhmuch moreum specificto a particular task in language . for instance you may have some kinds of contexts that will never occurin one language and will occur frequently in the other , the issue of getting enough trainingfor a particular kind of context becomes harder . we already actually do n't have a huge amount of training data the way wewe do it now is that we have a neural network andbasicallythe net network is trained almost to give binary decisions . but it would still be even more of a binary decision . that would be eveneven more distinct of a binary decision . i mean wewe could disagree about it at length but thethe real thing is if you 're interested in it you 'll probably try it andandwe 'll see .", "summary": "decisions: speaker mn013 does agree with mn007s assessment of the outcome , and points out the lack of data , but acknowledges that if mn007 is interested he will go ahead with it ."}
{"dialogue": "so i think hynek will be here monday . so i think , you know , we need tochoose thechoose the experiments carefully , so we can get uh keykey questions answereduh before then so um the question we 're gon na wan na gothrough next week when hynek shows up i guess is given that we 've been", "summary": "decisions: must be careful in choosing which experiments to perform as an important visitor is coming soon ."}
{"dialogue": "so um the question we 're gon na wan na gothrough next week when hynek shows up i guess is given that we 've been we 're uh looking atuh , by then i guess , combinations of features and multi - band uh , and we 've been looking atcross - language , crosstaskissues . but they 've been looking at uhat these issues . at the on - line normalization and the uhvoice activity detection . and i guess when he comes here we 're gon na have to start deciding aboutum what do we choosefrom what we 've looked atto um blend withsome group of things in what they 've looked at and once we choose that , how do we split up theeffort ?", "summary": "decisions: also need to come up with a stronger plan for collaboration with ogi ."}
{"dialogue": "and i guess when he comes here we 're gon na have to start deciding aboutum what do we choosefrom what we 've looked atto um blend withsome group of things in what they 've looked at and once we choose that , how do we split up theeffort ?", "summary": "decisions: must decide what from both can be brought together , and how then can the work be divided ."}
{"dialogue": "yeah , i mean you can check with uhdave johnson . andsomebody could doyou know , uh , check outuh the multi - threadinglibraries . but . notice how i said somebody and <laugh> turned my head your direction . that 's one thing you do n't get in these recordings . and then we 'd be set for when we did have five or eight , to have it really be useful . there 'sthere 'sthere 's gon na be debugging hassles i mean , i guess the prudent thing to do would be for somebody to do the work onon getting our code runningon that machine with two processorseven though there are n't five or eight .", "summary": "decisions: someone ( implied with gestures in the meeting ) must speak to a person outside the group with regards to using a multiprocessor linux machine that is available ."}
{"dialogue": "andsomebody could doyou know , uh , check outuh the multi - threadinglibraries . i mean , i guess the prudent thing to do would be for somebody to do the work onon getting our code runningon that machine with two processorseven though there are n't five or eight . there 'sthere 'sthere 's gon na be debugging hassles and then we 'd be set for when we did have five or eight , to have it really be useful .", "summary": "decisions: debugging the process while there are just two processors bodes well for when they have 8 to multi-thread ."}
{"dialogue": "so , um i could try to getum the train the neural network trainings or the htk stuff running under linux , and to start with i 'mwondering which one i should pick first . uh , probably the neural net", "summary": "decisions: speaker mn026 volunteers to get some training running under linux ."}
{"dialogue": "uh , probably the neural net", "summary": "decisions: it is agreed that he should start with the neural net training , then work on htk ."}
{"dialogue": "butactually there is something important , is thatum we made a lot of assumption concerning the on - line normalization and we just noticeduh recently thatuh theapproach that we were usingwas notuhleading to very good resultswhen weused the straight features to htk . sowhat we see thatisthere is that umuh the way we were doing this was not correct , when we use the networksour number are better thatuh pratibha results . andbasically , the first thing is the mmm , alpha uhvalue . um , i used point five percent , which was the default value in thein the programs here . and pratibha used five percent . i assume that this was not important becauseuh previous results fromfrom dan andshow that basicallythebothboth values g give the samesameuh results . it was true on uhti - digits but it 's not true on italian . uh , second thing is the initialization of thestuff . actually , uh what we were doing is to start the recursion from the beginning of theutterance . and using initial values that are the global mean and variancesmeasured across the whole database . and pratibha did something different is that heuh she initialed the um values of the mean and varianceby computingthis on thetwenty - five first frames of each utterance . mmm . there were other minor differences , so . uh , i changed the code uh and now we have a baseline that 's similar to the ogi baseline . well , thethethe networks are retaining with these newfeatures .", "summary": "problems: incorrect assumptions were made when considering the on-line normalization for the main task . members used different values to a previous study , and whilst it was believed not to make a difference , it does , so networks are being retrained ."}
{"dialogue": "therethere isanother difference , is that the noisethe noises are different . well , forfor the italian part i mean theuhthe umnetworks are trained with noise fromaurorati - digits , and perhaps the noise arequite different from the noisesin the speech that italian . uh <laugh> <inbreath> um now , what 's the noise conditionumof the training data the noise condition is the same so there 's not astatisticalsta a strong ststatistically differentnoise characteristic betweenuh the training and test no these are the s s s same noises , at leastat least for the firstfor the well - matched ,", "summary": "problems: currently working with noise conditions being the same in training and test data , but there is nothing which matches the noise on the italian test data ."}
{"dialogue": "none", "summary": "problems: in fact no other language matches the noise from aurora data ."}
{"dialogue": "yeah , so for the italian the results are <outbreath> uhstranger so what appears is that perhaps spanish isnot very close to italian because uh , well , when using thethe network trained only on spanish it 'sthe error rate isalmost uh twicethe baseline error rate .", "summary": "problems: spanish was being used to train for italian as it was assumed they were the most similar , but that may not be as close a match as thought ."}
{"dialogue": "so they 'rethey 're doingthethe vad i guess they mean voice activity detection so again , it 's the silence so um their uhthe results look pretty good . so um i think that it 'sit 's nice to do that in this because in fact , it 's gon na give a better word error result and therefore will help within an evaluation . um . uh , as you know , part of the problem with evaluation right now is that theword models are pretty bad and nobody wantshashas approached improving them .", "summary": "problems: ogi have an interesting approach to voice activation detection for removing blocks of silence , that shows good results , but currently the word model being used is too poor to make good use of this and no one is working on improving it ."}
{"dialogue": "so , uh , you 've got some , uh , xerox things to pass out ? ok , s so there is kind of summary of what has been done summary of experiments since , well , since last week and also since thewe 've started to runwork on this . um . so since last week we 've started to fill the column with um <mouth> uh features w with nets trained on plp with on - line normalization", "summary": "abstract: the main topic for discussion by the berkeley meeting recorder group was progress on the experiments run as part of the groups main project , a speech recogniser for the cellular industry ."}
{"dialogue": "so , uh , you 've got some , uh , xerox things to pass out ? yeah , i 'm sorry for the table , but as it grows in size , uh , it . uh , so for th the last column we use our imagination . ok , s so there is kind of summary of what has been done summary of experiments since , well , since last week and also since thewe 've started to runwork on this . um . so since last week we 've started to fill the column with um <mouth> uh features w with nets trained on plp with on - line normalization but with delta also , uhwhen we use the large training set using french , spanish , and english , you have one hundred and six without delta and eighty - nine with the delta . a and again all of these numbers are with a hundred percent being , uh , the baseline performance , and training with other languages is a little bit worse . we have a ninety - one number , so , it 's multi - english , and , yeah , and here the gap is still more important between using delta and not using delta . if y if i take the training s the large training set , it 'swe have one hundred and seventy - two , and one hundred and four when we use delta . uh . even if the contexts used is quite the same , except for the multi - english , which is always one of the best . then we started to work on a large dat database containing , uh , sentences from the french , from the spanish , from the timit , from spine , uh fromuh english digits , and from italian digits . anduh , actually we did this before knowing the result of all the data , uh , so we have to to redo the uhthe experiment training the net with , uh plp , but with delta . and first in the experiment - one ii doii use different mlp , yeah , and test across everything . so i guess the other thing is to takeyou knowif one were to take , uh , you know , a couple of the most successful of these , yeah , try all these different tests . we still have to work on finnish , um , basically , to make a decision on which mlp can be the best across the different languages . for the moment it 's the timit network , and perhaps the network trained on everything . uh , well , the next part of the document is , well , basically , a kind of summary of whateverything that has been done . so . we have seventy - nine m l ps trained on tenon ten different databases .", "summary": "abstract: this included reporting the results , and making conclusions to shape future work ."}
{"dialogue": "um , discussion with hynek , sunil and pratibha for trying to plug in their ourour networks with theirwithin their block diagram , uh , where to plug in thethe network , uh , after thethe feature , before as um a as a plugin or as a anoth another path , actually hynek would like to see , perhaps if you remember the block diagram there is , uh , temporal lda followed b by a spectral lda for each uh critical band . and he would like to replace these by a network which would , uh , make the system look like a trap . um , there are still open questions there , the future work is , well , try to connect to theto maketo plug in the system to the ogi where to put the mlp basically . so . uh , wewe wan na get their path running here , if so , we can add this other stuff . as an additional path yeah , the way we want to do it perhaps is tojust to get the vad labels and the final features . so they will send us thewell , provide us with the feature files , so weso . first thing of course we 'd wan na do there is to make sure that when we get those labels of final features is that we get the same results as them . without putting in a second path . yeah just th w i i just to make sure that wehavewe understand properly what things are , our very first thing to do is tois to double check that we get the exact same results as them on htk .", "summary": "abstract: also discussed were the details of the continued collaboration with project partner ogi ."}
{"dialogue": "so , on the msg uh problem um , i think that inin theum , in the shorttimesolution um , that is , um , trying to figure out what we can proceed forward with to make the greatest progress , i think it 's kind of in category that it 's , itit may be complicated . and uh it might beif someone 's interested in it , uh , certainly encourage anybody to look into it in the longer term , once we get out of this particular rushuh for results . but in the short term , unless you have somesome s strong idea of what 's wrong , butbut mymy guess would be that it 's something that is a simple thing that could take a while to find .", "summary": "decisions: further investigation into the lack of difference using msg features makes should not be made while they are on their current short time scale for results ."}
{"dialogue": "yeah , thatseems like a good thing to do , probably , not uh again a short - term sort of thing . the two of the main issues perhaps are still the language dependency <inbreath> and the noise dependency . and perhaps to try to reduce the language dependency , we should focus on finding some other kind of training targets . for moment you usewe use phonetic targets but we could also use articulatory targets , soft targets , and perhaps even , um use networks that does n't do classification but just regression and well , basically com com compute features and noit not , nnn , features without noise . i mean uh , transform the fea noisy features <inbreath> in other features that are not noisy .", "summary": "decisions: same goes for anything else that comes up and looks interesting , leave it for just now ."}
{"dialogue": "so i guess the other thing is to takeyou knowif one were to take , uh , you know , a couple of the most successful of these , yeah , and test across everything . yeah , try all these different tests . but one of the core quote '' open questions `` for that is um , um , if we take the uhyou know , the best ones here , maybe not just the best one , but the best few or something you want the most promising group from these other experiments . we know that there 's a mis there 's a uhaa loss in performance when the neural net is trained on conditions that are different thanthan , uh we 're gon na test on , but well , if you look over a range of these different tests um , how well do these different ways of combining the straight features with the mlp features , uh stand up over that range ? look at these different ways of combining it . and just looktake that case and then look over all the different things . how does thathow does that compare between the all the different test sets , and forand for the couple different ways that you have ofofof combining them . um . how well do they stand up , over the", "summary": "decisions: really should pick which results are looking the best at this stage , and take only them further ."}
{"dialogue": "but you have twotwo effects , the effect of changing language and the effect of training on something that 'sviterbi - aligned instead of handhand - labeled . do you think the alignments are bad ? i mean , have you looked at the alignments at all ? what the viterbi alignment 's doing ? might be interesting to look at it . yeah . butyeah . but , perhaps it 's not really thethe alignment that 's bad but thejust the ph phoneme string that 's used for the alignment the pronunciation models and so forth therethere might be errors just in theinin the ph string of phonemes . yeah , so this is not really the viterbi alignment ,", "summary": "decisions: someone should look closely at the non-timit databases , their viterbi alignments , and their phoneme strings to see is that is why timit is better ."}
{"dialogue": "so . uh , wewe wan na get their path running here , if so , we can add this other stuff . as an additional path yeah , the way we want to do it perhaps is tojust to get the vad labels and the final features . so they will send us thewell , provide us with the feature files , so weso . first thing of course we 'd wan na do there is to make sure that when we get those labels of final features is that we get the same results as them . without putting in a second path . yeah just th w i i just to make sure that wehavewe understand properly what things are , our very first thing to do is tois to double check that we get the exact same results as them on htk .", "summary": "decisions: need to get ogi 's system from them , and get it running like they do , before integrating into it ."}
{"dialogue": "so , it it 's stillit hurts youseems to hurt you a fair amount to add in this french and spanish . i wonder why well stephane was saying that they were n't hand - labeled , the french and the spanish . yeah ! as we mentioned , timit is the only that 's hand - labeled , and perhaps this is what makes the difference . yeah , the other are just viterbi - aligned . well , the timit network is still the best the fact that it 'sit 's hand - labeled . but you have twotwo effects , the effect of changing language and the effect of training on something that 'sviterbi - aligned instead of handhand - labeled . do you think the alignments are bad ? i mean , have you looked at the alignments at all ? what the viterbi alignment 's doing ? might be interesting to look at it . yeah . butyeah . but , perhaps it 's not really thethe alignment that 's bad but thejust the ph phoneme string that 's used for the alignment the pronunciation models and so forth therethere might be errors just in theinin the ph string of phonemes . yeah , so this is not really the viterbi alignment , we can , we can tell which training set gives the best result , but <mouth> we do n't know exactly why .", "summary": "problems: it is unclear if the english timit database is providing the best results because english is the best language or timit is the most accurately labelled dataset because it was hand labelled ."}
{"dialogue": "yeah , i 'm sorry for the table , but as it grows in size , uh , it . uh , so for th the last column we use our imagination . a and again all of these numbers are with a hundred percent being , uh , the baseline performance , and eighty - nine with the delta . uhwhen we use the large training set using french , spanish , and english , you have one hundred and six without delta yeah , so , it 's multi - english , we have a ninety - one number , and training with other languages is a little bit worse . if y if i take the training s the large training set , it 'swe have one hundred and seventy - two , and one hundred and four when we use delta . and this isthe results are on the other document . yeah , we ju just to be clear , the numbers here are uh recognition accuracy . yes , and the baselinethe baseline havei is eighty - two . baseline is eighty - two . yeah , eh , actually , if w we look at the table , the huge table , when you said the baseline system was uh , uh eighty - two percent , that was trained on what and tested on what ? that was , uh italian mismatched d uh , uh , digits , uh , is the testing , and the training is italian digits ? yeah . so the `` mismatch `` just refers to the noise andand , uh microphone and so forth , so , umso what that says is that in a matched condition , <sniff> we end up with a fair amount worse putting in the uh plp . now w woulddo we have a number , i suppose for the matched ii do n't mean matched , but uh use of italiantraining in italian digits for plp only ? so this isbasically this is in the table . uhso the number is fifty - two , another table . fifty - two percent . fift - sono , it 'sit 's the no , fifty - two percent of eighty - two ? ofofof uheighteen eighty . of eighteen . so it 'sit 's error rate , basically . it 's plus six . it 's er error rate ratio . oh this is accuracy ! yeah . uh , so we have nineninelet 's say ninety percent . oh , i 'm sorry , i k i keep getting confused because this is accuracy . yeah , sorry .", "summary": "problems: the results table was very large and difficult to follow ; it was unclear which of the numbers were error or accuracy rate , and straight rates or percentages of the baseline ."}
{"dialogue": "here the problem seems to be is that we do n't have a hug a really huge net with a really huge amount of training data . but we have s ffor this kind of task , i would think , sort of a modest amount . i mean , a million frames actually is n't that much . we have a modest amount ofof uh training data from a couple different conditions , and then uhinyeah , thatand the real situation is that there 's enormous variability that we anticipate in the test set in terms of language , and noise type uh , and uh , uh , channel characteristic ,", "summary": "problems: there is very limited training data , over only a few conditions ."}
{"dialogue": "and then uhinyeah , thatand the real situation is that there 's enormous variability that we anticipate in the test set in terms of language , and noise type uh , and uh , uh , channel characteristic ,", "summary": "problems: test and real data is likely to encompass much more variability ."}
{"dialogue": "none", "summary": "abstract: the icsi meeting recorder group at berkeley are approaching an important milestone on their project ."}
{"dialogue": "uh today we 're looking at a number of uh things we 're trying it 's only one small experiment to know what happened . to apply also to in include also thethe silence of the mlp we have the fifty - six form and the silence to pick up the silence and we include those . the silence plus the klt output ? no they 'rei think there is this silence in addition to the um klt outputs it is because wewewe just keep uh we do n't keep all the dimensions after the klt and we not s we are not sure if we pickwe have the silence . so we try to add the silence also in addition to thethese twenty - eight dimensions . do you e um they mentionedmade someuh when i was on the phone with sunil theythey mentioned some weighting scheme that was used to evaluate all of these numbers . um well it 's uh forty percent for ti - digit , sixty for all the speechdat - cars , um and we do n't have the ti - digits part yet ? generally what you observe with ti - digits is that the result are very close whatever thethe system . so it looks to mei guess the same given that we have to take the filt ones out of thethe running because of this delay problemso it looks to me like the ones you said i agree areare the ones to look at but i just would add thethethe second row one so if we can know whathow many words are in each and then um dave uh dave promised to get us something tomorrow which will be there as far as they 've gotten <laugh> friday and then we 'll operate with that do we fix the system uh tomorrow or do we fix the system on tuesday ? i think we fixed on tuesday , yeah . iyeah , ok except that we do have to write it up . so maybe what we do is wewewe uh as soon as we get the data from them we start the training and so forth but we start the write - up right away because as you say therethere 's only minor differences between these . i think youwe couldwe could start soon , yeah . write up something . well anyway , sounds like there 'll be a lot to do just to <laugh> work with our partners to fill out the tables <laugh> over the next uh next few days yes , so i meani think we have to actually get it done tuesday um so then next thursday we can sort of have a little aftermath but my assumption is that we basically have to be done tuesday .", "summary": "abstract: they discussed most recent results , finalized plans to continue and discussed the work required and timing needed for completion of this stage of the project ."}
{"dialogue": "and so have you put all these numbers together into a single number representing that ? uh not yet . ok so that should be pretty easy to do and that would be good then we could compare the two and say what was better .", "summary": "decisions: mn007 and fn002 need to find a way of combining result figures into one easily comparable way of judging performance ."}
{"dialogue": "soyou know how many words are in uh one of these test sets ? um it 'sit dependswellthe well matched is generally larger than the other sets see thei mean the reason i 'm asking isisis we have all these small differences and i do n't know how seriously to take them , right ? so uh i ifif you had uh just you knowto give an example , if you had uh um if you had a thousand words then uh aa tenth of a percent would just be one word , soso it would n't mean anything . um so um yeah it be kind ofi 'd kind of like to know what the sizes of these test sets were actually . well also just to know the numbers , so anyway if you could just mail out what those numbers are and thenthenthatthat be great .", "summary": "decisions: they were also asked to mail round numbers detailing the size of their test-sets , so that group members can assess the seriousness of figures such as word error rates ."}
{"dialogue": "so it looks to mei guess the same given that we have to take the filt ones out of thethe running because of this delay problemso it looks to me like the ones you said i agree areare the ones to look at but i just would add thethethe second row one so basically we willi think we 'll try toto focus on these three architectures andand perhaps i was thinking also a fourth one with justjust a single klt yeah , i mean that would be pretty low maintenance to try it .", "summary": "decisions: there are now just 4 architectures that will be carried forward for testing ."}
{"dialogue": "do we fix the system uh tomorrow or do we fix the system on tuesday ? i think we fixed on tuesday , yeah . iyeah , ok except that we do have to write it up . so maybe what we do is wewewe uh as soon as we get the data from them we start the training and so forth but we start the write - up right away because as you say therethere 's only minor differences between these . i think youwe couldwe could start soon , yeah . write up something . yes , so i meani think we have to actually get it done tuesday but my assumption is that we basically have to be done tuesday . um so then next thursday we can sort of have a little aftermath", "summary": "decisions: though the final system is not due to be fixed , until tuesday , writing it up must begin sooner ."}
{"dialogue": "yeah , andand ii wouldyou know , i wouldi 'd kind of like to see it maybe i cani can edit it a bit", "summary": "decisions: anything written must go through me013 for editing ."}
{"dialogue": "um so then next thursday we can sort of have a little aftermath andand uh maybe next meeting we can start talking a little bit about where we want to go from here uh in terms of uh the research . um you know what things uh did you think of when you were uh doing this process that uh you just did n't really have time to adequately work on", "summary": "decisions: discussion on future work once this stage is out of the way will be held at the next meeting ."}
{"dialogue": "uh so one of the ideas that you had mentioned last time was having aa second um silence detection . um yeah so it seems f for thethe well match and mismatched condition it 's uh it brings something . uh but uh actually apparently there arethere 's no room left for any silence detector at the server side because of the delay . oh we ca n't do it . no .", "summary": "problems: while using a second silence detection system it was found that while providing some improvement , it added too great a delay on the server side of the system ."}
{"dialogue": "none", "summary": "abstract: the berkley meeting recorder group discussed the most recent progress with their current project , a digit recognition system for use in cell phones ."}
{"dialogue": "so , i got , uhthese results from , uh , stephane . also , um , i think that , uhumwe might hear later today , about other results . i think s that , uh , there were some other very good results that we 're gon na wan na compare to . but , <inbreath> r our results from otherother places , you know most of the time , eveni mean even though it 's true that the overall number for danishwe did n't improve it i mean , i think that , uh , one of the things that hynek was talking about was understanding what was in the other really good proposals and trying to see if what should ultimately be proposed is some , uh , combination of things . so < nasal inbreath > um , since we have a bit farther to travel than <laugh> some of the others , <inbreath> uh , we 'll have to get done a little quicker . but , um , i mean , it 's just tracing down these bugs . i mean , just exactly this sort of thing of , you know , whywhy these features seem to be behaving differently , uh , in california than in oregon .", "summary": "abstract: this included some discussion of results , comparing various other groups ' systems , issues involving the set up , and plans for future work ."}
{"dialogue": "we have a little bit of time on that , actually . we have a day or so , whenwhenwhen do you folks leave ? sunday ? until saturday midnight , or something , we have when is the development seti mean , the , uh , uh , test set results due ? uh , probably the day after they leave , but we 'll have to <laugh> we 'll have to stop it the day beforewe leave . i think tha i think thethe meeting is on the thirteenth or something . this tuesday , and thethe , uh , results are due like the day before the meeting or something .", "summary": "decisions: results are required for an upcoming meeting , but since some group members will be away , results need to be in sooner ."}
{"dialogue": "the other thing that strikes me , just looking at these numbers is , just taking the best cases , i mean , some of these , of course , even with all of ourour wonderful processing , still are horrible kinds of numbers . but just take the best case , the well - matcheduh , german case afterer well - matched danish after we the kind of numbers we 're getting are about eight or nineuhp percenterrorper digit . this is obviously not usable , i mean , if you have ten digits for a phone numberi mean , every now and then you 'll get it right . so , in a way , that 's , you know , that 's sort of the dominant thing is that even , say on the development set stuff that we saw , the , uh , the numbers that , uh , that alcatel was getting when choosing out the best single numbers , <inbreath> it was justyou know , it was n't good enough forforaafor a real system . so , uh , we still have stuff to do . uh <laugh> uh <laugh> i mean , they 're much better than they were , you know . we 're talking about thirty to sixty percent , uh , error rate reduction . that 'sthat 's really great stuff toto do that in relatively short time . but even after that it 's still , you know , so poor thatthat , uh , no one could really use it .", "summary": "problems: although error rates have been greatly reduced , current rates are still unusable in a practical situation ."}
{"dialogue": "because , um , um , when we use the straight features , we are not able to get these nice number you know most of the time , eveni mean even though it 's true that the overall number for danishwe did n't improve it y actually , uh , um , for the danish , there 's still some kind of mystery with the icsi ogi one , i mean . uh , so , uh , that 's probably something wrong with the features that we get from ogi . uh , and sunil is working onon trying toto check everything . but , um , i mean , it 's just tracing down these bugs . i mean , just exactly this sort of thing of , you know , whywhy these features seem to be behaving differently , uh , in california than in oregon .", "summary": "problems: there is a problem replicating some results found by partner ogi , but it is unclear why ."}
{"dialogue": "so what are you doing ? uh , well , we 'vea little bit worked on trying to see , uh , what were the bugs and the problem with the latencies .", "summary": "abstract: the berkeley meeting recorder group discussed the progress of several of their members ."}
{"dialogue": "none", "summary": "abstract: the progress being made on the group 's main project , a speech recogniser for the cellular industry was reported ."}
{"dialogue": "youyou had a discussion with sunil about this though ? no . yeah , you should talk with him . uh , cuz they could be doing the same thing andor something . we justwe just have to be in contact more . i think thatthethe fact that wewe did that withhad that thing with the latencies was indicative of the fact that there was n't enough communication . but , well , when we add up everything it 'sit will be alright . so it would be around two hundred and forty what 's the allowable ? two - fifty , uh , well the people who had very low latency want it to be lowuh , very <laugh> very very narrow , uh , latency bound . unfortunately we 're the main ones with long latency , a personi do n't think a person can tell the difference between , uh , you know , a quarter of a second and a hundred milliseconds , i 'm not even sure if we can tell the difference between a quarter of a second and half a second . i mean it justit feels so quick . uh , one thing that would be nogood to find out about from this conference call is that what they were talking about , what they 're proposing doing , was having a third party , um , run a good vad , andand determine boundaries . and then given those boundaries , then have everybody do the recognition . uh , i guess they argued about that yesterday", "summary": "abstract: the group also touched upon matters that had broader implications for the work , such as the work of other groups on the same project ."}
{"dialogue": "uh , maybe we can talk about a couple other things briefly , so you 're coming up with your quals proposal , um , but i 'm , uh , looking into extending the work done by larry saul and john allen and uh mazin rahim . so , uh , y you want to talk maybe a c two or three minutes about what we 've been talking about today and other days ? we 're interested in , um , methods for far mike speech recognition , um , mainly , uh , methods that deal with the reverberationin the far mike signal .", "summary": "abstract: there were also some progress reports from group members working on other projects ."}
{"dialogue": "do you have news from the conference talk ? yesterday morning on video conference . no , nobody 's told me anything . no , that would have been a good thing to find out before this meeting , i mean , let 'slet 's assume for right now that we 're just kind of plugging on ahead , because even if they tell us that , uh , the rules are different , uh , we 're still interested in doing what we 're doing . uh , one thing that would be nogood to find out about from this conference call is that what they were talking about , what they 're proposing doing , was having a third party , um , run a good vad , andand determine boundaries . and then given those boundaries , then have everybody do the recognition . uh , i guess they argued about that yesterday i don'tdo n't know the answer but we should find out .", "summary": "decisions: no one from the group attended a recent video conference about their main project , but they need to find out what was discussed in it ."}
{"dialogue": "i mean , let 'slet 's assume for right now that we 're just kind of plugging on ahead , because even if they tell us that , uh , the rules are different , uh , we 're still interested in doing what we 're doing .", "summary": "decisions: until they do , they will continue on , assuming nothing major has been changed ."}
{"dialogue": "youyou had a discussion with sunil about this though ? no . yeah , you should talk with him . no , i mean , because thethethethe whole problem that happened before was coordination , soso you need to discuss with him what we 're doing , uh , cuz they could be doing the same thing andor something . we justwe just have to be in contact more . i think thatthethe fact that wewe did that withhad that thing with the latencies was indicative of the fact that there was n't enough communication .", "summary": "decisions: need to discuss any new investigation with partners to make sure work is not repeated ."}
{"dialogue": "do you have news from the conference talk ? yesterday morning on video conference . no , nobody 's told me anything . no , that would have been a good thing to find out before this meeting , i mean , let 'slet 's assume for right now that we 're just kind of plugging on ahead , because even if they tell us that , uh , the rules are different , uh , we 're still interested in doing what we 're doing .", "summary": "problems: there was a recent video conference meeting discussing the cellular project , but no one from the group attended and so do not know if it has any implications for their work , if any important decisions were made ."}
{"dialogue": "so it would be around two hundred and forty justjust barely in there . what 's the allowable ? two - fifty , unless they changed the rules . which there isthere 's some discussion of . what were they thinking of changing it to ? uh , well the people who had very low latency want it to be lowuh , very <laugh> very very narrow , uh , latency bound . and the people who have longer latency do n't . unfortunately we 're the main ones with long latency , and basically the best proposal had something like thirty or forty milliseconds of latency .", "summary": "problems: this includes decisions on the desired latency for the system , since the group is currently at the limit ."}
{"dialogue": "also we were thinking toto , uh , apply the eh , spectral subtraction from ericsson and toto change the contextual klt for lda . well , there 's a lot of different ways of computing the noise spectrum . it seems like this kind of thing could add to the latency . i mean , depending on where the window was that you used to calculatethe signal - to - noise ratio . not necessarily . cuz if you do n't look into the future , actually , it 's a mmmif - if you want to have a good estimation on non - stationary noise you have to look in thein the future . but what doeswhatwhatwhat does alcatel do ? andand france telecom . they just look in the past . i guess it works because the noise are , uh pret uh , almost stationary yeah , y i mean , you 're talking about non - stationary noise but i think that spectral subtraction is rarelyisis not gon na work really well forfor non - stationary noise , but it 's hard to that 's hard to do .", "summary": "problems: spectral subtraction , which the group is currently investigating as a method of dealing with noise , may add to the delay time , but also it is hard to do with non-linear noise ."}
{"dialogue": "let 'slet 's , i mean , i think that asas we said before that one of the things that we 're imagining is that uh therethere will be <inbreath> uh in the system we end up with there 'll be something to explicitly uh uh do something about noise so um i suggest actually now wewewe sorta move on andand hear what 'swhat 'swhat 's happening inin other areas um . <inbreath> and uh i do n't know if we 've talked lately about thethe plans you 're developing that we talked about this morning uh what 's next ?", "summary": "abstract: the berkeley meeting recorder group met to discuss their recent progress ."}
{"dialogue": "so y you guys had aa meeting with uhwith hynek which i unfortunately had to miss . so everybody knows what happened except me . well . uh first we discussed about some of the points that i was addressing in the mail i sent last week . about the um , wellthe downsampling problem . uh and about the f the length of the filters so basically that wasthat 's <inbreath> all we discussed about .", "summary": "abstract: this included a recap of a meeting with one of the members of their research partner ogi ."}
{"dialogue": "let 'slet 's , i mean , i think that asas we said before that one of the things that we 're imagining is that uh therethere will be <inbreath> uh in the system we end up with there 'll be something to explicitly uh uh do something about noise so um i suggest actually now wewewe sorta move on andand hear what 'swhat 'swhat 's happening inin other areas like <inbreath> what 'swhat 's happening with your <inbreath> investigations <inbreath> about echos and so on . well um i have n't started writing the test yet , i 'm meeting with adam today um and he 's going t show me the scripts he has for um <mouth> <inbreath> running recognition on mee meeting recorder digits . i have n't asked hynek forfor thefor his code yet . cuz i looked at uh avendano 's thesis and <mouth> i do n't really understand what he 's doing yet um . <inbreath> and uh i do n't know if we 've talked lately about thethe plans you 're developing that we talked about this morning um . so continuing to um extend so i mean , there 's these issues of what are thewhat are the variables that you use and do you combine them using the soft `` and - or `` or you do something , you know , more complicated uh what 's next ? i could say a little bit about w stuff i 've been playing with .", "summary": "abstract: there were progress reports from group members working on echo cancellation , acoustic feature detection , and htk optimization , along with discussion of many issues arising from this topics ."}
{"dialogue": "i mean i g i guess the key thing for me isis figuring out how to better coordinate between the two sides uh i was talking with hynek about it later and thethesort of had the sense sort of thatthat neither group of people wanted toto bother the other group too much . but i think that <inbreath> you were sort of waiting for them to <inbreath> tell you that they had something for you and <inbreath> they were sort of waiting for you andandand uh we ended up with this thing where theythey were filling up all of the possible latency themselves , but there was also problemperhaps a problem of communication . now we will try to just talk more .", "summary": "decisions: the group must try to communicate more with research partners ogi ."}
{"dialogue": "i mean i g i guess the key thing for me isis figuring out how to better coordinate between the two sides uh i was talking with hynek about it later and thethesort of had the sense sort of thatthat neither group of people wanted toto bother the other group too much . but i think that <inbreath> you were sort of waiting for them to <inbreath> tell you that they had something for you and <inbreath> they were sort of waiting for you andandand uh we ended up with this thing where theythey were filling up all of the possible latency themselves , but there was also problemperhaps a problem of communication . now we will try to just talk more .", "summary": "problems: there have been communication problems between the group and their partners at ogi , with both groups waiting for the other to be the one to make contact ."}
{"dialogue": "i mean i g i guess the key thing for me isis figuring out how to better coordinate between the two sides uh i was talking with hynek about it later but i think that <inbreath> you were sort of waiting for them to <inbreath> tell you that they had something for you and thethesort of had the sense sort of thatthat neither group of people wanted toto bother the other group too much . and <inbreath> they were sort of waiting for you andandand uh we ended up with this thing where theythey were filling up all of the possible latency themselves , but there was also problemperhaps a problem of communication . now we will try to just talk more .", "summary": "problems: this has made it hard to coordinate efforts ."}
{"dialogue": "so the onlythe only uh hesitation i had about it since , i mean i have n't see the data is it sounds like it 'sit 's <inbreath> continuous variables and a bunch of them . i do n't know how complicated it is to go from there what you really want are these binarylabels , and just a few of them . and maybe there 's a trivial mapping if you wan na do it and it 's e but it iii worry a little bit that this is a research project in itself , whereas um <inbreath> if you did something instead thatlike um having some manual annotation by <inbreath> uh you know , linguistics students , this wouldthere 'd be a limited s set of things that you could do a as per our discussions withwith john before course then , that 's the other question is do you want binary variables .", "summary": "problems: when looking at articulatory features , the data will be continuous , so may need a mapping to binary decisions ."}
{"dialogue": "so the onlythe only uh hesitation i had about it since , i mean i have n't see the data is it sounds like it 'sit 's <inbreath> continuous variables and a bunch of them . i do n't know how complicated it is to go from there what you really want are these binarylabels , and just a few of them . and maybe there 's a trivial mapping if you wan na do it and it 's e but it iii worry a little bit that this is a research project in itself , whereas um <inbreath> if you did something instead thatlike um having some manual annotation by <inbreath> uh you know , linguistics students , this wouldthere 'd be a limited s set of things that you could do a as per our discussions withwith john before course then , that 's the other question is do you want binary variables .", "summary": "problems: this could end up as a huge research project by itself , so must be careful ."}
{"dialogue": "ok , so uh <breath> had some interesting mail from uh dan ellis . uh . since the last meeting we 'vewe 've tried to put together um <mouth> the clean low - pass um downsampling , upsampling , i mean ,", "summary": "abstract: the meeting recorder group at berkeley met to discuss recent progress ."}
{"dialogue": "uh . since the last meeting we 'vewe 've tried to put together um <mouth> the clean low - pass um downsampling , upsampling , i mean , uh the new filter that 's replacing the lda filters ,", "summary": "abstract: of greatest interest was the progress on improving the latency and performance of their recogniser ."}
{"dialogue": "ok , so uh <breath> had some interesting mail from uh dan ellis . where this came up was that uh i was showing off these wave forms that we have on the web andand uh <breath> i just sort of had n't noticed this , but thatthe major , major component in the wavein the second wave form in that pair of wave forms is actually the air conditioner . can i ask a , i meana sort of top - level question , which is <breath> um `` ifif most of what the ogi folk are working with is trying to <breath> integrate this otherother uh spectral subtraction , <breath> why are we worrying about it ? ``", "summary": "abstract: there was also concern over overlap of work with partners ogi , and a lack of a good example of room reverberation for demonstrations ."}
{"dialogue": "um the other thing that i do n't know the answer to , but when people are using feacalc here , uh whether they 're using it with the high - pass filter option or not . so when we 're doing all these things using our software there is and <breath> it 'sit 's prettyit 's not a very severe filter . does n't affect speech frequencies , so . wewewe want to go and check that in i for anything that we 're going to use the p d but if we do make use of the cheap mikes , <breath> uh we want to be sure to do thatthat filtering before we <breath> process it .", "summary": "decisions: everyone must be sure and use the high-pass filtering option on the groups software , to deal with irregularities between mics ."}
{"dialogue": "is there any further discussion about thisthis idea ofof having some sort of source code control ? well . for the moment they 're there is this eurospeech deadline , sounds like a great idea butbut i think thatthat um <breath> he 's saying people are sort of scrambling for a eurospeech deadline . but that 'll be uh , uh done in a week . so , maybe after <breath> this next one . yeah . so , i mean , ii think that you could certainly start looking atat the issue uh butbut uh <breath> i think it 's probably , on s from what stephane is saying , it 'sit 's unlikely to get sort of active participation from the two sides until after they 've but i couldtry to look into like this uh cvs over the web . that seems to be a very popular <breath> way ofpeople distributing changes andover , you know , multiple sites and things so maybe <breath> if i can figure out how do that easily and then pass the information on to everybody so that it 's <breath> you know , as easy to do as possible andand people don'tit wo n't interfere withtheir regular work , and if you 're interested in using cvs , i 've set it up here , so maybe i can ask you some questions . so . i 'll be away tomorrow and monday but i 'll be back on tuesday or wednesday .", "summary": "decisions: in order to coordinate better with ogi , some sort of source code control is required and me018 has offered to investigate , but only minimal progress can be made until after the upcoming deadline for eurospeech ."}
{"dialogue": "none", "summary": "decisions: when he returns me026 will help ."}
{"dialogue": "do you remember when the next meeting is supposed to be ? it 's uh in june . h hynek will be back in town uh the week after next , backback in the country . and startstart organizing uh <breath> more visits and connections and so forth , working towards june .", "summary": "decisions: also , in two weeks one of the ogi members will return , and meetings should be arranged with him before the next big project meeting ."}
{"dialogue": "um . yeah , the other thing is that you saw thatthat mail about uh the vadv a ds performing quite differently ? thisthere was this experiment of uh `` what if we just take the baseline ? `` and you inc incorporate the different v a and it looks like thethe french vad is actually uh bettersignificantly better . yeah but i do n't know which vad they use . it 's pratibha thatthat did this experiment . um . we should ask which vad she used . heactually , i think that he say with the good vad offrom ogi i mean it was enough better thatthat it would <mouth> uh account for a fair amount of the difference between our performance , actually . so if they have a better one , we should use it .", "summary": "decisions: ogi seem to be having some good results with voice activation detection , so the group need to find out which is the best vad and start using it ."}
{"dialogue": "ok , so uh <breath> had some interesting mail from uh dan ellis . where this came up was that uh i was showing off these wave forms that we have on the web andand uh <breath> i just sort of had n't noticed this , but thatthe major , major component in the wavein the second wave form in that pair of wave forms is actually the air conditioner . i <laugh> <breath> i have to be more careful about using that as aas a <breath> as a good illustration , uh , in fact it 's not , of uh <breath> of the effects of room reverberation . it is is n't a bad illustration of the effects of uh room noise . <breath> onon uh some mikes since i was talking about reverberation and showing this thing that was noise , it was n't a good match , so i think we 'll change ourour picture on the web , when we 're @ @ . dave , the other thing , actually , isis this business about this wave form . maybe you and i can talk a little bit at some point about <breath> coming up with a better <breath> uh demonstration of the effects of reverberation for our web page ,", "summary": "problems: the is a waveform example of room reverberation on the groups website that was used in a presentation ."}
{"dialogue": "ok , so uh <breath> had some interesting mail from uh dan ellis . where this came up was that uh i was showing off these wave forms that we have on the web andand uh <breath> i just sort of had n't noticed this , but thatthe major , major component in the wavein the second wave form in that pair of wave forms is actually the air conditioner . i <laugh> <breath> i have to be more careful about using that as aas a <breath> as a good illustration , uh , in fact it 's not , of uh <breath> of the effects of room reverberation . it is is n't a bad illustration of the effects of uh room noise . <breath> onon uh some mikes since i was talking about reverberation and showing this thing that was noise , it was n't a good match , it made a goodgood audio demonstration because when we could play that clip thethethe really <breath> obvious difference is that you can hear two voices and <breath> <laugh> in the second one and only hear but i mean you can'twhen you play it back in a room with ayou know a big room , <breath> nobody can hear that difference really .", "summary": "problems: it turns out that it is a good example of many things , but not the reverb it is supposed to contain ."}
{"dialogue": "so i think we 'll change ourour picture on the web , when we 're @ @ . um <breath> another , i was thinking of was um <breath> taking some spectral slices , and look at the spectrum or cepstrum that you get out of there , well , i mean um all the recognizers look at frames . at one point in time or uh twentyover twenty milliseconds or something , <breath> you have a spectrum or a cepstrum . maybe you and i can talk a little bit at some point about <breath> coming up with a better <breath> uh demonstration of the effects of reverberation for our web page , but i mean you can'twhen you play it back in a room with ayou know a big room , <breath> nobody can hear that difference really . but for thethe visual , just , you know , i 'd like to have uh <breath> uh , you know , the spectrogram again , the other thing that we had in there that i did n't like was that um <breath> the most obvious characteristic of the difference uh when you listen to it is that there 's a second voice , and thethethethethe uh <mouth> cuts that we have there actually do n't correspond to the full wave form . but <breath> itit 's um <breath> it 's the first six seconds or something <breath> of it and it 's in <breath> the seventh or eighth second or something where @ @ the second voice comes in . so wewe would like to actually see <breath> the voice coming in , too , i think ,", "summary": "problems: need to find a better example , maybe by just looking at a closer section of waveform ."}
{"dialogue": "it seems better when we look at the mismatched case but <mouth> i think we are likelike cheated here by theth this problem that <breath> uh in some cases when you modify slightslightly modify the initial condition you end up <breath> completely somewhere air somewhere else in thein the space , <breath> the parameters . i don'ti do n't think it means that the new system is more robust but i mean <breath> from this se seventy - eight um percent recognition rate system , <breath> i could change the transition probabilities for thethe first hmm andit will end up to eighty - nine also . by using point five instead of point six , point four <breath> as in thethe htk script . yeah i looked at um <breath> looked at the results when stephane did that and it 'sit 's really wo really happens . i mean th the only difference is you change the self - loop transition probability by a tenth of a percent and it causes ten percent difference in the word error rate . and n not tenth of a percent , one tenth , it 's just very um you know get stuck in some local minimum and this thing throws you out of it i guess . well , what 'swhat areaccording to the rules whatwhat are we supposed to do about the transition probabilities ? i think you 're not allowed to that 's supposed to be point six , for the self - loop . but changing it to point five i think is which gives you much better results , but that 's <breath> not allowed . yeah , but even if you use point five , i 'm not sure it will always give you the better results right . we only tested it on thethe medium mismatch ,", "summary": "problems: minor experimenting found that by dropping the self-loop transition in the hmms by just 0.1 % can increase performance by 10 % , but the rules of the task forbid this change ."}
{"dialogue": "yeah , actually the way the final score is computed is quite funny . it 's not a mean of word error rate . it 's not a weighted mean of word error rate , it 's a weighted mean of improvements . which means that <mouth> actually the weight on the well - matched is well i well what whatwhat happened is that if you have a small improvement or a small if on the well - matched case <breath> it will have uh huge influence on the improvement compared to the reference because the reference system isisis quite good forfor the well - ma well - matched case also . so they do improvement in terms of uh accuracy ? rather than word error rate ? no , it 's compared to the word er it 's improvement on the word error rate , so if you have uh ten percent error and you get five percent absolute uh <breath> improvement then that 's fifty percent . ok . so what you 're saying then is that if it 's something that has a small word error rate , <breath> then uh aeven a relatively small improvement on it , in absolute terms , <breath> will show up as quitequite large in this . but yeah that 'sthat 'sit 's the notion of relative improvement . that 's why i 've been saying we should be looking at word error rate uh andand notnot at <breath> at accuracies . i mean uh we probably should have standardized on that all the way through . but you 'rebut when you look at the numbers , your sense of the relative size of things is quite different .", "summary": "problems: there is some confusion over what the results produced mean , since it appears they are weighted , which biases improvements in some cases quite heavily ."}
{"dialogue": "um . what i was asking , though , is uharewhat 'swhat 's the level of communication with uh <breath> the o g i gang now , about this well , we are exchanging mail as soon as we < breath-laugh > we have significant results . for the moment , they are working on integrating <breath> the um <mouth> spectral subtraction apparently from ericsson . we are working on our side on other things like <breath> uh also trying a sup spectral subtraction but ofof our own , i mean , another <breath> spectral substraction . can i ask a , i meana sort of top - level question , which is <breath> um `` ifif most of what the ogi folk are working with is trying to <breath> integrate this otherother uh spectral subtraction , <breath> why are we worrying about it ? `` it 's just uhwell it 's another they are trying to u to use the um <mouth> the ericsson and we 're trying to use somethingsomething else . and what they did at ogi is just <breath> uh they do n't use on - line normalization , for the moment , on spectral subtraction i think as soon as they will try on - line normalization <breath> there will be a problem . so yeah , we 're working on the same thing but <breath> i think with differentdifferent system intellectually it 's interesting to work on things th uh one way or the other but i 'mi 'm just wondering if um <breath> on the list of things that there are to do , if there are things that we wo n't do because <breath> we 've got two groups doing the same thing . justjust asking . in fact if you getif you go into uha uh harmonics - related thing <breath> it 's definitely going to be different than what they 're doing should have some interesting properties in noise .", "summary": "problems: speaker me013 is worried that his groups work on spectral subtraction overlaps with that of ogi , and that it may be time better spent on other tasks ."}
{"dialogue": "um . <mouth> <breath> what are we talking about today ? uh , well , first there are perhaps these uh meeting recorder digits that we tested .", "summary": "abstract: the main purpose of the meeting of icsi 's meeting recorder group at berkeley was to discuss the recent progress of it 's members ."}
{"dialogue": "uh , well , first there are perhaps these uh meeting recorder digits that we tested . perhaps the point is that we 've been working on <breath> is , yeah , we have put the um the good vad in the system and <breath> it really makes a huge difference . yeah , and then we 've started to work with this of um voiced - unvoiced stuff . no , i w <breath> i begin to play <laugh> with matlab and to found some parameter robust for voiced - unvoiced decision . what 's up with you ? so i 've been looking at avendano 's work but it 'sit 's an approach to deal with <breath> reverberation or thatthe aspect of his work that i 'm interested in", "summary": "abstract: this includes reports on the progress of the groups main digit recogniser project , with interest on voice-activity detectors and voiced / unvoiced detection , work on acoustic feature detection , and research into dealing with reverberation ."}
{"dialogue": "uh , well , first there are perhaps these uh meeting recorder digits that we tested . theboth the uh <breath> the sri system and the oth y you doi think you read some of thethe zeros as o 's and some as zeros . is there a particular way we 're supposed to read them ? perhaps in the sheets there should be another sign for the i mean . i think people will do what they say . i mean in digit recognition we 've done before , you haveyou have two pronunciations for that value , `` o `` and `` zero `` . no , they just write andand people pronounce `` o `` or zero and you justthey just want people to read the digits as you ordinarily would", "summary": "abstract: there was also talk of comparing different recognition systems and training datasets , and a discussion of the pronunciation of the digit zero for the recording at the end of the meeting ."}
{"dialogue": "uh i 'll try to write up in my next stat status report a nice description of <breath> what he 's doing ,", "summary": "decisions: in his next status report , me026 will summarise the work he has been researching ."}
{"dialogue": "but to me it justit just meant a practical <breath> point that um if we want to <breath> publish results on digits thatthat people pay <breath> attention to we probably should uh cuz we 've had the problem before that you getshow some <breath> nice improvement on something that 'sthat 's uh , uhit seems like too large a number , and uh <breath> uh people do n't necessarily take it so seriously .", "summary": "problems: the digit recognition system is still not working well enough , they must get better results if they want to publish and be noticed ."}
{"dialogue": "our back - end isis fairly simple but until now , well , the attempts to improve it orhave fail i mean so to <breath> so there 'sthere 'sthere 's two things being affected . i mean . one is thatthat , you know , there 's something simple that 's wrong with the back - end . we 've been playing a number of states uh ii do n't know if he got to the point of playing with the uh number of gaussians yet but , yeah , so far he had n't gotten any big improvement , but that 's all with the same amount of data which is pretty small . perhaps it 's not related , the amount of data but the um recording conditions . i uh but i 'mi 'm almost certain that itit <breath> i mean , that it has to do with the um amount of training data . itit 'sit 's orders of magnitude off . let 's see , in thein these multi - train things did we include noisy data in the training ? i mean , that could be hurting us actually , for the clean case . you know , i do n't think there 's anything magical here . it 's , you know , we used a simple htk system with a modest amount of data . and this is aa , you know , modern <breath> uh system uh hashas a lot of nice points to it . so . i mean , the htk is an older htk , even . i mean , there 's <breath> even though it 's close - miked there 's stillthere really is background noise . um . and <breath> uh i suspect when the ti - digits were recorded if somebody fumbled or said something wrong or something that they probably made them take it over . it was noti mean there was no attempt to have it be realistic in anyin any sense at all . ti - digit isit 's very , very clean and it 's like studio recording whereas these meeting recorder digits sometimes you have breath noise", "summary": "problems: they have not really made many improvements , which may be due to their comparatively small training set , or the conditions the data is recorded under ."}
{"dialogue": "uh . the problem is that it 's very big and <breath> <mouth> we still have to think how towhere to put it uh either some delay and weif we put it on the server side , it does n't work , because on the server side features you already have lda applied <breath> from the f from the terminal side and <breath> so you accumulate the delay", "summary": "problems: the new vad is quite a large network , and adds a delay to the process ."}
{"dialogue": "so wha where did this good vad come from ? it 's um from ogi . this is the one they had originally ? yeah , but they had toget rid of it because of the space , but the abso assumption is that we will be able to make a vad that 's small and that works fine .", "summary": "problems: this caused ogi to drop it , though speaker mn007 is assuming that a smaller and equally effective system can be developed ."}
{"dialogue": "but the other thing is uh to use a different vad entirely . ii do n't know what the thinking was amongst thethethe <breath> the etsi folk but um if everybody agreed sure let 's use this vad and take that out of there they just want , apparentlythey do n't want to fix the vad because they think there is some interaction between feature extraction andand vad or frame dropping but they still <mouth> want tojust to give some um <breath> requirement for this vad because it 'sit will not be part ofthey do n't want it to be part of the standard . so there just will be some requirements that are still notuh not yet uh ready i think . but i do n't think we need to be stuck on using our or ogi 'svad . we could use somebody else 's if it 's smaller you know , as long as it did the job .", "summary": "problems: the alternative is to get yet another vad form somewhere else , though it 's not clear if they will even be required in the final system ."}
{"dialogue": "yeah , it 'sit 's another problem . if you look at this um spectrum , is it <breath> the mel - filters ? and what we clearly see is that in some cases , and thethe harmonics are resolved by the f well , there are still appear after mel - filtering , and it happens <breath> for high pitched voice because the width of the lower frequency mel - filters <breath> is sometimes even smaller than the pitch . so we were thinking to modify the mel - spectrum to have something thatthat 's smoother on low frequencies .", "summary": "problems: there are some problems with the voiced / unvoiced feature detection , because some pitches are slipping through the filtering ."}
{"dialogue": "so what happened since , um , <breath> last week is well , from ogi , these experiments onputting vad on the baseline .", "summary": "abstract: the icsi meeting recorder group at berkeley met to discuss progress on their main project , aurora ."}
{"dialogue": "i have something just fairly brief to report on . andbut it runs much much faster . ii think mit only took something like , uh , three or four hours to do the full training , as opposed to wh what , sixteen hours or something like that ? oh , the other thing that i did was , um , <breath> i compiledthe htk stuff for the linux boxes . there was a conference call this tuesday . i do n't know yet the <breath> what happened <breath> tuesday , but <breath> the points that they were supposed to discuss is still , <mouth> uh , things like <breath> the weights , so what happened since , um , <breath> last week is there was a <breath> start of some effort on something related to voicing or something . so basically we try to , <breath> <breath> uh , find <breath> good features that could be used for voicing detection ,", "summary": "abstract: they discussed a conference call with project partners , there have been some developments that should help speed up experiments , along with some progress made in the current area they are looking , voiced / unvoiced detection ."}
{"dialogue": "n um , not not not much is new . um , anything toadd ? well , i 've been continuing reading . i went off on a little tangent this past week ,", "summary": "abstract: a number of other members of the group also reported the progress they were making on their work ."}
{"dialogue": "i 've forgotten now what the name of that machine is but i cani can send email around about it . um , you have to makeyou have to make sure that in your dot cshrc , <breath> um , it detects whether you 're running on the linux or aa sparc and points to the right executables . and you may not have had that in your dot cshrc before , if you were always just running the sparc . uh , i cani can tell you exactly what you need to do to get all of that to work .", "summary": "decisions: me018 will mail people with details about changes to their system in order to run code on the ibm linux machine , along with the name of the machine ."}
{"dialogue": "when you say `` we have that `` , does sunil have it now , too , no . because we 're still testing . so we 'll perhaps <breath> <mouth> <breath> try to convince ogi people to use the new <breath> the new filters uh , hashas anything happened yet on this business of having some sort of standard , uh , source , not yet but i wi i will <breath> call them now they arei think they have more time well , eurospeech deadline is <breath> over", "summary": "decisions: mn007 is going to try and convince ogi to use his new filters , and enquire as to the setting of a standard for the system ."}
{"dialogue": "there was a conference call this tuesday . i do n't know yet the <breath> what happened <breath> tuesday , but <breath> the points that they were supposed to discuss is still , <mouth> uh , things like <breath> the weights ,", "summary": "problems: there was a conference call for the aurora project , but no one from icsi was involved ."}
{"dialogue": "do you know who waswho wassince we were n't in on it , uh , do you know who was in from ogi ? but <breath> the points that they were supposed to discuss is still , <mouth> uh , things like <breath> the weights , i have no idea . so the points were thethe weightshow to weight the different error rates <breath> that are obtained from different language andand conditions . it 's not clear that they will keep the same kind of weighting . some people are arguing that it would be better to have weights on well , toto combine error ratesbefore computing improvement . and so , perhaps they will change the weights to well , i mean , the fact that it 's inconsistent is an obvious mistake . but the question is , do you average the relative improvementsor do you average the error rates and take the relative improvement maybe of that ? and the thing is it 's not just a pure average because there are these weightings . it 's just when youwhen you get all done , i think that they pro but i think they started off this process with the notion that <breath> you should besignificantly better than the previous standard . so they said `` how much is significantly better ? andand so they said `` well , <breath> you know , you should have half the errors , `` or something , `` that you had before `` . but it does seem like i i it does seem like it 's more logical to combine them first but there is thisthisis this still this problem of weights . whenwhen you combine error rate it tends togive more importance to the difficult cases , some people think that <breath> it 's more important to look at <breath> to have ten percent imp relative improvement onwell - matched case than to have fifty percent on the m mismatched , and other people think that it 's more important to improve a lot on the mismatch it sounds like they do n't really have a good idea about what the final application is gon na be . i mean , they don theythey don'tthey do n't reallyknow , i think . so the argument for that being thethethe more important thing , <breath> is that you 're gon na try and do that , <breath> but you wan na see how badly it deviates from that whenwhenwhen the , uhit 's a little different . the opposite argument is you 're never really gon na have a good sample of all these different things . i gather that in these meetings it 'sit 's really tricky to make anything <breath> ac <breath> make anypolicy change because <breath> < clears throat > everybody hashas , uh , their own opinion but there is probably aa big change that will <breath> be made is that thethe baselineth they want to have a new baseline , perhaps , and apparently , <mouth> uh , some people are pushing to still keep this fifty percent number . so they want <breath> to have at least fifty percent improvement on the baseline , so whose vad uh , they did n't decide yet .", "summary": "problems: not only are the group unsure what if anything was decided , but project changes are being considered including changing the baseline and improvement weighting , though everyone has their own opinion on these matters ."}
{"dialogue": "andhe 's been doing all the talking this isthis by the way a bad thing . we 're trying to get , um , m more female voices in this record as well . make sur make sure carmen <laugh> talks as well . i do n't know .", "summary": "problems: the group needs more female voices in the meeting recorder data , though fn002 does not consider herself very suitable ."}
{"dialogue": "i do n't really have , uh , anything new . been working onmeeting recorder stuff . what 's new with you ? so there 's nothingnew . what 's old with you that has developed over the last week or two ? well , so we 've been mainly working on the report any - anything new on the thing that , uh , you were working on with the , uh ? i do n't have results yet . so , whatwha <laugh> wh wha what what 's going on ? well , we work in the report , too , how are , uh , uhhow are things going with what you 're doing ? i took a lot of time just getting my taxes out of the way so , i 'mi 'm starting to write code now for my work but i do n't have any results yet . do you wannasay something about your stuff here ? ijust , um , continuing looking at , uh , ph uh , phonetic events , it 'sthat 's pretty much it .", "summary": "abstract: although the members of icsi 's meeting recorder group at berkeley had little progress to report , there were still a number of issues relating to their work to discuss ."}
{"dialogue": "do you think that would be the case for next week also ? what 's your projection on ? so the experiment is to , um , run our front - end like normal , with the default , uh , insertion penalties and so forth , and then tweak that a little bit and see how much of a difference it makes that 's something i 'd like to understand before we actually use something from it , ii was thinking gettinggetting us a set of acoustic events toum , to be able to distinguish between , uh , phones and words and stuff . can you give an example of an event ? so , he in this paper , um , it 's talking about phoneme recognition using acoustic events . so , things like frication or , uh , nasality . just to expand a little bit on the idea of acoustic event . there 's , umin my mind , anyways , there 's a difference between , um , acoustic features and acoustic events . and i think of acoustic features as being , um , things that linguists talk about , stuff that 's not based on data , necessarily . that 's not based on , you know , acoustic data . so they talk about features for phones , which may or may not be all that easy to measure in the acoustic signal . versus an acoustic event , which is just < mike noise > some <spikes> something in the acoustic signal <spike> that is fairly easy to measure . it 's kinda like the difference between top - down and bottom - up . i think of the acousticyou know , phonetic features as being top - down . you know , you look at the phone and you say this phone is supposed to beyou know , have this feature , this feature , and this feature . whether tha those features show up in the acoustic signal is sort of irrelevant . whereas , an acoustic event goes the other way . here 's the signal . here 's some event . and then thatyou know , that may map to this phone sometimes , and so it 's sort of a different way of looking .", "summary": "abstract: these included making plans for upcoming experiments , clarifying definitions , and approaches which may or may not be against the rules of the aurora project , alongside alternatives that would not be ."}
{"dialogue": "so , my suggestion , though , is that youyou not necessarily finish that . but that you put it all together so that it 'syou 've gotyou 've got a clearer structure to it . so that , you knowso that such a thing can be written . and right now it 's kind of important that we actually go forward with experiments .", "summary": "abstract: there was also debate about the necessary continuation of a group report ."}
{"dialogue": "i was saying hynek 'll be here next week , uh , wednesday through friday uh , through saturday , i wo n't be here thursday and friday . but my suggestion is that , uh , at least for this meeting , people should go ahead , uh , cuz hynek will be here , so maybe i can have that for next week when hynek 's here . maybethat 's maybe a topic especially if you talk with him when i 'm not here , that 's a topic you should discuss with hynek to , you know , double check it 's ok . well , this 'll be , i think , something for discussion with hynek next week .", "summary": "abstract: plans were also made with regard to a visitor from research partner ogi"}
{"dialogue": "so the experiment is to , um , run our front - end like normal , with the default , uh , insertion penalties and so forth , and then tweak that a little bit and see how much of a difference it makes so by `` our front - end `` i mean take , you know , the aurora - two s take some version that stephane has that is , you know , our current best version of something . howhow much , uh , does it improve if you actually adjust that ? when you adjusted those numbers for mel cepstrum , did it ? uh , ii do n't remember off the top of my head . yeah . i did n't even write them down . looking at thei wrote down what the deletions , substitutions , and insertions were , for different numbers of states per phone . um , but , uh , thatthat 's all i wrote down . i would need to do that . i can do that for next week . but i think it would beit 'd be good to know that . so maybe i can have that for next week when hynek 's here .", "summary": "decisions: for next weeks meeting , speaker me018 will provide numbers on his experiments into adjusting insertion penalties ."}
{"dialogue": "y yeah . basically we we 've stopped , uh , experimenting , so , my suggestion , though , is that youyou not necessarily finish that . but that you put it all together so that it 'syou 've gotyou 've got a clearer structure to it . you know what things are , you have things documented , you 've looked things up that you needed to look up . so that , you knowso that such a thing can be written . whenwhenwhen do you leave again ? first of july . and that you figure on actually finishing it inin june . because , you know , you 're gon na have another bunch of results to fit in there anyway . and right now it 's kind of important that we actually go forward with experiments . soso , ii think it 's good to pause , and to gather everything together and make sure it 's in good shape , so that other people can get access to it and so that it can go into a report in june . but i think <inbreath> toto really work onon fine - tuning the report n at this point isis probably bad timing , iithink .", "summary": "decisions: speaker me013 feels that mn007 and fn002 should just put together the coherent bare-bones of their report , and move back to experimenting , leaving the report for the end of the project ."}
{"dialogue": "maybethat 's maybe a topic especially if you talk with him when i 'm not here , that 's a topic you should discuss with hynek to , you know , double check it 's ok . there is also the spectral subtraction , i think maybe we should , uh , try to integrate it inin our system . i think that would involve to <breath> to mmm <mouth> use a bigaal already a big bunch of the system of ericsson . because he has spectral subtraction , then it 's followed by , <mouth> um , other kind of processing that 'sare dependent on theuh , if it 's speech or noi or silence . and s ii think it 's important , um , <mouth> to reduce this musical noise and thisthis increase of variance during silence portions . this was in this would involve to take almost everything fromfrom thethis proposal and then just add some kind of on - line normalization inin the neural network . well , this 'll be , i think , something for discussion with hynek next week .", "summary": "decisions: he also feels that they should discuss some aspects of future work , for clarity 's sake , with the visitor from ogi ."}
{"dialogue": "uh , so the next question to ask , which is i think the one thatthatthat andreas was dre addressing himself to in the lunch meeting , is , um , we 're not supposed to adjust the back - end , but anybody using the system would . if you were just adjusting the back - end , how much better would you do , uh , in noise ? uh , because the language scaling and insertion penalties and so forth are probably set to be about right for mel cepstrum . but , um , they 're probably not at all set right for these things , as for these other things , it may turn out that , uh , <inbreath> it 's kind of reasonable . i mean , andreas gave a very reasonable response , and he 's probably not gon na be the only one who 's gon na say this in the future peoplepeople within this tight - knit community who are doing this evaluation <inbreath> are accepting , uh , more or less , that these are the rules . but , people outside of it who look in at the broader picture are certainly gon na say `` well , wait a minute . you 're doing all this standing on your head , uh , on the front - end , when all you could do is just adjust this in the back - end with one s one knob . `` so we have to at least , i think , determine that that 's not true , and as you sayas you point outfinding ways to then compensate for that in the front - end < clears throat > also then becomes a priority for this particular test , that 's permitted ? well , ogi doesdid that . at some point they did that forfor the voice activity detector . the rules as i understand it , is that in principle the italian and the spanish and the english italian and the finnish and the english ? were development data and spanish , yeah . on which you could adjust things . and theand the german and danish were the evaluation data . and then when they finally actually evaluated things they used everything . itit does n't appear that there 's strong evidence that even though things were somewhat tuned on those three or four languages , thatthat going to a different language really hurt you . and the noises were not exactly the same . i mean they were different drives . different cars . it 's tuned more than , you know , aaaa you 'd really like to have something that needed no particular noise at all , but that 's not really what this contest is . that 's something i 'd like to understand before we actually use something from it , it 's probably something that , mmm , theyou know , the , uh , experiment designers did n't really think about , because i think most people are n't doing trained systems , or , you know , uh , systems that are like ours , where you actually use the data to build models . i mean , they justdoing signal - processing . except that , uh , that 's what we used in aurora one , and then they designed the things for aurora - two knowing that we were doing that . and they did n't forbid us to build models on the data ? no . but , i thinki think that itit it probably would be the case that if , say , we trained on italian , uh , data and then , uh , we tested on danish data and it did terribly , uh , thatthat it would look bad . and i think someone would notice maybethat 's maybe a topic especially if you talk with him when i 'm not here , that 's a topic you should discuss with hynek to , you know , double check it 's ok .", "summary": "problems: the main project the group is working on , aurora , has a number of rules attaches as to what developers can and can not play with , but this needs to be clarified ."}
{"dialogue": "as for these other things , it may turn out that , uh , <inbreath> it 's kind of reasonable . i mean , andreas gave a very reasonable response , and he 's probably not gon na be the only one who 's gon na say this in the future peoplepeople within this tight - knit community who are doing this evaluation <inbreath> are accepting , uh , more or less , that these are the rules . but , people outside of it who look in at the broader picture are certainly gon na say `` well , wait a minute . you 're doing all this standing on your head , uh , on the front - end , when all you could do is just adjust this in the back - end with one s one knob . `` so we have to at least , i think , determine that that 's not true , and as you sayas you point outfinding ways to then compensate for that in the front - end < clears throat > also then becomes a priority for this particular test ,", "summary": "problems: the rules are adhered to in the small community , but make no sense from a broader research perspective ."}
{"dialogue": "are you discovering anything , uh , that makes you scratch your head as you write this report , like why did we do that , or why did n't we do this , uh . yeah . actually , there were some tables that were also with partial results . we just noticed that , wh while gathering the result that for some conditions we did n't have everything .", "summary": "problems: while writing their report , mn007 and fn002 have noticed some tables contain only partial results , and there are things they do not recall the reasoning behind ."}
{"dialogue": "none", "summary": "abstract: the meeting recorder group of icsi at berkeley met without their most senior member , but attending instead was a visitor from research partner ogi ."}
{"dialogue": "andand uh so , ii think that carmen and stephane reported on uh amsterdam meeting , which was kind of interesting because it was for the first time we realized we are not friends really , but we are competitors .", "summary": "abstract: he reported on a recent project meeting from his group 's perspective ."}
{"dialogue": "because it was for the first time we realized we are not friends really , but we are competitors . it seemed like there were still some issues , that they were trying to decide ? there is a plenty ofthere 're plenty of issues .", "summary": "abstract: there was much politics involved , and disagreement between groups ."}
{"dialogue": "so what we are doing at ogi now is uh uh uh working basically on our parts which we i think a little bit neglected , and then most of the effort is uh now also aimed at this e e trap recognition .", "summary": "abstract: he also brought the icsi members up to date with his group 's latest work ."}
{"dialogue": "how 's your documentation or whatever so have you been running some new experiments ?", "summary": "abstract: the icsi group reported their most recent progress and detailed their recent findings ."}
{"dialogue": "so we were just discussing , since you mentioned that , init w driving in the car with morgan this morning , we were discussing a good experiment for b for beginning graduate student who wants to run a lot ofwho wants to get a lot of numbers on something which is , like , `` imagine that you willyou will start putting every co any coefficient , which you are using in your vector , in some general power . like sort of you take a s power of two , or take a square root , or something . because uh your uh gaussian mixture model , so you 're compressing the range of this coefficient , so it 's becoming less efficient . morgan was @ @ and he washe was saying well this might be the alternative way how to play with awith a fudge factor , you know , and i said `` well in that case why do n't we just start compressing individual elements , like whenwhen because we observed that uh higher parameters were more important than lower for recognition . and basically thethe c - ze c - one contributes mainly slope ,", "summary": "abstract: having discussed this with the icsi project leader , the ogi member told of some future investigation they had devised , which would look at the adjusting the importance of some features ."}
{"dialogue": "none", "summary": "abstract: this led to a great deal of discussion ."}
{"dialogue": "when we talked about aurora still i wanted to m make a pleauh encourage for uh more communication betweenbetween uhuh different uh parts of the distributed uhuh center . uh even when there is absolutely nothing toto s to say but the weather is good in ore - inin berkeley . i 'm sure that it 's being appreciated in oregon and maybe it will generate similar responses down here ,", "summary": "abstract: there were also further calls for greater communication between the groups ."}
{"dialogue": "if we mail to `` aurora - inhouse `` , does that go up to you guys also ? no . do we have a mailing list that includes uh the ogi people ? uh no . we do n't have . maybe we should set that up . that would make it much easier . and then we also can send thethe dis to the same address and it goes to everybody", "summary": "decisions: icsi currently has no mailing list which includes ogi personnel , so they will set one up ."}
{"dialogue": "there is a plenty ofthere 're plenty of issues . like the voice activity detector , well and what happened was that they realized that if two leading proposals , which was french telecom alcatel , and us both had uh voice activity detector . and i said `` well big surprise , i mean we could have told you thatn n n four months ago , except we did n't because nobody else was bringing it up `` . obviously french telecom did n't volunteer this information either , cuz we were working onmainly on voice activity detector for past uh several months and everybody said `` well but this is not fair . we did n't know that . `` and of course uh theit 's not working on features really . and so then ev ev everybody else says `` well we shouldwe need to do a new eval evaluation without voice activity detector , or we have to do something about it `` . and in principle iuh iwe agreed . but in that case , uh we would like to change the uhthe algorithm because uh if we are working on different data , we probably will use a different set of tricks . but unfortunately nobody ever officially can somehow acknowledge that this can be done , because french telecom was saying `` no , no , no , now everybody has access to our code , so everybody is going to copy what we did . `` well our argument was everybody ha has access to our code , and everybody always had access to our code . we never uhuh denied that . we thought that people are honest , that if you copy something and if it is protectedprotected by patent then you negotiate , or something , butand french telecom was saying `` no , no , no , there is a lot of little tricks which uh sort of uh can not be protected and you guys will take them , `` which probably is also true . and i think they have to be honest in the long run , because winning proposal againuh what will be available th iswill be a code . so the uhthe people can go to code and say `` well listen this is what you stole from me `` the biggest problem of course is that f that alcatel french telecom cl claims `` well we fulfilled the conditions . we are the best . and e and other people do n't feel that , because theyso they now decided thatthatisthe whole thing will be done on well - endpointed data , still not clear if we are going to run theif we are allowed to run uh uh new algorithms , because uh we would fight for that , really . at least our experience is that only endpointing aa mel cepstrum gets uhgets you twenty - one percent improvement overall and twenty - seven improvement on speechdat - car", "summary": "problems: there was disagreement at the project meeting over two group development of voice activity detectors , particularly since one group makes their code available to all and the others do not ."}
{"dialogue": "at least our experience is that only endpointing aa mel cepstrum gets uhgets you twenty - one percent improvement overall and twenty - seven improvement on speechdat - car then obvious the databaseuh i mean thethetheuh the baseline will go up . and nobody can then achieve fifty percent improvement . so they agreed that uh there will be a twenty - five percent improvement required onon uh h u m bad mis badly mismatched and so , so now they want to say `` wewe will require fifty percent improvement only for well matched condition , and only twenty - five percent for the serial cases . `` and uhand they almost agreed on that except that it was n't a hundred percent agreed . and so last time uh during the meeting , i just uh brought up the issue , for two years we are fighting for fifty percent improvement and suddenly you are saying `` oh no wewe will do something less `` , and everybody said `` oh we discussed that and you were not a mee there `` and i said `` well a lot of other people were not there because not everybody participates at these teleconferencing c things . `` then they said `` oh no no no because uh everybody is invited . `` however , there is only ten or fifteen lines , so people ca n't even con you know participate . so eh they agreed , and so they said `` ok , we will discuss that . `` so now officially , nokia is uh uh complaining and said theythey are looking for support , uh i think qualcomm is uh saying , too `` we should n't abandon the fifty percent yet . we should at least try once again , one more round . ``", "summary": "problems: there were also issues relating to the amount of improvement required if the baseline is improved ."}
{"dialogue": "none", "summary": "abstract: the icsi meeting recorder group met once more to discuss their recent progress in various projects , as well as discuss some of the issues that have arisen in the last week ."}
{"dialogue": "well i <inbreath> tried this mean subtraction method . due to avendano , <inbreath> i 'm taking s um <inbreath> six seconds of speech ,", "summary": "abstract: there has been further work on voiced / unvoiced detection , along with spectral subtraction ."}
{"dialogue": "so uh , he 's not here , ok , and wh when did stephane take off ? i think that stephane will arrive today or tomorrow . so he 'she 's going to icassp which is good . and also mmm ih hynek last week say that if i have time i can to begin toto study well seriously the france telecom proposal to look at the code i begin toto work also in that . but the first thing that i do n't understand is that they are using r - the uh log energy that this quite i do n't know why they have some constant in the expression of the lower energy .", "summary": "abstract: the group discussed one members attendance at a conference , and another groups code , which is proving hard to follow ."}
{"dialogue": "and also mmm ih hynek last week say that if i have time i can to begin toto study well seriously the france telecom proposal to look at the code i begin toto work also in that . but the first thing that i do n't understand is that they are using r - the uh log energy that this quite i do n't know why they have some constant in the expression of the lower energy .", "summary": "problems: in trying to understand france telecom 's code , there does not appear to be a reason for a particular constant value ."}
{"dialogue": "sunil 's here for the summer , sunil since you 're <inbreath> haven'thave n't been at one of these yet , why do n't yo you tell us what 'swhat 's up with you ?", "summary": "abstract: the icsi meeting recorder group at berkley have a temporary new member on loan from research partner ogi ."}
{"dialogue": "sunil since you 're <inbreath> haven'thave n't been at one of these yet , why do n't yo you tell us what 'swhat 's up with you ? uh , the otherother thing what i tried was , i just um , uh , took the baseline and then ran it with the endpoint inf uh th information , just the aurora baseline , to see that how much the baseline itself improves by just supplying the information of thei mean the w speech and nonspeech . i found that the baseline itself improves by twenty - two percent by just giving the wuh . because thethe secondthe new phase is going to be with the endpointed speech . and just to get a feel of how much the baseline itself is going to change by adding this endpoint information , i just , uh , use so people wo n't even have to worry about , uh , doing speech - nonspeech then . yeah", "summary": "abstract: he began the meeting by reporting his recent activities , which included looking at the new baseline system ."}
{"dialogue": "and then just uh , i guess uh , progress reports individually , and then uh , plans for where we go between now and then , pretty much . so maybe uh , just briefly , you could remind us about the related experiments . cuz you did some stuff that you talked about last week , the main thing that we did is just to take the spectral subtraction from the france telecom , we are playingwe are also playing , trying to put other spectral subtraction mmm , in the code . it would be a very simple spectral subtraction , on the um , mel energies anything else going on ? i do n't have good result , with theinc including the new parameters ,", "summary": "abstract: the other members of the group also reported their recent progress in areas such as spectral subtraction and voicing detection ."}
{"dialogue": "with whatwhat other new p new parameter ? so maybeyou probably need to back up a bit i tried to include another new parameter to the traditional parameter , that , like , the auto - correlation , the r - zero and r - one over r - zero and another estimation of the var the variance of the difference forof the spec si uh , spectrum of the signal andand the spectrum of time after filt mel filter bank . the idea is to found another feature for discriminate between voice sound and unvoice sound . and we try to use this new featurefeature . anything on your end you want to talk about ? sunil hasn'thas n't heard about uh , what i 've been doing . so basically that 's just , um , trying to propose um , uh , your next youryour following years ofof your phd work , tryingtrying to find a project toto define andand to work on . so , i 've been , uh , looking into , um , doing something about r uh , speech recognition using acoustic events . um , building robust um , primary detectors for these acoustic events , and using the outputs of these robust detectors to do speech recognition .", "summary": "abstract: they also explained some of their projects to their guest ."}
{"dialogue": "i could say a few words about um , some of the uh , compute stuff that 's happening around here , so that people in the group know . so we just put in an order for about twelve new machines , uh , to use as sort of a compute farm . and andreas has sort of gotten that all uh , fixed up and up to speed . and he 's got a number of little utilities that make it very easy to um , <mouth> run things using p - make and customs . and i can send an email around or , maybe i should do an faq on the web site about it or something . how about an email that points to the faq , and , if you say that and then some job that you want to execute , uh , it will find the fastest currently available machine , and export your job to that machine , and , so , soon , when we get all the new machines up , <mouth> um , e then we 'll have lots more compute to use . there 's a lot of nice features to it and it kinda helps to balance the load of the machines", "summary": "abstract: the group shall soon be taking delivery of more machines for a computation farm , and they discussed some software tools for running large processes ."}
{"dialogue": "and i can send an email around or , maybe i should do an faq on the web site about it or something . how about an email that points to the faq ,", "summary": "decisions: speaker me018 will construct an faq about the new computing tools and setup , and email details ."}
{"dialogue": "i mean we 've had these discussions before , andand one of the things that struck me was thatuh , about this line of thought that was particularly interesting to me was that we umwhenever you condense things , uh , in an irreversible way , um , you throw away some information . and so the question is , uh , can we figure out if there 's something we 've thrown away that we should n't have . when they were looking at the difference between the filter bank and the fft that was going into the filter bank , i was thinking `` oh , ok , so they 're picking on something they 're looking on it to figure out noise , or voicevoiced property whatever . `` but for me sort of the interesting thing was , `` well , but is there just something in that difference which is useful ? `` so another way of doing it , maybe , would be just to take the fft uh , power spectrum , and feed it into a neural network , and , you know , maybe if it 's used in combination , it will get at something that we 're missing . it 's just a thought . yeah , i cani will try to do that .", "summary": "decisions: fn002 agrees to try an alternative approach to her new feature for voicing detection ."}
{"dialogue": "let 's see , maybe we should just get a list of items i guess there 's the usualupdates , everybody going around and saying , uh , you know , what they 're working on , the things that happened the last week .", "summary": "abstract: the icsi meeting recorder group at berkeley met once more to discuss group members ' progress ."}
{"dialogue": "well , i 've been working onon t mainly on on - line normalization this week . uh , i 've been trying differentslightlyslightly different approaches . yeah . i 've been playing a little bit with some kind of thresholding , how about you , sunil ? so , um , i 've been , uh , implementing this , uh , wiener filtering for this aurora task . oh . how about you , carmen ? mmm . i 'm working with vts .", "summary": "abstract: the majority of the group are working on tasks related to the aurora project , including on-line normalization and wiener filtering ."}
{"dialogue": "how about you , barry ? um , <mouth> still working on mymy quals preparation stuff . so , um , <mouth> i guess i 'll just pass it on to dave . well , in my lunch talk last week ii said i 'd tried phase normalization and gotten garbage results using that l um , long - term mean subtraction approach .", "summary": "abstract: other progress was also reported ."}
{"dialogue": "none", "summary": "abstract: a large part of the meeting was spent discussing calculations and approaches using the white-board in the room ."}
{"dialogue": "so do you maybe make errors in different places ? different kinds of errors ? i did n't look , uh , more closely . i i really would like to suggest looking , um , a little bit at the kinds of errors . i know you can get lost in that and go forever and not see too much , but <breath> sometimes , just seeing that each of these things did n't make things better may not be enough . it may be that they 're making them better in some ways and worse in others , or increasing insertions and decreasing deletions , you know , helping with noisy case but hurting in quiet case . and if you saw that then maybe youit would <mouth> something would occur to you of how to deal with that .", "summary": "decisions: at me013 's behest , the group need to look closer at the errors made in tests on the aurora project , because the error rate may not be telling the whole picture ."}
{"dialogue": "a third thing is that , um , <outbreath> i play a little bit with the , um <outbreath> finding what was different between , um , he had the france telecom blind equalization in the system . the number o of mfcc that waswere used was different . you used thirteen and we used fifteen . uh , so thetheright now , thethe system that is there in thewhat we have in the repositories , withuses fifteen . so , we haven'tw we have been always using , uh , fifteen coefficients , not thirteen ? um , i 'll t s run some experiments to see whetheronce i have this < 3 tongue taps > noise compensation to see whether thirteen and fifteen really matters or not . never tested it with the compensation , but without , <breath> uh , compensation it was like fifteen was s slightly better than thirteen ,", "summary": "decisions: mn052 volunteers to run some experiments into how different numbers of mfccs affect results ."}
{"dialogue": "well , in my lunch talk last week ii said i 'd tried phase normalization and gotten garbage results using that l um , long - term mean subtraction approach . it turned out there was a bug in my matlab code . so , um , i 've been , uh , implementing this , uh , wiener filtering for this aurora task . ii actually thought it wasit was doing fine when i tested it once . i it 's , like , using a small section of the code . and i got , <breath> like , worse results than not using it . so , i 've been trying to find where the problem came from . and then it looks like i have some problem in the way there is somesome very silly bug somewhere . ii mean , i uh , it actuallyi it actually made the whole thing worse . and it 's , likew it 'sit 's very horrible . i was likei 'm trying to find where the m m problem came ,", "summary": "problems: some previously reported results from me026 were determined to be garbage due to a bug in the codespeaker mn052 also feels that his strange results are down to a bug ."}
{"dialogue": "so , should we just do the same kind of deal where wego around and do , uh , status reportkind of things ?", "summary": "abstract: a typical progress report meeting for the icsi meeting recorder group at berkeley ."}
{"dialogue": "so , should we just do the same kind of deal where wego around and do , uh , status reportkind of things ? why do n't you go ahead , barry ? well , this past week i 've just been , uh , getting down and dirty into writing mymy proposal . so , uh , you want to go next , dave ? last week i finally got results from the sri system about this mean subtraction approach . and i also , um , did some experimentsabout normalizing the phase . do you want to go , stephane ? i 'm more interested in trying to figure out what 's still the difference between the sri system and the aurora system . th i 've been playing with this wiener filter , like . how about you , carmen ? well , i am still working with , eh , vts .", "summary": "abstract: each of the group reported their most recent progress , and any results they have achieved ."}
{"dialogue": "wh why would that be , um , <breath> considering that we actually got an improvement in near - mike performance using htk ? uh , with some input from , uh , andreas , i have a theory in two parts . becausethis is also one big difference betweenthe two systems . the other differences werethe fact that maybe the acoustic models of the sri are moresri system are more complex . you know , they have channel adaptation . well , there 's also the normalization .", "summary": "abstract: this then prompted discussion about the reasons behind such findings , which were for the most part not as expected ."}
{"dialogue": "i 'm more interested in trying to figure out what 's still the difference between the sri system and the aurora system . uh , the next thing is thisthis vad problem that , uh , the second thing is thethis spectral subtraction . which i 've just started yesterday to launch a bunch of , uh , <noise> twenty - five experiments , uh , with different , uh , values for the parameters that are used .", "summary": "abstract: topics the group touched upon included spectral subtraction , phase normalization , voice activity detection , along with comparisons between systems ."}
{"dialogue": "none", "summary": "decisions: * na *"}
{"dialogue": "o o one thing , um , i noticed is that , um , the mean subtraction seems to make the pzm signals louder after they 've been re - synthesized . so i was wondering , is it possible that one reason it helped with the aurora baseline system isjust as a kind of gain control ? cuz some of the pzm signals sound pretty quiet if you do n't amplify them . i do n't see whywhy your signal is louder after processing , i do n't think just multiplying the signal by two would have any effect . i mean , i think if you really have louder signals , what you mean is that you havebetter signal - to - noise ratio . i think , maybei did n't look , but one thing that makes a difference is this dc offset compensation . uh , ehdo y did you have a look atat the meet uh , meeting digits , if they have a dc component , no . the dc component could be negligible . i mean , anyall of the mikes have the dc removalsome capacitor sitting right inthat bias it . yeah . the microphone is n't gon na pass any dc . actually , there areinstrumentation mikes thatthat do passgo down to dc . no , it 's the electronics . then there 's amplification afterwards . you can have dc offset in the data .", "summary": "problems: a couple of issues have arisen that need to be looked into further such as dc-offset and effects of pzm signals ."}
{"dialogue": "well , we s decide to m toto obtain the new expression if we work in the cepstral domain . but <laugh> i 'm not sure if that will be usefu useful . it 's quite a lotit 's a lot of work . and i want to know ifif we have somefeeling thatthe result i do n't have any feeling if this will work better than apply vts aft in cepstral domain will work better than apply in m melin filter bank domain . i don'ti do n't know absolutely nothing . yeah . well , you 'rei think you 're the first one here to work with vts , uh , maybe we could call someone else up who has , i don'ti do n't have a good feeling for it .", "summary": "problems: speaker fn002 is worried about running vts in the cepstral domain , because it requires a lot of work , and it is not clear that it will be much better than running it in the mel domain ."}
{"dialogue": "uh , the next thing is thisthis vad problem that , so , i 'm just talking about thethe curves that ii sent <breath> i sent you so , whi that shows that <mouth> when the snr decrease , < clears throat > uh , the currentvad approach does n't drop much framesfor some particular noises , uh , which might be then noises that are closer to speech , uh , acoustically . i i just to clarify something for me . they were supp supposedly , in the next evaluation , they 're going to be supplying us with boundaries . so does any of this matter ? first of all , the boundaries might be , uhlike we would have t two hundred milliseconds orbefore and after speech . so removing more than that might still makea differencein the results . do we ? i mean , is there some reason that we think that 's the case ? no . but maybe we 'll get some insight on that whenwhen , uh , the gang gets back from crete .", "summary": "problems: similarly , since at the next stage of the project data will have marked boundaries , it is not clear that voice-activity detection is worth pursuing ."}
{"dialogue": "so , um , <mouth> i guess we got lots to catch up on . and we have n't met for a couple of weeks .", "summary": "abstract: the icsi meeting recorder group of berkeley met for the first time in two weeks ."}
{"dialogue": "so , um , since we 're looking at putting this , ummean log m magnitude spectral subtraction , um , into the smartkom system , i i did a test seeing if , um , it would work using past onlyand plus the present to calculate the mean . so i 've been working on that wiener filtering . so , < clears throat > i 've been , uh , working still on the spectral subtraction .", "summary": "abstract: group members reported their progress in the areas of spectral subtraction , wiener filtering and noise estimation ."}
{"dialogue": "i do n't know much aboutas much as i should about the rest of the system but if you did first pass with , um , thewitheither without the mean sub subtraction or with aa very short time one , and then , um , once you , uh , actually had the whole utterance in , if you did , um , the , uh , uh , longer time version then , based on everything that you had , um , and then at that point only used it to distinguish between , you know , top n , um , possible utterances or something , youyou mightit might not take very much time . i mean , i know in the large vocabulary stu uh , uh , systems , people were evaluating on in the past , some people really pushed everything in to make it in one pass but other people did n't and had multiple passes . the argument , um , against multiple passes was u u has often been `` but we want to this to be r you knowhave a nice interactive response `` . and the counterargument to that which , say , uh , bbn i think had , was `` yeah , but our second responses aresecond , uh , passes and third passes are really , really fast `` . do we know yet ? aboutas far as what they 'rewhat the rules are going to be and what we can use ? so actually i received aa new document , describing this . and what they did finally is to , mmm , uh , not to align the utterances but to perform recognition , um , only on the close - talking microphone , and to take the result of the recognition to get the boundaries uh , of speech . oh , so they will send files so everybody will have the same boundaries to work with ? yeah . all of that sort of stuff is things that they 're debating in their standards committee . andand that 's sort of one of the because if we completely ignore latency , and then we discover that we really have to do something about it , we 're going to befind ourselves in a bind .", "summary": "abstract: they also discusses topics relating to the rules and preferences of the project they are working on , including single vs multiple passes ."}
{"dialogue": "can i ask just aa high level question ? can you just say like one or two sentences about wiener filtering and whywhy are people doing that ? i mean , so the basic principle of wiener filter is like you try to minimize the , uh , d uh , difference between the noisy signal and the clean signal and for this i u simply used some code that , uh , < breath-laugh > i had fromfrom belgium , which is technique that , um , takes a bunch of frame , and for each frequency bands of this frame , takes a look at the minima of the energy . and then average these minima and take this as anan energy estimate of the noise for this particular frequency band .", "summary": "abstract: a number of the group also took time to explain the basics of their approaches to the group ."}
{"dialogue": "just for a visit ? uh , we 'll see . we mightmight end up with some longer collaboration or something . so he 's gon na look in on everything we 're doing and give us hishis thoughts . and uh hans - uh , hans - guenter will be here , um , i think by nextnext tuesday or so . so he 'she 's going to be here for about three weeks ,", "summary": "abstract: there are hopes that a visitor coming for three weeks , may lead to a longer term collaboration ."}
{"dialogue": "th - that 's his spectral subtraction group ? is that right ? yeah . so i guess i should probably talk to him a bit too ? yeah .", "summary": "decisions: the visitor works on spectral subtraction , so speaker me026 will make sure he talks to him ."}
{"dialogue": "but the spectral subtraction scheme that you reported on also re requires aa noise estimate . yeah . could n't you try this for that ? do you think it might help ? yeah , forfor sure i will . i can try also , mmm , the spectral subtraction .", "summary": "decisions: speaker mn007 agreed , at me013 's suggestion , to try his noise compensation scheme in compensation with the prior work on spectral subtraction ."}
{"dialogue": "yeah , another thing that iit 's important to mention is , um , that this has a this has some additional latency . and i noticed that it 's better if we take into account this latency . it 's depending on how all this stuff comes out we may or may not be able to add any latency . b but i do n't think we have to worry too much on that right now whileyou kno . i would worry about it a little . because if we completely ignore latency , and then we discover that we really have to do something about it , we 're going to befind ourselves in a bind . andand that 's sort of one of the all of that sort of stuff is things that they 're debating in their standards committee .", "summary": "problems: in implementing smoothing to the spectral subtraction , latency has been increased ; while some feel this is nothing to worry about , others feel it is better to worry now , in case it turns out to be something to worry about ."}
{"dialogue": "none", "summary": "abstract: another weekly meeting on icsi 's meeting recorder group at berkeley , though the members are joined by a visiting researcher ."}
{"dialogue": "so , yeah , thethis past week i 've been main mainly occupied with , um , getting some results , u from the sri system trained on this short hub - five training set for the mean subtraction method . so the last week , uh , i showed some results with only speechdat - car so i was like looking into `` why , what is wrong with the ti - digits ? `` . and i found that , the noise estimation is a reason for the ti - digits to perform worse than the baseline . yeah , there are two figures showing actually the , mmm , um , performance of the current vad . well , i only say that thethis is , a summary of theof all the vts experiments", "summary": "abstract: the groups regulars reported progress on their work on mean subtraction , noise estimation , voice activity detection and the vector taylor series ."}
{"dialogue": "and then there 's um , another thing i wan na start looking at , um , <breath> wi is , um , the choice of the analysis window length . with thewith the htk set - up i should be able to do some experiments , on just varying that length , say between one and three seconds , in a few different reverberation conditions , i guess one thing that might also be an issue , uh , cuz part of what you 're doing is you 're getting aa spectrum over a bunch of different kinds of speech sounds . and so it might matter how fast someone was talking for instance . you know , if youififif there 's a lot of phones in one second maybe you 'll get aa really good sampling of all these different things , and <breath> and , uh , on the other hand if someone 's talking slowly maybe you 'd need more . a actually i was just thinking about what i was asking about earlier , wi which is about having <breath> less than say twelve seconds in the smartkom system to do the mean subtraction . you said in <breath> systems where you use cepstral mean subtraction , they concatenate utterances and , <breath> do you know how they address this issue of , um , testing versus training ? i think what they do is they do it always on - line , i mean , that you just take what you have from the past , that you calculate the mean of this and subtract the mean . and , um , soso in tha in that case , wh what do they do when they 're t um , performing the cepstral mean subtraction on the training data ? sobecause you 'd have hours and hours of training data . so do they cut it off and start over ? and so if you 're splitting things up into utterances so , for instance , in a dialogue system , where you 're gon na be asking , uh , you know , th for some information , there 's some initial th something . and i think the heuristics of exactly how people handle that and how they handle their training i 'm sure vary from place to place . so you 'dyouand so in training you would start over atat every new phone call or at every <breath> new speaker . itit seems to be the best whatwh wh whatwhat we can do in this moment is multi - condition training . and every when we now start introducing somesome noise reduction technique wewe introduce also somehow artificial distortions . and these artificial distortionsuh , i have the feeling that they are the reason whywhy we have the problems in this multi - condition training . that means the h m ms we trained , they arethey are based on gaussians , and if we introduce now thisthis u spectral subtraction , or wiener filtering stuff i mean , this is your noise estimate and you somehow subtract it or do whatever . and then i think what you do is you introduce somesome artificial distribution in this inin the models . soso , basically ourour position is <breath> that , um , we should n't be unduly constraining the latency at this point because we 're all still experimenting with trying to make the performance better in the presence of noise . uh , there is a minority in that group who is a arguingwho are arguing for <breath> um , uh , having a further constraining of the latency . so we 're s just continuing to keep aware of what the trade - offs are and , you know , whatwhat do we gain from having longer or shorter latencies ? well , france telecom waswaswas very short latency it was in the order of thirty milliseconds", "summary": "abstract: while on these topics , related areas discussed included recognition window length , training versus test set sizes , artificial distortion and latency concerns ."}
{"dialogue": "maybe youyou are leaving inin about two weeks carmen . whatwhat i would do is iii would pick @ @ the best consolation , which you think , and <breath> c createcreate all the results for the whole database that you get to the final number asas sunil did it and maybe also toto write somehow a document where you describe your approach , and what you have done . i was thinking to do that next week . i wi ii will do that next week .", "summary": "decisions: speaker fn002 is soon to be leaving the group , and so she will choose her best setup , run a complete set of experiments , and write up her work , procedure and results for next week ."}
{"dialogue": "so the other thing is thei 'm just looking at a little bit on the delay issue where the delay of the system is like a hundred and eighty millisecond . so <breath> i justjust tried another sk systemi mean , another filter which i 've like shown at the end . which is very similar to the existing uh , filter . onlyuh , only thing is that the phase isis like a totally nonlinear phase so it 's just likeit 's like a three percent relative degradation , butbut is thereis there a problem with the one hundred eighty milliseconds ?", "summary": "problems: new filters introduced to reduce latency by mn052 , performed slightly worse than those they replaced ."}
{"dialogue": "for italian and spanish it 'sth this value works good but not necessarily for finnish . but unfortunately there is , like , this forty millisecond latency yeah , so i would try to somewhat reduce this @ @ . i already know that if i completely remove this latency , so . <breath> um , itum there is a three percent hit on italian .", "summary": "problems: whereas mn007 has added some latency to the process which he feels he can reduce ."}
{"dialogue": "anyway we < clears throat > after coming back from qualcomm we had , you know , very strong feedback and , uh , i think it was <breath> hynek and guenter 's and my opinion also that , um , you know , we sort of spread out to look at a number of different ways of doing noise suppression . but given the limited time , uh , it was sort of time tochoose one . uh , and so , uh , th the vector taylor series had n't really worked out that much . uh , the subspace stuff , uh , had not been worked with so much . um , so it sort of came down to spectral subtraction versus wiener filtering . uh , we had a long discussion about how they were the same and how they were d uh , completely different .", "summary": "abstract: icsi 's meeting recorder group have returned from a meeting with some important decisions to make ."}
{"dialogue": "so instead they went to yosemite and bonded , andand they came out with a singlesingle piece of software . so it 's <breath> anotheranother victory for international collaboration . soso you guys have combinedor you 're going to be combining the software ? well , the piece of software has , like , plenty of options , so depending on that , itit becomes either spectral subtraction or wiener filtering . but the thing isthe important thing is that there is a piece of software that youthat we all will be using now .", "summary": "abstract: they have developed a piece of software which allows them to implement their two main approaches to dealing with noise ."}
{"dialogue": "but , stillso , there will be a piece of software with , <mouth> < clears throat > uh , will give this system , the fifty - three point sixty - six , by default howhow ishow good is that ? it 's just one percent off of thebest proposal . it 's betweeni we are second actually if we take this system . compared to the last evaluation numbers ? yeah . yeah . so itso , um , it 'sit it 's not using our full bal bag of tricks , if you will . and , uh , and itit is , uh , very close in performance to the best thing that was there before . uh , but , you know , looking at it another way , maybe more importantly , uh , <breath> we did n't have any explicit noise , uh , handling we did n't explicitly have anything to deal with stationary noise .", "summary": "abstract: the base rate is currently set at the second best rate as of the last project evaluation , and it does not yet include everything the group have been working on ."}
{"dialogue": "i mean , i gather you haveit sounds like you have a few more days ofof nailing things down with the software and so on . butand thenbut , um , <sniff> arguably what we should do is , even though the software can do many things , we should for now pick a set of things , and not change that . and then focus oneverything that 's left . so there 's the neural net issue . there 's the vad issue . and , uh , there 's the second streamthing . what was the issue with the vad ? i guess they still allow two hundred milliseconds on either side or some ? and all the speech pauses , which issometimes on the speechdat - car you have pauses that are more than one or two seconds . we cou we can do better , i think , so , our current vad isis more than twenty percent , while their is fourteen . that 'sthat 's a good set of work thatthat , uh just one more thing . like , should we do something f more for the noise estimation , yeah . i was wondering about that .", "summary": "abstract: with this in mind , they have decided to set most things , and concentrate on studying only a few key aspects , the neural network , the voice activity detector , and the noise estimation ."}
{"dialogue": "and i think , you know , that our goal should be by next week , when hynek comes back , <breath> uh , touh , really just to have a firm path , uh , for theyou know , for the time he 's gone , ofof , uh , what things will be attacked .", "summary": "decisions: by the time a senior member of their research partners ogi returns , they want to have a firm plan of what they will be doing ."}
{"dialogue": "we do still , however , have to consider its latency . we ca n't have unlimited amounts of latency . uh , y you know , that 's still being debated by theby people in europe but , <breath> uh , no matter how they end up there , it 's not going to be unlimited amounts , so wei mean , ifso if weifso which is like if we reduce the delay of va yeah . theyou smooth it and then delay the decision by so that 'sthat 's really notnot bad . so we may in factwe 'll see what they decide . we may in fact have , <breath> um , thethe , uh , latency time available forto have a neural net . what amount of latency are you thinking about when you say that ? you know , they 're saying , uhone group is saying a hundred and thirty milliseconds and another group is saying two hundred and fifty milliseconds .", "summary": "problems: system latency is still an issue , but limits have still not been set by the project heads ."}
{"dialogue": "so the frame - dropping is the last thing that we do . did you happen to notice how much , <breath> uh , the change was due to just this frame - dropping problem ? just the frame - dropping problem . and then we have to be careful with that alsowith the neural net because inthe proposal the neural net was also , uh , working onafter frame - dropping . oh , that 's a real good point .", "summary": "problems: the group have encountered problems with frame-dropping , and will need to bear that in mind since their neural network would come after that stage ."}
{"dialogue": "none", "summary": "abstract: icsi 's meeting recorder group at berkeley met mainly to discuss work on their main project , the aurora task , but also talked about the work of one of their student members ."}
{"dialogue": "sowewe had a meeting with , uhwith hynek , um , inin which , uh , uh , sunil and stephane , uh <mouth> summarized where they were andand , uh , talked about where we were gon na go . so thatthat happened sort of mid - week . but i guess maybe the thingsince you weren'tyo you guys were n't at thatthat meeting , might be justjust to , um , sort of recap , uh , thethe conclusions of the meeting . you 're talking about the meeting with hynek ? since he 's going out of town like now , and i 'm going out town in a couple weeks , uh , and time is marching , sort of , given all the mu many wonderful things we could be working on , whatwhat will we actually focus on ? and , uhand what do we freeze ? and , you know , what do we ? and then within that , i guess the idea was to freeze a certain set of options for now , to run it , uh , a particular way , and decide on what things are gon na be experimented with , as opposed to just experimenting with everything . so keep a certain set of things constant . uh , maybe describe roughly whatwhat we are keeping constant for now , well . so we 've been working like six weeks onon the noise compensation and we end up with something that seems reasonable . are you gon na usewhich of the two techniques ? so finally it 'sit 's , um , wiener filtering on fft bins . so we are going to fix this for the moment and work on the other aspects of < clears throat > the whole system . but structurally it seemed like the thingsthe main things thatthat we brought up that , uh , areare gon na need to get worked on seriously are , uh , uh , a < clears throat > a significantly better vad , uh , putting the neural net on , um , which , you know , we have n't been doing anything with , the , uh , neural net at the end there , and , uh , the , uh , <breath> opening up the second front .", "summary": "abstract: some members of the group met recently with research partners to settle on the current state of their software , and decide on the future work they would investigate , and these decisions were relayed to the rest of the group ."}
{"dialogue": "but structurally it seemed like the thingsthe main things thatthat we brought up that , uh , areare gon na need to get worked on seriously are , uh , uh , a < clears throat > a significantly better vad , uh , putting the neural net on , um , which , you know , we have n't been doing anything with , the , uh , neural net at the end there , and , uh , the , uh , <breath> opening up the second front . the other half of the channel ? yeah , yeah , i mean , cuz wewe havewe have , uh , uh , half thethe , uh , data rate that they allow . and , uh , so the initial thing which came from , uh , the meeting that we had down south was , uh , that , um , we 'll initially just put in a mel spectrum as the second one . it 's , you know , cheap , easy . there 's a question about exactly how we do it . we probably will go to something better later , andand , < clears throat > um , you know , in some sense we 're all doing fairly similar things . so how did they fill up thisall thesethese bits ? um , why are we using half ? we have the on - line normalization and then we have the lda rasta . the lda rasta , uh , throws away high modulation frequencies . and they 're not doing that . so that if you throw away high modulation frequencies , then you can downsample . and , uh , so iyou know , wewe 've found in a lot of ways for quite a while that having a second stream uh , helps a lot . so that 'sthat 's put in , and you know , it may even end up with mel spectrum even though i 'm saying i think we could do much better , just because it 's simple . so this second stream , will it add latency to the system no , it 's in parallel . we 're not talking about computation time here . so it 's just in terms of what data it 's depending on . it 's depending on the same data as the other .", "summary": "abstract: of the three areas for the future , they touched mostly upon the use of a second , parallel , data stream ."}
{"dialogue": "what about the , umuh , the new part of the evaluation , the , uh , wall street journal part ? have you ever worked with the mississippi state h uh , software ? not yet . well youyou may be called upon to help , uh , uh , on account of , uh , all the work in this stuff here has been , uh , with small vocabulary . ok . oh , so they 're gon na just deliver a system basically . yeah , th ii guess it 's almost ready . so they have released their , uh , document , describing the system . cuz one of the things that might be helpful , if you 'veif you 've got time in all of this is , is ifif these guys are really focusing on improving , uh , all the digit stuff , uh , maybeand you got the front - end from them , maybe you could do the runs for the sure . andand , you know , iron out hassles thatthat you have to , uh , tweak joe about or whatever , because you 're more experienced with running the large vocabulary stuff . so i 'll point you to the web site and the mails corresponding . so these sugges thesethis , uh , period during which people are gon na make suggestions is to know whether it is actually biased towards any set of features or yeah , so i th th certainly the thing that i would want to know about is whether we get really hurt , uh , on in insertion penalty , language model , scaling , sorts of things . using our features . uh , in which case , um , h hari or hynek will need to , you know , push the casemore aboutabout this . and we may be able to revisit this idea about , you know , somehow modifying our features to work with", "summary": "abstract: the group also discussed a new part to the evaluation , the use of a chunk of the wall street journal ."}
{"dialogue": "got anything to tell us ? well , i 've been reading some literature about clustering of data . ok , so we 're talking about discovering intermediate categories to , umto classify . and , uh , i was looking at some of the work that , uh , sangita was doing on these traps things . so she has , umshe has temporal patterns for , um , a certain set of phonemes , fromfrom timit , um , and , um , i was thinking about ways toto generalize this because w you 'reit 's sort of like ait 's not a completely automatic way of clustering , are you looking at these in narrow bands ? yeah , i mean , it seems somehow that needs th uh , there 's a couple things that i wonder about with this . i mean , if you 're going for this sort of thing where you haveuh , little detectors that are looking at narrow bands , then what you 're going to be looking for should be some category that you can find with the narrow bands . um , the sort of standard answer about this sort of thing is that if you 're trying to findthe right system in some sense , whether you 're trying by categories oror parametersum , and your goal is discrimination , then having choices based on discrimination as opposed to , um , unsupervised nearness of things , um , is actually better . um , and i do n't know if thati mean , since you 're dealing with issues of robustness , you know , maybemaybe this is n't right , but it 'd be something i 'd be concerned about . because , for instance , you can imagine , uh , uh , i i if you remember fromfrom , uhfrom youryour quals , john ohala saying that , uh , `` buh `` and `` puh `` differed , uh , not really cuz of voicing but because of aspiration . so , um , if you lookedif you were doing some coarse clustering , you probably would put those two sounds together . and yet , i would gue i would guess that many of your recognition errors were coming from , uh , um , pfft , screwing up on this distinction . if you go and take any recognizer that 's already out there and you say , `` how well is it distinguishing betweenschwas and stops ? `` boy , i bet they 're all doing nearly perfectly on this ,", "summary": "abstract: speaker me006 is working on data clustering , and discussion of related issues led to more general acoustic matters ."}
{"dialogue": "so , i 'll , umi 'll actuallyafter the meeting i 'll add the second stream to the vad and maybe i 'll start with the feature net in that case . ok , so just figure how to take the features from the final", "summary": "decisions: after the meeting , mn052 volunteered to get the second data stream up and running in the current software ."}
{"dialogue": "have you ever worked with the mississippi state h uh , software ? not yet . well youyou may be called upon to help , uh , uh , on account of , uh , all the work in this stuff here has been , uh , with small vocabulary . ok . cuz one of the things that might be helpful , if you 'veif you 've got time in all of this is , is ifif these guys are really focusing on improving , uh , all the digit stuff , uh , maybeand you got the front - end from them , maybe you could do the runs for the sure . andand , you know , iron out hassles thatthat you have to , uh , tweak joe about or whatever , because you 're more experienced with running the large vocabulary stuff . so i 'll point you to the web site and the mails corresponding . you know joe , just to sort of ask him about the issue of , um , different features having different kinds of , uh , scaling characteristics and so on . so sh shall we , like , add chuck also to the mailing lists ? that 'd be great . yeah , i guess maybe hari or hynek , one of them , has tosend a mail to joe . ii could send him an email . ii was just talking with him on email the other day actually . uh , yeah , and just , um , se maybe see . yeah , so maybe just cc hari and say that you 've just been asked to handle the large vocabulary part here , why do n't you just ask joe but cc hari , and then in the note say , `` hari , hopefully this is ok with you `` . and then if joe feels like he needs a confirmation , hari can answer it .", "summary": "decisions: since he has been asked to assist in a particular aspect of the work , me018 has to contact the relevant persons in order to be added to the according mailing list ."}
{"dialogue": "oh , so they 're gon na just deliver a system basically . yeah , th ii guess it 's almost ready . so they have released their , uh , document , describing the system . so these sugges thesethis , uh , period during which people are gon na make suggestions is to know whether it is actually biased towards any set of features or yeah , so i th th certainly the thing that i would want to know about is whether we get really hurt , uh , on in insertion penalty , language model , scaling , sorts of things . using our features . uh , in which case , um , h hari or hynek will need to , you know , push the casemore aboutabout this . and we may be able to revisit this idea about , you know , somehow modifying our features to work with", "summary": "problems: there is a new system coming from ogi for dealing with the wall street journal data , and me013 wanted everyone to pay attention to areas where the groups might get hurt because of their features ."}
{"dialogue": "none", "summary": "abstract: icsi 's meeting recorder group at berkeley meets to discuss , for the most part , progress on the aurora project ."}
{"dialogue": "um , i 've been playing with , first , the , um , vad . um , < clears throat > so it 's exactly the same approach ,", "summary": "abstract: the main areas being worked on were the voice activity detector and the tandem data streams ."}
{"dialogue": "but well , we could probably put the delta , um , <mouth> before on - line normalization . what if you used a smaller window for the delta ? i mean , i guess there 's a lot of things you could do to so if youif you put the delta before the , uh , ana on - lineif uhthenthen it could go in parallel . cuz the time constant of the on - line normalization is pretty long compared to the delta window , and you could experiment with cutting various pieces of these back a bit , i mean , we 're s we 're notwe 're not in terrible shape . well , what 's yourwhat 's your thought about what to do next with it ? i 'm surprised , because i expected the neural net to help more when there is more mismatch , as it was the case for the well , we mightuh , we might have to experiment with , uh better training sets . ithe other thing is , i mean , before you found that was the best configuration , but you might have to retest those things now that we have differentthe rest of it is different , for instance , what 's the effect of just putting the neural net on without the o otherother path ? i mean , you know what the straight features do . in the , uma lot of the , umthe hub - five systems , um , recently have been using lda . andand they , umthey run lda on the features right before they train the models . uh , this lda is different from the lda that you are talking about . the lda that yousaying is , like , you take a block of features , like nine frames or something , and then do an lda on it , and then reduce the dimensionality to something like twenty - four or something like that . so this is a two dimensional tile . and the lda that we are f applying is only in time , so it 's likemore like a filtering in time , but what if you putran the other kind of lda , uh , on your features right before they go into the hmm ? but it 'sit 's like a nonlinear discriminant analysis . the tandem stuff is kind of like i nonlinear lda . but i mean , w but the other features that you have , um , th the non - tandem ones , well , in the proposal , they were transformed u using pca , yeah , it might be that lda could be better . the uh , other thing i was wondering was , um , if the neural net , um , has anybecause of the different noise con unseen noise conditions for the neural net , where , like , you train it on those four noise conditions , while you are feeding it with , like , a additionalsome four plus somef few more conditions which it has n't seen , actually , instead of just h having c uh , those cleaned up t cepstrum , sh should we feed some additional information , likethethe i mean , should we f feed the vad flag , also , at the input so that itit has some additional discriminating information at the input ? we have the vad information also available at the back - end . so if it is something the neural net is not able to discriminate the classes so , by having an additional , uh , feature which says `` this is speech and this is nonspeech `` , i mean , it certainly helps in some unseen noise conditions for the neural net . so you 're saying , feed that , also , intothe neural net . yeah . so it it 's anadditional discriminating information . the other thingyou could do is just , um , p modify the , uh , output probabilities of theof the , uh , uh , um , neural net , tandem neural net , based on the fact that you have a silence probability .", "summary": "abstract: the group discussed possible further investigations that arose from these areas , including better linking the two ."}
{"dialogue": "and actually it brought up a question which may be relevant to the aurora stuff too . um , i know that when you figured out the filters that we 're using for the mel scale , there was some experimentation that went on atat , uhat ogi . but one of the differences that we found between the two systems that we were using , thethe aurora htk system baseline systemand the system that we werethethe uh , other system we were using , the uh , the sri system , was that the sri system had maybe a , um , hundred hertz high - pass . still , it 's possible that we 're getting in some more noise . so i wonder , is it @ @ was theretheir experimentation with , uh , say , throwing away that filter or something ? so i think whenwhen he gets done with his prelim study i think <laugh> one of the next things we 'd want to do is to take this , uhuh , noise , uh , processing stuff andand , uhuh , synthesize some speech from it .", "summary": "abstract: they also consider how aspects of an absent member 's work might be applied to the current project ."}
{"dialogue": "so i wo n't be here for uh , i 'm leaving next wednesday . i 'm leavingleaving next wednesday . so next week i wo n't , and the week after i wo n't , cuz i 'll be in finland . by that time you 'll beuh , you 'll both be gonefrom here . so it 'll be a few weeks , really , before we have a meeting of the same cast of characters . and then uh , uh , we 'll start up again with dave anddave and barry and stephane and us on the , uh , twentieth .", "summary": "abstract: the meeting closed with a discussion of upcoming absences , and how meetings would continue ."}
{"dialogue": "is there any word yet about the issues about , um , adjustments for different feature sets or anything ? you asked me to write to him uh , i 'lli 'll d i 'll double check that and ask him again . it 's like thatthat could r turn out to be an important issue for us .", "summary": "decisions: speaker me018 must confirm what is needed to work with the new software in terms of adjustments with someone further up the project chain ."}
{"dialogue": "for instance , what 's the effect of just putting the neural net on without the o otherother path ? i mean , you know what the straight features do . when youinin the old experiments when you ran with the neural net only , and did n't have this side path , um , uh , with thethe pure features as well , did it make things better to have the neural net ? it wasb a little bit worse . until you put the second path in with the pure features , the neural net was n't helping at all . it was helping , uh , if the features are b were bad , as soon as we added lda on - line normalization , and < clears throat > all these things , then well , i still think it would be k sort of interesting to see what would happen if you just had the neural net without the side thing . andand the thing ii have in mind is , uh , maybe you 'll see that the results are not just a little bit worse . maybe that they 're a lot worse . but if on the ha other hand , uh , it 's , say , somewhere in between what you 're seeing now andandand , uh , what you 'd have with just the pure features , then maybe there is some problem of aof a , uh , combination of these things , or correlation between them somehow . if it really is that the net is hurting you at the moment , then i think the issue is to focus onon , uh , improving thethe net .", "summary": "decisions: the system at it 's current stage employs the neural networks and second stream , but the group leader would like the network investigated separately , incase it is hurting performance ."}
{"dialogue": "is there any word yet about the issues about , um , adjustments for different feature sets or anything ? it 's like thatthat could r turn out to be an important issue for us . cuz they have , uh , already frozen those in i insertion penalties and all those stuff is whati feel . and they have these tables with , uh , various language model weights , insertion penalties . so now , we may come back to the situation where we may be looking for a modification of the features to account for the fact that we ca n't modify these parameters . but it 's still worth , i think , justsinceyou know , just chatting with joe about the issue .", "summary": "problems: there are worries regarding the need to make adjustments so the new software can handle the group 's different feature set ."}
{"dialogue": "but the problem is still that the latency is too large . thethe latency of the vad is two hundred and twenty milliseconds . wh - what 's the baseline you need to be under ? well , we do n't know . they 're still arguing about it . i mean , if it 's twoifif it 's , uhif it 's two - fifty , then we could keep the delta where it is if we shaved off twenty . if it 's two hundred , if we shaved off twenty , we couldwe could , uh , meet it by moving the delta back . so , how do you know that what you have is too much if they 're still deciding ? i mean , the main thing is that since that we got burned last time , andyou know , by not worrying about it very much , we 're just staying conscious of it . i mean , ififif a week before we have to be done someone says , `` well , you have to have fifty milliseconds less than you have now `` , it would be pretty frantic around here .", "summary": "problems: the system , whilst improved , also has increased latency , and while the limit has not been set , the group need to reduce it ."}
{"dialogue": "you 're just using the full ninety features ? from the networks , it 's twenty - eight . and from the other side it 's forty - five . so it 'syou have seventy - three features , there 's a klt after the neural network , asas before . that 's how you get down to twenty - eight ? i wanted to do something very similar to the proposal as a firstfirst try . but we have tofor sure , we have to go down , because the limit is now sixty features . we have to find a way to decrease the number of features . they felt they wanted to set a limit . so they chose sixty . iii think it 's kind of r arbitrary too .", "summary": "problems: likewise the number of features the use in their system , since this has been set at an arbitrarily low value ."}
{"dialogue": "yeah , actually < clears throat > to s eh , what i observed in the hm case is that the number of deletion dramatically increases . itit doubles . when i added the num the neural network it doubles the number of deletions . yeah , so i do n't you know <laugh> how to interpret that , me either . andand didan other numbers stay the same ? they p stayed the same , did they increase the number of deletions even for the cases that got better ? no . so it 's only the highly mismatched ? now the only thing thatthat bothers me about all this is that iiithethe fact i i it 's sort of bothersome that you 're getting more deletions . so i might maybe look at , is it due to the fact that um , the probability of the silence at the output of the network , is , tootoo high", "summary": "problems: there has been an increase in the number of deletion in the errors , which is of some concern ."}
{"dialogue": "none", "summary": "abstract: icsi 's meeting recorder group met to discuss their progress in various aspects of the aurora project , but also to hear more about other developments relevant to the group ."}
{"dialogue": "yeah . so there was this conference call this morning , and the only topic on the agenda was just to discuss a and to come atuh , to get a decision about this latency problem .", "summary": "abstract: on the aurora project , there were reports on a project conference call , the status of the tandem neural networks , and progress with the mississippi state recognizer ."}
{"dialogue": "uh , yeah . there were like two hours ofdiscussions , and then suddenly , <breath> uh , people were tired , i guess , and they decided on < mike noise > a number , two hundred and twenty , included e including everything . so , currently d uh , we have system that has two hundred and thirty . we have to reduce it by ten milliseconds somehow . that 's not a problem , ii guess . w it 'sit 's p d primaryprimarily determined by the vad at this point , s so we can make the vad a little shorter . yeah . we probably should do that pretty soon so that we do n't get used to it being a certain way . uh , yeah . so , the second thing is the system that we have currently . oh , yes . we have , like , a system that gives sixty - two percent improvement , but <mouth> if you want to stick to the <breath> this latency well , it has a latency of two thirty , but <breath> if you want also to stick to the number <breath> of features thatlimit it to sixty , <breath> then we go a little bit down but it 's still sixty - one percent .", "summary": "abstract: the latency limit has been set , and the group 's system is performing very well , but is a little over ."}
{"dialogue": "um , while we 're still on aurora stuffmaybe you can talk a little about the status with the , uh , <breath> wall street journal <breath> things for it . so i 've , um , downloaded , uh , a couple of things from mississippi state . they wrote some scripts that sort of make it easy to run <breath> the system on the wall street journal , uh , data . um , so i have n't run the scripts yet . uh , i 'm waitingthere was one problem with part of it and i wrote a note to joe asking him about it . so i 'm waiting to hear from him . they 'rei i 'm still waiting for them torelease the , um , <mouth> multi - cpu version of their scripts , cuz right now their script only handles processing on a single cpu , which will take a really long time to run . so , as soon as they get that , then i 'lli 'll grab those too yeah . cuz we have to get started , yeah . i 'll go ahead and try to run it though with just the single cpu one , anditheythey , <breath> um , released like a smaller data set that you can use that only takes like sixteen hours to train and stuff . so i cani can run it on that just to make sure that the <breath> the thing works and everything . so it could bei mean , chuck and i had actually talked about this a couple times , andandover some lunches , i think , <breath> that , um , <mouth> one thing that we might wan na do the - there 's this question about , you know , what do you wan na scale ? suppose y you ca n't adjust <breath> these word insertion penalties and so forth , so you have to do everything at the level of the features . and , uh , one thing i had suggested at an earlier time was maybe some sort of scaling , some sort of root oror something of the , um , <mouth> uh , features . it occurred to me later , because what you really want to do is scale the , uh , @ @ the range of the likelihoods rather than but , i mean , i guess we still have n't had a <breath> a ruling back on this . and we may end up being in a situation where we just you know really ca n't change the <breath> word insertion penalty . but the other thing we could do <breath> isalso we could i mean , thisthis may not help us , <breath> uh , in the evaluation but it might help us in our understanding at least . we might , <breath> just run it with different insper insertion penalties , and show that , uh , `` well , ok , not changing it , <breath> playing the rules the way you wanted , we did this . but in fact if we did that , it made aa big difference . ``", "summary": "abstract: on the larger vocabulary task , there are still a few issues to resolve before work can really get started ."}
{"dialogue": "so michael kleinschmidt , who 's a phd student from germany , <breath> showed up this week . he 'll be here for about six months . and he 's done some work using <breath> an auditory modelof , um , <breath> human hearing , andusing that f uh , to generate speech recognition features . andhe did <breath> work back in germany <breath> with , um , a toy recognition system <breath> using , um , isolated <breath> digit recognition <breath> as the task . he w he 's coming here to u u use it on a <breath> uh , a real speech recognition system . th - this isbecause it 's , umthere are these different parameters for the shape of these <breath> basis functions , <breath> um <breath> there are a lot of different possible basis functions . and so he <breath> he actually does <breath> an optimization procedure to choose an <breath> an optimal set of basis functions out of all the possible ones . is , <breath> um , <mouth> he starts withhe has a set of m of them . i mean , he t he tries , um , <mouth> usingjust m minus one of them . so there are m possible subsets of this <breath> length - m vector . he tries classifying , using each of the m <breath> possible sub - vectors . whichever sub - vector , <breath> um , works thethe best , i guess , he says <breath> thethe fe feature that did n't use was the most useless feature , so we 'll throw it out and we 're gon na randomly select another featurefrom the set of possible basis functions . so i th i think it 'sit 'si think it 's kinda neat stuff . the thing that i wanted toto add to it also was to have us use this in a multi - stream way . soso that , um , <mouth> when you come up with these different things , <breath> and these different functions , <breath> you do n't necessarily just put them all into one huge vector , but perhaps < clears throat > you <breath> have some of them in one stream and some of them in another stream , and so forth . well , that sort of segues intowhatwhat i 'm doing . um , <breath> so , uh , the big picture is k um , <mouth> come up with a set of , <breath> uh , intermediate categories , then build intermediate category classifiers , then do recognition , um , so right now i 'm inin the phase where <breath> i 'm looking atat , um , deciding on a initial set of intermediate categories . and <breath> i 'm looking <breath> for data data - drivenmethods that can help me find , <breath> um , a set of intermediate categories <breath> of speech that , uh , will help me to discriminatelater down the line . and one of the ideas , <breath> um , that was to take atake a neural net traintrain an ordinary neural net <breath> to <breath> uh , to learn the posterior probabilities of phones . um , <mouth> the other onewas , <breath> um , to , <breath> uh , come up with aaa modelum , a graphical model , <breath> that treatsthe intermediate categories <breath> as hiddenhidden variables , latent variables , that we do n't know anything about , but that through , <breath> um , s statistical training and the em algorithm , <breath> um , at the end of the day , <breath> we have , umwe have learned something about thesethese latent , umlatent variables which happen to correspond to <breath> intermediate categories .", "summary": "abstract: the group heard of the plan of one of it 's member 's work into intermediate classifiers , and also of how a visiting research student 's work into auditory models can be applied to their work ."}
{"dialogue": "ho - how much memory d ? h how many ? i d i d uh , ii do n't kn remember exactly , yeah . i 'd like tosee that , cuz maybe i could think a little bit about it , cuz we <mouth> maybe we could make it a little smaller uh , i 'd like to see how far off we are . but i guess it 's still within their rules to havehave it on the , uh , t uh , server side .", "summary": "decisions: speaker me013 wants to know how much memory the tandem network takes up ."}
{"dialogue": "uh , yeah . there were like two hours ofdiscussions , and then suddenly , <breath> uh , people were tired , i guess , and they decided on < mike noise > a number , two hundred and twenty , included e including everything . so , currently d uh , we have system that has two hundred and thirty . we have to reduce it by ten milliseconds somehow . that 's not a problem , ii guess . w it 'sit 's p d primaryprimarily determined by the vad at this point , s so we can make the vad a little shorter . yeah . we probably should do that pretty soon so that we do n't get used to it being a certain way . uh , yeah . so , the second thing is the system that we have currently . oh , yes . we have , like , a system that gives sixty - two percent improvement , but <mouth> if you want to stick to the <breath> this latency well , it has a latency of two thirty , but <breath> if you want also to stick to the number <breath> of features thatlimit it to sixty , <breath> then we go a little bit down but it 's still sixty - one percent .", "summary": "problems: it is only a minor problem that the latency limit has been set below the current systems level , and also keeping the number of features within limits only drops performance a little ."}
{"dialogue": "uh , and if we drop the tandem network , then we have fifty - seven percent . uh , but th the two th two thirty includes the tandem network ? and i is the tandem network , uh , small enough that it will fit on the terminal size uh , no , i do n't think so . it 's stillin terms of computation , if we use , like , their way of computing thethe mapsthethe mips , <breath> i think it fits , but it 's , uh , m mainly a problem of memory . and i do n't know how muchthis can be discussed or not , because it 'sit could be in rom , so it 's maybe not that expensive . ho - how much memory d ? h how many ? i d i d uh , ii do n't kn remember exactly , yeah . i 'd like tosee that , cuz maybe i could think a little bit about it , cuz we <mouth> maybe we could make it a little smaller uh , i 'd like to see how far off we are . but i guess it 's still within their rules to havehave it on the , uh , t uh , server side .", "summary": "problems: a more significant problem is that the tandem approach may not fit in the memory space allowed , and removing it drops performance more ."}
{"dialogue": "yeah . the last thing is that i think we are getting close to human performance . well , that 's something i would like to investigate further , i did , like , umi did , uh , listen to the m most noisy utterances of the speechdat - car italian and tried to transcribe them . so this is a particular human . this isthis i this is stephane . that 's thethe flaw of the experiment . um , but what happens also is that if i listen to the , um <noise> a re - synthesized version of the speech andi re - synthesized this using a white noise that 's filtered by a lpc , uh , filter while our system is currently at seven percent . but still , uh , < breath-laugh > what happens isis that , <mouth> uh , the digit error rate on this is around one percent , well , you can argue , that , uhthat this is not speech , so the ear is not trained to recognize this . but s actually it sound likewhispering , there 's two problems there . i meani mean , soso the first is <breath> that by doing lpc - twelve with synthesized speech w like you 're saying , uh , it 's <breath> i i you 'reyou 're adding other degradation . so it 's not just the noise but you 're adding in fact some degradation because it 's only an approximation . and the second thing iswhich is m maybe more interestingis that , um , <breath> if you do it with whispered speech , you get this number . what if you haddone analysisre - synthesis and taken the pitch as well ? so now you put the pitch in . what would the percentage be then ? see , that 's the question . that would say at least for people , having the pitch is really , really important , i mean , th the thing is lpc is not aa really great representation of speech . uh , but i i do n't know . i do do n't wan na take you away from other things . yeah . i mean , it 's probably not worth your time . it 'sit 's a side thing andandand there 's a lot to do .", "summary": "problems: some of the group had issues with mn007 's approach to human performance testing , but this was considered more of a side issue ."}
{"dialogue": "so what we hadwas that we were gon na talk about data collection , so <outbreath> so the questionthatthat we started with was whether there was anything else we should do duringduring th during the collection . i guess a lot of the stuff we 're doing now really is pilot", "summary": "abstract: the discussion concerned mainly ideas about data collection and the nature and generation of queries on meetings ."}
{"dialogue": "right . i mean , webecause you 'd have several people with these pads , you could collect different things . andso why do n't we just use the notes that somebody takes ? and i guess the crosspads was certainly one idea , so , i j i think we should just say this is notwe do n't want to put any extra burden on people , but if they happen to generate minutes , couldcould they send it to us ? butbut if there 's some cases where they will , then it would be helpful . crosspads we were going to try ,", "summary": "abstract: meeting notes taken by participants as standard minutes or summaries , or on devices like crosspads can provide useful information ."}
{"dialogue": "but i 'm just saying first of all there 's a whole bunch of fusion issues that darpa 's interested in .", "summary": "abstract: there is also interest in the speech community for fusion of speech with visual data ."}
{"dialogue": "i think for this data capture , it would be nice to have a digital camera just to take pictures of who 's there , and then we could also put in what 's on the board . well , minimally , i mean , whatwhat dan is referring to at least having some representation of the p the spatial position of the people , like for a meeting like this , at least , uh , take a polaroid of the <laugh> of theof the boards , a couple digital pictures of thethe table and boards to set the context of the meeting .", "summary": "abstract: taking some photos of the whiteboard and the positioning of participants is easy enough to do ."}
{"dialogue": "and the fir third thing i wanted to say is the summaries afterwards , ie my thought was to have multiple people summarize it , on recording rather than writing you know , a two - minute summary of what the meeting was about , i think you would get , so , my proposal would be that it may be worth considering both of those types , you know , the note - taking and a spontaneous oral summary afterwards , yeah . i think thati think doing it orally at the end of the meeting is the best time . and then the last thing c would be for those people who are willing to stay afterwards and give an oral summary .", "summary": "abstract: another option would be the recording by participants of short oral summaries of the meeting ."}
{"dialogue": "i just do n't know how else to generate the queries other than getting an expert to actually listen to the meeting and say `` that 's important , but if we were asking the question , which i thought we were , ofofof , um , `` how do we figure out what 's the nature of the queries that people are gon na want to ask of such a system ? `` , knowing what 's important does n't tell you what people are going to be asking . now i 'm thinking that the summarya summary , uh , is actually a reasonable , uh , bootstrap into thisinto what we 'd like to get at . the question i had about queries was , um , so what we 're planning to do is have people look at the summaries and then generate queries ? u ii actually think thatthat , uh , again , just as a bootstrap , if we do have something like summaries , then having the people who are involved in the meetings themselves , who are cooperative and willing to do yet more , come up withwithwith queries , uh , could at least givegive landay an idea of the kind of things that people might want to know .", "summary": "abstract: summaries could be used to bootstrap for queries , the exact nature of which remained nebulous ."}
{"dialogue": "andand th i think that might then help me to think of thingseven things that are n't listed in the summary , but just as aas aas a refresh of what the general thing was going on in the meeting . andbut for somenew reason i 'mi 'mi 'm interested ininin the old stuff . you know , if this is something that requires aa one - word answer or it 's one place in the recording versus was there general agreement on this issue of all the people who ha absolutely . so i think we 're gon na have to start with keywords i i was wondering ifif there might be one s more source of queries which is indicator phrases like `` action item `` ,", "summary": "abstract: candidate types are keyword searches , action items , elaboration on points of interest , and agreement between participants ."}
{"dialogue": "iii mean , i guess what i what ii keep coming back to in my own mind is that , um , the soonest we can do it , we need to get up some kind of system ifyou know , ifuh , as soon as we can get that going at any kind of level , then i think we 'll have a much better handle on what kind of questions people want to ask than in anyanything we do before that . well , and again , if we can figure out a way to jimmy aaaa very rough system , say in a year , thenuh , so that in the second and third years wewe actually have something to", "summary": "abstract: an initial prototype system to test any hypotheses can be pipelined ."}
{"dialogue": "and then what they 're gon na do is take the cd - rom and transfer it to analog tape oh , is this ibm ? yeah . and <breath> give it to a transcription service , uh , that will", "summary": "abstract: the recorded data will be stored on cd-rom 's and sent to ibm for transcription ."}
{"dialogue": "different level , prosody and all that sort of stuff . w mymy u feeling right now on format is you guys have been doing all the work", "summary": "abstract: there is also work being done on the annotation of prosody ."}
{"dialogue": "and , i guess we just left it as @ @ thatif there 's found data that can be transformed for use in speech recognition easily , then of course we would do it , but they were recorded anyway , like the congressional hearings and , you know , for legal purposes or whatever . but it includes like standard corpora that have been used for years in linguistics andother fields .", "summary": "abstract: the corpus could be enriched with found data ( public or collected by other projects ) , if those prove appropriate for use in the project ."}
{"dialogue": "to c and i 'll put together an overall cover . people are supposed to send me u r for theirfor web pages , uh , you need to put together a mailing list . we talked about that we 're getting the recording equipment running at uw .", "summary": "abstract: finally , project web pages and mailing list are being set up and uw are going to investigate the suitability of their recording equipment ."}
{"dialogue": "and other tasks during data collection , but if we had the crosspads , we could ask people , you know , ifif something comes up < audible closure > write it down and mark it < audible closure > somehow , so , if you could sense just when people are writing , and you tell them not to doodle , or try not tobe using that for other purposes , and each person has a note pad . they just get it when they come in the room . then you c you can just have a fffplot of wh you know , who 's writing when . but i bet that 'sthat will allow you to go into thesort of the hot places where people are writing things down . so <outbreath> so the questionthatthat we started with was whether there was anything else we should do duringduring th during the collection . and i guess the crosspads was certainly one idea , ok . so crosspads , we 're just gon na try it and see what happens . crosspads we were going to try ,", "summary": "decisions: within the piloting of data collection ideas , it was decided that crosspads are going to be used for detection of `` hot points '' during the meeting ."}
{"dialogue": "and the fir third thing i wanted to say is the summaries afterwards , andso why do n't we just use the notes that somebody takes ? ie my thought was to have multiple people summarize it , on recording rather than writing you know , a two - minute summary of what the meeting was about , i think you would get , so , my proposal would be that it may be worth considering both of those types , you know , the note - taking and a spontaneous oral summary afterwards , so , i j i think we should just say this is notwe do n't want to put any extra burden on people , but if they happen to generate minutes , couldcould they send it to us ? yeah . i think thati think doing it orally at the end of the meeting is the best time . getting electronic summary from a note - taking person if they happen to do it anyway . and then the last thing c would be for those people who are willing to stay afterwards and give an oral summary .", "summary": "decisions: other ideas to be tested are the use of summaries or minutes -if a group normally produce them- and the recording of oral summaries by individual participants after the meeting ."}
{"dialogue": "i think for this data capture , it would be nice to have a digital camera just to take pictures of who 's there , and then we could also put in what 's on the board . well , minimally , i mean , whatwhat dan is referring to at least having some representation of the p the spatial position of the people , like for a meeting like this , at least , uh , take a polaroid of the <laugh> of theof the boards , a couple digital pictures of thethe table and boards to set the context of the meeting .", "summary": "decisions: photographing the contents of the board and the positions of the meeting participants will provide extra information ."}
{"dialogue": "i 'm also wondering if we could ask thethe people aa question which would be `` what was the most interesting thing you got out of this meeting ? `` we 'lli mean , we 'llwe 'll be telling them that the reason we 're trying to do this isis to d generate queries in the future , uh , and then going around the room at the end to just sayqu ask people to mention something interesting that they learned .", "summary": "decisions: for query generation purposes , all participants will also be asked for their highlight of the meeting ."}
{"dialogue": "and , i guess we just left it as @ @ thatif there 's found data that can be transformed for use in speech recognition easily , then of course we would do it ,", "summary": "decisions: the general goal regarding the corpus is to investigate the acquisition of further appropriate data through public sources or available collections of other institutions ."}
{"dialogue": "i do n't think we should have rules of participation , so i 'm just writing here , we 're not gon na try to specify rules of interaction", "summary": "decisions: as to recordings at icsi , the group agreed that imposing rules of participationin order to avoid speaker overlaps was not desirable ."}
{"dialogue": "but i think we should try toget a variety of meetings . that 's something that if we get thethe meeting stuff going at uw , that i probably can do more than you guys , so it also depends on the style of the group of people . but we 're gon na try to get more variety by i using differentgroups of people", "summary": "decisions: instead , they will aim for collecting stylistically varied data ( different group dynamics and types of meeting ) ."}
{"dialogue": "people are supposed to send me u r for theirfor web pages , to c and i 'll put together an overall cover . we talked about that we 're getting the recording equipment running at uw .", "summary": "decisions: further action will also be taken to close other pending issues: the web pages will be organised , the recording room will be finalised and uw will also test their recording infrastructure ."}
{"dialogue": "and , uh , once we get out beyond our little group , the people 's motivation factor , uh , reduces enormously . you 're probably not gon na geta lot of people wanting to do this . thatthat y that you can'tcertainly ca n't require it or people are n't gon na want to do this .", "summary": "problems: the recording of meetings and any possible additional tasks must be set up in a user-friendly way , otherwise it would be difficult to recruit volunteers ."}
{"dialogue": "so , i j i think we should just say this is notwe do n't want to put any extra burden on people , but if they happen to generate minutes , couldcould they send it to us ? yeah . what i was gon na say is that i do n't want to ask people to do something they would n't normally do in a meeting . you 're probably not gon na geta lot of people wanting to do this . thatthat y that you can'tcertainly ca n't require it or people are n't gon na want to do this .", "summary": "problems: asking participants to do more than they normally would in a meeting could put people off ."}
{"dialogue": "but thatit 's gon na be a lot of effort on our part to create it , and store it , i think that if you have that , then people who are interested in vision can use this database . the problem with it is you 'll have more people who do n't want to be filmed than who do n't want to be recorded . but , you know , that 's a lot of infrastructure and work .", "summary": "problems: the video-recording of meetings , apart from adding an extra level of instrumentation complexity , can also make people apprehensive ."}
{"dialogue": "i mean , the down - side to that is that he sort of indicated that the , uh , quality of <outbreath> the handwriting recognition was quite poor .", "summary": "problems: the usability and usefulness of crosspads is not certain ."}
{"dialogue": "but as far as i know they did n't offer that data to the community at this meeting . so there 's lots of recordings that they 're not close - talk mike ,", "summary": "problems: acquiring data from other sources will not be straightforward , as they may either not be suitable for this project or not publicly available ."}
{"dialogue": "i just do n't know how else to generate the queries other than getting an expert to actually listen to the meeting and say `` that 's important , but if we were asking the question , which i thought we were , ofofof , um , `` how do we figure out what 's the nature of the queries that people are gon na want to ask of such a system ? `` , knowing what 's important does n't tell you what people are going to be asking . uh , i would n't have any idea what kind of questions i want to ask .", "summary": "problems: querying is also a major issue: what users would ask from a system is not clear ."}
{"dialogue": "i mean , < long inbreath > < forceful outbreath > the level of the query could be , you know , very low - level or very high - level .", "summary": "problems: how this system would resolve high-level queries ( eg regarding agreement between participants ) is also hard to tell at this stage ."}
{"dialogue": "uh , so do theyhow are they gon na do the multi - channel ?", "summary": "problems: as transcription has not started yet , there was concern as to how ibm will deal with multi-channel data ."}
{"dialogue": "i just wanted to be sure that we will not be having a lot of data which ca n't be processed .", "summary": "problems: the abundance of speaker overlaps may also affect the quality of the trascription ."}
{"dialogue": "so the there will be jargon that we he there 'll be transcription errors .", "summary": "problems: however , it was accepted that some problems with the transcription of jargon are , to an extent , unavoidable ."}
